[{"desc": "If you don't see the perfect job position, just apply to this one - we'll brainstorm to put you in position to do the best work of your life at Hugging Face!\nRequirements\n \nYou're deeply passionate about AI, open source, and democratizing technology\n \nYou've done something awesome \u2014 maybe it's a project, a paper, a startup, or a viral meme with source code. \n \nYou thrive in ambiguity and love shaping your own role\n \nYou're excited to collaborate with one of the most vibrant AI communities in the world\n \nBenefits\n \nA chance to design your dream job at a mission-driven company. \n \nWork with (and learn from) a kind, ambitious, and wildly talented team. \n \nA culture that values openness, experimentation, and fun. \n \nCompetitive salary, equity, unlimited time off, and remote-first flexibility. \n \nThe joy of knowing your work contributes to shaping the open AI movement", "comp": "0", "title": "Wild Card", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4308979019", "loc": "United States", "company": "Hugging Face"}, {"desc": "About The Team\nPost-Training is responsible for training the models to be deployed into ChatGPT, the API, and future products. The team partners closely with research and product teams across the company, and conducts research as a final step to prepare for real world deployment to millions of users, ensuring that our models are safe, efficient, and reliable.\nAbout The Role\nWe are looking for a self-starter full stack engineer who can help us rapidly prototype and develop internal products or tools used by researchers, such as visualization for our evaluation of models. You should be comfortable being truly full stack, such as building front-end from scratch and debugging backend and data pipelines. Ideal candidates are comfortable being scrappy and working independently at fast speeds.\nThis role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nIn This Role, You Will\nRapidly prototype and build tooling or visualization for researchers.\nCollaborate with research teams to build full stack tooling.\nDesign, implement, test, and debug code across our research stack.\nYou Might Thrive In This Role If You\nHave experience building backend infrastructure that is easy to maintain.\nHave experience building products that end users interface with.\nHave experience experience shipping things quickly with competing priorities or deadlines.\nProficiency with JavaScript, React, and other web technologies.\nProficiency with some backend language (we use Python).\nHave mastered multiple programming languages and feel comfortable spinning up new services from scratch.\nAre a team player, willing to do a variety of tasks that move the team forward.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Software Engineer, Full Stack", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4242761480", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe ChatGPT team works across research, engineering, product, and design to bring OpenAI\u2019s technology to the world.\nWe seek to learn from deployment and broadly distribute the benefits of AI, while ensuring that this powerful tool is used responsibly and safely. We aim to make our innovative tools globally accessible, transcending geographic, economic, or platform barriers. Our commitment is to facilitate the use of AI to enhance lives, fostered by rigorous insights into how people use our products.\nAbout The Role\nWe are looking for an experienced fullstack engineer to join our new ChatGPT Growth team to spearhead high-impact projects that amplify the user base of ChatGPT and Plus Subscribers. Your role will include projects such as optimizing account access, notifications, SEO, fostering value discovery, and virality. As we are in the nascent stages of growth at OpenAI, we will rely on you to discover pivotal areas where strategic bets or incremental efforts can catalyze significant impact. We value engineers who are impact-driven, autonomous, adept at discerning crucial insights from experimental results, and have a strong intuition for how to remove barriers to unlocking the magic of ChatGPT.\nIn This Role, You Will\nDrive long-term growth of ChatGPT through a combination of data analysis, product ideation, and experimentation to optimize product experiences.\nPlan and deploy backend APIs necessary to power these product experiences.\nExecute on projects by working closely with research, product, design, data science and other members of product teams to land impact on product goals.\nCreate a diverse and inclusive culture that makes all feel welcome while enabling radical candor and the challenging of group-think.\nYou Might Thrive In This Role If You\nShipped features on web that optimize the user funnel, such as landing pages, product pages, purchase flows, search flows, etc.\nAre highly analytical and have experience designing and implementing A/B tests, with a scientific approach to data-based experiments. You know exactly what and how to track business metrics and KPIs.\nHave a voracious and intrinsic desire to learn and fill in missing skills. An equally strong talent for sharing that information clearly and concisely with others\nAre comfortable with ambiguity and rapidly changing conditions. You view changes as an opportunity to add structure and order when necessary\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $160K - $385K", "comp": "$160,000.00", "title": "Full Stack Software Engineer, Growth", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4307261950", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nPost-Training is responsible for training the models to be deployed into ChatGPT, the API, and future products. The team partners closely with research and product teams across the company, and conducts research as a final step to prepare for real world deployment to millions of users, ensuring that our models are safe, efficient, and reliable.\nAbout The Role\nWe are looking for a self-starter full stack engineer who can help us rapidly prototype and develop internal products or tools used by researchers, such as visualization for our evaluation of models. You should be comfortable being truly full stack, such as building front-end from scratch and debugging backend and data pipelines. Ideal candidates are comfortable being scrappy and working independently at fast speeds.\nThis role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nIn This Role, You Will\nRapidly prototype and build tooling or visualization for researchers.\nCollaborate with research teams to build full stack tooling.\nDesign, implement, test, and debug code across our research stack.\nYou Might Thrive In This Role If You\nHave experience building backend infrastructure that is easy to maintain.\nHave experience building products that end users interface with.\nHave experience experience shipping things quickly with competing priorities or deadlines.\nProficiency with JavaScript, React, and other web technologies.\nProficiency with some backend language (we use Python).\nHave mastered multiple programming languages and feel comfortable spinning up new services from scratch.\nAre a team player, willing to do a variety of tasks that move the team forward.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $255K - $405K", "comp": "$255,000.00", "title": "Full Stack Engineer, Post Training", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4242752317", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nPost-Training is responsible for training the models to be deployed into ChatGPT, the API, and future products. The team partners closely with research and product teams across the company, and conducts research as a final step to prepare for real world deployment to millions of users, ensuring that our models are safe, efficient, and reliable.\nAbout The Role\nWe are looking for a self-starter full stack engineer who can help us rapidly prototype and develop internal products or tools used by researchers, such as visualization for our evaluation of models. You should be comfortable being truly full stack, such as building front-end from scratch and debugging backend and data pipelines. Ideal candidates are comfortable being scrappy and working independently at fast speeds.\nThis role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nIn This Role, You Will\nRapidly prototype and build tooling or visualization for researchers.\nCollaborate with research teams to build full stack tooling.\nDesign, implement, test, and debug code across our stack.\nVery comfortable refactoring codebases\nYou Might Thrive In This Role If You\nStrong background in writing maintainable, testable, clean code.\nEnjoyment of code quality, refactoring, and building robust internal codebases.\nHave experience building products that end users interface with, or building internal tools.\nHave experience experience shipping things quickly with competing priorities or deadlines.\nProficiency with Python\nAre a team player, willing to do a variety of tasks that move the team forward.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Software Engineer, Post-Training Research", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4241258600", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nOpenAI\u2019s Applications Engineering organization builds and operates the products that bring our cutting-edge research to millions of users and developers worldwide. We power products such as ChatGPT, the OpenAI API, and emerging AI-native applications. Our teams span product engineering, infrastructure, and safety, working together to ensure that OpenAI\u2019s technology is delivered with reliability, security, and a world-class user experience.\nAbout The Role\nWe\u2019re looking for frontend engineers to craft the user interfaces that make advanced AI accessible and intuitive. You\u2019ll partner with design, product, and research teams to build responsive, performant, and secure web applications that bring OpenAI\u2019s models to life.\nIn This Role, You Will\nBuild and maintain scalable web applications using modern JavaScript/TypeScript, React, and related technologies.\nCreate reusable UI components and front-end infrastructure to accelerate product development.\nOptimize client performance and ensure accessibility across browsers and devices.\nWork closely with designers to implement intuitive, user-friendly interfaces.\nContribute to end-to-end product planning and decision-making.\nYou Might Thrive In This Role If You\nHave up to 6 years of professional experience building production web applications.\nAre fluent in TypeScript/JavaScript, React, and modern web tooling.\nCare deeply about design fidelity, performance, and accessibility.\nEnjoy iterating quickly to deliver polished, user-focused features.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Software Engineer, Frontend", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4302947449", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe ChatGPT team works across research, engineering, product, and design to bring OpenAI\u2019s technology to the world.\nWe seek to learn from deployment and broadly distribute the benefits of AI, while ensuring that this powerful tool is used responsibly and safely. We aim to make our innovative tools globally accessible, transcending geographic, economic, or platform barriers. Our commitment is to facilitate the use of AI to enhance lives, fostered by rigorous insights into how people use our products.\nAbout The Role\nWe are looking for an experienced backend engineer to join our new ChatGPT Growth team to spearhead high-impact projects that amplify the user base of ChatGPT and Plus Subscribers. Your role will include projects such as optimizing account access, notifications, SEO, fostering value discovery, and virality. As we are in the nascent stages of growth at OpenAI, we will rely on you to discover pivotal areas where strategic bets or incremental efforts can catalyze significant impact. We value engineers who are impact-driven, autonomous, adept at discerning crucial insights from experimental results, and have a strong intuition for how to remove barriers to unlocking the magic of ChatGPT.\nIn This Role, You Will\nDrive long-term growth of ChatGPT through a combination of data analysis, product ideation, and experimentation to optimize product experiences.\nPartner with iOS, Android, and fullstack engineers to \nPlan and deploy backend systems necessary to power these product experiences.\nExecute on projects by working closely with research, product, design, data science and other members of product teams to land impact on product goals.\nCreate a diverse and inclusive culture that makes all feel welcome while enabling radical candor and the challenging of group-think.\nYou Might Thrive In This Role If You\nShipped features to power experiences that optimize the user funnel, such as landing pages, product pages, purchase flows, search flows, etc.\nAre highly analytical and have experience designing and implementing A/B tests, with a scientific approach to data-based experiments. You know exactly what and how to track business metrics and KPIs, and aren\u2019t afraid to dive deep into data to earn the insights.\nHave a voracious and intrinsic desire to learn and fill in missing skills. An equally strong talent for sharing that information clearly and concisely with others\nAre comfortable with ambiguity and rapidly changing conditions. You view changes as an opportunity to add structure and order when necessary\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $160K - $385K", "comp": "$160,000.00", "title": "Backend Software Engineer, Growth", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4307272907", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nWe bring OpenAI's technology to the world through products like ChatGPT and the OpenAI API.\nWe seek to learn from deployment and distribute the benefits of AI, while ensuring that this powerful tool is used responsibly and safely. Safety is more important to us than unfettered growth.\nAbout The Role\nWe are looking for a self-starter engineer who loves building new products in an iterative and fast-moving environment. In this role, you will be bringing our large language models to millions of users around the world. Our users include everyday enthusiasts as well as professionals for ChatGPT, and everyone from hobbyists to large enterprises for the OpenAI API \u2014 you\u2019ll interface directly with users to develop the features they want most! You will also collaborate closely with the research teams that created the core models and work with them on continual improvement. You will be a key part of the effort to push these technologies forward, and onto the next 100x users.\nIn This Role, You Will\nOwn the development of new customer-facing ChatGPT and OpenAI API features and product experiences end-to-end\nTalk to users to understand their problems and design solutions to address them\nWork with the research team to get relevant feedback and iterate on their latest models\nCollaborate with a cross-functional team of engineers, researchers, product managers, designers, and operations folks to create cutting-edge products\nOptimize applications for speed and scale\nYour Background Looks Something Like\n5+ years of relevant engineering experience at tech and product-driven companies\nProficiency with JavaScript, React, and other web technologies\nProficiency with some backend language (we use Python)\nSome experience with relational databases like Postgres/MySQL\nInterest in AI/ML (direct experience not required)\nAbility to move fast in an environment where things are sometimes loosely defined and may have competing priorities or deadlines\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Software Engineer, Full-Stack", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4208436343", "loc": "New York, NY", "company": "OpenAI"}, {"desc": "About The Team\nPost-Training is responsible for training the models to be deployed into ChatGPT, the API, and future products. The team partners closely with research and product teams across the company, and conducts research as a final step to prepare for real world deployment to millions of users, ensuring that our models are safe, efficient, and reliable.\nAbout The Role\nWe are looking for a self-starter full stack engineer who can help us rapidly prototype and develop internal products or tools used by researchers, such as visualization for our evaluation of models. You should be comfortable being truly full stack, such as building front-end from scratch and debugging backend and data pipelines. Ideal candidates are comfortable being scrappy and working independently at fast speeds.\nThis role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nIn This Role, You Will\nRapidly prototype and build tooling or visualization for researchers.\nCollaborate with research teams to build full stack tooling.\nDesign, implement, test, and debug code across our research stack.\nYou Might Thrive In This Role If You\nHave experience building backend infrastructure that is easy to maintain.\nHave experience building products that end users interface with.\nHave experience experience shipping things quickly with competing priorities or deadlines.\nProficiency with JavaScript, React, and other web technologies.\nProficiency with some backend language (we use Python).\nHave mastered multiple programming languages and feel comfortable spinning up new services from scratch.\nAre a team player, willing to do a variety of tasks that move the team forward.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $255K - $405K", "comp": "$255,000.00", "title": "Full Stack Software Engineer, Research Team", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4242754190", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nOpenAI\u2019s mission is to ensure that artificial general intelligence (AGI) benefits all of humanity. A key part of achieving that mission is training models that deeply understand and reflect human preferences \u2014 the \nHuman Data\n team is at the heart of that effort.\nThe Human Data engineering team creates the systems that enable scalable, high-quality human feedback. These systems are essential to how OpenAI trains and improves its most advanced models. Engineers on this team collaborate closely with world-class researchers to bring alignment techniques to life \u2014 from experimental ideas to production-ready feedback loops.\nAbout The Role\nWe\u2019re looking for software engineers to join the Human Data team and build the platforms, prototypes, tools, and infrastructure that power how our AI models are trained, aligned, and evaluated. You\u2019ll partner with researchers and cross-functional teams to bring alignment ideas to life, influence future model training, and shape how models interact with the real world.\nWe\u2019re looking for people who are excited by technical ownership, enjoy working across the stack, and are eager to solve ambiguous problems in a high-impact, fast-paced environment.\nThis role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nIn This Role, You Will\nBuild and maintain robust full-stack systems for feedback collection, data labeling, and evaluation pipelines, while maintaining high levels of security.\nTranslate experimental alignment research into scalable production infrastructure, including inference and model training stacks.\nDesign and iterate on user-facing tools and backend services to support high-quality data workflows\nPartner with researchers, engineers, and program leads to shape feedback loops and model interaction paradigms\nDrive infrastructure improvements that enable faster iteration and scaling across OpenAI\u2019s frontier models, from internal research tooling all the way to production ChatGPT.\nYou Might Thrive In This Role If You\nHave strong software engineering fundamentals and experience building production systems at scale\nEnjoy full-stack development with end-to-end ownership \u2014 from backend pipelines to user interfaces\nAre motivated by high-impact collaboration with research teams and solving novel, ambiguous problems\nAre excited to shape how AI systems learn from human preferences and reflect a broad range of human values\nCare deeply about inclusive tooling and building systems that enhance model safety, reliability, and usefulness\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $255K - $405K", "comp": "$255,000.00", "title": "Software Engineer, Research - Human Data", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4232830096", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nOpenAI\u2019s Applications Engineering organization builds and operates the products that bring our cutting-edge research to millions of users and developers worldwide. We power products such as ChatGPT, the OpenAI API, and emerging AI-native applications. Our teams span product engineering, infrastructure, and safety, working together to ensure that OpenAI\u2019s technology is delivered with reliability, security, and a world-class user experience.\nAbout The Role\nWe\u2019re looking for backend engineers to design and scale the systems that drive our customer-facing products. In this role, you\u2019ll architect and maintain the services and infrastructure that power OpenAI applications\u2014from large-scale distributed systems and databases to APIs and data pipelines. You\u2019ll collaborate closely with product, research, and infrastructure teams to bring new AI capabilities to production while ensuring performance, safety, and compliance at global scale.\nIn This Role, You Will\nDesign and build robust backend services and APIs that power products like ChatGPT and the OpenAI API.\nDevelop scalable data pipelines and storage systems for high-volume, low-latency workloads.\nImprove system reliability, observability, and security across production environments.\nCollaborate with product and research teams to translate cutting-edge AI into dependable, user-ready features.\nParticipate in an on-call rotation to maintain uptime and respond to critical incidents.\nYou Might Thrive In This Role If You\nHave up to 6 years of professional software engineering experience.\nAre proficient in one or more backend languages (e.g., Python, Go, Rust, or similar) and distributed systems concepts.\nEnjoy building infrastructure that supports billions of requests and petabytes of data.\nCare deeply about reliability, safety, and performance in production environments.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Software Engineer, Backend", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4302948403", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Data Visualization team at OpenAI is responsible for building and maintaining all the visualization tools used for analyzing various software and hardware aspects of our custom-built hyperscale supercomputers. This includes visualizing hardware (nodes, network, racks, etc.), monitoring how a user\u2019s job is running on the platform, and assessing the health of the underlying systems. These tools allow us to analyze, improve, and operate the platform for running and training the world\u2019s largest AI models. We work at the cutting edge of speed and scale, combining the traditions of High-Performance Computing (HPC) with a modern cloud and containerized environment.\nOur team is incubated within OpenAI\u2019s Research team, operating at the forefront of AI innovations. The Platform Visualization team complements the existing platform teams that ensure our researchers are minimally impacted by hardware faults. We maximize available supercomputing capacity for researchers and maintain the reliability, scalability, and user-friendliness of job lifecycle management, with an emphasis on efficient job scheduling, quota management, and job execution workflows.\nAbout The Role\nAs a Software Engineer on the Platform Visualization team, you will play a critical role in designing, developing, and maintaining the full-stack visualization tools that are essential for analyzing the software and hardware aspects of OpenAI\u2019s hyperscale supercomputers. Your work will involve creating intuitive front-end interfaces and back-end systems for visualizing hardware components, monitoring training job performance on the platform, and ensuring the health of underlying systems.\nIn this role, you will collaborate closely with other engineering and research teams to gather requirements, understand visualization needs, and deliver full-stack solutions that enhance our ability to analyze, improve, and operate the platform.\nKey Responsibilities\nDevelop and maintain full-stack visualization tools for hardware and software analysis.\nDesign intuitive front-end interfaces and robust back-end systems for monitoring the performance and health of supercomputer systems.\nCollaborate with researchers and engineers to understand their needs and deliver effective full-stack visualization solutions.\nEnsure high performance, reliability, and scalability of visualization tools across both front-end and back-end systems.\nContinuously improve existing tools and develop new features to meet evolving requirements.\nQualifications\nStrong experience in full-stack software development, with a focus on building scientific or infrastructure visualization tools.\nProficiency in both front-end and back-end programming languages such as Python, JavaScript, SQL, or similar.\nFamiliar with front-end technologies like React and back-end technologies like Node.js, and databases like Snowflake.\nExperience with visualization libraries and frameworks (e.g., Plotly, Grafana).\nStrong understanding of full-stack architecture, design principles, and best practices.\nExcellent problem-solving skills and attention to detail.\nStrong communication skills and the ability to work collaboratively in a team environment.\nBonus: Prior experience technically leading a team of 4+ engineers, as this is a 0-1 effort with team growth on the horizon\nBonus if familiar with High-Performance Computing (HPC) environments and modern cloud/container technologies (e.g., Kubernetes, Azure).\nThis role offers the opportunity to work on some of the largest and most advanced AI infrastructure in the world, directly contributing to the success of OpenAI and the advancement of the field of AI. If you are passionate about cutting-edge technology and eager to tackle complex challenges, we would love to hear from you\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $255K - $405K", "comp": "$255,000.00", "title": "Software  Engineer, Data Visualization", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4207339818", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nWe bring OpenAI's technology to the world through products like ChatGPT and the OpenAI API. Our customers build fast-growing businesses around our APIs, which power products that were never before possible. We simultaneously ensure that our powerful tools are used responsibly. Safe deployment is more important to us than unfettered growth.\nThe Engineering team manages a massive fleet of GPUs with scalable, robust infrastructure powered by Kubernetes, Go, Python, Terraform, Kafka, Postgres, and Snowflake.\nAbout The Role\nWe\u2019re looking for experienced and creative engineers to help us scale our existing systems and build the next-generation system to enable a whole new class of products. We are seeking an engineer who is comfortable with full-stack development and has experience with Real-Time Communication (RTC). Candidates should have experience with scaled real-time communication systems in production.\nResponsibilities\nDesign and build development and production platforms that power our systems.\nPartner with researchers, engineers, product managers, and designers to bring new features and research capabilities to the world.\nAccelerate engineering productivity by empowering your fellow engineers with excellent tooling and systems.\nBuild and provide operational support for globally deployed systems, powering some of the most advanced products in the market. This includes participating in an on-call rotation to respond to critical incidents as needed.\nYou Might Thrive In This Role If You\nHave significant experience building (and rebuilding) production systems to deliver new product capabilities and handle increasing scale.\nHave experience with real-time communication products and systems, including audio and video calling, WebRTC or competing protocols, encoding/decoding, signaling, lip sync, etc.\nCare deeply about user experience and take pride in building products that solve customer needs.\nHave a humble attitude, eagerness to help colleagues, and a willingness to do whatever it takes to make the team succeed.\nOwn problems end-to-end and are willing to pick up any necessary knowledge to get the job done.\nHave been a startup founder or an early-stage engineer.\nExperience in Machine Learning techniques is a plus but not required.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Software Engineer, Real Time", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201891599", "loc": "Seattle, WA", "company": "OpenAI"}, {"desc": "About The Team\nThe Compute Runtime team builds the low level framework components to power our ML training systems. We work on building robust, scalable, high performance components to support our distributed training workloads. Our priorities are to maximize the productivity of our researchers and our hardware, with the goal of accelerating progress towards AGI.\nAbout The Role\nAs a Distributed Systems engineer, you will work to deliver powerful APIs orchestrating thousands of computers moving and persisting vast amounts of data. This requires both providing easy to use, introspectable systems that can promote a fast debugging and development cycle, while also enabling that experience to scale to our newest supercomputers maintaining stability and performance throughout.\nWe\u2019re looking for people who love optimizing an end to end system, understanding high performance I/O to maximize local performance and distributed across our supercomputers. We want someone excited by the rapid pace of responding to the dynamic and evolving needs of our training systems architectures.\nThis role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nIn This Role, You Will\nWork across our Python and Rust stack\nProfile and optimize and help design for scale our compute and data capabilities\nWork on deploying our training framework to our latest supercomputers rapidly responding to the changing shapes and needs of the ML systems.\nYou Might Thrive In This Role If You\nHave worked on large distributed systems\nLove figuring out how systems work and continuously come up with ideas for how to make them faster while minimizing complexity and maintenance burden\nHave strong software engineering skills and are proficient in Python and Rust or equivalent.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $250K - $460K", "comp": "$250,000.00", "title": "Software Engineer, Distributed Systems", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4290325458", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Scaling team designs, builds, and operates critical infrastructure that enables research at OpenAI.\nOur mission is simple: accelerate the progress of research towards AGI. We do this by building core systems that researchers rely on - ranging from low-level infrastructure components to research-facing custom applications. These systems must scale with the increasing complexity and size of our workloads, while remaining reliable and easy to use.\nAbout The Role\nAs we grow, we\u2019re looking for a pragmatic and versatile software engineer who thrives in fast-moving environments and enjoys building systems that empower others.\nThis is a generalist software engineering role with an emphasis on distributed systems, data processing infrastructure, and operational excellence. You\u2019ll develop and operate foundational backend services that power key OpenAI\u2019s research workflows - both by creating new infrastructure and by building on existing systems. The use cases will span across observability, analytics, performance engineering, and other domains, all with the goal of solving meaningful and impactful problems to research.\nThis role is based in San Francisco, CA or open to being remote within the US. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nIn This Role, You Will\nDesign, build, and operate scalable backend systems that support various ML research workflows, including observability and analytics.\nDevelop reliable infrastructure that supports both streaming and batch data processing at scale.\nCreating internal-facing tools and applications as needed.\nDebug and improve performance of services running on Kubernetes, including operational tooling and observability.\nCollaborate with engineers and researchers to deliver reliable systems that meet real-world needs in production.\nHelp improve system reliability by participating in the on-call rotation and responding to critical incidents. \nYou Might Thrive In This Role If You Have\nStrong proficiency in Python/Rust and backend software development, ideally in large codebases.\nExperience with distributed systems and scalable data processing infrastructure, including technologies like Kafka, Spark, Trino/Presto, Iceberg.\nHands-on experience operating services in Kubernetes, with familiarity in tools like Terraform and Helm.\nComfort working across the stack - from low-level infrastructure components to application logic - and making trade-offs to move quickly.\nA focus on building systems that are both technically sound and easy for others to use.\nCuriosity and adaptability in fast-changing environments, especially in high-growth orgs.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Software Engineer, Infrastructure - Analytics", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201247553", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Sora team is pioneering multimodal capabilities for OpenAI\u2019s foundation models. We\u2019re a hybrid research and product team focused on integrating multimodal functionalities into our AI products, ensuring they are reliable, user-friendly, and aligned with our mission of broad societal benefit.\nAbout The Role\nAs a Software Engineer, Distributed Data Systems, you will design and scale the infrastructure that powers large-scale multimodal training and evaluation at OpenAI. You\u2019ll manage distributed data pipelines, collaborate closely with researchers to translate requirements into robust systems, and harden pipelines that serve as the backbone for Sora\u2019s rapid iteration cycles.\nWe\u2019re looking for engineers who are detail-oriented, have strong experience with distributed systems, and excel at building reliable infrastructure in high-stakes environments.\nThis role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nIn This Role, You Will\nDesign, build, and maintain data infrastructure systems such as distributed compute, data orchestration, distributed storage, streaming infrastructure, machine learning infrastructure while ensuring scalability, reliability, and security.\nEnsure our data platform can scale by orders of magnitude while remaining reliable and efficient\nPartner with researchers to deeply understand requirements and translate them into production-ready systems.\nHarden, optimize, and maintain critical data infrastructure systems that power multimodal training and evaluation.\nYou Might Thrive In This Role If You\nHave strong experience with distributed systems and large-scale infrastructure with a strong interest in data.\nAre detail-oriented and bring rigor to building and maintaining reliable systems.\nDemonstrate excellent software engineering fundamentals and organizational skills.\nAre comfortable with ambiguity and rapid change\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $255K", "comp": "0", "title": "Software Engineer, Distributed Data Systems", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4295714561", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Sora team is pioneering multimodal capabilities for OpenAI\u2019s foundation models. We\u2019re a hybrid research and product team focused on integrating multimodal functionalities into our AI products, ensuring they are reliable, user-friendly, and aligned with our mission of broad societal benefit.\nAbout The Role\nWe are seeking an experienced Full Stack Engineer to drive the development of our multimodal product features. In this role, you will collaborate closely with product managers, designers, researchers, and fellow engineers to translate cutting-edge research into scalable, impactful products.\nAs we explore new frontiers in video-enabled AI and other modalities, you will build end-to-end solutions that define our product strategy and lay the foundations for these initiatives. We value engineers who take initiative, demonstrate strong product instincts, and maintain a user-centric focus throughout their work.\nIn This Role, You Will\nDesign and develop robust, user-centric front-end interfaces and scalable back-end systems for innovative multimodal product features.\nCollaborate cross-functionally to translate user needs and research insights into comprehensive product solutions. Integrate advanced video and multimodal capabilities seamlessly into our existing products.\nContribute to defining technical roadmaps, architectural decisions, and product strategy.\nYou Might Thrive In This Role If You\nHave 6+ years of industry experience as a Full Stack Engineer, with a proven track record of shipping impactful, user-focused products.\nExcel in dynamic environments, quickly adapting and turning complex requirements into elegant, practical solutions.\nAre proactive, eager to learn new technologies, and enthusiastic about sharing insights and mentoring team members.\nHave experience with modern front-end frameworks (React, Angular, Vue) and back-end systems (Python, Node.js, Go, Ruby).\nBonus: Have experience developing video-based products or infrastructure, which will be valuable as our product scales.\nThis role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Full Stack Engineer, Sora", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201248547", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nOpenAI Labs explores the edges of what\u2019s possible with AI. We start from the latest breakthroughs \u2013 or overlooked research with untapped potential \u2013 and expand their capabilities by prototyping entirely new ways for people to benefit from AI.\nAbout The Role\nAs a Full-Stack Software Engineer on the Labs team, you will create new ways for people to interact with AI.\nYour work will begin as rapid internal experiments: prototypes built to explore surprising capabilities or novel interfaces. Some will spark entirely new products or research directions, shaping how millions of people experience AI. Across projects, you\u2019ll ship these ideas internally, learn from how people use them, and \u2013 if they prove promising \u2013 hand them off to product teams to take forward before moving on to the next frontier.\nSometimes you\u2019ll start by playing with a researcher\u2019s early demo, identify emerging behaviors, and push on them in collaboration with researchers. Other times, you\u2019ll start from a capability that hasn\u2019t yet been fully explored and design a novel interface around it.\nWe\u2019re looking for creative people who love to tinker and explore, chasing sparks of magic and shaping them into experiences that help the world go further and discover new possibilities.\nLocation\nThis role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nIn This Role, You Will\nExplore emerging capabilities and collaborate with researchers to uncover surprising new behaviors \u2013 whether from the model itself or from how people respond \u2013 and push their limits through creative experimentation.\nDesign and prototype new interfaces and interaction patterns that rethink how people experience AI, making powerful capabilities feel intuitive, delightful, and inspiring.\nBring ideas to life quickly, turning concepts into working demos \u2013 and evolving those prototypes into robust, testable experiences ready for real-world feedback.\nShip early, learn from real usage, and iterate fast \u2013 refining ideas based on how people actually use them.\nHand off the most promising prototypes to product teams to scale before moving on to the next frontier.\nYou Might Thrive In This Role If You\nHave demonstrated experience building and shipping full-stack applications, from intuitive interfaces to reliable backend systems.\nBuild things for fun and care deeply about craft: curiosity drives you, and creating is how you explore ideas.\nAre energized by ambiguity and excited to turn novel capabilities into tangible, working experiences.\nHave a refined product taste and intuition for what great interactions should feel like.\nCare about how ideas work in people\u2019s hands and evolve through real use.\nValue iteration as much as invention; refining is part of the creative process.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $255K - $325K", "comp": "$255,000.00", "title": "Full-Stack Software Engineer, Frontier Exploration", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4309292995", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nAt OpenAI, we\u2019re building the connective tissue between our mission and our people. People Innovation Labs is a fast-moving engineering team embedded in the People organization, focused on rethinking how we find and retain the best talent and empower everyone to do their best work. From recruiting to culture, we\u2019re designing systems that give our People Team a significant edge by infusing OpenAI\u2019s models and first-principles thinking into every aspect of our work. Our projects range from greenfield 0-1 products like OpenHouse (our internal knowledge hub) to AI-powered automations and scalable recruiting tools. We\u2019re defining the future of work at OpenAI, creating a blueprint for how AI can supercharge productivity, culture, and innovation.\nAbout The Role\nWe are looking for a self-starter engineer who loves building new products in an iterative and fast-moving environment. This team is for full stack product engineers who are deeply curious about culture, recruiting and people development, and want to know everything from the business strategy and metrics down through the code that gets us there. In this role, you will work with members of the People Team and leaders across the company to build software focused on HR, culture and recruiting from the ground up. You\u2019ll also innovate on how we apply LLMs in these domains.\nIn This Role, You Will\nOwn the full product development lifecycle for new people products end-to-end\nTalk to internal stakeholders to understand their problems and design solutions to address them\nWork with the research team to share relevant feedback and iterate on applying their latest models\nCollaborate with a cross-functional team of engineers, HRBPs, recruiters, researchers, product managers, designers, and people in operations to create cutting-edge products\nYour Background Might Look Something Like\n4+ years of professional engineering experience (excluding internships) in relevant roles at tech and product-driven companies\nFormer founder, or early engineer at a startup who built a product from scratch is a plus\nInterest in building company culture and/or recruiting the world\u2019s most talented people\nProficiency with JavaScript, React, and other web technologies\nProficiency with a backend language (we use Python)\nSome experience with relational databases like Postgres/MySQL\nInterest in AI/ML (direct experience not required)\nAbility to move quickly in an environment with loosely defined tasks and competing priorities or deadlines\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Software Engineer, Full Stack (People Innovation)", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4268919673", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Data Visualization team at OpenAI is responsible for building and maintaining all the visualization tools used for analyzing various software and hardware aspects of our custom-built hyperscale supercomputers. This includes visualizing hardware (nodes, network, racks, etc.), monitoring how a user\u2019s job is running on the platform, and assessing the health of the underlying systems. These tools allow us to analyze, improve, and operate the platform for running and training the world\u2019s largest AI models. We work at the cutting edge of speed and scale, combining the traditions of High-Performance Computing (HPC) with a modern cloud and containerized environment.\nOur team is incubated within OpenAI\u2019s Research team, operating at the forefront of AI innovations. The Platform Visualization team complements the existing platform teams that ensure our researchers are minimally impacted by hardware faults. We maximize available supercomputing capacity for researchers and maintain the reliability, scalability, and user-friendliness of job lifecycle management, with an emphasis on efficient job scheduling, quota management, and job execution workflows.\nAbout The Role\nAs a Software Engineer on the Platform Visualization team, you will play a critical role in designing, developing, and maintaining the full-stack visualization tools that are essential for analyzing the software and hardware aspects of OpenAI\u2019s hyperscale supercomputers. Your work will involve creating intuitive front-end interfaces and back-end systems for visualizing hardware components, monitoring training job performance on the platform, and ensuring the health of underlying systems.\nIn this role, you will collaborate closely with other engineering and research teams to gather requirements, understand visualization needs, and deliver full-stack solutions that enhance our ability to analyze, improve, and operate the platform.\nKey Responsibilities\nDevelop and maintain full-stack visualization tools for hardware and software analysis.\nDesign intuitive front-end interfaces and robust back-end systems for monitoring the performance and health of supercomputer systems.\nCollaborate with researchers and engineers to understand their needs and deliver effective full-stack visualization solutions.\nEnsure high performance, reliability, and scalability of visualization tools across both front-end and back-end systems.\nContinuously improve existing tools and develop new features to meet evolving requirements.\nQualifications\nStrong experience in full-stack software development, with a focus on building scientific or infrastructure visualization tools.\nProficiency in both front-end and back-end programming languages such as Python, JavaScript, SQL, or similar.\nFamiliar with front-end technologies like React and back-end technologies like Node.js, and databases like Snowflake.\nExperience with visualization libraries and frameworks (e.g., Plotly, Grafana).\nStrong understanding of full-stack architecture, design principles, and best practices.\nExcellent problem-solving skills and attention to detail.\nStrong communication skills and the ability to work collaboratively in a team environment.\nBonus: Prior experience technically leading a team of 4+ engineers, as this is a 0-1 effort with team growth on the horizon\nBonus if familiar with High-Performance Computing (HPC) environments and modern cloud/container technologies (e.g., Kubernetes, Azure).\nThis role offers the opportunity to work on some of the largest and most advanced AI infrastructure in the world, directly contributing to the success of OpenAI and the advancement of the field of AI. If you are passionate about cutting-edge technology and eager to tackle complex challenges, we would love to hear from you\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Software Engineer, Data Visualization", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201251239", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Core Services team is responsible for building and managing foundational services. It acts as the bridge between core infrastructure (e.g. compute, storage, networking) and product engineering teams, and enables product teams to move fast, build reliably, and scale efficiently.\nAbout The Role\nAs a software engineer in the core services team, you will design and operate critical backend platforms such as caching systems, workflow orchestration, metadata stores, and file services. You\u2019ll focus on building highly reliable, scalable, and performant systems that serve as the backbone of our products.\nWe\u2019re looking for people who are passionate about building infrastructure that empowers product teams, love working on distributed systems challenges, and enjoy creating well-designed APIs and abstractions that accelerate development.\nThis role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nIn This Role, You Will\nDesign, build, and maintain shared infrastructure services such as caching layers, workflow orchestration (Temporal), metadata stores, and file storage services.\nCollaborate with product teams to provide scalable, reliable primitives that abstract the complexities of distributed systems.\nImprove performance, resilience, and scalability of core services that power customer-facing applications.\nYou Might Thrive In This Role If You\nHave experience with distributed systems, caching infrastructure (e.g., Redis, Memcached), metadata storage (e.g., FoundationDB), or workflow orchestration (e.g., Temporal, Cadence).\nHave experience running containerized services in cloud environments and integrating them into automated build/test/release (CI/CD) workflows.\nUnderstand trade-offs in consistency models, replication strategies, and performance optimization in multi-region systems.\nExcel at communication and collaboration with cross-functional teams, and are obsessed with delivering customer success.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Software Engineer, Core Services", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4267815605", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Knowledge Innovation team is scaling OpenAI with OpenAI. We are building an AI powered knowledge system that evolves and learns as our products, systems and customers evolve. We leverage our state of the art models, technologies, and products (some external, some still in the lab) to assist or completely automate robust operations supporting both internal and external customers. We support OpenAI customers and internal partners globally, powering systems from customer support to integrity to product insights. We are a self-contained multi-disciplinary team, who enjoy a lightning fast feedback loop with customers at scale, some of whom sit just a few pods away. We iterate fast, and engineer for reliable long-term impact. We're constantly looking for the similarities and patterns in different types of work, and focus on building simple primitives, to apply world class knowledge to many domains.\nThe work of this team exemplifies use of OpenAI technologies. We build systems so everyone can see the leverage that is possible with well designed AI-based implementations. We do this by working through internal use cases focused on Customers (specifically knowledge systems, automation systems, and automated agent systems) to prove impact, then we scale.\nAbout The Role\nWe\u2019re looking for \nFull Stack Engineers\n who're passionate about blending production-ready platform architecture with new tech and new paradigms. You\u2019ll push the boundaries of OpenAI\u2019s newest technologies to enable interactions and automations that are not only functional, but delightful. We value proactive, customer-centric engineers who can get the foundational details right (data models, architecture, security) in service of enabling great products.\nIn This Role, You Will\nOwn the end-to-end development lifecycle for new platform capabilities and integrations with other systems\nCollaborate closely with engineers, data scientists, information systems architects, and internal customers to understand their problems and implement effective solutions\nWork with product and research team to share relevant feedback and iterate on applying their latest models\nYour Background Might Look Something Like\n4+ years of professional engineering experience (excluding internships) in relevant roles at tech and product-driven companies\nFormer founder, or early engineer at a startup who has built a product from scratch is a plus\nProficiency with JavaScript, React, and other web technologies\nProficiency with a backend language (we use Python)\nSome experience with relational databases like Postgres/MySQL\nInterest in AI/ML (direct experience not required)\nProven ability to thrive in fast-growing, product-driven companies by effectively navigating loosely defined tasks and managing competing priorities or deadlines.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Software Engineer, Full Stack (Knowledge Innovation)", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201892639", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nOur team brings OpenAI\u2019s most capable technology to the world through our developer platform: the OpenAI API. As the leading AI development platform, our API is used by millions of developers and the majority of enterprises around the world, and powers the majority of AI applications that you may use on a daily basis. Most recently, we\u2019ve released gpt-5, gpt-realtime, Responses API, Agents SDK, and many other products and features.\nAbout The Role\nWe are looking for a software engineer to own the design of our APIs. Our API \nis\n our product, and as such we treat its design and development with care and intentionality. Every endpoint, every field name, and every enum value is a product interface that we want to design well. We are looking for engineers who not only love building APIs, but who will also sweat the details around API design and have a discerning taste for well designed API experience. You will play a major role in shaping the future roadmap of the OpenAI API \u2013 by both building and designing it.\nIn This Role, You Will\nDesign and build products that we launch in API \u2013 extending existing endpoints, adding new endpoints, or rethinking our entire API suite.\nPlay a major role in our API Review process \u2013 working with all other teams to ensure our APIs meet our design standard.\nCollaborate closely with the rest of the API team, our Developer Experience team, and our GTM team to make our APIs the best in the world.\nYou Might Thrive In This Role If You\nAppreciate taste in API design \u2013 you believe there are well designed APIs and poorly designed APIs\nCan thrive and operate independently in a fast-paced environment with ambiguous requirements and goals\nLove building for other developers, and thrive on feedback from opinionated users\nAre an engineer at heart, but are willing to lean into product decisions.\nThink of APIs as ladders.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $255K - $405K", "comp": "$255,000.00", "title": "Software Engineer - API Designer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4309503199", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nStorage Infrastructure provides APIs for data access, placement, and lifecycle management, while ensuring that the storage systems\u2019 capacity, throughput, and IOPs satisfy the needs of our AI researchers. Scalability, reliability, security, and usability are the core concerns of the team.\nAbout The Role\nAs an engineer on the Storage Infrastructure team, you will design, build, and operate Exascale systems to scalably and reliably manage our research data across multiple regions.\nWe\u2019re looking for distributed systems engineers who have worked on exascale data management systems or distributed filesystems.\nIn This Role, You Will\nDevelop software to manage exascale data, and make it accessible to researchers\nDrive the reliability, predictability, and cost effectiveness of our storage systems\nInterface with researchers to understand and accommodate data use-cases\nEnsure the security of our critical datasets\nYou Might Thrive In This Role If You\nHave a deep understanding of distributed systems principles and a proven track record in designing and building scalable, reliable, and secure storage solutions.\nPossess strong programming skills\nHave experience working in public clouds (especially Azure)\nAre familiar with AI/ML data access patterns\nBias for action and comfort building in a fast paced, dynamic environment\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Software Engineer, Compute - Storage", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201888974", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Payments Team is working to make AGI financially sustainable by enabling OpenAI to accept payments across our existing products (ChatGPT, ChatGPT for Teams, API) and supporting future commercial experiences. We own the user-facing payments experience, direct integrations with payment service providers, and other supporting infrastructure that powers checkout and payment flows. Payments works closely with teams across Finance, Legal, Growth, Product, external vendors and more to ensure our payments infrastructure scales with the business and supports evolving commercial goals.\nAbout The Role\nAs a Software Engineer on the Payments Team, you will play a pivotal role in shaping the infrastructure that powers OpenAI\u2019s financial systems. You\u2019ll design and build core payments systems, partner with cross-functional teams to deliver scalable solutions, and ensure that our financial systems support rapid product iteration and global reach. We\u2019re looking for people who are pragmatic, collaborative, and energized by the opportunity to build systems that are foundational to OpenAI\u2019s long-term mission and sustainability.\nThis role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nIn This Role, You Will\nArchitect, implement and scale core payment infrastructure.\nBuild robust and extensible financial primitives to enable rapid iteration and support hyper-growth.\nCollaborate closely with internal and external stakeholders (e.g. Finance, GTM, Product, etc) to translate business requirements into clean, scalable technical systems.\nDemonstrate high levels of ownership to get changes shipped in the highly-regulated domain of payments.\nCreate a seamless user experience for checkout around the world.\nImprove the reliability, observability and auditability of money movement at OpenAI.\nYou Might Thrive In This Role If You\nHave 5+ years of professional experience in software engineering, ideally with a focus on payments or financial systems at scale.\nAre familiar with payment processors (e.g., Stripe, Adyen, Braintree) or have built similar internal financial systems, e.g. storing cardholder data, pricing, online commerce, etc.\nBring a strong product mindset and a desire to deeply understand product needs and design for long-term flexibility.\nThrive in high-growth, ambiguous environments, and can balance fast execution with technical rigor and system reliability.\nExcellent communication skills, with ability to build consensus among stakeholders both internally and externally.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Software Engineer, Payments", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4254103546", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nFull Stack engineers within the Fleet Scheduling team are dedicated to building intuitive and scalable interfaces that empower researchers to efficiently manage AI workloads across some of the largest supercomputers in the world. Our focus is on developing robust, high-performance systems that provide real-time insights, resource tracking, and seamless interaction with complex infrastructure. We aim to optimize resource allocation, minimize operational overhead, and create user-friendly tools that enhance researcher productivity and system transparency.\nAbout The Role\nYou will design, develop, and operate web-based systems that provide a powerful and intuitive interface to OpenAI\u2019s supercomputing clusters. You will collaborate closely with researcher, product and infrastructure teams to deliver scalable solutions that enable seamless monitoring, job scheduling, and resource management. This is an opportunity to work at the cutting edge of AI infrastructure, designing tools that scale to exascale workloads while maintaining usability and performance.\nThis role is based in \nSan Francisco, CA.\n We use a hybrid work model of \n3 days in the office per week\n and offer relocation assistance to new employees.\nIn This Role, You Will\nDesign and develop full-stack web applications to track, monitor, and manage large-scale AI workloads in real time.\nCollaborate with researchers and infrastructure teams to translate complex operational needs into intuitive UIs and scalable backends.\nBuild data visualization tools (e.g., Gantt charts, dashboards) to provide insights into job scheduling and resource allocation.\nOptimize backend services to handle massive data throughput while ensuring low-latency performance and high availability.\nImplement frontend components that provide seamless interactions with scheduling, storage, and compute systems.\nEnsure system security, reliability, and scalability across globally distributed supercomputing infrastructure.\nYou Might Thrive In This Role If You\nSignificant experience in full-stack development, with expertise in modern frontend frameworks (React, Vue, or Angular) and backend technologies (Python, Go, or Node.js).\nExperienced in building scalable, high-performance web applications for complex distributed systems.\nStrong understanding of RESTful and GraphQL APIs, distributed databases, and cloud infrastructure (especially Azure).\nExecution-focused with a keen eye for usability, performance, and scalability in enterprise-scale systems.\nComfortable working in fast-paced, highly collaborative environments with tight timelines and evolving priorities.\nBonus Points If You\nHave experience working with Kubernetes, Docker, and cloud-native application deployment.\nUnderstand AI/ML workload scheduling and orchestration challenges.\nHave experience with real-time data processing, visualization libraries, and observability tooling.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Full Stack Engineer, Fleet Scheduling", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201250320", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Search team grounds and empowers AI with real-time information and clear references. We are reimagining the search tech stack and user experience from the ground up for the AI era. We are seeking talented senior engineers to help build our search infrastructure from the ground up to enable our users to have an optimized search experience.\nAbout The Role\nIn this role, you will help build a next-gen information retrieval stack optimized for an LLM to use. You will be responsible for designing, building, and maintaining the infrastructure that powers our search capabilities. This role will work closely with cross-functional teams to ensure the performance, scalability, and reliability of our search systems, enabling our users to access information quickly and accurately.\nThis role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nIn This Role, You Will\nDesign, develop, and maintain scalable search infrastructure to support large-scale data processing and retrieval.\nOptimize search algorithms and indexing processes to improve search relevance and performance.\nWork with a small, senior team of engineers and researchers to combine existing best practices with innovative approaches based on modern deep learning to develop industry-leading systems \nYou Might Thrive In This Role If You\nHave significant experience building, scaling, and optimizing search systems at scale\nExperience building highly scalable systems from scratch\nHave a voracious and intrinsic desire to learn and fill in missing skills, and an equally strong talent for sharing that information clearly and concisely with others\nExpertise in C++ is required\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Software Engineer, Search Infrastructure", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201891591", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Model Behavior team shapes how our models interact with people. We view the model as the product itself, aiming to create intuitive experiences that exceed user expectations and feel like magic.\nThe team partners closely with research and product teams across the company to improve the real-world usefulness of our models at scale. Our work directly impacts hundreds of millions of users globally and contributes to OpenAI's mission of broadly distributing safe AI.\nAbout The Role\nWe are looking for an engineer with experience in evaluation systems, observability, and data pipelines. You will design and build systems to understand (1) how users engage with our models, (2) identify where our models fall short, and (3) design/develop fundamental, launch blocking, evals for model behavior. This includes:\nStanding up robust evaluations (automated evals, human evals, product metrics, query sets).\nDeveloping tooling, dashboards, and visualizations to measure and track model behavior improvements.\nBuilding interfaces and pipelines for human raters, autoraters, and hybrid workflows.\nCapturing online signals (A/B tests, usage telemetry) and reconciling them with offline metrics.\nPrototyping fast and iterating with research, product, and safety partners under tight timelines.\nThis role spans evaluation design, data pipelines, and cross-functional collaboration. You should thrive in ambiguous, scrappy environments and care deeply about measurement quality and user experience.\nThis role is based in San Francisco, CA. We use a hybrid model (3 days in office/week) and offer relocation support.\nIn This Role, You Will\nBuild evaluation systems to measure core dimensions at scale and identify new areas for improvement\nDesign pipelines for collecting and validating high-quality human data.\nBuild a robust data-flywheel to quickly launch evals on user signals\nDevelop robust evaluations to define and track improvements in model behavior\nRapidly prototype and develop tooling, dashboards, and visualizations for researchers and applied teams\nDevelop and integrate autorater models into the eval loop.\nPrototype dashboards and interfaces that surface eval results to researchers and applied teams to support launch decisions.\nDebug contradictions between offline and online metrics, and drive experiments to resolve them.\nCollaborate across research, safety, infrastructure, and product teams to deliver solutions that improve model efficiency and user experience\nOwn and support experiments that validate hypotheses around model behavior\nYou Might Thrive In This Role If You\nHave built evaluations for capability and model improvements\nHave experience building and maintaining observability tooling\nEnjoy owning 0\u21921 user-facing products or tools, ideally in a startup or fast-moving environment\nShip quickly under competing priorities and tight deadlines\nUnderstand how evaluations work and are curious about model training and iteration\nCare about product polish and usability\nCollaborate effectively across teams and take on diverse tasks to move work forward\nAre a team player, willing to do a variety of tasks that move the team forward\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $255K - $405K", "comp": "$255,000.00", "title": "Software Engineer, Model Behavior", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4278854970", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Youth Well-Being product team is part of the Integrity pillar at OpenAI, responsible for ensuring that our state-of-the-art AI technologies are deployed in safe, age-appropriate, and beneficial ways\u2014especially for youth and families.\nWe work across OpenAI\u2019s entire product surface area, from ChatGPT to future-facing tools, to architect safety and trust into the foundation of our systems. Our mission: empower families while meeting the highest standards of regulatory compliance and ethical responsibility.\nThis work is core to OpenAI\u2019s mission to ensure AGI benefits all of humanity. Safety, especially for the most vulnerable users, is more important to us than unfettered growth.\nAbout The Role\nWe\u2019re looking for a Senior Software Engineer to help architect and build the foundational systems that power family- and youth-facing experiences at scale. You\u2019ll help define how teens and guardians engage with OpenAI products\u2014ensuring those experiences are safe, compliant, and empowering.\nYou\u2019ll operate across a broad technical surface: building identity primitives, age assurance pipelines, and guardian tools that support both proactive and reactive interventions. You\u2019ll collaborate closely with a cross-functional team of engineers, data scientists, designers, user researchers, and policy experts.\nThis is a high-impact, 0\u21921 opportunity to set the standard for how families interact with generative AI.\nIn This Role, You Will\nArchitect and implement teen and guardian experiences across OpenAI products, including ChatGPT.\nBuild global age assurance systems that are privacy-preserving and tailored to regional compliance needs.\nDesign and evolve our identity infrastructure to support scalable, secure, and resilient user journeys at consumer internet scale.\nHelp define safety and well-being metrics, and continuously improve user trust through technical interventions.\nYou Might Thrive In This Role If You\nHave built products or infrastructure for users under 18, or have a strong interest in digital safety, youth well-being, or educational technology.\nHave hands-on experience with identity platforms, auth/authz systems, or user verification at scale.\nHave worked on systems with regulatory complexity (e.g., COPPA, GDPR-K, UK OSA, KOSA) or experience navigating legal constraints in product development.\nAre comfortable owning complex, ambiguous problems end-to-end, learning quickly, and adapting to fast-changing priorities. Can thrive in a cross-functional team, with strong collaboration across policy, research, legal, and product functions.\nCare deeply about building systems that are not just performant, but also inclusive, thoughtful, and ethical.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $255K - $405K", "comp": "$255,000.00", "title": "Software Engineer, Youth Well-Being", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4246012589", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Kernels team at OpenAI builds the low-level software that accelerates our most ambitious AI research.\nWe work at the boundary of hardware and software, developing high-performance kernels, distributed system optimizations, and runtime improvements to make large-scale training and inference more efficient.\nOur work enables OpenAI to push the limits by ensuring models - from LLMs to recommender systems - to run reliably on advanced supercomputing platforms. That includes adapting our software stack to new types of accelerators, tuning system performance end-to-end, and removing bottlenecks across every layer of the stack.\nAbout The Role\nOn the Accelerators team, you will help OpenAI evaluate and bring up new compute platforms that can support large-scale AI training and inference.\nYour work will range from prototyping system software on new accelerators to enabling performance optimizations across our AI workloads.\nYou\u2019ll work across the stack, collaborating with both hardware and software aspects - working on kernels, sharding strategies, scaling across distributed systems, and performance modeling.\nYou'll help adapt OpenAI's software stack to non-traditional hardware and drive efficiency improvements in core AI workloads. This is not a compiler-focused role, rather bridging ML algorithms with system performance - especially at scale.\nIn This Role, You Will\nPrototype and enable OpenAI's AI software stack on new, exploratory accelerator platforms.\nOptimize large-scale model performance (LLMs, recommender systems, distributed AI workloads) for diverse hardware environments.\nDevelop kernels, sharding mechanisms, and system scaling strategies tailored to emerging accelerators.\nCollaborate on optimizations at the model code level (e.g. PyTorch) and below to enhance performance on non-traditional hardware. Perform system-level performance modeling, debug bottlenecks, and drive end-to-end optimization.\nWork with hardware teams and vendors to evaluate alternatives to existing platforms and adapt the software stack to their architectures.\nContribute to runtime improvements, compute/communication overlapping, and scaling efforts for frontier AI workloads.\nYou Might Thrive In This Role If You Have\n3+ years of experience working on AI infrastructure, including kernels, systems, or hardware-software co-design\nHands-on experience with accelerator platforms for AI at data center scale (e.g., TPUs, custom silicon, exploratory architectures).\nStrong understanding of kernels, sharding, runtime systems, or distributed scaling techniques.\nFamiliarity with optimizing LLMs, CNNs, or recommender models for hardware efficiency.\nExperience with performance modeling, system debugging, and software stack adaptation for novel architectures.\nExposure to mobile accelerators is welcome, but experience enabling data center-scale AI hardware is preferred.\nAbility to operate across multiple levels of the stack, rapidly prototype solutions, and navigate ambiguity in early hardware bring-up phases\nInterest in shaping the future of AI compute through exploration of alternatives to mainstream accelerators.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $310K - $380K", "comp": "$310,000.00", "title": "Software Engineer, Accelerators", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4255879060", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Applied team at OpenAI safely brings cutting-edge technology to the world. We have released groundbreaking products such as ChatGPT, Plugins, DALL\u00b7E, and APIs for GPT-4, GPT-3, embeddings, and fine-tuning. Our team also manages large-scale inference infrastructure. With much more on the horizon, our impact continues to grow.\nOur customers create fast-growing businesses using our APIs, enabling product features previously unimaginable. ChatGPT exemplifies the current scope of possibilities. We prioritize the responsible use of our powerful tools, valuing safe deployment over unchecked expansion.\nWithin Applied Engineering, the Financial Engineering team ensures that our products are monetized effectively to accommodate customers' varying needs and scales. Collaborating closely with the GTM and Finance teams, we strive to tailor our billing stack to our evolving internal requirements. We seek an experienced engineer to architect and refine our billing systems, enhancing their functionality to meet the demands of our increasingly complex and expansive product offerings.\nIn This Role, You Will\nArchitect and build the next generation of billing and monetization systems at OpenAI.\nDevelop across the stack to create comprehensive billing integrations for our range of ChatGPT and API users.\nDesign a versatile billing platform suitable for both subscription and usage-based offerings, ensuring scalability and enterprise readiness/flexibility.\nConstruct and integrate tools that empower internal teams to seamlessly incorporate billing data into their workflows.\nCollaborate closely with a wide array of stakeholders, including the Product, Data, Finance, and Go-To-Market teams, as well as fellow engineers.\nYou Might Thrive In This Role If You\nPossess a minimum of 5 years of professional software engineering experience, with added experience in payments, billing, or monetization seen as a bonus.\nEnjoy engaging with various partners, particularly those outside of engineering.\nHave a keen and innate desire to learn and acquire new skills, coupled with a strong ability to impart that knowledge clearly and succinctly to others.\nBring significant experience in developing (and redeveloping) production systems to launch new product capabilities and to handle scaling challenges.\nAre deeply invested in creating an exceptional user experience, taking pride in crafting products that address customer needs.\nAbility to move fast in an environment where things are sometimes loosely defined and may have competing priorities or deadlines.\nOpenAI US Applicant Privacy Policy \nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Software Engineer, Financial Engineering", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201890719", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "Location: San Francisco, CA (Hybrid: 4 days onsite/week). Relocation assistance available.\nAbout The Team\nWe build foundational platform software that enables reliable, secure, and performant products. The team works across system layers and partners closely with adjacent engineering groups to deliver robust capabilities from concept through launch.\nAbout The Role\nWe\u2019re seeking a Systems Software Engineer to design, implement, and debug core platform components and the pipelines that build and update system images. You\u2019ll work across operating system layers, focusing on performance, security, and deep system debugging to ship production\u2011grade systems.\nIn This Role, You Will\nDesign, implement, and debug system\u2011level components and services across kernel and user space.\nConfigure and maintain OS platform services (init, services, networking, security policies) and related tooling.\nBuild and operate image and update pipelines, ensuring reliability, reproducibility, and rollback safety.\nInstrument and analyze performance using profiling and tracing; optimize CPU, memory, I/O, and power usage.\nOwn platform observability and reliability: logging, crash capture, watchdogs, and diagnostics.\nCollaborate with cross\u2011functional teams to define interfaces and deliver end\u2011to\u2011end features.\nEstablish strong engineering practices: code review, CI, reproducible builds, and release management.\nPartner with external suppliers to support builds and deployments.\nYou Might Thrive In This Role If You\nHave shipped production systems software on modern operating systems.\nAre proficient in C/C++ and a scripting language, and comfortable with OS internals (concurrency, memory management, filesystems, networking, power management).\nBring strong systems debugging skills using debuggers, tracers, profilers, and logs across kernel/user\u2011space boundaries.\nUnderstand configuration of platform services and interfaces, and can translate requirements into stable, well\u2011documented APIs.\nAre fluent in user\u2011space foundations (service management, IPC, networking, packaging, automation).\nHave experience building platform images and designing update mechanisms for reliability and security.\nPreferred Qualifications\nExposure to platform security (secure boot, sandboxing, mandatory access controls, attestation).\nExperience with graphics/media, hardware acceleration, or high\u2011throughput data paths.\nFamiliarity with connectivity stacks and network configuration.\nObservability and diagnostics in distributed or resource\u2011constrained environments.\nWork on open\u2011source platforms or contributions to systems projects.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $405K", "comp": "0", "title": "System Software Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4278835338", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Fleet team builds core components to enable productive research from small to state of the art scale across OpenAI, with the goal of accelerating progress towards AGI. We frequently collaborate with other teams to speed up the development of new state-of-the-art capabilities.\nAbout The Role\nAs we scale up with more researchers and engineers joining OpenAI, we seek a pragmatic and passionate engineer with a strong focus on the development experience for both engineers and scientists.\nIn this role, you will be responsible for building and maintaining systems that allow our research + engineering organization to iteratively develop, test, and deploy new features reliably, with high velocity, and with a frictionless and fast development cycle.\nYou will help oversee and drive to the vision of how we should build, test and deploy software. You will drive the design of our continuous integration pipelines, testing infrastructure, training and support around our build system. Our current environment relies heavily on Python, Rust, and C++, which you will take ownership of and strive to transform into a state of the art development experience for research.\nUltimately, your role will be to provide the necessary tools and metrics to support our fast-paced culture and ensure a stable, scalable platform for growth, while also fostering a seamless and low friction experience for OpenAI\u2019s research.\nThis role is based in San Francisco, CA. For a San Francisco role, we use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nYou Might Thrive In This Role If You\nHave supported large monorepo development and deployment before\nAre a proficient Python programmer working in large monorepos\nAre proficient with Docker and Kubernetes\nExperienced in CI/CD\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Software Engineer, Research Developer Productivity", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4302617642", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Integrity team at OpenAI is dedicated to ensuring that our cutting-edge technology is not only revolutionary but also secure from a myriad of adversarial threats. We strive to maintain the integrity of our platforms as they scale.\nThe Integrity team is at the front lines of defending against financial abuse, scaled attacks, and other forms of misuse that could undermine the user experience or harm our operational stability. Integrity Foundations provides the core building blocks and infrastructure for this work.\nAbout The Role\nAt OpenAI, our mission is to advance AI in a way that is safe, reliable, and aligned with broad societal values. The integrity foundations role is crucial for maintaining the trustworthiness of our platforms. You will be pivotal in developing robust defenses against a spectrum of adversarial behaviors that threaten our ecosystem.\nIn this role, you'll work with our entire engineering team to design and implement systems that detect and prevent abuse, promote user safety, and reduce risk across our platform. You'll be at the forefront of our efforts to ensure that the immense potential of AI is harnessed in a responsible and sustainable manner.\nIn This Role, You Will\nDevelop and enhance systems to detect and prevent various forms of abuse including financial fraud, botting, and scripting.\nCollaborate with cross-functional teams to design solutions that protect against and mitigate adversarial attacks without compromising user experience.\nAssist with response to active incidents on the platform and build new tooling and infrastructure that address the fundamental problems.\nYou Might Thrive In This Role If You\nHave at least 3 years of professional software engineering experience.\nHave experience setting up and maintaining production backend services and data pipelines.\nHave a humble attitude, an eagerness to help your colleagues, and a desire to do whatever it takes to make the team succeed.\nAre self-directed and enjoy figuring out the best way to solve a particular problem\nOwn problems end-to-end, and are willing to pick up whatever knowledge you're missing to get the job done.\nCare about AI Safety in production environments and have the expertise to build software systems that defend against abuse.\nBuild tools to accelerate your own workflows, but only when off-the-shelf solutions would not do.\nOur tech stack\nOur infrastructure is built on Terraform, Kubernetes, Azure, Python, Postgres, and Kafka. While we value experience with these technologies, we are primarily looking for engineers with strong technical skills and the ability to quickly pick up new tools and frameworks.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Software Engineer, Integrity Foundations", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201246620", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Strategic Deployment team makes frontier models more capable, reliable, and aligned to transform high-impact domains. On one hand, this involves deploying models in real-world, high-stakes settings to drive AI-driven transformation and elicit insights\u2014training data, evaluation methods, and techniques\u2014to shape our frontier model development. On the other hand, we leverage these learnings to build the science and engineering of impactful frontier model deployment.\nPut differently, we want to understand: if AGI is viewed as AI being able to majorly transform our economy, how close are we to AGI? What\u2019s still missing? How do we bridge these gaps?\nAbout The Role\nAs a \nSoftware Engineer in the Strategic Deployment team\n, you will help OpenAI identify real-world domains that are ripe for transformation through frontier AI capabilities. You\u2019ll act as a hands-on builder, partnering with subject matter experts to understand the key aspects of a given domain, pinpointing the most critical tasks in that domain, and developing technical proofs-of-concept that build conviction driving OpenAI\u2019s strategic engagements.\nWe\u2019re looking for people who combine a strong engineering background with an entrepreneurial mindset\u2014engineers who can thrive in ambiguity, quickly iterate toward the signal, and adapt their approach as new insights emerge. You should be deeply curious about where AI can (and can\u2019t yet) have impact, and excited to push the boundaries of what\u2019s possible.\nThis role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nIn This Role, You Will\nDrive prototyping sprints into specific domains in collaboration with domain experts.\nTranslate real-world tasks into tractable engineering problems and develop proof-of-concept solutions.\nDeliver working demos, run in-the-wild evaluations, and distill insights into actionable guidance for OpenAI\u2019s research and deployment teams.\nYou Might Thrive In This Role If You\nCare about real-world impact of AI.\nAre excited to drive how frontier models are developed and deployed.\nHave hands-on experience in engineering systems.\nAre excited by startup-style ambiguity and enjoy working across disciplines to drive a project from zero to one.\nEnjoy working in open-ended problem spaces and high-feedback environments.\nAre a curious, adaptable generalist who enjoys learning fast, asking deep questions, and solving open-ended problems.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Software Engineer, Strategic Deployment", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4299586802", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Database Systems team specializes in high-performance distributed databases. Our team built Rockset, the real-time search, analytics, and vector database that powers all vector search and retrieval augmented generation (RAG) at OpenAI. In addition to retrieval, as an online database, Rockset powers core functionality across all of OpenAI's product lines and many critical internal use cases.\nAbout The Role\nWe are looking for engineers passionate about distributed systems, close-to-the-metal performance optimization (our core engine is written in C++), and building scalable database infrastructure from the ground up. As an engineer on the Database Systems team, you'll contribute to the core database engine, driving improvements across ingestion, query execution, indexing, and storage. You'll partner with teams across OpenAI to unlock new product capabilities and help scale online database reliability and throughput as usage grows by orders of magnitude.\nIn This Role You Will\nDesign, build, and operate high-performance distributed systems\nIdentify and resolve performance bottlenecks to scale infrastructure to the next order of magnitude\nDefine long-term technical direction and guide system evolution\nCollaborate with product, engineering, and research teams to deliver scalable and reliable infrastructure\nDig deep into complex production issues across the stack\nContribute to incident response, postmortems, and best practices for system reliability\nYou Might Thrive In This Role If You\nHave significant experience building, scaling, and optimizing distributed systems at scale\nAre curious about database internals, storage engines, or low-latency query systems\nEnjoy debugging challenging performance issues in complex, high-throughput systems\nHave experience operating production clusters at scale (e.g., Kubernetes or other orchestration systems)\nThink rigorously about scalability, correctness, and reliability\nThrive in fast-paced environments with high autonomy and impact\nQualifications\n4+ years of relevant industry experience, with 2+ years leading large scale, complex projects or teams as an engineer or tech lead\nExperience with distributed systems at scale, with a strong focus on performance, reliability, and scalability\nStrong communication skills and ability to collaborate across highly technical and cross-functional teams\nProficiency in a systems programming language such as C++ (our core engine is written in C++) is strongly preferred\nFluency in cloud environments (AWS, GCP, Azure) and IaC tools (Terraform or similar)\nExperience with Linux systems, CI/CD pipelines, and modern observability stacks (Prometheus, Grafana, etc.)\nDomain knowledge in areas such as databases, data systems, storage engines, indexing, and query processing is a plus but not required\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $255K - $405K", "comp": "$255,000.00", "title": "Software Engineer, Database Systems", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4268364964", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nJoin the engineering teams that bring OpenAI\u2019s ideas safely to the world!!\nThe Applied Engineering team works across research, engineering, product, and design to bring OpenAI\u2019s technology to consumers and businesses. We seek to learn from deployment and distribute the benefits of AI, while ensuring that this powerful tool is used responsibly and safely. Safety is more important to us than unfettered growth.\nAbout The Role\nWe\u2019re seeking a Full-Stack Engineer who can work across the entire software stack. You\u2019ll join a nimble team where you\u2019ll help drive deployment of OpenAI\u2019s technology into new environments and infrastructure to enable the critical missions in the public sector. This role engages cross-functionally with internal product, security, and compliance teams to build required functionality and ensure we\u2019re delivering a scalable, reliable platform. You\u2019ll interface directly with customers to build the features they need most.\nThis role is based in Washington D.C. and San Francisco, CA. Occasional travel to customer sites is required for this role.\nIn This Role, You Will\nOwn the development of new customer-facing ChatGPT and OpenAI API features end-to-end, both on-premises and in the cloud, for our public sector customers.\nPartner and directly embed with teams across the business, including engineering, security, and compliance, to enable our products to work within the unique constraints of new environments.\nTalk to users to understand their problems and design solutions to address them\nWork with the research team to get relevant feedback and iterate on their latest models\nCollaborate with a cross-functional team of engineers, researchers, product managers, designers, and operations folks to create cutting-edge products\nOptimize applications for speed and scale\nYou Might Thrive In This Role If You\nHold an active US security clearance\n5+ years of relevant engineering experience at tech and product-driven companies\nProficiency with JavaScript, React, and other web technologies\nProficiency with some backend language (we use Python)\nSome experience with underlying infrastructure primitives like Kubernetes and Terraform\nInterest in AI/ML (direct experience not required)\nAbility to move fast in an environment where things are sometimes loosely defined and may have competing priorities or deadlines\nAn interest in enabling public sector use cases with unique requirements\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $255K - $405K", "comp": "$255,000.00", "title": "Full-Stack Engineer, Gov", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4207339825", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Applied AI team safely brings OpenAI's technology to the world. We released ChatGPT, Plugins, DALL\u00b7E, and the APIs for GPT-4, GPT-3, embeddings, and fine-tuning. We also operate inference infrastructure at scale. There's a lot more on the immediate horizon.\nWe seek to learn from deployment and distribute the benefits of AI, while ensuring that this powerful tool is used responsibly and safely. Safety is more important to us than unfettered growth. We serve end-users directly through ChatGPT, and serve developers through our APIs, which power product features that were never before possible.\nAbout The Role\nThe Engineering Acceleration team designs, builds and maintains the foundational systems that engineers use to build ChatGPT and the API. This is a fast-growing team and you will get a chance to own and define the strategy, vision, and plan for how to increase developer productivity.\nIn This Role, You Will\nDrive the design, development, and implementation of tools, systems, and processes that accelerate engineering velocity, reduce manual effort, and increase the quality of output.\nUse our latest AI tools to re-think how we can be the most productive team in the industry.\nWork closely with various teams within OpenAI to understand their workflows, challenges, and needs, and ensure the tools and systems built by the Engineering Acceleration team address these requirements.\nBring new features and research capabilities to the world by partnering with product engineers to lay the necessary technical foundations.\nGuide and advise product engineering teams on best practices for ensuring observable, scalable systems.\nLike all other teams, we are responsible for the reliability of the systems we build. This includes an on-call rotation to respond to critical incidents as needed.\nYou Might Thrive In This Role If You\nHave 5+ years of experience in engineering, including 3+ years of experience in infrastructure building tooling for developers.\nHave experience-driven empathy for the tools, frustrations, and processes that slow engineering teams down and lead to toil or burnout.\nHave a voracious and intrinsic desire to learn and fill in missing skills\u2014and an equally strong talent for sharing learnings clearly and concisely with others.\nAre comfortable with ambiguity and rapidly changing conditions. You view changes as an opportunity to add structure and order when necessary.\nAs technical context: at the heart of our infrastructure is a large-scale deployment of GPU nodes running in dozens of Kubernetes clusters across regions. Some core technologies we build with include Terraform, Buildkite, Postgres, Cosmos DB, Kafka, Python, and FastAPI.\nThis role is exclusively based in our San Francisco HQ. We offer relocation assistance to new employee.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Software Engineer, Dev Productivity", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201895412", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Integrity team at OpenAI is dedicated to ensuring that our cutting-edge technology is not only revolutionary, but also secure from a myriad of adversarial threats. We strive to maintain the integrity of our platforms as they scale.\nThe Integrity team is at the front lines of defending against financial abuse, scaled attacks, and other forms of misuse that could undermine the user experience or harm our operational stability.\nAbout The Role\nAs a Machine Learning Engineer in OpenAI's Applied Group, you will have the opportunity to work with some of the brightest minds in AI. You'll contribute to deploying state-of-the-art models in production environments, helping turn research breakthroughs into tangible solutions that improve the trust and safety of our platform. If you're excited about fine tuning LLMs and building ML models this role is your chance to make a significant mark.\nIn This Role, You Will\nInnovate and Deploy: Design and deploy advanced machine learning models that solve real-world problems. Bring OpenAI's research from concept to implementation, creating AI-driven applications with a direct impact.\nCollaborate with the Best: Work closely with researchers, software engineers, and product managers to understand complex business challenges and deliver AI-powered solutions. Be part of a dynamic team where ideas flow freely and creativity thrives.\nOptimize and Scale: Implement scalable data pipelines, optimize models for performance and accuracy, and ensure they are production-ready. Contribute to projects that require cutting-edge technology and innovative approaches.\nLearn and Lead: Stay ahead of the curve by engaging with the latest developments in machine learning and AI. Take part in code reviews, share knowledge, and lead by example to maintain high-quality engineering practices.\nMake a Difference: Monitor and maintain deployed models to ensure they continue delivering value. Your work will directly influence how AI benefits individuals, businesses, and society at large.\nYou Might Thrive In This Role If You\nMaster's/ PhD degree in Computer Science, Machine Learning, Data Science, or a related field. \nDemonstrated experience in deep learning and transformers models\nProficiency in frameworks like PyTorch or Tensorflow\nStrong foundation in data structures, algorithms, and software engineering principles.\nExperience with search relevance, ads ranking or LLMs is a plus.\nAre familiar with methods of training and fine-tuning large language models, such as distillation, supervised fine-tuning, and policy optimization\nExcellent problem-solving and analytical skills, with a proactive approach to challenges.\nAbility to work collaboratively with cross-functional teams.\nAbility to move fast in an environment where things are sometimes loosely defined and may have competing priorities or deadlines\nEnjoy owning the problems end-to-end, and are willing to pick up whatever knowledge you're missing to get the job done\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Machine Learning Engineer, Integrity", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201247607", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Agent Infrastructure team at OpenAI is responsible for building systems that enable training and deployment of highly useful AI agents, both internally and for the world.\nWe work hand-in-hand with researchers to design and scale the environment in which agentic models are trained \u2013 providing a workspace for AI models to execute code, debug issues, and develop software just as human SWEs do. Our training environment for agentic models operates at an extremely high scale and has the flexibility to emulate any environment in which an agent might work.\nAt the same time, our team builds and maintains OpenAI\u2019s core platform for the deployment and execution of agents in production. Our systems power products such as Codex, Operator, tool use in ChatGPT, and future agentic products.\nSome of the most challenging technical problems in scaling the capabilities and utility of agents and agentic models lie in the infrastructure layer \u2013 and our team is focused on building the research and production systems that enable OpenAI to train the most capable models in the world, and maximize the utility of our agentic products for users around the world.\nAbout The Role\nAs a Software Engineer on the Agent Infrastructure team, you will have the opportunity to work closely with both research and product at OpenAI - building and scaling systems to train highly capable agentic models, and building the platform and integrations to launch new agents to hundreds of millions of users worldwide.\nYour work will consist of both building new capabilities - standing up the infrastructure and integrations needed to train more complex agentic models - and rapidly scaling these new capabilities to some of the largest compute clusters in the world. At the same time, you\u2019ll be instrumental to the launch of agentic products at OpenAI - building, maintaining, and scaling the production platform on which all agents run.\nWe\u2019re looking for people with deep experience building AI infrastructure and who are used to working closely with researchers to build high-performance systems at massive scale for novel use cases.\nThis role is based in San Francisco, CA or New York City, NY. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nIn This Role, You Will\nPush massive compute clusters to their limits. You will be a core contributor to a novel container orchestration platform built in-house by our team to scale far beyond what\u2019s possible with systems like Kubernetes.\nDevelop and maintain FastAPI and gRPC APIs that serve as the interface for our agentic infrastructure used both in training and production.\nUse Terraform to stand up and evolve complex infrastructure for both research and production.\nCollaborate with research teams to stand up and optimize systems for novel AI training runs and experimental applications.\nYou Might Thrive In This Role If You\nHave deep experience working on large-scale machine learning infrastructure. You know how to reason about training at scale, identifying bottlenecks and engineering solutions to optimize system performance in training environments.\nKnow how to build new things from 0-1 quickly, and then scale them 1,000,000x.\nHave a keen eye for performance and optimization. You know how to squeeze the most performance out of complex, globally-distributed systems.\nKnow your way around cloud platforms and work with infrastructure-as-code tech like Terraform.\nAre driven by solving complex, ambiguous problems at the intersection of infrastructure scalability, virtualization efficiency, and agentic capabilities.\nHave deep technical expertise in virtualization and containerization technologies (e.g. Kata, Firecracker, gVisor, Sysbox) and are passionate about optimizing runtime performance.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Software Engineer, Agent Infrastructure", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201249271", "loc": "Buffalo-Niagara Falls Area", "company": "OpenAI"}, {"desc": "About The Team\nThe Intelligence and Investigations team seeks to rapidly detect and disrupt abuse in AI technologies to ensure their safe use. We are dedicated to identifying emerging abuse trends, analyzing risks, and working with our internal partners to implement effective mitigation strategies to protect against misuse. Our efforts contribute to OpenAI's overarching goal of developing AI that benefits all of humanity.\nAbout The Role\nAs an Intelligence Systems Engineer, you\u2019ll be focused on advancing our Intelligence & Investigations efforts at OpenAI, ensuring the safe and responsible use of AI across our products and services.\nWe are seeking a self-starter to prototype, develop, and maintain new tools and processes that integrate OpenAI\u2019s models and infrastructure to enable internal teams to make sense of large, open-domain datasets, fight abuse, and inform high-stakes decisions.\nYou will be a crucial technical bridge between our data scientists and subject matter experts and technical teams like Platform Integrity, Safety Systems, and Research by leading the development of innovative tools and processes that bolster goals in scaled collections, investigations, and analysis.\nThe ideal candidate has strong analytical and data skills, with a background in both prototyping and building scalable systems that can swiftly detect emerging threats, process vast amounts of information, and deliver insights to stakeholders. We value professionals with outstanding communication skills, a commitment to continuous learning, and who are dedicated to promoting the responsible use of AI.\nThis role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nIn This Role, You Will\nPrototype, build, and maintain at-scale intelligence systems that detect, triage, and monitor targeted signals from both open-source and internal data\nAnalyze requirements and deliver end-to-end solutions that address complex intelligence challenges while ensuring code quality and scalability\nBe a crucial technical bridge between our Intelligence needs and technical teams like Platform Integrity, Safety Systems, and Research\nContribute to shaping the team\u2019s technical strategy and design user interfaces for non-technical investigators and analysts\nPrototype new applications to automate team workflows and route leads\nReport on scaled impact using advanced data analysis and visualization products\nWork closely with internal stakeholders and address their technical intelligence needs\nYou might thrive in this role if you have / are:\nExperience in engineering and project management, ideally with a focus on security, intelligence, or data analysis products.\nStrong technical background and proven track record of building and maintaining systems that enable users to make sense of large, open-domain datasets, fight abuse, and inform high-stakes decisions.\nProficiency in data analysis, SQL / Python, and application of novel AI techniques for problem-solving.\nDemonstrated ability to leverage cross-functional teams, manage complex product ecosystems, and deliver results in a fast-paced and sometimes ambiguous environment.\nStrong belief in & passion for the value of AI in enabling humans to better understand the complexity of the world\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Fullstack Engineer, Intelligence Systems", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4301018460", "loc": "United States", "company": "OpenAI"}, {"desc": "About The Team\nOpenAI\u2019s Privacy Engineering team sits at the intersection of Security, Privacy, Legal, and Core\u202fInfrastructure.\u202fOur mission is to build data infrastructure and systems to support our privacy, legal, and security teams\u2014securely, quickly, and at scale. Our guiding principles include: defensibility by default, enabling researchers, preparing for future transformative technologies, and building a robust security culture.\nAbout The Role\nWe\u2019re looking for a Software Engineer who can design and operate technical systems that support legal compliance workflows, including secure data processing and document review. You\u2019ll partner daily with Legal, Security, IT, and partner engineering teams to turn legal processes into concrete technical workflows. This role is ideal for an engineer who loves large\u2011scale data problems and understands the rigor required when the results may be scrutinized.\nThis position is located in San\u202fFrancisco. Relocation assistance is available.\nIn This Role, You Will\nDesign and operate data storage pipelines that can operate at scale.\nBuild search & discovery services (e.g., Spark/Databricks, index layers, metadata catalogs) based on the needs of partner teams.\nAutomate secure data transfers\u2014encrypting, checksumming, and auditing exports to reviewers.\nStand up locked\u2011down compute environments that balance usability with security controls.\nInstrument monitoring and KPIs that maintain accountability of data holds and productions.\nCollaborate cross\u2011functionally to codify SOPs, threat models, and chain\u2011of\u2011custody documentation that withstand scrutiny.\nYou Might Thrive In This Role If You\nHave hands\u2011on experience building or operating large\u2011scale data\u2011lake or backup systems (Azure, AWS, GCP).\nKnow your way around Terraform or Pulumi, CI/CD, and can turn ad\u2011hoc legal requests into repeatable pipelines.\nComfortable working with discovery workflows (legal holds, enterprise document collections, secure review) or eager to build expertise quickly.\nAble to communicate technical concepts \u2014 from storage governance to block-ID APIs \u2014 clearly to teams such as Legal, Engineering, and others.\nHave shipped secure solutions that balance speed, cost, and evidentiary defensibility\u2014and can articulate the trade\u2011offs.\nCommunicate crisply, document rigorously, and enjoy working across disciplines under tight deadlines.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $325K - $405K", "comp": "$325,000.00", "title": "Software Engineer, Data Platform", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4275248087", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "This role will support the fleet infrastructure team at OpenAI. The fleet team focuses on running the world\u2019s largest, most reliable, and frictionless GPU fleet to support OpenAI\u2019s general purpose model training and deployment. Work on this team ranges from\nMaximizing GPUs doing useful work by building user-friendly scheduling and quota systems\nRunning a reliable and low maintenance platform by building push-button automation for kubernetes cluster provisioning and upgrades\nSupporting research workflows with service frameworks and deployment systems \nEnsuring fast model startup times though high performance snapshot delivery across blob storage down to hardware caching \nMuch more!\nAbout The Role\nAs an engineer within Fleet infrastructure, you will design, write, deploy, and operate infrastructure systems for model deployment and training on one of the world\u2019s largest GPU fleet. The scale is immense, the timelines are tight, and the organization is moving fast; this is an opportunity to shape a critical system in support of OpenAI's mission to advance AI capabilities responsibly.\nThis role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nIn This Role, You Will\nDesign, implement and operate components of our compute fleet including job scheduling, cluster management, snapshot delivery, and CI/CD systems.\nInterface with researchers and product teams to understand workload requirements\nCollaborate with hardware, infrastructure, and business teams to provide a high utilization and high reliability service \nYou Might Thrive In This Role If You\nHave experience with hyperscale compute systems\nPossess strong programming skills\nHave experience working in public clouds (especially Azure)\nHave experience working in Kubernetes\nExecution focused mentality paired with a rigorous focus on user requirements\nAs a bonus, have an understanding of AI/ML workloads\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $325K - $590K", "comp": "$325,000.00", "title": "Software Engineer, GPU Infrastructure", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4218939095", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nOur mission at OpenAI is to discover and enact the path to safe, beneficial AGI. To do this, we believe that many technical breakthroughs are needed in generative modeling, reinforcement learning, large scale optimization, active learning, among other topics.\nAbout The Role\nAs a Software Engineer, you will help build AI systems that can perform previously impossible tasks or achieve outstanding levels of performance. This requires good engineering (for example designing, implementing, and optimizing state-of-the-art AI models), writing bug-free machine learning code (surprisingly difficult!), and building the science behind the algorithms employed. In all the projects this role pursues, the ultimate goal is to push the field forward.\nThe Research Acceleration team builds high-quality research tools and frameworks to increase research productivity across OpenAI, with the goal of accelerating progress towards AGI. For example, we develop Triton, a language and compiler for writing custom GPU kernels. The aim of Triton is to provide an open-source environment to write fast code at higher productivity than CUDA.\nWe frequently collaborate with other teams to speed up the development of new state-of-the-art capabilities. For example, we recently collaborated with our Codegen research team on the Codex model, which can generate code in Python and many other languages.\nDo you love research tools, compilers, and collaborating on cutting-edge AI models? If so, this role is for you! We are looking for people who are self-directed and enjoy determining the most meaningful problem to solve in order to accelerate our research.\nWe're Looking For a Track Record Of\n 3+ years of relevant engineering experience\n Owning problems end-to-end, with a willingness to pick up whatever knowledge is missing to get the job done\n Bonus: contributions to an AI framework such as PyTorch or Tensorflow, or compilers such as GCC, LLVM, or MLIR\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Software Engineer, Triton Compiler", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201247554", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "This role will support the fleet infrastructure team at OpenAI. The fleet team focuses on running the world\u2019s largest, most reliable, and frictionless GPU fleet to support OpenAI\u2019s general purpose model training and deployment. Work on this team ranges from\nMaximizing GPUs doing useful work by building user-friendly scheduling and quota systems\nRunning a reliable and low maintenance platform by building push-button automation for kubernetes cluster provisioning and upgrades\nSupporting research workflows with service frameworks and deployment systems \nEnsuring fast model startup times though high performance snapshot delivery across blob storage down to hardware caching \nMuch more!\nAbout The Role\nAs an engineer within Fleet infrastructure, you will design, write, deploy, and operate infrastructure systems for model deployment and training on one of the world\u2019s largest GPU fleet. The scale is immense, the timelines are tight, and the organization is moving fast; this is an opportunity to shape a critical system in support of OpenAI's mission to advance AI capabilities responsibly.\nThis role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nIn This Role, You Will\nDesign, implement and operate components of our compute fleet including job scheduling, cluster management, snapshot delivery, and CI/CD systems.\nInterface with researchers and product teams to understand workload requirements\nCollaborate with hardware, infrastructure, and business teams to provide a high utilization and high reliability service \nYou Might Thrive In This Role If You\nHave experience with hyperscale compute systems\nPossess strong programming skills\nHave experience working in public clouds (especially Azure)\nHave experience working in Kubernetes\nExecution focused mentality paired with a rigorous focus on user requirements\nAs a bonus, have an understanding of AI/ML workloads\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Software Engineer, Research Infrastructure", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201249277", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Applied team safely brings OpenAI's technology to the world. We released ChatGPT; Plugins; DALL\u00b7E; and the APIs for GPT-4, GPT-3, embeddings, and fine-tuning. We also operate inference infrastructure at scale. There's a lot more on the immediate horizon.\nOur customers build fast-growing businesses around our APIs, which power product features that were never before possible. ChatGPT is a prime example of what is currently possible. We simultaneously ensure that our powerful tools are used responsibly. Safe deployment is more important to us than unfettered growth.\nThe Fraud Engineering team works within our Applied Engineering organization identifying and responding to fraudsters on our platform. We are looking for a software engineer with anti fraud & abuse experience to help architect and build our next-generation anti-fraud systems.\nIn This Role, You Will\nDesign and build systems for fraud detection and remediation while balancing fraud loss, cost of implementation, and customer experience\nWork closely with finance, security, product, research, and trust & safety operations to holistically combat fraudulent and abusive actors on our system\nStay abreast of the latest techniques and tools to stay several steps ahead of determined and well resourced adversaries\nUtilize GPT-4 and future models to more effectively combat fraud and abuse\nYou Might Thrive In This Role If You\nHave at least 5 years of software engineering experience in backend and data systems.\nHave at least 2 years experience in fraud or abuse analysis, investigation, and/or operations\nCan dive into our codebase, intuit how it works, and be able to have a strong intuition for suggestions that will lead us to a stronger engineering position.\nA voracious and intrinsic desire to learn and fill in missing skills. An equally strong talent for sharing that information clearly and concisely with others\nAre comfortable with ambiguity and rapidly changing conditions. You view changes as an opportunity to add structure and order when necessary\nExperience in Machine Learning techniques is a plus, but not required\nOur tech stack\nOur infrastructure is built on Terraform, Kubernetes, Azure, Python, Postgres, and Kafka. While we value experience with these technologies, we are primarily looking for engineers with strong technical skills and the ability to quickly pick up new tools and frameworks.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Software Engineer, Scaled Abuse", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201244668", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nSecurity is at the foundation of OpenAI\u2019s mission to ensure that artificial general intelligence benefits all of humanity. The Identity Infrastructure Engineering team sits at the core of this effort, designing and building the identity and access management solutions that protect our model weights, customer data, and critical systems across multiple cloud environments. We partner with teams across OpenAI\u2014Applied Engineering, Research, IT, and Security\u2014to provide a secure and scalable platform for permissioning, orchestration, and innovative AI research.\nAbout The Role\nAs a \nSoftware Engineer on the Identity Infrastructure Engineering team\n, you\u2019ll be instrumental in creating, deploying, and operating foundational security tools and infrastructure. You will work with a broad range of technologies to support multi-cloud deployments, ensuring that researchers and engineers can safely build, test, and scale transformative AI systems. The role requires a balance of strong technical depth, cross-functional collaboration, and a passion for embedding secure-by-default principles into every layer of our stack.\nWe are looking for Software Engineers interested in coming to tackle challenges in these areas:\nIdentity & Access Orchestration: Build and maintain the systems and interfaces that manage user and service identity, ensuring fine-grained access controls are consistent across cloud providers and internal services.\nMulti-Cloud Security: Design architectures and tooling that protect model weights, custom data, and sensitive assets while operating seamlessly in AWS, Azure, GCP, or future cloud environments.\nAutomation & Tooling: Develop robust frameworks, APIs, and CLI tools that automate recurring security tasks (like provisioning or rotating credentials), freeing teams to focus on AI innovation without sacrificing security.\nIn This Role, You Will\nBuild new features for our IAM platform that seamlessly integrate with evolving cloud services, enabling teams to work efficiently while adhering to security best practices.\nDrive security innovation by designing tools, processes, and architectures that protect data at scale and reinforce a secure development culture across the organization.\nCollaborate cross-functionally with researchers, engineers, and compliance teams to address security requirements for multi-cloud deployments, large-scale model training, and emerging AI use cases.\nImplement and refine access policies that strike the right balance between enabling rapid experimentation and protecting high-value assets, including model weights and customer data.\nTroubleshoot complex identity or access issues across distributed systems, ensuring minimal downtime and a safe environment for AI research and product teams.\nYou Might Thrive In This Role If You\nA background in building secure systems\u2014from core IAM services to orchestration layers that manage credentials, roles, or policies at scale.\nProficiency in programming languages such as Python, Go, or similar, with a track record of writing high-quality, maintainable code.\nExperience with modern cloud infrastructure (AWS, Azure, GCP) and familiarity with industry-standard security protocols (OAuth, SAML, OpenID Connect) and authentication/authorization patterns.\nA security-focused mindset, with knowledge of threat modeling, risk assessment, and the ability to embed security features throughout the software development lifecycle.\nExcellent collaboration skills\u2014you work well across diverse technical and non-technical teams, turning broad objectives into actionable solutions.\nThis role is based in San Francisco, CA. We use a hybrid work model of three days in the office per week and offer relocation assistance to new employees.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $255K - $325K", "comp": "$255,000.00", "title": "Software Engineer, Identity Infrastructure Engineering", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4242445585", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nOpenAI\u2019s Enterprise Identity team builds and maintains the core authentication and authorization systems used across our enterprise products. We ensure secure, scalable, and seamless access for small businesses and global organizations adopting ChatGPT, API, and other OpenAI offerings. Our work is foundational to enterprise security, IT integration, and safe deployment of AI in the workplace.\nAbout The Role\nWe\u2019re looking for a software engineer to lead the development of OpenAI\u2019s enterprise identity platform. You\u2019ll design and implement systems that support SSO, SCIM, RBAC, and identity federation across all OpenAI products. Your work will directly support our most critical customers and unlock safe, large-scale enterprise adoption of OpenAI\u2019s models.\nIn This Role, You Will\nBuild the next generation of enterprise authentication and authorization infrastructure, including SAML, OIDC, and OAuth2.0 integrations.\nDesign and implement support for key enterprise standards: SSO, SCIM provisioning, RBAC, and delegated access.\nEvolve our identity data model and architecture to support complex customer org structures.\nPartner with GTM, security, and product teams to shape identity features that meet current and future enterprise needs from small business to multinational organizations.\nDevelop tools and APIs for other engineering teams to integrate enterprise identity seamlessly.\nYou Might Thrive In This Role If You\nHave experience building and operating production authentication and identity systems at scale.\nAre fluent in identity protocols (OAuth2.0, SAML, SCIM, OIDC) and their security considerations.\nHave worked with platforms like Auth0, WorkOS, or Ory Hydra.\nAre proficient in backend development (Python preferred).\nEnjoy building secure, developer-friendly APIs and infrastructure.\nAre excited about shaping how enterprises safely access and govern the use of frontier AI.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $240K - $370K", "comp": "$240,000.00", "title": "Software Engineer, Enterprise Identity", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4305805247", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Applied AI team works across research, engineering, product, and design to bring OpenAI\u2019s technology to the world.\nWe seek to learn from deployment and broadly distribute the benefits of AI, while ensuring that this powerful tool is used responsibly and safely. We aim to make our innovative tools globally accessible, transcending geographic, economic, or platform barriers. Our commitment is to facilitate the use of AI to enhance lives, fostered by rigorous insights into how people use our products.\nAbout The Role\nIn this role, you\u2019ll lead development of the systems we use to evaluate the quality of our AI models and products. You\u2019ll help us leverage a combination of human and automated methods to accelerate robust iteration and development of new models and product features.\nWe\u2019re looking for an experienced engineer with a track record of building effective systems to evaluate quality in domains like search or other AI-oriented areas.\nThis role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nIn This Role, You Will\nBuild and evolve a framework for quality evaluation that enables our research and product engineering teams to identify gaps in quality, track progress, and accelerate robust iteration\nWork with a small, senior team of engineers and researchers to combine existing best practices with innovative approaches based on state-of-the-art models to develop industry-leading systems\nYou Might Thrive In This Role If You\nHave significant experience building systems to evaluate quality for search or other AI-oriented areas\nHave a voracious and intrinsic desire to learn and fill in missing skills, and an equally strong talent for sharing that information clearly and concisely with others\nThrive on going deep into data to identify issues and trends\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $245K - $465K", "comp": "$245,000.00", "title": "Software Engineer, Search Evaluations", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4247960080", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Workload team is responsible for designing and running OpenAI\u2019s LLM training and inference infrastructure that powers frontier models at massive scale. Our systems unify how researchers train and serve models, abstracting away the complexity of performance, parallelism, and execution across vast GPU/accelerator fleets. By providing this foundation, the Workload team ensures that researchers can focus on advancing model capabilities while we handle the scale, efficiency, and reliability required to bring those models to life.\nAbout The Role\nWe are looking for an engineer to design and implement the dataset infrastructure that powers OpenAI\u2019s next-generation training stack. You will be responsible for building standardized dataset interfaces, scaling pipelines across thousands of GPUs, and proactively testing performance bottlenecks. In this role, you will collaborate closely with the multimodal researchers, and other infra groups to ensure datasets are unified, efficient, and easy to consume.\nIn This Role, You Will\nDesign and maintain standardized dataset APIs, including for multimodal (MM) data that cannot fit in memory.\nBuild proactive testing and scale validation pipelines for dataset loading at GPU scale.\nCollaborate with teammates to integrate datasets seamlessly into training and inference pipelines, ensuring smooth adoption and a great user experience.\nDocument and maintain dataset interfaces so they are discoverable, consistent, and easy for other teams to adopt.\nEstablish safeguards and validation systems to ensure datasets remain reproducible and unchanged once standardized.\nDebug and resolve performance bottlenecks in distributed dataset loading (e.g., straggler systems slowing global training).\nProvide visualization and inspection tools to surface errors, bugs, or bottlenecks in datasets.\nYou Might Thrive In This Role If You\nHave strong engineering fundamentals with experience in distributed systems, data pipelines, or infrastructure.\nHave experience building APIs, modular code, and scalable abstractions, while recognizing that abstractions ultimately serve the users and UX is an important part of the abstractions design.\nAre comfortable debugging bottlenecks across large fleets of machines.\nTake pride in building infrastructure that \u201cjust works,\u201d and find joy in being the guardian of reliability and scale.\nAre collaborative, humble, and excited to own a foundational (if not glamorous) part of the ML stack.\nBonus Points If You\nHave background knowledge in data math, probability, or distributed data theory.\nHave worked with GPU-scale distributed systems or dataset scaling for real-time data\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Software Engineer, Data Infrastructure - Research", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4301012545", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nOur Robotics team is focused on unlocking general-purpose robotics and pushing towards AGI-level intelligence in dynamic, real-world settings. Working across the entire model stack, we integrate cutting-edge hardware and software to explore a broad range of robotic form factors. We strive to seamlessly blend high-level AI capabilities with the constraints of physical systems to improve peoples\u2019 lives.\nAbout The Role\nWe're seeking talented Robotics Software Engineers to expand our robotics data collection and evaluation program. This highly technical role involves designing, implementing, and optimizing software solutions across diverse robotics hardware. You'll work closely and collaboratively with multidisciplinary teams; including software, hardware, research, and operations - to drive advancements in our robotic systems.\nThis role is based in San Francisco, CA, and requires in-person 4 days a week.\nIn This Role, You Will\nHelp develop and grow our data collection labs, owning the entire integration lifecycle, from identifying and sourcing new hardware to collaborating with mechanical and electrical engineers on setup, software integration, and operational deployment.\nDevelop innovative robot control interfaces suited to a variety of morphologies, environments, and tasks.\nCollaborate closely with research and engineering teams to develop automation tools and machinery that facilitate the evaluation of advanced robotic policies.\nLead the design and implementation of data collection, visualization, and quality control processes.\nYou Might Thrive In This Role If You\nPossess strong software engineering fundamentals.\nHave extensive experience integrating and deploying industrial automation systems. off-the-shelf robotics, or related hardware into production environments.\nBring hands-on experience delivering production-quality software within collaborative engineering teams.\nHave a strong background in Rust or C++.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $255K - $325K", "comp": "$255,000.00", "title": "Robotics Software Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4226027212", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "Overview\nThe Data Acquisition team within the Foundations organization at OpenAI is responsible for all aspects of data collection to support our model training operations. Our team manages web crawling and GPTBot services and works closely with Data Processing, Architecture, and Scaling teams. We are looking for a skilled Full-Stack Engineer to join our Data Acquisition team to build and optimize the interfaces and tools that power our data infrastructure.\nResponsibilities\nDevelop and maintain full-stack applications that support data acquisition, including internal tools and dashboards.\nCollaborate closely with cross-functional teams, including Data Processing, Architecture, and Scaling, to ensure seamless data ingestion and workflow management.\nDesign and implement APIs to facilitate data interactions between internal services and external data sources.\nEnhance user experience by developing intuitive web-based interfaces for managing and monitoring data pipelines.\nOptimize backend services for performance, scalability, and security in a distributed computing environment.\nWork with legal and compliance teams to ensure our data acquisition processes adhere to privacy regulations and best practices.\nDeploy and maintain infrastructure using Kubernetes and Infrastructure-as-Code (IaC) methodologies.\nAnalyze system performance, conduct experiments, and improve data workflows to maximize efficiency.\nQualifications\nBS/MS/PhD in Computer Science or a related field.\n4+ years of industry experience in full-stack development.\nProficiency in frontend frameworks (React, Vue, or similar) and backend technologies such as Python, Node.js, or Go.\nStrong expertise in RESTful APIs, GraphQL, and database design (SQL and NoSQL).\nExperience building data-intensive applications that handle large-scale datasets.\nFamiliarity with cloud platforms (AWS, GCP, or Azure) and container orchestration (Kubernetes, Docker).\nPrior experience with web crawling and large-scale data processing is a plus.\nStrong problem-solving skills and ability to balance multiple tasks in a fast-moving environment.\nExcellent communication and collaboration skills.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Full-Stack SWE, Data Acquisition (Foundations)", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201890743", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Applied team works across research, engineering, product, and design to bring OpenAI\u2019s technology to consumers and businesses.\nWe seek to learn from deployment and distribute the benefits of AI, while ensuring that this powerful tool is used responsibly and safely. Safety is more important to us than unfettered growth.\nAbout The Role\nWe're seeking a Data Engineer to take the lead in building our data pipelines and core tables for OpenAI. These pipelines are crucial for powering analyses, safety systems that guide business decisions, product growth, and prevent bad actors. If you're passionate about working with data and are eager to create solutions with significant impact, we'd love to hear from you. This role also provides the opportunity to collaborate closely with the researchers behind ChatGPT and help them train new models to deliver to users. As we continue our rapid growth, we value data-driven insights, and your contributions will play a pivotal role in our trajectory. Join us in shaping the future of OpenAI!\nIn This Role, You Will\nDesign, build and manage our data pipelines, ensuring all user event data is seamlessly integrated into our data warehouse.\nDevelop canonical datasets to track key product metrics including user growth, engagement, and revenue.\nWork collaboratively with various teams, including, Infrastructure, Data Science, Product, Marketing, Finance, and Research to understand their data needs and provide solutions.\nImplement robust and fault-tolerant systems for data ingestion and processing.\nParticipate in data architecture and engineering decisions, bringing your strong experience and knowledge to bear.\nEnsure the security, integrity, and compliance of data according to industry and company standards.\nYou Might Thrive In This Role If You\nHave 3+ years of experience as a data engineer and 8+ years of any software engineering experience(including data engineering).\nProficiency in at least one programming language commonly used within Data Engineering, such as Python, Scala, or Java.\nExperience with distributed processing technologies and frameworks, such as Hadoop, Flink and distributed storage systems (e.g., HDFS, S3).\nExpertise with any of ETL schedulers such as Airflow, Dagster, Prefect or similar frameworks.\nSolid understanding of Spark and ability to write, debug and optimize Spark code. \nThis role is exclusively based in our San Francisco HQ. We offer relocation assistance to new employees.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Analytics Data Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201251289", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Applied Engineering team works across research, engineering, product, and design to bring OpenAI\u2019s technology to consumers and businesses.\nYou\u2019ll join the team responsible for running the core infrastructure that supports products like ChatGPT and the API. The systems we support include our kubernetes clusters, infrastructure deployment, our networking stack, cloud abstractions, and more.\nWe seek to learn from deployment and distribute the benefits of AI, while ensuring that this powerful tool is used responsibly and safely. Safety is more important to us than unfettered growth.\nAbout The Role\nThe cloud infrastructure team builds and maintains infrastructure abstractions allowing OpenAI to ship products quickly and scalably.\nThis role is based in San Francisco, CA.\nIn This Role, You Will\nDesign and build the development and production platforms that power our products, enabling reliability and security at scale\nEnsure our infrastructure can scale to the next order of magnitude\nHelp create a diverse, equitable, and inclusive culture that makes all feel welcome while enabling radical candor and the challenging of group think\nLike all other teams, we are responsible for the reliability of the systems we build. This includes an on-call rotation to respond to critical incidents as needed.\nYou Might Thrive In This Role If You\nHave 5+ years building core infrastructure \nHave experience operating orchestration systems such as Kubernetes at scale\nHave experience building abstractions over cloud platforms\nTake pride in building and operating scalable, reliable, secure systems\nAre comfortable with ambiguity and rapid change\nThis role is exclusively based in our San Francisco HQ. We offer relocation assistance to new employees.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Software Engineer, Cloud Infrastructure", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4277724692", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nJoin the engineering teams that bring OpenAI\u2019s ideas safely to the world!\nThe Applied Engineering team works across research, engineering, product, and design to bring OpenAI\u2019s technology to consumers and businesses. We seek to learn from deployment and distribute the benefits of AI, while ensuring that this powerful tool is used responsibly and safely. Safety is more important to us than unfettered growth.\nAbout The Role\nWe are looking for an outcome-oriented Software Engineers to deeply partner with our most strategic and high-impact customers in the public sector. In this role you will take on various roles, actively coding and leveraging your software engineering experience throughout the stages of application ideation, development, delivery, and scaling. You will embed directly throughout the project lifecycle, working on-site and being hands-on with every aspect of the solution from design to production.\nThis role is based in Washington D.C. and San Francisco, CA. Travel to and working from customer sites is required for this role.\nIn This Role, You Will\nDeeply embed with our most strategic public sector customers, serving as their technical thought partner in ideating and directly developing novel full-stack applications on our platform\nLeverage your software engineering expertise in Python and JavaScript to create initial prototypes and contribute back durable product features\nProactively provide guidance to our customers on how to maximize business impact from their applications, accelerating their time to value\nForge and manage relationships with our customers\u2019 leadership and stakeholders to ensure their application\u2019s successful deployment and scale\nCollaborate closely with public sector teammates and cross-functional teams across the company to strategically drive our platform towards exceeding customer expectations\nYou Might Thrive In This Role If You\nHold an active US security clearance or ability to obtain/maintain one\nHave 5+ years of software engineering experience, with an emphasis on customer-facing roles\nProficient in Python, Javascript, and relevant technologies\nFamiliar with deployment models, including to cloud platforms (Azure, AWS) and the underlying infrastructure primitives (Kubernetes, Terraform)\nCan proactively identify opportunities for maximizing our customers\u2019 business value through leveraging the OpenAI API\nOwn outcomes end-to-end, and are willing to pick up whatever knowledge you're missing to get the job done to ensure both your team and our customers succeed\nSkilled communicator adept at explaining complex technical concepts to both technical and non-technical audiences with clarity and concision\nLed complex technical projects and programs with many stakeholders\nHave a humble attitude and an eagerness to help others with empathy\nOperate with high horsepower, are adept at frequent context switching and working on multiple projects at once with expansive ownership, and ruthlessly prioritize\nThrive in dynamic environments and can navigate ambiguity with ease\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Software Engineer, Gov", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4308101365", "loc": "Washington, DC", "company": "OpenAI"}, {"desc": "Overview\nThe Data Acquisition team within the Foundations organization at OpenAI is responsible for all aspects of data collection to support our model training operations. Our team manages web crawling and GPTBot services and works closely with Data Processing, Architecture, and Scaling teams. We are looking for a skilled Software Engineer to join our Data Acquisition team.\nResponsibilities\nOwn and lead engineering projects in the area of data acquisition including web crawling, data ingestion, and search.\nCollaborate with other sub-teams, such as Data Processing, Architecture, and Scaling, to ensure smooth data flow and system operability.\nWork closely with the legal team to handle any compliance or data privacy-related matters.\nDevelop and deploy highly scalable distributed systems capable of handling petabytes of data.\nArchitect and implement algorithms for data indexing and search capabilities.\nBuild and maintain backend services for data storage, including work with key-value databases and synchronization.\nDeploy solutions in a Kubernetes Infrastructure-as-Code environment and perform routine system checks.\nConduct and analyze experiments on data to provide insights into system performance.\nQualifications\nBS/MS/PhD in Computer Science or a related field.\n4+ years of industry experience in software development.\nExperience with large web crawlers a plus\nStrong expertise in large stateful distributed systems and data processing.\nProficiency in Kubernetes, and Infrastructure-as-Code concepts.\nWillingness and enthusiasm for trying new approaches and technologies.\nAbility to handle multiple tasks and adapt to changing priorities.\nStrong communication skills, both written and verbal.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Software Engineer, Data Acquisition", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201889849", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe GTM (Go-To-Market) Innovation team is an internal powerhouse revolutionizing how we engage customers through groundbreaking applications of our technology. As an incubator, we amplify the impact of Sales, Technical Success, Enablement, and Revenue Operations by deploying our technology at scale. This team applies advanced capabilities to real-world interactions \u2014 reshaping conversations with customers, learning from every exchange, and finding novel ways to show the value of our technology.\nAbout The Role\nWe\u2019re looking for Full Stack software engineers with a product mindset to join the GTM Innovation team.\nAs a product engineer on this team, you\u2019ll help OpenAI meet the world at scale. You\u2019ll partner closely with go-to-market teams to understand their workflows, identify leverage points, and ship novel solutions using OpenAI\u2019s API platform.\nYou\u2019ll move quickly from prototype to production, and your work will directly shape how customers experience our technology in the field. This role is ideal for engineers who want to be close to users, own end-to-end outcomes, and help define entirely new categories of enterprise software.\nIn This Role, You Will\nBuild high-impact applications and tools that accelerate OpenAI\u2019s go-to-market efforts\nWork across the full product lifecycle for GTM: prototype, iterate, ship, and maintain\nEmbed with Sales, Technical Success, and Revenue Operations to identify user needs and build for them\nApply OpenAI\u2019s models in novel ways to solve real-world customer and internal workflow problems\nTranslate learnings into feedback for Applied and Research teams to inform product development\nYou\u2019ll Thrive In This Role If You\nHave 4+ years of experience as a software/ML/product engineer working on user-facing systems\nFormer founder, or early engineer at a startup who built a product from scratch is a plus\nAre fluent in Python or JavaScript and comfortable building full-stack applications\nHave built or prototyped LLM-powered workflows using the OpenAI API (or similar)\nTake initiative, move quickly, and operate with a strong sense of ownership\nEnjoy working closely with end users and shaping 0\u21921 products\nAre collaborative, curious, and motivated to make an outsized impact at the frontier of AI\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Full Stack Software Engineer, GTM Innovation", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4303787993", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Safety Systems team is responsible for various safety work to ensure our best models can be safely deployed to the real world to benefit the society and is at the forefront of OpenAI's mission to build and deploy safe AGI, driving our commitment to AI safety and fostering a culture of trust and transparency.\nThe Trustworthy AI team works on action relevant or decision relevant research to ensure we shape A(G)I keeping societal impacts in mind. This includes work on full stack policy problems such as building methods for public inputs into model values and understanding impacts of anthropomorphism of AI. We aim to translate nebulous policy problems to be technically tractable and measurable. We then use this work to inform and build interventions that increase societal readiness for increasingly intelligent systems. Our team also works on external assurances for AI with an aim for increasing independent checks and forming additional layers of validation.\nAbout The Role\nWe are looking to hire exceptional research scientists/engineers that can push the rigor of work needed to increase societal readiness for AGI. Specifically, we are looking for those that will enable us to translate nebulous policy problems to be technically tractable and measurable.\nThis role is based in our San Francisco HQ. We offer relocation assistance to new employees.\nIn This Role, You Will Enable\nSet research and strategies to study societal impacts of our models in an action-relevant manner and figure out how to tie this back into model design\nBuild creative methods and run experiments that enable public input into model values\nIncreasing rigor of external assurances by turning external findings into robust evaluations\nFacilitating and growing our ability to effectively de-risk flagship model deployments in a timely manner\nYou Might Thrive In This Role If You\nAre excited about OpenAI\u2019s mission of building safe, universally beneficial AGI and are aligned with OpenAI\u2019s charter\nDemonstrate a passion for AI safety and making cutting-edge AI models safer for real-world use.\nPossess 3+ years of research experience (industry or similar academic experience) and proficiency in Python or similar languages \nThrive in environments involving large-scale AI systems and multimodal datasets\nEnjoy working on large-scale, difficult, and nebulous problems in a well-resourced environment\nExhibit proficiency in the field of AI safety, focusing on topics like RLHF, adversarial training, robustness, LLM evaluations\nHave past experience in interdisciplinary research\nShow enthusiasm for socio-technical topics\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Research Engineer, Trustworthy AI", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201245652", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nOpenAI\u2019s Applications Engineering organization builds and operates the products that bring our cutting-edge research to millions of users and developers worldwide. We power products such as ChatGPT, the OpenAI API, and emerging AI-native applications. Our teams span product engineering, infrastructure, and safety, working together to ensure that OpenAI\u2019s technology is delivered with reliability, security, and a world-class user experience.\nAbout The Role\nWe\u2019re seeking Android engineers to create and evolve the ChatGPT Android app and future AI-powered mobile experiences. You\u2019ll build new features, optimize performance, and integrate the latest Android platform capabilities to deliver a seamless, delightful assistant in every user\u2019s pocket.\nIn This Role, You Will\nBuild and ship new experiences on Android that showcase the power of AI.\nOptimize app performance, reliability, and responsiveness at global scale.\nEstablish robust testing frameworks and refine app architecture for long-term maintainability.\nCollaborate with product, design, research, and backend teams to deliver high-impact features.\nProvide technical leadership to shape the future of OpenAI\u2019s Android platform.\nYou Might Thrive In This Role If You\nHave up to 6 years of professional software engineering experience.\nHave a proven track record of building high-quality Android applications in production.\nAre fluent in Kotlin (and/or Java) and familiar with Android development tools and architecture components.\nPrioritize performance, security, and user experience in mobile development.\nEnjoy working cross-functionally to bring ambitious product ideas to life.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Software Engineer, Android", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4302940557", "loc": "New York City Metropolitan Area", "company": "OpenAI"}, {"desc": "By applying to this role, you will be considered for Research Engineer roles across all teams at OpenAI.\nAbout The Role\nAs a Research Engineer here, you will be responsible for building AI systems that can perform previously impossible tasks or achieve unprecedented levels of performance. We're looking for people with solid engineering skills (for example designing, implementing, and improving a massive-scale distributed machine learning system), writing bug-free machine learning code, and building the science behind the algorithms employed.\nThe most outstanding deep learning results are increasingly attained at a massive scale, and these results require engineers who are comfortable working in large distributed systems. We expect engineering to play a key role in most major advances in AI of the future.\nWe Expect You To\nHave strong programming skills\nHave experience working in large distributed systems\nBe excited about OpenAI\u2019s approach to research \nNice To Have\nInterested in and thoughtful about the impacts of AI technology\nPast experience in creating high-performance implementations of deep learning algorithms\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Research Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201246673", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Integrity team at OpenAI is dedicated to ensuring that our cutting-edge technology is not only revolutionary but also secure from a myriad of adversarial threats. We strive to maintain the integrity of our platforms as they scale.\nThe Integrity team is at the front lines of defending against financial abuse, scaled attacks, and other forms of misuse that could undermine the user experience or harm our operational stability.\nAbout The Role\nAt OpenAI, our mission is to advance AI in a way that is safe, reliable, and aligned with broad societal values. We are seeking a Software Engineer who will work at the intersection of large-scale distributed systems and security infrastructure. In this role you will build, scale, and defend critical backend services: powering training infrastructure at scale \nand\n protecting the platform from misuse, adversarial behavior, and systemic abuse. Your work will ensure both performance, reliability, and safety across our systems.\nIn This Role, You Will\nDesign and maintain systems and frameworks that enable effective identification and assessment of emergent risks (e.g., reasoning, instruction-following, or agentic behavior) supporting security and safety teams in catching issues before they lead to external incidents.\nArchitect and build scalable, resilient backend systems and internal tooling to support a lean, high-efficiency operating model\nProactively probe systems to uncover latent bugs and failure modes before they manifest in production\nYou Might Thrive In This Role If You\nHave at least 5 years of software engineering experience working on distributed systems, platforms, or infrastructure.\nLove figuring out how systems work and continuously come up with ideas for how to make them faster while minimizing complexity and maintenance burden\nAre deeply versed in potential failure modes of AI and ML systems (e.g. sycophancy, adversarial inputs, jailbreaks, harmful outputs) and have experience detecting or mitigating them\nEnjoy working adjacent to research teams and translating novel technical ideas into production-grade, safe systems \u2014 rather than operating purely in product or commercial domains\nProactively investigate complex systems to uncover bugs, edge cases, and unexpected failure modes, using insights to strengthen reliability.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "System Software Engineer, Integrity", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4265918652", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nApplied Evals defines what good looks like for safe, advanced AI systems. We turn complex, high-value workflows into clear, reproducible signals that guide model training and product quality. Our work bridges frontier customers and models, ensuring improvements show up where users experience them. We combine hands-on, unscalable efforts with systems that others can extend, creating a compounding loop of model improvement.\nAbout The Role\nWe\u2019re hiring product-minded engineers to design and build evals and harnesses that capture real-world quality for advanced AI systems. You\u2019ll own the loop from prototyping with users to building reliable pipelines and integrating signals into training stacks. This role sits at the center of model improvement. The systems you design will directly shape how models behave, accelerate their reliability, and raise the standard for what customers expect.\nYou\u2019ll collaborate closely with research and product teams and work across the stack, from backend pipelines to user-facing interfaces. The work includes evaluating multi-turn and tool-using systems, designing agent harnesses, and applying reinforcement learning and related methods in production settings. Engineers who succeed in this role bring both a builder\u2019s mindset and the judgment to create reusable systems that others can build on. Many thrive here by operating like founders or founding engineers, taking initiative, moving quickly, and creating structure where none exists.\nThis role is based in our San Francisco HQ. We use a hybrid work model of 3 days in the office per week and offer relocation assistance.\nIn This Role, You Will\nDefine the core evaluation signals that drive model improvement at OpenAI, turning vague product gaps into crisp, defensible measures of quality\nDesign agents, harnesses, and eval pipelines that are reliable, reproducible, and extendable\nPrototype solutions with real workflows and convert them into scalable feedback loops\nConnect evaluation signals directly to research and training systems so product improvements show up in what users experience\nShape model interaction paradigms by partnering with engineering, research, and product teams on how models are deployed and measured\nBuild reusable systems and tools that enable contributions from across the company and steadily raise the quality bar\nYou\u2019ll Thrive In This Role If You\nBring 4+ years of experience in software engineering with strong fundamentals and a track record of shipping production systems end-to-end\nHave experience building AI agents or applications, including designing evals and improving performance through prompting or scaffolding\nAre familiar with evaluation methods for LLMs and have worked with patterns like multi-agent workflows, tool use, or long context.\nAre familiar with deep learning concepts or have prior exposure to training models.\nCommunicate clearly across technical and non-technical audiences across levels\nAre motivated by high-impact collaboration with research and product teams and thrive in ambiguity\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $255K - $325K", "comp": "$255,000.00", "title": "Software Engineer, Applied Evals", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4285827352", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Safety Systems team is dedicated to ensuring the safety, robustness, and reliability of AI models and their deployment in the real world.\nBuilding on the many years of our practical alignment work and applied safety efforts, Safety Systems addresses emerging safety issues and develops new fundamental solutions to enable the safe deployment of our most advanced models and future AGI, to make AI that is beneficial and trustworthy.\nLearn more about OpenAI\u2019s approach to safety\nAbout The Role\nAt OpenAI, we're dedicated to advancing artificial intelligence, and we know that creating a secure and reliable platform is vital to our mission. That's why we're seeking a software engineer to help us build out our trust and safety capabilities.\nIn this role, you'll work with our entire engineering team to design and implement systems that detect and prevent abuse, promote user safety, and reduce risk across our platform. You'll be at the forefront of our efforts to ensure that the immense potential of AI is harnessed in a responsible and sustainable manner.\nIn This Role, You Will\nArchitect, build, and maintain anti-abuse and content moderation infrastructure designed to protect us and end users from unwanted behavior.\nWork closely with our other engineers and researchers to utilize both industry standard and novel AI techniques to measure, monitor and improve AI models\u2019 alignment to human values. .\nDiagnose and remediate active incidents on the platform and build new tooling and infrastructure that address the root causes of system failure.\nYou Might Thrive In This Role If\nYou have built and run production services in a high growth, rapidly scaling environment.\nYou can debug live issues and restore systems quickly.\nYou have worked on content safety, fraud, or abuse, or are motivated and excited to work on present-day (\u201cnow-term\u201d) AI safety. \nYou have experience with Python or with modern languages such as C++, Rust, or Go, and are able to quickly ramp up on Python.\nYou understand the trade-offs of capabilities and risks and navigate them to deploy novel products and features safely. \nYou can critically assess risks of a new product or feature and devise innovative solutions to mitigate these risks without harming the product experience.\nYou\u2019re pragmatic. You know when to build a quick, good-enough fix, and when to invest in a robust, lasting solution.\nYou possess strong project management skills. You are self-directed and can remove roadblocks to drive projects to completion with minimal guidance.\nYou\u2019ve deployed classifiers or machine learning models, or are excited to learn about modern ML infra.\nOur tech stack\nOur infrastructure is built on Terraform, Kubernetes, Azure, Python, Postgres, and Kafka. While we value experience with these technologies, we are primarily looking for engineers with strong technical skills who understand the fundamental problems these tools solve, and can quickly pick up new tools and frameworks. \nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Software Engineer, AI Safety", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201250279", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Privacy Engineering Team at OpenAI is committed to integrating privacy as a foundational element in OpenAI's mission of advancing Artificial General Intelligence (AGI). Our focus is on all OpenAI products and systems handling user data, striving to uphold the highest standards of data privacy and security.\nWe build essential production services, develop novel privacy-preserving techniques, and equip cross-functional engineering and research partners with the necessary tools to ensure responsible data use. Our approach to prioritizing responsible data use is integral to OpenAI's mission of safely introducing AGI that offers widespread benefits.\nAbout The Role\nWe are looking for a Software Engineer with experience developing secure backend systems that prioritize customer data protection. This role is ideal for someone who is deeply committed to the nexus of product development, security, and privacy.\nThis position is located in San Francisco. Relocation assistance is available.\nIn This Role, You Will\nDesign, build, and implement back-end systems that power privacy and security functions within our API products and consumer applications.\nConduct threat modeling, privacy design reviews, and code-level assessments to ensure the highest privacy and security standards.\nCollaborate with product managers, and other engineering teams to develop new products that leverage emerging research while maintaining privacy and security integrity.\nWork closely with the legal team to document and evaluate internal compliance practices, ensuring alignment with legal requirements and organizational standards, and conduct thorough internal audits to maintain the highest levels of compliance and integrity.\nCoordinate and actively participate in privacy incident response efforts.\nYou Might Thrive In This Role If You\nHave substantial experience in building (and re-engineering) production systems to meet legal requirements, manage increased scale, and uphold privacy and security standards.\nHave led or been a significant contributor to security projects, demonstrating a cross-functional collaboration skill set.\nDeeply care about user experience and take pride in developing products that meet customer needs whilst drawing on experience in threat modeling, secure design, and regulatory compliance.\nPossess a humble attitude, strong communication skills, and an eagerness to support your colleagues, reflecting a readiness to do whatever is necessary for team success.\nTake responsibility for problems from beginning to end, demonstrating problem-solving abilities and preparedness to acquire any missing knowledge necessary to get the job done.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Software Engineer, Privacy", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4268560316", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nOpenAI\u2019s Inference team powers the deployment of our most advanced models - including our GPT models, 4o Image Generation, and Whisper - across a variety of platforms. Our work ensures these models are available, performant, and scalable in production, and we partner closely with Research to bring the next generation of models into the world. We're a small, fast-moving team of engineers focused on delivering a world-class developer experience while pushing the boundaries of what AI can do.\nWe\u2019re expanding into multimodal inference, building the infrastructure needed to serve models that handle image, audio, and other non-text modalities. These workloads are inherently more heterogeneous and experimental, involving diverse model sizes and interactions, more complex input/output formats, and tighter coordination with product and research.\nAbout The Role\nWe\u2019re looking for a software engineer to help us serve OpenAI\u2019s multimodal models at scale. You\u2019ll be part of a small team responsible for building reliable, high-performance infrastructure for serving real-time audio, image, and other MM workloads in production.\nThis work is inherently cross-functional: you\u2019ll collaborate directly with researchers training these models and with product teams defining new modalities of interaction. You'll build and optimize the systems that let users generate speech, understand images, and interact with models in ways far beyond text.\nIn This Role, You Will\nDesign and implement inference infrastructure for large-scale multimodal models.\nOptimize systems for high-throughput, low-latency delivery of image and audio inputs and outputs.\nEnable experimental research workflows to transition into reliable production services.\nCollaborate closely with researchers, infra teams, and product engineers to deploy state-of-the-art capabilities.\nContribute to system-level improvements including GPU utilization, tensor parallelism, and hardware abstraction layers.\nYou Might Thrive In This Role If You\nHave experience building and scaling inference systems for LLMs or multimodal models.\nHave worked with GPU-based ML workloads and understand the performance dynamics of large models, especially with complex data like images or audio.\nEnjoy experimental, fast-evolving work and collaborating closely with research.\nAre comfortable dealing with systems that span networking, distributed compute, and high-throughput data handling.\nHave familiarity with inference tooling like vLLM, TensorRT-LLM, or custom model parallel systems.\nOwn problems end-to-end and are excited to operate in ambiguous, fast-moving spaces.\nNice To Have\nExperience working with image generation or audio synthesis models in production.\nExposure to distributed ML training or system-efficient model design.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Software Engineer, Inference - Multi Modal", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4234473876", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe GTM (Go-To-Market) Innovation team is an internal powerhouse revolutionizing how we engage customers through groundbreaking applications of our technology. As an incubator, we amplify the impact of Sales, Technical Success, Enablement, and Revenue Operations by deploying our technology at scale. This team applies advanced capabilities to real-world interactions \u2014 reshaping conversations with customers, learning from every exchange, and finding novel ways to show the value of our technology.\nAbout The Role\nWe\u2019re looking for backend software engineers with a product mindset to join the GTM Innovation team.\nYou\u2019ll help OpenAI meet the world at scale. You\u2019ll partner closely with go-to-market teams to understand their workflows, identify leverage points, and ship novel solutions using OpenAI\u2019s API platform.\nYou\u2019ll move quickly from prototype to production, and your work will directly shape how customers experience our technology in the field. This role is ideal for engineers who want to be close to users, own end-to-end outcomes, and help define entirely new categories of enterprise software.\nIn This Role, You Will\nBuild high-impact applications and tools that accelerate OpenAI\u2019s go-to-market efforts\nWork across the full product lifecycle for GTM: prototype, iterate, ship, and maintain\nEmbed with Sales, Technical Success, and Revenue Operations to identify user needs and build for them\nApply OpenAI\u2019s models in novel ways to solve real-world customer and internal workflow problems\nTranslate learnings into feedback for Applied and Research teams to inform product development\nYou\u2019ll Thrive In This Role If You\nHave 4+ years of experience as a software/ML/product engineer working on user-facing systems\nFormer founder, or early engineer at a startup who built a product from scratch is a plus\nAre fluent in Python or JavaScript and comfortable building full-stack applications\nHave built or prototyped LLM-powered workflows using the OpenAI API (or similar)\nTake initiative, move quickly, and operate with a strong sense of ownership\nEnjoy working closely with end users and shaping 0\u21921 products\nAre collaborative, curious, and motivated to make an outsized impact at the frontier of AI\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $255K - $405K", "comp": "$255,000.00", "title": "Backend Software Engineer, GTM Innovation", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4249798671", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nOpenAI is dedicated to ensuring that our AI systems are safe, trustworthy, useful, and consistently aligned with human values, even as they scale in complexity and capability. Our research focuses on methods that help AI reliably follow human intent in diverse scenarios\u2014including adversarial or high-stakes settings\u2014and ultimately maximize its benefit to individuals and society.\nA critical component of our approach involves leveraging high-quality human and synthetic data to train and evaluate models, ensuring alignment techniques remain effective as capabilities grow. We work with experts across domains and modalities to develop scalable methods for generating high-quality data, and using it to produce safe and useful models.\nThe two pillars of our approach are: (1) harnessing improved capabilities into alignment, making sure that our alignment techniques improve, rather than break, as capabilities grow, and (2) centering humans by developing mechanisms and interfaces that enable humans to both express their intent and to effectively supervise and control AIs, even in highly complex situations.\nWe're looking for individuals with strong ML engineering skills, research experience, and a deep understanding of Human-Machine Interaction challenges, especially with novel and highly capable models.\nAbout The Role\nAs a Research Engineer, you will:\nResearch and model mechanisms that create value for people, with an emphasis on explaining or predicting preferences, behaviors, and satisfaction.\nQuantify the nuances of human behavior and capture them in data-driven systems, whether by designing advanced labeling tasks or analyzing user feedback patterns\nDesign robust evaluations for measuring alignment and real-world utility, iterating quickly to uncover what makes certain feedback and training protocols more effective.\nDesign and evaluate new Human-AI-interaction paradigms and scalable oversight methods that redefine how humans interact with, understand, and supervise our models.\nDevelop and evaluate alignment capabilities that are subjective, context-dependent, and hard to measure.\nYou Might Thrive In This Role If You\nHave experience with machine learning frameworks (e.g., PyTorch) and are comfortable experimenting with large-scale models.\nEnjoy moving fluidly between high-level research questions and low-level implementation details, adapting methods to solve ambiguous, dynamic problems.\nAre goal-oriented instead of method-oriented, and are not afraid of tedious but high-value work when needed.\nHave an interest or background in cognitive science, computational linguistics, human-computer interaction, or social sciences. \nAre strongly motivated by OpenAI\u2019s mission of building safe, universally beneficial AGI and are aligned with OpenAI\u2019s charter\nWant to work on systems that balance breakthrough capabilities with robust alignment, ultimately shaping a safer and more human-centered AI landscape.\nExcel in fast-paced, collaborative, and cutting-edge research environments.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Research Engineer, Human-Centered AI", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201896170", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nOur Inference team brings OpenAI\u2019s most capable research and technology to the world through our products. We empower consumers, enterprise and developers alike to use and access our start-of-the-art AI models, allowing them to do things that they\u2019ve never been able to before. We focus on performant and efficient model inference, as well as accelerating research progression via model inference.\nAbout The Role\nWe are looking for an engineer who wants to take the world's largest and most capable AI models and optimize them for use in a high-volume, low-latency, and high-availability production and research environment.\nIn This Role, You Will\nWork alongside machine learning researchers, engineers, and product managers to bring our latest technologies into production.\nWork alongside researchers to enable advanced research through awesome engineering.\nIntroduce new techniques, tools, and architecture that improve the performance, latency, throughput, and efficiency of our model inference stack.\nBuild tools to give us visibility into our bottlenecks and sources of instability and then design and implement solutions to address the highest priority issues.\nOptimize our code and fleet of Azure VMs to utilize every FLOP and every GB of GPU RAM of our hardware.\nYou Might Thrive In This Role If You\nHave an understanding of modern ML architectures and an intuition for how to optimize their performance, particularly for inference.\nOwn problems end-to-end, and are willing to pick up whatever knowledge you're missing to get the job done.\nHave at least 5 years of professional software engineering experience.\nHave or can quickly gain familiarity with PyTorch, NVidia GPUs and the software stacks that optimize them (e.g. NCCL, CUDA), as well as HPC technologies such as InfiniBand, MPI, NVLink, etc.\nHave experience architecting, building, observing, and debugging production distributed systems. Bonus point if worked on performance-critical distributed systems.\nHave needed to rebuild or substantially refactor production systems several times over due to rapidly increasing scale.\nAre self-directed and enjoy figuring out the most important problem to work on. \nHave a humble attitude, an eagerness to help your colleagues, and a desire to do whatever it takes to make the team succeed.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Software Engineer, Model Inference", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201248494", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Post-Training team is responsible for training and improving pre-trained models to be deployed into ChatGPT, the API, and potential future products. The team partners closely with research and product teams across the company, and conducts research as a final step to prepare for real world deployment to millions of users, ensuring that our models are safe, efficient, and reliable.\nAbout The Role\nAs a Research Engineer / Scientist, you will research and develop improvements to our models. Our team works in research areas combining reinforcement learning and products.\nWe're looking for individuals with strong ML engineering skills and research experience, especially with novel and highly capable models. An ideal candidate is passionate about product-driven research.\nThis role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nIn This Role, You Will\nOwn and pursue a research agenda to improve model capability and performance.\nCollaborate closely with the other research and product teams, allowing customers to optimize their own models.\nBuild robust evaluations for tracking modeling improvements.\nDesign, implement, test, and debug code across our research stack.\nYou Might Thrive In This Role If You\nHave a deep understanding of machine learning and machine learning applications.\nHave a working knowledge of relevant models, and building evaluations for model capability improvement.\nAre comfortable diving into a large ML codebase to debug.\nThrive in a dynamic and technically complex environment.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Research Engineer / Research Scientist, Post-Training", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4235535983", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nOpenAI\u2019s Applications Engineering organization builds and operates the products that bring our cutting-edge research to millions of users and developers worldwide. We power products such as ChatGPT, the OpenAI API, and emerging AI-native applications. Our teams span product engineering, infrastructure, and safety, working together to ensure that OpenAI\u2019s technology is delivered with reliability, security, and a world-class user experience.\nAbout The Role\nWe\u2019re seeking iOS engineers to craft and evolve the ChatGPT iOS app and future AI-powered mobile experiences. You\u2019ll build new features, optimize performance, and integrate the latest Apple platform capabilities to deliver a seamless, delightful assistant in every user\u2019s pocket.\nIn This Role, You Will\nBuild and ship new experiences on iOS that showcase the power of AI.\nOptimize app performance, reliability, and responsiveness at global scale.\nEstablish robust testing frameworks and refine app architecture for long-term maintainability.\nCollaborate with product, design, research, and backend teams to deliver high-impact features.\nProvide technical leadership to shape the future of OpenAI\u2019s iOS platform.\nYou Might Thrive In This Role If You\nHave up to 6 years of professional software engineering experience.\nHave a proven track record of building high-quality iOS applications in production.\nAre fluent in Swift and familiar with the Apple development ecosystem (Xcode, UIKit/SwiftUI).\nPrioritize performance, security, and user experience in mobile development.\nEnjoy working cross-functionally to bring ambitious product ideas to life.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Software Engineer, iOS", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4302947447", "loc": "New York City Metropolitan Area", "company": "OpenAI"}, {"desc": "About The Team\nThe Workload Networking team is responsible for the collective communication stack used in our largest training jobs. Using a combination of C++ and CUDA we work on novel collective communication techniques that enable efficient training of our flagship models on our largest custom built supercomputers.\nThe models we train are key ingredients to the AI research progress at OpenAI and the field as a whole, and we continually incorporate learnings from our entire research org into our training platform.\nAbout The Role\nAs a Software Engineer, Networking you will design and implement custom networking collectives that are tightly integrated into our training stack.\nWe\u2019re looking for people who have a background in low level performance critical software. Experience with collective communication is a bonus.\nThis role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nIn This Role, You Will\nCollaborate closely with ML researchers to design and implement efficient collective operations in C++ and CUDA.\nEnsure that our largest training jobs take full advantage of the different network transports used in our supercomputers.\nWork on simulations to inform our future supercomputer network designs. \nYou Might Thrive In This Role If You\nHave written distributed algorithms using RDMA in the past.\nAre comfortable writing low level performance sensitive CPU and/or GPU code.\nAre familiar with network simulation techniques.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Software Engineer, Collective Communication", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201250289", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nOpenAI is at the forefront of artificial intelligence, driving innovation and shaping the future with cutting-edge research. Our mission is to ensure that AI's benefits reach everyone. We are looking for visionary Research Engineers to join our Applied Group, where you'll transform groundbreaking research into real-world applications that can change industries, enhance human creativity, and solve complex problems.\nAbout The Role\nAs a Research Engineer in OpenAI's Applied Group, you will have the opportunity to work with some of the brightest minds in AI. You'll contribute to deploying state-of-the-art models in production environments, helping turn research breakthroughs into tangible solutions. If you're excited about making AI technology accessible and impactful, this role is your chance to make a significant mark.\nIn This Role, You Will\nInnovate and Deploy: Design and deploy advanced machine learning models that solve real-world problems. Bring OpenAI's research from concept to implementation, creating AI-driven applications with a direct impact.\nCollaborate with the Best: Work closely with researchers, software engineers, and product managers to understand complex business challenges and deliver AI-powered solutions. Be part of a dynamic team where ideas flow freely and creativity thrives.\nOptimize and Scale: Implement scalable data pipelines, optimize models for performance and accuracy, and ensure they are production-ready. Contribute to projects that require cutting-edge technology and innovative approaches.\nLearn and Lead: Stay ahead of the curve by engaging with the latest developments in machine learning and AI. Take part in code reviews, share knowledge, and lead by example to maintain high-quality engineering practices.\nMake a Difference: Monitor and maintain deployed models to ensure they continue delivering value. Your work will directly influence how AI benefits individuals, businesses, and society at large.\nYou Might Thrive In This Role If You\nMaster's/ PhD degree in Computer Science, Machine Learning, Data Science, or a related field. \nDemonstrated experience in deep learning and transformers models\nProficiency in frameworks like PyTorch or Tensorflow\nStrong foundation in data structures, algorithms, and software engineering principles.\nExperience with search relevance, ads ranking or LLMs is a plus.\nAre familiar with methods of training and fine-tuning large language models, such as distillation, supervised fine-tuning, and policy optimization\nExcellent problem-solving and analytical skills, with a proactive approach to challenges.\nAbility to work collaboratively with cross-functional teams.\nAbility to move fast in an environment where things are sometimes loosely defined and may have competing priorities or deadlines\nEnjoy owning the problems end-to-end, and are willing to pick up whatever knowledge you're missing to get the job done\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Research Engineer, Applied AI Engineering", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201889860", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nSecurity is at the foundation of OpenAI\u2019s mission to ensure that artificial general intelligence benefits all of humanity.\nThe Security team protects OpenAI\u2019s technology, people, and products. We are technical in what we build but are operational in how we do our work, and are committed to supporting all products and research at OpenAI. Our Security team tenets include: prioritizing for impact, enabling researchers, preparing for future transformative technologies, and engaging a robust security culture.\nAbout The Role\nWe are seeking a Software Engineer, Security Observability to join our Security team. In this role, you will be responsible for building secure, scalable systems that enhance our security observability infrastructure. Leveraging your strong engineering skills, you will collaborate with cross-functional teams to develop, deploy, and maintain robust software solutions that support our security and detection capabilities.\nThis role is open to remote employees, or relocation assistance is available to one of our OpenAI offices in San Francisco, Seattle, or New York City.\nIn This Role, You Will\nDesign and develop scalable software systems that facilitate security observability across our infrastructure.\nBuild and maintain data pipelines that centralize and store security-relevant data from diverse sources.\nProactively improve the resilience and reliability of data systems to ensure high platform availability\nCollaborate closely with Detection & Response (D&R) and other security teams to reduce the company\u2019s security risk.\nContribute to data engineering in support of forensic investigations and compliance efforts.\nYou Might Thrive In This Role If You Have\nStrong software engineering experience, with proficiency in programming languages such as Python, Golang, or similar.\nA background in infrastructure as code, with experience using tools like Terraform and working with cloud platforms such as Azure.\nExperience with building and maintaining data pipelines, particularly for security-related use cases.\nA generalist engineering mindset, with the flexibility to pivot between various technical domains such as databases, site reliability engineering (SRE), or security.\nThe ability to collaborate effectively with security and engineering teams to understand evolving data needs and implement scalable solutions.\nA proactive and detail-oriented approach to problem-solving, with a focus on improving security data visibility and forensic capabilities.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $325K - $405K", "comp": "$325,000.00", "title": "Software Engineer, Security Observability", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4279838557", "loc": "New York, NY", "company": "OpenAI"}, {"desc": "About The Team\nThe Fleet team at OpenAI supports the computing environment that powers our cutting-edge research and product development. We oversee large-scale systems that span data centers, GPUs, networking, and more, ensuring high availability, performance, and efficiency. Our work enables OpenAI\u2019s models to operate seamlessly at scale, supporting both internal research and external products like ChatGPT. We prioritize safety, reliability, and responsible AI deployment over unchecked growth.\nAbout The Role\nAs a software engineer on the Fleet High Performance Computing (HPC) team, you will be responsible for the reliability and uptime of all of OpenAI\u2019s compute fleet. Minimizing hardware failure is key to research training progress and stable services, as even a single hardware hiccup can cause significant disruptions. With increasingly large supercomputers, the stakes continue to rise.\nBeing at the forefront of technology means that we are often the pioneers in troubleshooting these state-of-the-art systems at scale. This is a unique opportunity to work with cutting-edge technologies and devise innovative solutions to maintain the health and efficiency of our supercomputing infrastructure.\nOur team empowers strong engineers with a high degree of autonomy and ownership, as well as ability to effect change. This role will require a keen focus on system-level comprehensive investigations and the development of automated solutions. We want people who go deep on problems, investigate as thoroughly as possible, and build automation for detection and remediation at scale.\nIn This Role, You Will\nBuild and maintain automation systems for provisioning and managing server fleets.\nDevelop tools to monitor server health, performance, and lifecycle events.\nCollaborate with clusters, networking, and infrastructure teams.\nPartner with external operators to ensure a high level of quality.\nIdentify and fix performance bottlenecks and inefficiencies.\nContinuously improve automation to reduce manual work.\nYou Might Thrive In This Role If You Have\nExperience managing large-scale server environments.\nA balance of strengths in building and operationalizing.\nProficiency in Python, Go, or similar languages.\nStrong Linux, networking, and server hardware knowledge.\nComfort digging into noisy data with SQL, PromQL, and Pandas or any other tool.\nBonus Skills\nPrior hardware expertise is not required for this role.\nExperience with low level details of hardware components, protocols, and associated Linux tooling (e.g., PCIe, Infiniband, networking, power management, kernel perf tuning)\nKnowledge of hardware management protocols (e.g., IPMI, Redfish).\nHigh-performance computing (HPC) or distributed systems experience.\nPrior experience developing, managing, or designing hardware.\nFamiliarity with monitoring tools (e.g., Prometheus, Grafana).\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $325K - $590K", "comp": "$325,000.00", "title": "Software Engineer, GPU Infrastructure - HPC", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4244087611", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nWe are the Online Storage team powering ChatGPT, Sora, and the OpenAI APIs. We\u2019re a growing team set up to own the databases and online\u2011storage infrastructure that serve all our products.\nAbout The Role\nAs OpenAI scales, we\u2019re seeking experienced, problem\u2011solving engineers to build robust, high\u2011performance, and scalable database systems. Our ability to rapidly iterate on products while ensuring reliability and speed is key to our success.\nYou\u2019ll work in a fast\u2011paced, collaborative environment, building systems that serve hundreds of millions of users globally, with a strong emphasis on safety, reliability, and performance.\nWe\u2019re hiring skilled software engineers to join the Online Storage team. You\u2019ll help design and build a large\u2011scale database, collaborate with various product teams to scale it to meet their needs, and own operational excellence by defining SLAs and KPIs that directly satisfy stakeholder expectations. This is a critical role for engineers who thrive on solving complex, large\u2011scale challenges and are passionate about building resilient systems that perform under load.\nIn This Role, You Will\nDesign and build highly scalable, reliable, and performant database\nDesign and build highly simple and intuitive APIs for the underlying database\nAnalyze and resolve performance and scalability bottlenecks to improve overall system efficiency\nDebug, instrument, and fix system issues \u2014 from pinpointing root causes to delivering long-term solutions\nDefine technical strategy and guide the development of robust infrastructure that supports high-scale production systems and evolving business needs\nCollaborate closely with product teams to deeply understand requirements and deliver impactful solutions\nBoost engineering productivity by building intuitive tools and systems that empower fellow developers\nOwn the reliability of the systems you build, including participating in an on-call rotation to address critical incidents\nYou Might Thrive In This Role If You\nHave experience building (and rebuilding) production systems to support new product capabilities and growing scale\nCare deeply about the end-user experience and take pride in solving real customer needs\nEmbrace a humble, collaborative mindset and go the extra mile to support your teammates and the broader mission\nOwn problems end-to-end \u2014 you're comfortable learning on the fly to fill gaps and get things done\nBuild internal tools that improve workflows when off-the-shelf solutions fall short\nHave hands-on experience with distributed systems such as data storage, caching, search, or other backend infrastructure components\nPrioritize the reliability, scalability, and performance of large-scale systems\nThrive in ambiguous, fast-paced environments and enjoy iterating rapidly on product and research initiatives\nQualifications\n4+ years of industry experience, including 2+ years leading large-scale, complex projects or technical initiatives as an engineer or tech lead\nStrong passion for building distributed systems at scale, with a focus on reliability, scalability, security, and continuous improvement\nExpertise in systems programming, with hands-on experience in multi-threading and concurrency; proficiency in C++ and/or Python is highly preferred\nPreferably, domain experience in areas such as databases, large-scale data systems, storage, caching, search, or other core components of distributed infrastructure\nExcellent communication skills, with the ability to build consensus across diverse technical and non-technical stakeholders\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Software Engineer, Online Storage", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4208845030", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Intelligence & Investigations Engineering team builds systems that detect, analyze, and disrupt abuse across OpenAI\u2019s products. We partner closely with the Child Safety team and cross-functional groups to protect users while advancing OpenAI\u2019s goal of developing AI that benefits everyone.\nAbout The Role\nAs a Fullstack Engineer focused on child safety, you\u2019ll build data-intensive, AI-powered applications and infrastructure that enable operators and investigators to work effectively and responsibly. You\u2019ll adapt quickly in ambiguous, fast-moving environments to deliver well-crafted, reliable tooling for high-severity safety work.\nThis role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nCandidates should understand this role involves exposure to sensitive and egregious content.\nIn This Role, You Will\nPrototype, build, and maintain intelligence systems that detect, triage, and enable efficient human review of possible high severity harm\nWork hand in hand with operators and investigators, designing and delivering systems that enable them to do their work faster, more accurately, and more safely.\nDevelop across the stack: UIs, services, pipelines, and anything else required to solve the problems we face.\nInteract with partners across Product Policy, Platform Integrity, Safety Systems, and Research\nContribute to the team\u2019s technical strategy, especially for child safety related tools and systems\nReport on impact in a data-driven fashion\nYou Might Thrive In This Role If You\nHave a strong software engineering foundation and enjoy owning systems end-to-end\u2014from infrastructure and data ingestion to frontend tooling\nAre energized by working at the frontier of AI capabilities, integrating new models and APIs into practical systems\nHave experience building and operating large-scale data pipelines or search/retrieval systems\nAre proficient in Python and/or TypeScript, and familiar with tools like Spark, Kafka, Flink, data warehouses, and SQL\nTake a product-minded approach, design with user workflows in mind, and iterate quickly based on feedback\nFavor pragmatic solutions and can ship in hacky, low-support environments when needed\nAre comfortable navigating ambiguity and open-ended problem spaces with evolving goals\nHave prior experience working on engineering for high-severity harms\nBring intuition for the pain points and workflows of operations and investigative teams, and curiosity about solving complex investigations\nBonus: prior knowledge of child-safety-specific challenges such as secure handling of quarantined content and reporting to NCMEC\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Fullstack Engineer, Child Safety Tools & Systems", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4301435412", "loc": "United States", "company": "OpenAI"}, {"desc": "About The Team\nOpenAI\u2019s Applications Engineering team engineers, owns, and evolves OpenAI\u2019s core productivity ecosystem\u2014not simply as custodians of SaaS solutions, but by building custom tools, integrations, and automation that solve problems off-the-shelf software cannot. With a company-wide lens and deep technical expertise, we bridge gaps between teams, operationalize applications for scale, and deliver secure, seamless, and innovative employee experiences. We proactively design and develop custom solutions where required, creating paved paths that reduce friction, improve productivity, and enable other teams to focus on their core missions.\nAbout The Role\nAs a \nSoftware Engineer: Internal Applications, Enterprise\n, you are tasked with enhancing employee technology services through automation, Infrastructure-as-Code (IaC), and the development of workforce tooling. You will leverage OpenAI's models to optimize identity and access management (IAM) systems, build applications and dashboards for internal users, and streamline complex workflows through automation. This role involves designing and implementing efficient, secure, and scalable solutions, including intelligent Slack bots and integrations to improve operational efficiency and user experience.\nWe are seeking individuals passionate about leveraging automation and software engineering to solve complex workforce technology challenges. You should have a strong background in infrastructure automation, cloud services, and a deep understanding of identity management solutions. Your ability to build scalable and resilient systems, coupled with a problem-solving mindset, will be key to success in this role.\nIn This Role, You Will\nDesign, build, implement, and maintain secure, scalable, and performant workforce technology infrastructure, automation workflows, and bespoke tooling that improves the OpenAI employee experience.\nDeliver critical IT efficiencies and automation through both bespoke software development and first-party tooling to enhance technology service delivery.\nEmploy modern Infrastructure-as-Code (IaC) methodologies, developing GitOps-driven solutions to manage technology workflows at scale.\nBuild and maintain CI/CD pipelines for corporate infrastructure, deploying to progressively tested environments across multiple clouds (Azure, AWS, GCP).\nCreate scalable internal tools and dashboards to optimize workflows and improve visibility into engineering operations.\nDesign and manage internal integrations, including Slack bots and workflow automation solutions.\nSupport IAM processes by automating access provisioning and lifecycle management for internal applications.\nCollaborate with the IAM team to manage cloud-based identity and access controls, ensuring compliance with security policies and standards for internal applications.\nCollaborate with security teams to align technology automation initiatives with Zero Trust principles and compliance frameworks.\nImplement role-based access controls (RBAC) and mitigate security risks through automated policies.\nWork cross-functionally to identify areas for corporate technology service improvement and implement self-service solutions.\nManage multiple projects and initiatives, ensuring efficiency and alignment with business objectives.\nYou may be a fit for this role if you have:\nProficiency in a modern programming language, ideally Python.\nStrong knowledge of and experience with cloud platforms (Azure, AWS, GCP) and infrastructure management.\nDeep knowledge and experience managing corporate infrastructure at scale with Infrastructure-as-Code (IaC) practices & GitOps workflows (Terraform, Ansible, Chef, etc.) as well as cloud automation best practices.\nExperience integrating corporate infrastructure with CI/CD pipelines and DevOps workflows.\nProven track record of developing and maintaining internal tools to streamline corporate technology and business processes.\nDemonstrated experience developing internal automation solutions, such as Slack bots and integrations.\nStrong understanding of role-based access controls (RBAC) and security principles.\nExperience working with enterprise technology services and optimizing workflows at scale.\nExcellent stakeholder management skills and ability to work cross-functionally with IT, security, and business teams.\nClear and concise communication skills to explain technical concepts to both technical and non-technical audiences.\nA self-starter with strong analytical and problem-solving skills.\nYou Might Thrive In This Role If You Have\nExperience with front end application and UX development (React, Typescript, etc.)\nExperience with containerization technologies such as Docker and Kubernetes.\nFamiliarity with compliance frameworks such as SOC 2, ISO 27001, FedRAMP, and NIST.\nA security thought leader with contributions to Enterprise Applications & IAM-related open-source projects or technical communities.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $255K - $325K", "comp": "$255,000.00", "title": "Software Engineer, Internal Applications - Enterprise", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4293149960", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Sora team is pioneering multimodal capabilities for OpenAI\u2019s foundation models. We\u2019re a hybrid research and product team focused on integrating multimodal functionalities into our AI products, ensuring they are reliable, user-friendly, and aligned with our mission of broad societal benefit.\nAbout The Role\nWe\u2019re looking for a GPU Inference Engineer to contribute to improvements in model serving efficiency for Sora. This is a high-impact role where you\u2019ll drive initiatives to optimize inference performance and scalability. You\u2019ll also be engaged in model design, to help assist our researchers in developing inference-friendly models.\nThis role is critical to scaling the team\u2019s broader goals - it will directly enable leadership to focus on higher-leverage initiatives by building a stronger technical foundation.\nIn This Role You Will\nPerform engineering efforts focused on improving model serving, inference performance, and system efficiency\nDrive optimizations from a kernel and data movement perspective to improve system throughput and reliability\nPartner closely with research and product teams to ensure our models perform effectively at scale\nDesign, build, and improve critical serving infrastructure to support Sora\u2019s growth and reliability needs\nYou Might Thrive In This Role If You\nHave deep expertise in model performance optimization, particularly at the inference layer\nHave a strong background in kernel-level systems, data movement, and low-level performance tuning\nAre excited about scaling high-performing AI systems that serve real-world, multimodal workloads\nCan navigate ambiguity, set technical direction, and drive complex initiatives to completion\nThis role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $380K", "comp": "0", "title": "Software Engineer, GPU Inference", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4247626420", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "Location:\n San Francisco, CA (Hybrid: 4 days onsite/week). Relocation assistance available.\nAbout The Team\nWe build foundational imaging and perception capabilities that enable high\u2011quality visual experiences. The team works across platform, systems, and ML partners to deliver reliable, efficient solutions from concept through launch.\nAbout The Role\nWe\u2019re seeking an Imaging & Perception Software Engineer to design, implement, and optimize end\u2011to\u2011end imaging pipelines and perception features. You\u2019ll work across system layers\u2014from capture and synchronization to processing and delivery\u2014focusing on performance, quality, and robust integrations.\nIn This Role, You Will\nDesign, implement, and optimize imaging pipeline components and related platform services.\nDevelop interfaces and services for ingest, control, synchronization, and processing of visual data.\nImplement and tune core image\u2011quality and perception features using modern frameworks.\nBuild calibration, evaluation, and tuning workflows with clear quality metrics.\nOptimize algorithms for heterogeneous compute targets with attention to latency, power, and throughput.\nCollaborate with cross\u2011functional teams to integrate features end\u2011to\u2011end and validate at scale.\nEstablish strong engineering practices: code review, CI, reproducible builds, and release hygiene.\nYou Might Thrive In This Role If You\nHave shipped imaging or perception functionality in production environments.\nAre proficient in C++ and a scripting language (e.g., Python), and comfortable with performance\u2011sensitive systems software.\nUnderstand image processing, sensor fusion concepts, and metric\u2011driven quality evaluation.\nAre familiar with modern vision/imaging frameworks and ML deployment toolchains.\nExcel at debugging, profiling, and optimizing complex systems.\nPreferred Qualifications\nExperience with real\u2011time media frameworks and platform APIs.\nBackground in calibration, color/denoise/sharpen pipelines, or exposure/focus/white\u2011balance control.\nExperience optimizing for heterogeneous compute and memory architectures.\nContributions to open\u2011source imaging, media, or perception projects.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Camera Software Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4279843577", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nSecurity Products is a new business unit on a mission to transform cybersecurity by leveraging AI to give defenders a decisive advantage. We\u2019re building products that tackle some of the hardest, highest-impact problems in the field. We\u2019re starting with tools that are already proving their value internally at OpenAI, helping to protect our own systems. We operate with speed, purpose, and a deep sense of responsibility, partnering across engineering, research, and security to deliver real-world impact.\nAbout The Role\nAs a Full-Stack Software Engineer on the Security Products team, you\u2019ll play a key role in building the core systems that power our AI-powered cybersecurity products. You\u2019ll work as part of a small team to design, implement, and scale user-facing features, backend services, and integrations. This is a fast-moving, high-impact role where you\u2019ll collaborate closely with security experts, AI researchers, and other engineers to bring advanced AI capabilities into real-world security workflows. You'll help shape not just the product, but also the technical foundation and engineering culture of a rapidly growing team with a critical mission.\nYou\u2019ll Be Responsible For\nDeveloping, deploying, and maintaining systems and infrastructure to bring our security capabilities to users.\nTalking to users (internal and external) to understand their problems and designing solutions to address them.\nDesigning and implementing systems that integrate cutting-edge technologies to enhance security outcomes.\nCollaborating with a cross-functional team of engineers, researchers, product managers, designers, and operations personnel to create cutting-edge products.\nTroubleshooting and optimizing systems to improve performance, reliability, and security.\nOperating with agility, creativity, and a collaborative spirit.\nStaying informed about emerging AI technologies and security threats to help guide our technical direction.\nWe\u2019re Looking For Someone With\n5+ years of relevant engineering experience at technology and product-driven companies.\nProficiency with JavaScript, React, and other web technologies.\nProficiency in one or more backend programming languages such as Python, Go, or similar.\nExperience with public cloud infrastructure (e.g. Azure, AWS) and orchestration frameworks (e.g. Kubernetes, Terraform).\nInterest in security-related practices, such as secure coding, threat modeling, or detection systems (direct experience not required).\nInterest in AI/ML (direct experience not required).\nAbility to move fast in an environment where things are sometimes loosely defined and may have competing priorities or deadlines.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $325K - $490K", "comp": "$325,000.00", "title": "Software Engineer, Security Products", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4275244555", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "Location: San Francisco, CA (Hybrid: 4 days onsite/week). Relocation assistance available.\nAbout The Team\nWe develop foundational control and motion software that enables precise, reliable actuation across complex systems. The team partners closely with adjacent hardware, firmware, and software groups to deliver robust capabilities from concept through launch.\nAbout The Role\nWe\u2019re seeking a Control Systems Software Engineer to design, implement, and tune real\u2011time control algorithms and the software infrastructure around them. You\u2019ll focus on feedback\u2011based control, performance optimization, and dependable integration across sensing, actuation, and platform software.\nIn This Role, You Will\nDevelop, tune, and validate real\u2011time control algorithms for precise motion and actuation.\nImplement closed\u2011loop control techniques and controller tuning strategies.\nDesign and integrate feedback systems using common position/velocity/torque sensing approaches.\nCollaborate with partner teams to align control interfaces with platform and electronics constraints.\nImplement control loops and support libraries in a systems language with attention to timing and reliability.\nTest, debug, and optimize control performance across a range of operating conditions.\nLeverage modeling and simulation to inform control architecture and parameter selection.\nYou Might Thrive In This Role If You\nHave strong knowledge of feedback control, controller tuning, and real\u2011time implementation considerations.\nAre proficient in a systems programming language (e.g., C/C++)\nAre comfortable with system modeling, identification, and closed\u2011loop analysis.\nCollaborate effectively with mechanical, electrical, firmware, and software partners.\nCommunicate clearly and document designs, interfaces, and test results.\nPreferred Qualifications\nExperience with modeling/simulation tools and multi\u2011body or dynamic\u2011system analysis.\nBackground in precision motion, stabilization, or automation systems.\nFamiliarity with power\u2011stage fundamentals and actuation drive concepts.\nExposure to telemetry, diagnostics, and observability for real\u2011time systems.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Controls Software Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4278270903", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Developer Experience team at OpenAI has a singular focus: empowering developers globally. Our mission is to provide every developer and startup on the planet with the most delightful and seamless experience to integrate AI into their applications and products. We ensure developers have the tools, resources, and support they need to unlock AI\u2019s full potential.\nWe craft inspiring demos, powerful developer tools, sample projects, and engaging content to show how to build great applications with our frontier models such as OpenAI o3 and GPT-4.1, multimodal capabilities, and agents like Codex.\nWe collaborate closely with product, engineering, research, and GTM teams to ensure the developer journey\u2014from initial API call to full production deployment\u2014is seamless, effective, and delightful.\nAbout The Role\nAs a Developer Experience Engineer, you will create compelling technical content, developer tools, and sample applications designed to inspire developers and enable them to succeed with OpenAI\u2019s APIs, platform, and products for developers.\nYou will engage with developers and technical founders, demonstrating best practices and building innovative applications powered by frontier models, multimodal capabilities, and tools like Codex.\nWe\u2019re looking for people who combine strong technical skills, creativity, and a passion for engaging with and empowering developers.\nIn This Role, You Will\nDevelop demos and sample applications demonstrating cutting-edge integrations and best practices using reasoning models, multimodal capabilities, and agent tools.\nCreate high-quality technical content\u2014including tutorials, blog posts, videos, and code samples\u2014to educate and inspire the developer community about our models, APIs, and Codex.\nActively engage with and foster a vibrant local and global developer ecosystem around OpenAI\u2019s platform.\nRepresent OpenAI at developer events and online platforms, serving as a knowledgeable, approachable advocate for developers.\nGather and synthesize developer feedback to inform and enhance our product roadmap.\nCollaborate cross-functionally with product, engineering, and marketing teams to ensure adoption and success of OpenAI\u2019s developer tools and APIs.\nContribute directly to improving and refining OpenAI\u2019s developer interfaces and surfaces.\nOwn challenges end-to-end, proactively addressing gaps and acquiring new skills to resolve complex issues.\nYou Might Thrive In This Role If You\nAre passionate about crafting exceptional developer experiences and creating inspirational technical content and projects.\nBring a robust full-stack engineering background with demonstrated experience building innovative applications using AI and large language models (LLMs).\nHave strong user empathy and care deeply about delivering experiences developers truly appreciate.\nHave a proven track record of successfully creating engaging technical content, compelling demos, or innovative developer tooling that accelerates technology adoption.\nFind joy in coding, continuously shipping high-quality, impactful software.\nExcel in dynamic environments characterized by rapidly evolving priorities, ambiguity, and competing deadlines.\nAre an exceptional collaborator who thrives working cross-functionally and enjoys partnering with diverse teams.\nMaintain a genuine commitment to AI ethics and safety, strongly aligning with OpenAI's responsible AI development principles.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $280K - $345K", "comp": "$280,000.00", "title": "Developer Experience Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4250302588", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "Overview\nThe Data Acquisition team within the Foundations organization at OpenAI is responsible for all aspects of data collection to support our model training operations. Our team manages web crawling and GPTBot services and works closely with Data Processing, Architecture, and Scaling teams. We are looking for a skilled Senior Software Engineer to join our Data Acquisition team.\nResponsibilities\nOwn and lead engineering projects in the area of data acquisition including web crawling, data ingestion, and search.\nCollaborate with other sub-teams, such as Data Processing, Architecture, and Scaling, to ensure smooth data flow and system operability.\nWork closely with the legal team to handle any compliance or data privacy-related matters.\nDevelop and deploy highly scalable distributed systems capable of handling petabytes of data.\nArchitect and implement algorithms for data indexing and search capabilities.\nBuild and maintain backend services for data storage, including work with key-value databases and synchronization.\nDeploy solutions in a Kubernetes Infrastructure-as-Code environment and perform routine system checks.\nConduct and analyze experiments on data to provide insights into system performance.\nQualifications\nBS/MS/PhD in Computer Science or a related field.\n6+ years of industry experience in software development.\nExperience with large web crawlers a plus\nStrong expertise in large stateful distributed systems and data processing.\nProficiency in Kubernetes, and Infrastructure-as-Code concepts.\nWillingness and enthusiasm for trying new approaches and technologies.\nAbility to handle multiple tasks and adapt to changing priorities.\nStrong communication skills, both written and verbal.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Senior Software Engineer, Data Acquisition", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201892614", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Sora team is working on making video a key capability of OpenAI\u2019s foundation models. We are a hybrid research and product team that seeks to understand and expand the capabilities of our video models, while ensuring their reliability and safety. We accomplish this both through directly studying and experimenting with the models, as well as deploying them into the real-world to distribute their benefits widely.\nAbout The Role\nAs a Distributed Systems/ML engineer, you will work on improving the training throughput for our internal training framework and enable researchers to experiment with new ideas. This requires good engineering (for example designing, implementing, and optimizing state-of-the-art AI models), writing bug-free machine learning code (surprisingly difficult!), and acquiring deep knowledge of the performance of supercomputers. We\u2019re looking for people who love optimizing performance, understanding distributed systems, and who cannot stand having bugs in their code.\nThis role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nIn This Role, You Will\nCollaborate with researchers to enable them to develop systems-efficient video models and architectures\nApply the latest techniques to our internal training framework to achieve impressive hardware efficiency for our training runs\nProfile and optimize our training framework\nYou Might Thrive In This Role If You\nHave experience working with multi-modal ML pipelines\nLove diving deep into systems implementations and understanding their fundamentals in order to improve their performance and maintainability\nHave strong software engineering skills and are proficient in Python.\nHave experience understanding and optimizing training kernels\nAre passionate about understanding stable training dynamics\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Distributed Training Engineer, Sora", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201245598", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Role\nAs an early member of our Data team within the Go-To-Market (GTM) organization, you will play a pivotal role in building a data-centric culture, enhancing decision-making processes, and driving strategic initiatives through analytics. This role involves a variety of projects aimed at developing canonical data sources and dashboards that enable the business to derive trustworthy, actionable insights. Most importantly, you should expect to be a core member of the GTM team, helping to bring our technology to a wide range of customers and supporting our self serve and sales led motions.\nThis role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nIn This Role, You Will\nEmbed with the GTM team as a trusted partner, identifying high-impact analytics problems and pioneering data-driven solutions.\nEstablish a data-driven culture by driving the definition, tracking, and operationalizing of metrics\nManage cross-functional data projects about revenue, pricing, sales, product, marketing, growth, and other topics core to the business.\nCreate scalable pipelines for data collection, cleaning, and analysis from multiple sources, and manage the lifecycle of metrics and models from prototyping to production.\nDevelop and refine tools such as dashboards and reports that empower the team to extract and analyze data independently.\nConduct analyses to uncover insights and inform key decisions.\nUse presentations, memos, and tools to communicate complex data insights clearly and persuasively across the organization.\nYou Might Thrive In This Role If You Are/have\nOver 10 years of experience in a relevant Data role within dynamic, outcome-driven organizations.\nHighly skilled in SQL, with extensive experience extracting large datasets and designing ETL workflows.\nProficient in quantitative programming languages, Python preferred.\nExperienced in using business intelligence tools, such as Tableau and Looker, to communicate insights and enable self-serve.\nFamiliar with advanced custom visualizations, such as streamlit and plotly dash.\nAdept at crafting clear data stories using decks, memos, and dashboards to drive decision-making at every level.\nBest-in-class attention to detail and unwavering commitment to accuracy.\nDemonstrated ability to build effective partnerships across diverse teams and influence decision making with data.\nProven track record of delivering significant business impact, with a solid track record in Sales, Marketing, Finance, Growth, Support, or other GTM-related areas preferred.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Analytics Engineer, GTM", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4299675816", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe RL and Reasoning team drives the core reasoning paradigm and has created groundbreaking innovations such as o1 and o3. They focus on pushing the boundaries of reinforcement learning research, building next-generation generative models, and deploying them at scale.\nAbout The Role\nAs a Research Engineer/Research Scientist at OpenAI, you will advance the frontier of AI alignment and capabilities through cutting-edge RL methods. Your work will sit at the heart of training intelligent, aligned, and general-purpose agents, including the systems that power various models.\nWe\u2019re looking for people who have a background in reinforcement learning research, are able to iterate quickly, and are proficient at coding.\nThis role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nYou Might Thrive In This Role If\nYou love being on the cutting edge of RL and language model research.\nYou\u2019re a self-starter who takes initiative and ownership of ideas, driving them to completion.\nYou value principled approaches, simple experiments in tightly-controlled settings, and reaching trustworthy conclusions which stand the test of time.\nYou thrive in a fast-paced, dynamic, and technically complex environment where rapid iteration is key.\nYou\u2019re comfortable diving into a large ML codebase to debug and improve it.\nYou have a deep understanding of machine learning and machine learning applications.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Research Engineer/Research Scientist, RL/Reasoning", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4227550739", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nOur team brings OpenAI\u2019s most capable technology to the world through our products. Most recently, we released ChatGPT, GPT-4, the Whisper API, and DALL-E. We empower consumers and developers alike to use and access our start-of-the-art AI models, allowing them to do things that they\u2019ve never been able to before.\nAcross all product lines, we ensure that these powerful tools are used responsibly. This is a key part of OpenAI\u2019s path towards safely deploying broadly beneficial Artificial General Intelligence (AGI). Safety is more important to us than unfettered growth.\nAbout The Role\nWe are looking for a senior software engineer to build the foundational platform for identity across all OpenAI products. This involves building authentication, authorization, and access control systems \u2013 all while making the product experience seamless for our users and customers. You will work across our entire product fleet (ChatGPT, Plugins, API) and help us evolve and grow our identity offering. You will also work closely with other software engineers, who will use the platform to build out our products.\nIn This Role, You Will\nArchitect and build the next generation of authentication and authorization at OpenAI \u2013 including integration with our ambitious future product roadmap.\nWork across the stack to build end-to-end authentication products for our wide variety of ChatGPT and API users.\nDesign our identity platform for consumer internet scale, while also solving scalability bottlenecks as they arise. \nBuild tools and primitives to empower other engineers at OpenAI to more easily build authentication into their products.\nCollaborate closely with a broad set of stakeholders, including product, design, go-to-market, and other engineers. \nYou Might Thrive In This Role If You\nHave experience or interest in Authentication, Authorization, Federation, and Identity Management.\nInterest or experience with protocols such as OAuth 2.0, SAML, SCIM, and OpenID Connect.\nHave industry experience with projects such as Hydra or Auth0, and languages such as Python or Golang.\nOwn problems end-to-end, and are willing to pick up whatever knowledge you're missing to get the job done\nHave the ability to move fast in an environment where things are sometimes loosely defined and may have competing priorities or deadlines\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Senior Software Engineer, Identity Platform", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201248506", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Safety Systems team is dedicated to ensuring the safety, robustness, and reliability of AI models towards their deployment in the real world.\nOpenAI\u2019s charter calls on us to ensure the benefits of AI are distributed widely. Our Health AI team is focused on enabling universal access to high-quality medical information. We work at the intersection of AI safety research and healthcare applications, aiming to create trustworthy AI models that can assist medical professionals and improve patient outcomes.\nAbout The Role\nWe\u2019re seeking strong researchers who are passionate about advancing AI safety and improving global health outcomes. As a Research Scientist, you will contribute to the development of safe and effective AI models for healthcare applications. You will implement practical and general methods to improve the behavior, knowledge, and reasoning of our models in these settings. This will require research into safety and alignment techniques that we aim to generalize towards safe and beneficial AGI.\nThis role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nIn This Role, You Will\nDesign and apply practical and scalable methods to improve safety and reliability of our models, including RLHF, automated red teaming, scalable oversight, etc.\nEvaluate methods using health-related data, ensuring models provide accurate, reliable, and trustworthy information.\nBuild reusable libraries for applying general alignment techniques to our models.\nProactively understand the safety of our models and systems, identifying areas of risk.\nWork with cross-team stakeholders to integrate methods in core model training and launch safety improvements in OpenAI\u2019s products.\nYou Might Thrive In This Role If You\nAre excited about OpenAI\u2019s mission of ensuring AGI is universally beneficial and are aligned with OpenAI\u2019s charter.\nDemonstrate passion for AI safety and improving global health outcomes.\nHave 4+ years of experience with deep learning research and LLMs, especially practical alignment topics such as RLHF, automated red teaming, scalable oversight, etc.\nHold a Ph.D. or other degree in computer science, AI, machine learning, or a related field.\nStay goal-oriented instead of method-oriented, and are not afraid of unglamorous but high-value work when needed.\nPossess experience making practical model improvements for AI model deployment.\nOwn problems end-to-end, and are willing to pick up whatever knowledge you're missing to get the job done.\nAre a team player who enjoys collaborative work environments.\nBonus: possess experience in health-related AI research or deployments.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Research Engineer / Scientist, Health AI", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201246634", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Strategic Deployment team makes frontier models more capable, reliable, and aligned to transform high-impact domains. On one hand, this involves deploying models in real-world, high-stakes settings to drive AI-driven transformation and elicit insights\u2014training data, evaluation methods, and techniques\u2014to shape our frontier model development. On the other hand, we leverage these learnings to build the science and engineering of impactful frontier model deployment.\nPut differently, we want to understand: if AGI is viewed as AI being able to majorly transform our economy, how close are we to AGI? What\u2019s still missing? How do we bridge these gaps?\nAbout The Role\nWe are hiring a Human-AI Collaboration Lead to develop a hands-on understanding of how people and AI can work together most effectively.\nIn this role, you will study real-world workflows, design new patterns of human-AI collaboration, and generate insights that inform how we build and deploy models. This role blends research, hands-on experimentation, and product thinking, and your findings will shape how models are deployed for real-world impact.\nThis role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nIn This Role, You Will\nConduct field studies to observe and analyze human-AI collaboration.\nDesign and prototype new methods for integrating AI into workflows\nRun quantitative analyses to evaluate interaction patterns and effectiveness.\nTranslate research findings into recommendations for model development and deployment.\nCollaborate closely with researchers, engineers, and external partners.\nYou Might Thrive In This Role If You\nHave experience with field studies, productivity research, or real-world experimentation.\nAre comfortable navigating ambiguity to define the right problems to solve.\nBlend qualitative insight with quantitative rigor in your work.\nHave a background in business, economics, or computer science, with a focus on productivity, HCI, or applied research.\nAre excited about frontier AI, but focused on practical, high-impact applications.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $240K - $393K", "comp": "$240,000.00", "title": "Human-AI Collaboration Lead", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4233255125", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nSecurity is at the foundation of OpenAI\u2019s mission to ensure that artificial general intelligence benefits all of humanity.\nThe Security team protects OpenAI\u2019s technology, people, and products. We are technical in what we build but are operational in how we do our work, and are committed to supporting all products and research at OpenAI. Our Security team tenets include: prioritizing for impact, enabling researchers, preparing for future transformative technologies, and engaging a robust security culture.\nAbout The Role\nTrusted Computing and Cryptography\n is an engineering and security team within the OpenAI Security organization. We focus on:\ndeploying high-performance cryptography at scale\nkey management (including secure offline physical backups, multi-party computation)\ntrusted hardware enclaves that enable everything from boot measurements to GPU confidential computation\nWe're looking for a software engineer to join our team at OpenAI to help us build out and secure our critical computing infrastructure, focusing on trusted computing and cryptography at scale.\nThis role may be based remotely in the US with occasional travel to our San Francisco HQ or other offices as needed by the team or role. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nIn This Role, You Will\nWrite high-quality, performance-critical code in Rust and Python.\nWork alongside researchers, engineers, and security experts to integrate and scale advanced cryptographic techniques into our production and research systems.\nWrite foundational libraries to support cryptographic operations and ensure security best practices are embedded into our infrastructure.\nDesign, implement, and maintain secure key management systems for production environments.\nDesign and deploy systems that help us trust our infrastructure, using security primitives and technologies such as tpm2, Secure Boot, Nitro Enclaves, confidential computing, Intel SGX, and AMD-SEV.\nResearch, design, and implement operating system-level security measures, such as remote attestation, runtime TPM measurement, and host integrity verification.\nYou Might Thrive In This Role If You\nHave extensive experience as a software engineer working on global-scale production systems.\nAre experienced in deploying cryptographic systems at scale, with a strong understanding of production cryptographic key management.\nHave familiarity with security primitives, including but not limited to TPM2, Secure Boot, secure enclaves, and confidential computing platforms.\nHave professional experience programming in Python and proficiency in Rust and/or C/C++.\nOwn problems end-to-end and are willing to acquire any missing knowledge to get the job done.\nHave experience architecting, observing, and debugging production distributed systems.\nExhibit a humble attitude, eagerness to help colleagues, and a commitment to the team\u2019s success.\nAre self-directed and enjoy identifying the most important problems to tackle.\nHave experience rebuilding or significantly refactoring production systems to accommodate rapidly increasing scale.\nHave a good intuition for when off-the-shelf solutions will work and can quickly build tools to accelerate workflows when they won\u2019t.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Software Engineer, Trusted Computing and Cryptography", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4285056750", "loc": "United States", "company": "OpenAI"}, {"desc": "About The Team\nAt OpenAI, we\u2019re building safe and beneficial artificial general intelligence. We deploy our models through ChatGPT, our APIs, and other cutting-edge products. Behind the scenes, making these systems fast, reliable, and cost-efficient requires world-class infrastructure.\nThe Caching Infrastructure team is responsible for building a caching layer that powers many critical use cases at OpenAI. We aim to provide a high-availability, multi-tenant cache platform that scales automatically with workload, minimizes tail latency, and supports a diverse range of use cases.\nWe\u2019re looking for an experienced engineer to help design and scale this critical infrastructure. The ideal candidate has deep experience in distributed caching systems (e.g., Redis, Memcached), networking fundamentals, and Kubernetes-based service orchestration.\nIn This Role, You Will\nDesign, build, and operate OpenAI\u2019s multi-tenant caching platform used across inference, identity, quota, and product experiences.\nDefine the long-term vision and roadmap for caching as a core infra capability, balancing performance, durability, and cost.\nCollaborate with other infra teams (e.g., networking, observability, databases) and product teams to ensure our caching platform meets their needs.\nYou Might Thrive In This Role If You\nHave 5+ years of experience building and scaling distributed systems, with a strong focus on caching, load balancing, or storage systems.\nHave deep expertise with Redis, Memcached, or similar solutions, including clustering, durability configurations, client-side connection patterns, and performance tuning.\nHave production experience with Kubernetes, service meshes (e.g., Envoy), and autoscaling systems.\nThink rigorously about latency, reliability, throughput, and cost in designing platform capabilities.\nThrive in a fast-paced environment and enjoy balancing pragmatic engineering with long-term technical excellence.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $255K - $405K", "comp": "$255,000.00", "title": "Software Engineer, Caching Infrastructure", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4267836131", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nSecurity is at the foundation of OpenAI\u2019s mission to ensure that artificial general intelligence benefits all of humanity.\nThe Security team protects OpenAI\u2019s technology, people, and products. We are technical in what we build but operational in how we execute, and we support every product and research effort at OpenAI. Our tenets include prioritizing for impact, enabling researchers and developers, preparing for future transformative technologies, and fostering a strong, collaborative security culture.\nAbout The Role\nOpenAI is seeking a Security Software Engineer to join the Infrastructure Security (InfraSec) team.\nInfraSec safeguards the core of OpenAI\u2019s research and production environments\u2014GPU supercomputing clusters, multi-cloud infrastructure, datacenters, networking, storage, and the critical services that power our frontier AI models. Our charter spans everything from bare-metal hardware and firmware to Kubernetes clusters, service meshes, and the data pathways that carry highly sensitive model weights and user data.\nAs a Security Software Engineer, you will design and build critical foundational services, such as authentication systems, egress/ingress proxies, access brokers, and key management platforms, that demand high standards of reliability, scalability, and software craftsmanship. These systems form the security backbone of OpenAI\u2019s supercomputing environment and must remain robust under intense scale and adversarial pressure.\nIn This Role, You Will\nArchitect and implement production-grade security services (e.g., auth services, access brokers, secure proxies, key-management infrastructure) that provide strong guarantees across hardware, operating systems, Kubernetes, networks, and CI/CD.\nPartner with infrastructure and research engineers to embed security into high-performance compute clusters, enabling rapid model training and deployment without compromising protection.\nDevelop automation and detection tooling to continuously identify and mitigate risks in large-scale cloud and on-prem environments.\nDrive high-impact initiatives such as line-speed encryption, machine identity, and network isolation, continuously raising the security bar for emerging AI workloads.\nLead or participate in design reviews and threat models to ensure new systems launch with strong security foundations and operational excellence.\nYou Will Thrive In This Role If You Have\nStrong software engineering skills in languages such as Python, Go, Rust, or C/C++, with a track record of shipping and operating high-reliability distributed services.\nExperience building or operating critical security infrastructure (e.g., auth services, service-to-service proxies, certificate or key-management systems).\nDeep understanding of security principles, best practices, and common vulnerabilities.\nExpertise in securing large-scale cloud platforms (e.g., Azure, AWS, GCP), including multi-cloud networks and cloud-agnostic system design.\nFamiliarity with container and orchestration security (Kubernetes, service meshes) and modern authentication/authorization standards (OIDC, mTLS, SPIFFE/SPIRE).\nA proactive mindset, with the ability to identify and address security gaps or inefficiencies through automation and tooling.\nA track record of delivering scalable solutions and driving impactful changes across infrastructure in real-world projects.\nStrong analytical and problem-solving skills, with an ability to think critically and objectively assess security risks.\nExcellent communication skills, with the ability to convey complex security concepts to technical and non-technical stakeholders.\nExcitement about collaborating with cross-functional teams to build secure, reliable systems that scale globally.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Software Engineer, Infrastructure Security", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4309211504", "loc": "New York City Metropolitan Area", "company": "OpenAI"}, {"desc": "About The Team\nThe Codex team is responsible for building state-of-the-art AI systems that can write code, reason about software, and act as intelligent agents for developers and non-developers alike. Our mission is to push the frontier of code generation and agentic reasoning, and deploy these capabilities in real-world products such as ChatGPT and the API, as well as in next-generation tools specifically designed for agentic coding. We operate across research, engineering, product, and infrastructure\u2014owning the full lifecycle of experimentation, deployment, and iteration on novel coding capabilities.\nAbout The Role\nAs a member of the Codex team, you will advance the capabilities, performance, and reliability of AI coding models through a combination of research, experimentation, and system optimization. You\u2019ll collaborate with world-class researchers and engineers to develop and deploy systems that help millions of users write better code, faster\u2014while also ensuring these systems are efficient, cost-effective, and production-ready.\nWe\u2019re looking for people who combine deep curiosity, strong technical fundamentals, and a bias toward impact. Whether your strengths lie in ML research, systems engineering, or performance optimization, you\u2019ll play a pivotal role in pushing the state of the art and bringing these advances into the hands of real users.\nThis role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nIn This Role, You Might\nDesign and run experiments to improve code generation, reasoning, and agentic behavior in Codex models.\nDevelop research insights into model training, alignment, and evaluation.\nHunt down and address inefficiencies across the Codex system stack\u2014from agent behavior to LLM inference to container orchestration\u2014and land high-leverage performance improvements. Build tooling to measure, profile, and optimize system performance at scale.\nWork across the stack to prototype new capabilities, debug complex issues, and ship improvements to production.\nYou Might Thrive In This Role If You\nAre excited to explore and push the boundaries of large language models, especially in the domain of software reasoning and code generation.\nHave strong software engineering skills and enjoy quickly turning ideas into working prototypes.\nThink holistically about performance, balancing speed, cost, and user experience.\nBring creativity and rigor to open-ended research problems and thrive in highly iterative, ambiguous environments.\nHave experience operating across both ML systems and cloud infrastructure.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $380K - $460K", "comp": "$380,000.00", "title": "Research Engineer, Codex", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4278279915", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Interpretability team studies internal representations of deep learning models. We are interested in using representations to understand model behavior, and in engineering models to have more understandable representations. We are particularly interested in applying our understanding to ensure the safety of powerful AI systems. Our working style is collaborative and curiosity-driven.\nAbout The Role\nOpenAI is seeking a researcher passionate about understanding deep networks, with a strong background in engineering, quantitative reasoning, and the research process. You will develop and carry out a research plan in mechanistic interpretability, in close collaboration with a highly motivated team. You will play a critical role in helping OpenAI ensure future models remain safe even as they grow in capability. This will make a significant impact on our goal of building and deploying safe AGI.\nIn This Role, You Will\nDevelop and publish research on techniques for understanding representations of deep networks.\nEngineer infrastructure for studying model internals at scale.\nCollaborate across teams to work on projects that OpenAI is uniquely suited to pursue.\nGuide research directions toward demonstrable usefulness and/or long-term scalability.\nYou Might Thrive In This Role If You\nAre excited about OpenAI\u2019s mission of ensuring AGI benefits all of humanity, and are aligned with OpenAI\u2019s charter.\nShow enthusiasm for long-term AI safety, and have thought deeply about technical paths to safe AGI.\nBring experience in the field of AI safety, mechanistic interpretability, or spiritually related disciplines.\nHold a Ph.D. or have research experience in computer science, machine learning, or a related field.\nThrive in environments involving large-scale AI systems, and are excited to make use of OpenAI\u2019s unique resources in this area.\nPossess 2+ years of research engineering experience and proficiency in Python or similar languages.\nAre deeply curious.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $310K - $460K", "comp": "$310,000.00", "title": "Research Engineer / Scientist, Interpretability", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4249129377", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Strategic Deployment team makes frontier models more capable, reliable, and aligned to transform high-impact domains. On one hand, this involves deploying models in real-world, high-stakes settings to drive AI-driven transformation and elicit insights\u2014training data, evaluation methods, and techniques\u2014to shape our frontier model development. On the other hand, we leverage these learnings to build the science and engineering of impactful frontier model deployment.\nPut differently, we want to understand: if AGI is viewed as AI being able to majorly transform our economy, how close are we to AGI? What\u2019s still missing? How do we bridge these gaps?\nAbout The Role\nAs a Research Engineer/Research Scientist on the Strategic Deployment team, you\u2019ll tackle fundamental research questions and AI engineering challenges grounded in real-world deployment. Your work will build the science and engineering of reliable customization of frontier models and develop understanding and evaluations that fuel both strategically-important AI deployments and guide OpenAI\u2019s frontier model program.\nThis role is based in San Francisco, CA. We follow a hybrid model (3 days/week in-office) and offer relocation support.\nIn This Role, You Will\nConduct research on real-world-informed model generalization, robustness, and steerability.\nDesign challenging evaluations that capture real-world utility and reveal frontier model capability gaps.\nUse real deployments as a way to generate learnings to guide OpenAI\u2019s frontier model program.\nCollaborate with other researchers, infrastructure teams, and in some cases, domain experts and/or partners in strategic industries to surface major impact opportunities.\nYou Might Thrive In This Role If You\nHave a research background in ML, deep learning, or related areas (e.g., RL, evaluation science, robustness).\nHave strong engineering skills and are comfortable diving into a large ML codebase to debug and improve it.\nAre interested in foundational research informed by real-world deployment\u2014not just paper benchmarks.\nAre excited by ambiguous, open-ended problem spaces with high impact and stakes.\nEnjoy building tools, datasets, or infrastructure to elicit deeper insight.\nWant to shape how frontier models evolve toward AGI.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Research Engineer/Scientist, Strategic Deployment", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4204731076", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Alignment team at OpenAI is dedicated to ensuring that our AI systems are safe, trustworthy, and consistently aligned with human values, even as they scale in complexity and capability. Our work is at the cutting edge of AI research, focusing on developing methodologies that enable AI to robustly follow human intent across a wide range of scenarios, including those that are adversarial or high-stakes. We concentrate on the most pressing challenges, ensuring our work addresses areas where AI could have the most significant consequences. By focusing on risks that we can quantify and where our efforts can make a tangible difference, we aim to ensure that our models are ready for the complex, real-world environments in which they will be deployed.\nThe two pillars of our approach are: (1) harnessing improved capabilities into alignment, making sure that our alignment techniques improve, rather than break, as capabilities grow, and (2) centering humans by developing mechanisms and interfaces that enable humans to both express their intent and to effectively supervise and control AIs, even in highly complex situations.\nAbout The Role\nAs a Research Engineer / Research Scientist on the Alignment team, you will be at the forefront of ensuring that our AI systems consistently follow human intent, even in complex and unpredictable scenarios. Your role will involve designing and implementing scalable solutions that ensure the alignment of AI as their capabilities grow and that integrate human oversight into AI decision-making.\nThis role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nIn This Role, You Will\nWe are seeking research engineers and research scientists to help design and implement experiments for alignment research. Responsibilities may include:\nDevelop and evaluate alignment capabilities that are subjective, context-dependent, and hard to measure.\nDesign evaluations to reliably measure risks and alignment with human intent and values.\nBuild tools and evaluations to study and test model robustness in different situations.\nDesign experiments to understand laws for how alignment scales as a function of compute, data, lengths of context and action, as well as resources of adversaries.\nDesign and evaluate new Human-AI-interaction paradigms and scalable oversight methods that redefine how humans interact with, understand, and supervise our models.\nTrain model to be calibrated on correctness and risk.\nDesigning novel approaches for using AI in alignment research\nYou Might Thrive In This Role If You\nAre a team player \u2013 willing to do a variety of tasks that move the team forward.\nHave a PhD or equivalent experience in research in computer science, computational science, data science, cognitive science, or similar fields.\nHave strong engineering skills, particularly in designing and optimizing large-scale machine learning systems(e.g., PyTorch).\nHave a deep understanding of the science behind alignment algorithms and techniques.\nCan develop data visualization or data collection interfaces (e.g., TypeScript, Python).\nEnjoy fast-paced, collaborative, and cutting-edge research environments.\nWant to focus on developing AI models that are trustworthy, safe, and reliable, especially in high-stakes scenarios.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Research Engineer / Research Scientist, Alignment", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201890742", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nCodex\n is OpenAI\u2019s first-party developer product focused on agentic software engineering. We\u2019re building tools that help engineers design, write, test, and ship code faster\u2014safely and at scale. We partner tightly with research and product to translate model advances into tangible developer productivity.\nAbout The Role\nAs a Data Scientist on Codex, you will measure and accelerate product-market fit for AI developer tools. You\u2019ll define what \u201cdeveloper productivity\u201d means for our product, run experiments on new coding models and UX, and pinpoint where the model helps or hurts across languages and tasks. Your insights will directly shape how an entire industry builds software.\nThis role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nIn this role, you will\nEmbed with the Codex product team to discover opportunities that improve developer outcomes and growth\nDesign and interpret A/B tests and staged rollouts of new coding models and product features\nDefine and operationalize metrics such as suggestion acceptance, edit distance, compile/test pass rates, task completion, latency, and session productivity\nBuild dashboards and analyses that help the team self-serve answers to product questions (by language, framework, repo size, task type)\nDiagnose failure modes and partner with Research on targeted improvements (model quality signals, user feedback, evals)\nYou might thrive in this role if you have\n5+ years in a quantitative role at a developer-facing or high-growth product\nFluency in SQL and Python; comfort with experiment design and causal inference\nExperience defining product metrics tied to user value\nAbility to communicate clearly with PM, Eng, and Design\u2014and to influence product direction\nYou could be an especially great fit if you have\nStrong programming background; ability to prototype, run simulations, and reason about code quality\nFamiliarity with IDE/extension telemetry or developer tooling analytics\nPrior experience with NLP/LLMs, code models, or evaluations for generative coding\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Data Scientist, Codex", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4306158400", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe ChatGPT for Work team works across research, engineering, product, and design to bring OpenAI\u2019s technology to consumers and businesses.\nWe seek to learn from deployment and distribute the benefits of AI, while ensuring that this powerful tool is used responsibly and safely.\nAbout The Role\nYou will help build and deploy our ChatGPT for Work product. We shipped ChatGPT for Work in August last year, and we\u2019re humbled and excited by the reception \u2013 a recent study found that ChatGPT can drive up to 30% more productivity in knowledge work.\nWe\u2019re looking for experienced engineers, who are excited by the three components of shipping the best enterprise product:\nBuilding a secure, governable, scalable foundation that earns the trust of our customers\nPackaging the magic of OpenAI in a way that resonates with enterprise buyers\nShipping 0-1 products that give users 10x abilities in specific enterprise domains\nIn This Role, You Will\nPartner with researchers, engineers, product managers, and designers to bring new features and research capabilities to the world\nAccelerate engineering productivity by empowering your fellow engineers with excellent tooling and systems\nLike all other teams, we are responsible for the reliability of the systems we build. This includes an on-call rotation to respond to critical incidents as needed\nYou Might Thrive In This Role If You\nDeep understanding of engineering principles, industry best practices, and emerging technologies within their domain.\nHave meaningful experience with building (and rebuilding) production systems to deliver new product capabilities and to handle increasing scale\nCare deeply about the end user experience and take pride in building products to solve customer needs\nHave a humble attitude, an eagerness to help your colleagues, and a desire to do whatever it takes to make the team succeed\nOwn problems end-to-end, and are willing to pick up whatever knowledge you're missing to get the job done\nBuild tools to accelerate your own (and your teammates\u2019) workflows, but only when off-the-shelf solutions won\u2019t do\nHave been a startup founder or an early-stage engineer\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Principal Software Engineer, ChatGPT for Work", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201247580", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Frontier Evals team builds north star model evaluations to drive progress towards safe AGI/ASI. This team builds ambitious evaluations to measure and steer our models, and creates self-improvement loops to steer our training, safety, and launch decisions. Some of the team's open-sourced evaluations include SWE-bench Verified, MLE-bench, PaperBench, and SWE-Lancer, and the team built and ran frontier evaluations for GPT4o, o1, o3, GPT 4.5, ChatGPT Agent, and GPT5. If you are interested in feeling firsthand the fast progress of our models, and steering them towards good, this is the team for you.\nAbout You\nWe are seeking exceptional research engineers that can push the boundaries of our frontier models in the finance domain. We are looking for those who will help shape AI evaluations of financial reasoning and related capabilities, and will own individual threads within this endeavor end-to-end. This role will also involve collaboration with others on the frontier evals team across other domains.\nIn This Role, You'll\nIdentify important model capabilities, skills, and behaviors that are crucial to financial workflows, and design methods to quantify performance in these areas\nOwn and pursue a research agenda to identify an important model capability (especially as it relates to financial reasoning) and build evals to measure it\nContinuously refine evaluations of frontier AI models to assess the extent of frontier capabilities\nWe Expect You To Be\nStrong engineering and statistical analysis skills (with at least 2-3 years of full-time technical experience)\nPassionate about Excel spreadsheets and/or finance\nDetail-oriented and thorough\nTeam player / willing to do a variety of tasks to move the team forward\nPassionate and knowledgeable about AGI/ASI measurement\nAble to operate effectively in a dynamic and extremely fast-paced research environment as well as scope and deliver projects end-to-end\nIt Would Be Great If You Also Have\nPrior background / domain expertise in finance, especially investment banking or private equity (e.g., through internships, prior jobs)\nAn ability to work cross-functionally\nExcellent communication skills\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $200K - $370K", "comp": "$200,000.00", "title": "Research Engineer, Frontier Evals", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4207338904", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nSecurity is at the foundation of OpenAI\u2019s mission to ensure that artificial general intelligence benefits all of humanity.\nThe Security team protects OpenAI\u2019s technology, people, and products. We are technical in what we build but are operational in how we do our work, and are committed to supporting all products and research at OpenAI. Our Security team tenets include: prioritizing for impact, enabling researchers, preparing for future transformative technologies, and engaging a robust security culture.\nAbout The Role\nAs a Security Engineer you will join our OpenAI engineers and researchers in building, operating and securing transformational AI technologies. This role will focus on all aspects of Detection & Response, including infrastructure and operations, and will also contribute to the Security team as a strong generalist. In this role, you will:\nDrive projects in all major security verticals including: AppSec, InfraSec, OffSec and Detection and Response\nInnovate to solve novel security problems \nCollaborate on cutting-edge AI research, and use AI to improve OpenAI\u2019s Security posture \nThis role may be based in San Francisco, CA, Seattle, WA or New York City, NY. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nIn This Role, You Will\nInnovate on Detection and Response infrastructure \nBuild tools for managing the lifecycle of detection rules\nDevelop, measure, and tune detection rules to ensure effective and sustainable operations.\nAutomate manual response processes \nEnsure visibility and control of OpenAI\u2019s endpoint fleet (macOS, Windows)\nDriving improvements across identity access and management (IAM), device management, productivity software, and our use of public cloud environments (e.g. AWS, Microsoft Azure)\nYou Might Thrive In This Role If You\nExperience in Security or a Security-adjacent field\nExperience with Microsoft Azure and/or cloud infrastructure platforms\nKnowledge of modern adversary tactics, techniques, and procedures.\nProficiency with a scripting language (e.g. Python, Bash, PowerShell, or similar).\nAbility to empathize and collaborate with colleagues, independently manage and run projects, and prioritize efforts for risk reduction.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $255K - $405K", "comp": "$255,000.00", "title": "Security Engineer, Detection and Response", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4223095761", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "By applying to this role, you will be considered for Research Scientist roles across all teams at OpenAI.\nAbout The Role\nAs a Research Scientist here, you will develop innovative machine learning techniques and advance the research agenda of the team you work on, while also collaborating with peers across the organization. We are looking for people who want to discover simple, generalizable ideas that work well even at large scale, and form part of a broader research vision that unifies the entire company.\nWe Expect You To\nHave a track record of coming up with new ideas or improving upon existing ideas in machine learning, demonstrated by accomplishments such as first author publications or projects\nPossess the ability to own and pursue a research agenda, including choosing impactful research problems and autonomously carrying out long-running projects\nBe excited about OpenAI\u2019s approach to research \nNice To Have\nInterested in and thoughtful about the impacts of AI technology\nPast experience in creating high-performance implementations of deep learning algorithms\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Research Scientist", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201244689", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Frontier Systems team at OpenAI builds, launches, and supports the largest supercomputers in the world that OpenAI uses for its most cutting edge model training.\nWe take data center designs, turn them into real, working systems and build any software needed for running large-scale frontier model trainings.\nOur mission is to bring up, stabilize and keep these hyperscale supercomputers reliable and efficient during the training of the frontier models.\nAbout The Role\nWe are looking for engineers to operate the next generation of compute clusters that power OpenAI\u2019s frontier research.\nThis role blends distributed systems engineering with hands-on infrastructure work on our largest datacenters. You will scale Kubernetes clusters to massive scale, automate bare-metal bring-up, and build the software layer that hides the complexity of a magnitude of nodes across multiple data centers.\nYou will work at the intersection of hardware and software, where speed and reliability are critical. Expect to manage fast-moving operations, quickly diagnose and fix issues when things are on fire, and continuously raise the bar for automation and uptime.\nIn This Role, You Will\nSpin up and scale large Kubernetes clusters, including automation for provisioning, bootstrapping, and cluster lifecycle management\nBuild software abstractions that unify multiple clusters and present a seamless interface to training workloads\nOwn node bring-up from bare metal through firmware upgrades, ensuring fast, repeatable deployment at massive scale\nImprove operational metrics such as reducing cluster restart times (e.g., from hours to minutes) and accelerating firmware or OS upgrade cycles\nIntegrate networking and hardware health systems to deliver end-to-end reliability across servers, switches, and data center infrastructure\nDevelop monitoring and observability systems to detect issues early and keep clusters stable under extreme load\nYou Might Thrive In This Role If You\nHave deep experience operating or scaling Kubernetes clusters or similar container orchestration systems in high-growth or hyperscale environments\nBring strong programming or scripting skills (Python, Go, or similar) and familiarity with Infrastructure-as-Code tools such as Terraform or CloudFormation\nAre comfortable with bare-metal Linux environments, GPU hardware, and large-scale networking\nEnjoy solving fast-moving, high-impact operational problems and building automation to eliminate manual work\nCan balance careful engineering with the urgency of keeping mission-critical systems running\nQualifications\nExperience as an infrastructure, systems, or distributed systems engineer in large-scale or high-availability environments\nStrong knowledge of Kubernetes internals, cluster scaling patterns, and containerized workloads\nProficiency in cloud infrastructure concepts (compute, networking, storage, security) and in automating cluster or data center operations\nBonus: background with GPU workloads, firmware management, or high-performance computing\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Software Engineer, Frontier Clusters Infrastructure", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201248515", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nOur Robotics team is focused on unlocking general-purpose robotics and pushing towards AGI-level intelligence in dynamic, real-world settings. Working across the entire model stack, we integrate cutting-edge hardware and software to explore a broad range of robotic form factors. We strive to seamlessly blend high-level AI capabilities with the constraints of physical systems to improve peoples\u2019 lives.\nAbout The Role\nAs a Mechanical Engineer on the Robotics team, you will help shape the next generation of embodied AI. You\u2019ll design and prototype novel tactile and force sensor solutions, validate their performance through rigorous testing and analysis, and translate results into robust, manufacturable designs. By working across disciplines and with suppliers, you\u2019ll ensure every part\u2014from CAD model to production drawing\u2014meets the highest standards of reliability and scalability. This role offers the chance to shape how advanced sensing technology powers adaptive, intelligent machines in the real world.\nThis role is based in San Francisco, CA, and requires in-person 4 days a week.\nYou Might Thrive In This Role If You\nHave at least 6+ years of consumer or industrial electronics experience, including at least 2 years experience designing robotics hardware components and systems.\nExperienced with state of the art force, tactile, and proprioception sensor technology.\nIntegrate existing sensing technologies into new compact forms.\nDesign, prototype, and iterate on novel sensing technologies and applications.\nCollaborate with cross-functional partners to define requirements and translate them into practical sensor solutions.\nBuild detailed part and assembly models in CAD, ensuring designs are robust and manufacturable.\nApply engineering analyses\u2014including tolerance studies, FEA, and other simulations\u2014to validate designs before release.\nProduce clear, accurate 2D drawings aligned with production and inspection standards, with proper use of GD&T.\nHave a Bachelor\u2019s or Master's degree in Mechanical Engineering, Product Design, or related field, or equivalent practical experience.\nAdditional, Preferred Qualifications\nA passion for electro-mechanical product design, creative problem-solving, and driving innovation\nPractical knowledge of designing parts for plastic injection molding, sheet metal stamping, and casting processes.\nAbility to perform first-principles analysis across mechanics, thermal effects, stress/strain, and tolerances.\nExperience designing mechanical systems intended for high volume (1M+), problem-solving on assembly lines, and directing CM teams in all design phases.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $380K - $460K", "comp": "$380,000.00", "title": "Mechanical Engineer (Sensing)", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4287168226", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Safety Systems team is dedicated to ensuring the safety, robustness, and reliability of AI models and their deployment in the real world.\nBuilding on the many years of our practical alignment work and applied safety efforts, Safety Systems addresses emerging safety issues and develops new fundamental solutions to enable the safe deployment of our most advanced models and future AGI, to make AI that is beneficial and trustworthy.\nLearn more about OpenAI\u2019s approach to safety\nAbout The Role\nAt OpenAI, we're dedicated to advancing artificial intelligence, and we know that creating a secure and reliable platform is vital to our mission. That's why we're seeking Research Engineers to help us build out our trust and safety capabilities.\nIn this role, you\u2019ll be working closely with our engineers, researchers and data scientists to create and improve our safety mitigations via model training and ML systems work. You'll be at the forefront of our efforts to ensure that the immense potential of AI is harnessed in a responsible and sustainable manner.\nIn This Role, You Will\nInnovate and Deploy: Design and deploy advanced machine learning models that solve real-world problems. Implement safety measures at various stages of AI model development and deployment. This includes pre-training data filtration, post-training evaluation, deployment time safety mitigations and continuous monitoring to ensure models align with human values and safety standards.\nCollaborate with the Best: Work closely with researchers, software engineers, and product managers to understand complex business challenges and deliver AI-powered solutions. Be part of a dynamic team where ideas flow freely and creativity thrives.\nOptimize and Scale: Implement scalable data pipelines, optimize models for performance and accuracy, and ensure they are production-ready. Contribute to projects that require cutting-edge technology and innovative approaches.\nLearn and Lead: Stay ahead of the curve by engaging with the latest developments in machine learning and AI. Take part in code reviews, share knowledge, and lead by example to maintain high-quality engineering practices.\nMake a Difference: Monitor and maintain deployed models to ensure they continue delivering value. Your work will directly influence how AI benefits individuals, businesses, and society at large.\nYou Might Thrive In This Role If You\nDemonstrate a passion for AI safety and making cutting-edge AI models safer for real-world use.\nDemonstrated experience in deep learning and transformers models\nProficiency in frameworks like PyTorch or Tensorflow\nStrong foundation in data structures, algorithms, and software engineering principles.\nAre familiar with methods of training and fine-tuning large language models, such as distillation, supervised fine-tuning, and policy optimization\nAbility to work collaboratively with cross-functional teams across research, product and engineering\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Research Engineer, Safety Engineering", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4202084304", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Frontier Systems team at OpenAI builds, launches, and supports the largest supercomputers in the world that OpenAI uses for its most cutting edge model training.\nWe take data center designs, turn them into real, working systems and build any software needed for running large-scale frontier model trainings.\nOur mission is to bring up, stabilize and keep these hyperscale supercomputers reliable and efficient during the training of the frontier models.\nAbout The Role\nOn the Frontier Systems team, you\u2019ll build critical infrastructure that keeps our supercomputers running reliably for cutting-edge AI research. Even a single hardware failure can derail a large-scale training run, so minimizing disruptions is core to the mission.\nEngineers here own their work end-to-end and are trusted to make a real impact. This role is for someone who goes deep - who thrives on root-causing system-level issues and building automation to catch and fix problems at scale.\nIn This Role, You Will\nOwn and improve the system health checks that keep our hyperscale supercomputers stable during model training.\nLead deep dives into hardware failures and system-level bugs to understand how things break at scale.\nBuild automation that monitors and fixes issues across thousands of machines - so researchers can keep moving without interruption.\nYou Might Thrive In This Role If You Have\n7+ years of industry experience in software engineering \nProficiency with Python and shell scripting\nA high degree of comfort digging into noisy data with SQL, PromQL, and Pandas or any other tool necessary\nExperience developing reproducible analyses\nA balance of strengths in building and operationalizing\nPrior hardware expertise is not required for this role.\nBonus If You Have\nExperience with low level details of hardware components, protocols, and associated Linux tooling (e.g., PCIe, Infiniband, networking, power management, kernel perf tuning)\nExperience with visualization of large data centers and networks.\nExpertise with network operations and tooling\nExpertise with power management and stabilization\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Software Engineer, Frontier Systems", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4224766210", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nWe\u2019re hiring Software Engineers to join our Applied Infrastructure organization, and more specifically for our Database Systems and Online Storage teams. These teams operate with a high degree of autonomy and are deeply collaborative, with a shared mandate to raise the bar on safety, reliability, and velocity across OpenAI.\nAbout The Role\nYou\u2019ll be at the heart of scaling and hardening the infrastructure that powers some of the most widely used AI systems in the world. You\u2019ll help ensure our systems are highly reliable, observable, performant, and secure\u2014so researchers can iterate quickly, and products like ChatGPT and the OpenAI API can serve millions of users safely and effectively.\nThis is a hands-on, high-leverage role for engineers who thrive on ownership, love solving deep technical problems across the stack, and want to work on systems that support cutting-edge research and deploy at global scale. You\u2019ll play a key part in shaping technical direction, proactively improving system resilience, and collaborating closely with infra, product, and research teams to turn complex infrastructure into reliable platforms.\nIn This Role You Will\nDesign, build, and operate reliable and performant systems used across engineering.\nIdentify and fix performance bottlenecks and inefficiencies, ensuring our infrastructure can scale to the next order of magnitude.\nDig deep to resolve complex issues.\nContinuously improve automation to reduce manual work. Improve internal tooling and our developer experience.\nContribute to incident response, postmortems, and the development of best practices around system reliability and scalability.\nYou Might Thrive In This Role If You\nHave a deep understanding of distributed systems principles and a proven track record in building and operating scalable and reliable systems.\nHave a keen eye for performance and optimization. You know how to squeeze the most performance out of complex, globally-distributed systems.\nHave experience operating orchestration systems such as Kubernetes at scale and building abstractions over cloud platforms\nAre comfortable working in Linux environments, and with tools like Kubernetes, Terraform, CI/CD pipelines, and modern observability stacks.\nAre experienced in collaborating with cross-functional teams to ensure that reliability and scalability are considered in the design and development of new features and services.\nHave a humble attitude, an eagerness to help your colleagues, and a desire to do whatever it takes to make the team succeed.\nOwn problems end-to-end, and are willing to pick up whatever knowledge you're missing to get the job done.\nAre comfortable with ambiguity and rapid change.\nQualifications\n4+ years of relevant industry experience, with 2+ years leading large scale, complex projects or teams as an engineer or tech lead\nA passion for distributed systems at scale with a focus on reliability, scalability, security, and continuous improvement.\nProven experience as an reliability engineer, production engineer, or a similar role in a fast-paced, rapidly scaling company.\nStrong proficiency in cloud infrastructure (like AWS, GCP, Azure) and IaC tools such as Terraform. Proficiency in programming / scripting languages.\nExperience with containerization technologies and container orchestration platforms like Kubernetes.\nExperience with observability tools such as Datadog, Prometheus, Grafana, Splunk and ELK stack.\nExperience with microservices architecture and service mesh technologies.\nKnowledge of security best practices in cloud environments.\nStrong understanding of distributed systems, networking, and database technologies.\nExcellent problem-solving skills and ability to work in a fast-paced environment.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $255K - $405K", "comp": "$255,000.00", "title": "Software Engineer, Infrastructure Reliability", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4303429059", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nOpenAI\u2019s Platform and Infrastructure Engineering organization advances the mission of deploying artificial general intelligence (AGI) for the benefit of all by delivering secure, scalable, and resilient technology solutions. Our team builds and maintains robust infrastructure that safeguards OpenAI\u2019s data and systems while ensuring employees are well-equipped and seamlessly connected. By prioritizing security, reliability, and user-centric solutions, we empower OpenAI employees to drive impactful AI research, corporate operations, and product innovation.\nAbout The Role\nAs a \nClient Platform Engineer\n at OpenAI, you will play a pivotal role in securing, enhancing, and maintaining our endpoint management infrastructure across macOS, Windows, iOS, and Android devices. Your focus will be on building scalable, automated solutions that ensure seamless deployments, advanced security configurations, and efficient operational workflows. You will collaborate closely with IT, Security, and Engineering teams to implement modern endpoint management practices using automation, Infrastructure-as-Code (IaC), and monitoring strategies. This role offers an opportunity to work with cutting-edge tools and contribute to building a security-first, automation-driven endpoint ecosystem.\nWe\u2019re looking for people who are passionate about automation, endpoint security, and building scalable solutions that improve employee experience. You should have a strong background in managing macOS and iOS devices at scale, developing automated solutions using scripting, and configuration management tools, and driving operational excellence through process optimization and collaboration. Your problem-solving mindset and attention to detail will be key to success in this role.\nIn This Role, You Will\nDesign, build, implement, and maintain scalable and performant endpoint management infrastructure to facilitate best-in-class security of the OpenAI fleet comprised of macOS, Windows, iOS, and Android endpoints.\nDeliver critical endpoint management efficiencies and capabilities through bespoke software development and implementation of both industry-standard open source tooling and first-party software solutions.\nEmploy modern Infrastructure-as-Code (IaC) methodologies, develop GitOps-driven solutions to deliver consensus-based fleet management capabilities at scale.\nBuild and maintain CI/CD pipelines for fleet management infrastructure, deploying to progressively tested environments across multiple clouds (Azure, AWS, GCP).\nDesign, build, implement, and maintain scalable and performant endpoint management infrastructure to facilitate best-in-class security of the OpenAI fleet comprised of macOS, Windows, iOS, and Android endpoints.\nDeliver critical endpoint management efficiencies and capabilities through bespoke software development and implementation of both industry-standard open source tooling and first-party software solutions.\nEmploy modern Infrastructure-as-Code (IaC) methodologies, develop GitOps-driven solutions to deliver consensus-based fleet management capabilities at scale.\nBuild and maintain CI/CD pipelines for fleet management infrastructure, deploying to progressively tested environments across multiple clouds (Azure, AWS, GCP).\nDrive initiatives to adopt emerging CPE technologies, industry best practices, and optimize processes for scalability and operational efficiency.\nPartner with cross-functional teams to ensure seamless endpoint user experiences while maintaining strict security standards and continually increasing the bar.\nYou may be a fit for this role if you have:\nProficiency in a modern programming language (Python, Golang, Ruby, etc.)\nExtensive hands-on experience with Jamf PRO and Microsoft Intune to ensure comprehensive secure fleet management as well as experience with similar cloud identity providers.\nDemonstrated success and experience with open source endpoint management tooling for configuration management, mobile device management, application management, and telemetry such as Salt, Puppet, Munki, Nano/MicroMDM, osquery, Autopkg, WinGet, etc.\nHistory of developing and delivering secure, reliable, scalable, and technology solutions.\nDeep knowledge and experience managing corporate infrastructure at scale with Infrastructure-as-Code (IaC) practices & GitOps workflows (Terraform, Ansible, Chef, etc.)\nExperience integrating and operating fleet management infrastructure with CI/CD pipelines and DevOps workflows.\nProven track record of deploying and operating fleet management infrastructure in public cloud environments (Azure, AWS, GCP).\nA self-starter with strong analytical and problem-solving skills.\nYou Might Thrive In This Role If You Have\nDeep experience with open-source fleet management tools and frameworks.\nExperience with containerization technologies such as Docker and Kubernetes.\nFamiliarity with compliance frameworks such as SOC 2, ISO 27001, FedRAMP, and NIST.\nStrong soft skills, including stakeholder communication and cross-functional collaboration.\nRelevant professional certifications such as CISSP, CISA, CISM, CCSP.\nA security thought leader with contributions to CPE open-source projects or technical communities.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $255K - $325K", "comp": "$255,000.00", "title": "Client Platform Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4307266913", "loc": "New York, NY", "company": "OpenAI"}, {"desc": "About The Team\nData Platform at OpenAI owns the foundational data stack powering critical product, research, and analytics workflows. We operate some of the largest Spark compute fleets in production; design, and build data lakes and metadata systems on Iceberg and Delta with a vision toward exabyte-scale architecture; run high throughput streaming platforms on Kafka and Flink; provide orchestration with Airflow; and support ML feature engineering tooling such as Chronon. Our mission is to deliver reliable, secure, and efficient data access at scale and accelerate intelligent, AI assisted data workflows.\nJoin us to build and operate these core platforms that underpin OpenAI products, research, and analytics.\nWe\u2019re not just scaling infrastructure \u2013 we\u2019re redefining how people interact with data. Our vision includes intelligent interfaces and AI-assisted workflows that make working with data faster, more reliable, and more intuitive.\nAbout The Role\nThis role focuses on building and operating data infrastructure that supports massive compute fleets and storage systems, designed for high performance and scalability. You\u2019ll help design, build, and operate the next generation of data infrastructure at OpenAI. You will scale and harden big data compute and storage platforms, build and support high-throughput streaming systems, build and operate low latency data ingestions, enable secure and governed data access for ML and analytics, and design for reliability and performance at extreme scale.\nYou will take full lifecycle ownership: architecture, implementation, production operations, and on-call participation.\nYou\u2019ve supported Spark, Kafka, Flink, Airflow, Trino, or Iceberg as platforms. You\u2019re well-versed in infrastructure tooling like Terraform, experienced in debugging large-scale distributed systems, and excited about solving data infrastructure problems in the AI space.\nThis role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nIn This Role, You Will\nDesign, build, and maintain data infrastructure systems such as distributed compute, data orchestration, distributed storage, streaming infrastructure, machine learning infrastructure while ensuring scalability, reliability, and security\nEnsure our data platform can scale by orders of magnitude while remaining reliable and efficient\nAccelerate company productivity by empowering your fellow engineers & teammates with excellent data tooling and systems\nCollaborate with product, research and analytics teams to build the technical foundations capabilities that unlock new features and experiences\nOwn the reliability of the systems you build, including participation in an on-call rotation for critical incidents\nYou Might Thrive In This Role If You\nHave 4+ years in data infrastructure engineering OR\nHave 4+ years in infrastructure engineering with a strong interest in data\nTake pride in building and operating scalable, reliable, secure systems\nAre comfortable with ambiguity and rapid change\nHave an intrinsic desire to learn and fill in missing skills, and an equally strong talent for sharing learnings clearly and concisely with others\nThis role is exclusively based in our San Francisco HQ. We offer relocation assistance to new employees.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Data Infrastructure Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201249259", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nWe bring OpenAI's technology to the world through products like ChatGPT and the OpenAI API.\nWe seek to learn from deployment and distribute the benefits of AI, while ensuring that this powerful tool is used responsibly and safely. Safety is more important to us than unfettered growth.\nAbout The Role\nWe are looking for an experienced Research Engineer to work on retrieval & search problems across our API and ChatGPT. As the AI landscape has evolved over the last few years, retrieval & search have emerged as key use cases for our models, and we are investing in ensuring that we can offer these search-based product experiences for our users. You will be at the center of our retrieval & search efforts as a company, and the progress you drive here will reach millions of end users.\nIn This Role, You Will\nWork on retrieval & search algorithms and methodologies in close collaboration with our research team, including problems in such domains as document search, enterprise search, knowledge retrieval, and web-scale search.\nDeploy these search methodologies into production in both the API and ChatGPT to be used by millions of end users.\nExplore novel research topics in retrieval & search that may inform our product strategy in the medium and long term.\nPartner with researchers, engineers, product managers, and designers to bring new features and research capabilities to the world\nYou Might Thrive In This Role If You\nHave extensive prior experience building and maintaining production machine learning systems.\nHave prior experience working with vector databases, search indices, or other data stores for search and retrieval use cases\nHave prior experience building and iterating on internet-scale search systems\nOwn problems end-to-end, and are willing to pick up whatever knowledge you're missing to get the job done\nHave the ability to move fast in an environment where things are sometimes loosely defined and may have competing priorities or deadlines\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Research Engineer, Retrieval & Search, Applied Engineering", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201893436", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nWe're hiring across multiple teams, each focused on distinct areas of advancing artificial general intelligence (AGI). As an ML engineer supporting these teams, you\u2019ll help build the infrastructure that powers our research roadmap. Our goal is to dramatically accelerate research velocity by maximizing the efficiency of both our researchers and our hardware.\nAbout The Role\nWe're looking for ML engineers to help empower our researchers and accelerate research progress.\nIdeally, you've worked with researchers in the past and enjoy the challenges of a dynamic research environment. We're looking for people who love making the teams they work on more productive and love making the GPUs they\u2019re using more productive.\nThis role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nIn This Role, You Will\nBuild tooling or infrastructure to accelerate the teams you work on\nDig into issues across the stack, even if it goes outside your team\u2019s remit\nHelp co-design ML with systems considerations\nMake clever tradeoffs to unblock exploration while maintaining sanity\nDo what it takes to unblock research progress\nYou Might Thrive In This Role If You\nLove figuring out how to make ML systems work better\nHave experience with ML experimentation and LLM training or inference\nHave strong software engineering skills and are proficient in Python\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $325K - $405K", "comp": "$325,000.00", "title": "ML Infrastructure Generalist", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4298059996", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Strategic Deployment team makes frontier models more capable, reliable, and aligned to transform high-impact domains. On one hand, this involves deploying models in real-world, high-stakes settings to drive AI-driven transformation and elicit insights\u2014training data, evaluation methods, and techniques\u2014to shape our frontier model development. On the other hand, we leverage these learnings to build the science and engineering of impactful frontier model deployment.\nPut differently, we want to understand: if AGI is viewed as AI being able to majorly transform our economy, how close are we to AGI? What\u2019s still missing? How do we bridge these gaps?\nAbout The Role\nAs a \nResearch Engineer on the Focused Bets effort in the Strategic Deployment team\n, you will help OpenAI identify real-world domains that are ripe for transformation through frontier AI capabilities. You\u2019ll act as a technical lead and hands-on builder, partnering with subject matter experts to understand the key aspects of a given domain, pinpointing the most critical tasks in that domain, and developing technical proofs-of-concept that build conviction driving OpenAI\u2019s strategic engagements.\nWe\u2019re looking for people who combine a strong machine learning background with an entrepreneurial mindset\u2014engineers who can thrive in ambiguity, quickly iterate toward the signal, and adapt their approach as new insights emerge. You should be deeply curious about where AI can (and can\u2019t yet) have impact, and excited to push the boundaries of what\u2019s possible.\nThis role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nIn This Role, You Will\nDrive research and prototyping sprints into specific domains in collaboration with domain experts.\nTranslate real-world tasks into tractable ML/engineering problems and develop proof-of-concept solutions using OpenAI models and tools.\nDeliver working demos, run in-the-wild evaluations, and distill insights into actionable guidance for OpenAI\u2019s research and deployment teams.\nYou Might Thrive In This Role If You\nCare about real-world impact of AI.\nAre excited to drive how frontier models are developed and deployed.\nHave hands-on experience in AI research, systems, or applied science.\nAre excited by startup-style ambiguity and enjoy working across disciplines to drive a project from zero to one.\nEnjoy working in open-ended problem spaces and high-feedback environments.\nAre a curious, adaptable generalist who enjoys learning fast, asking deep questions, and solving open-ended problems.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Research Engineer, Focused Bets", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4260743323", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Privacy Engineering Team at OpenAI is committed to integrating privacy as a foundational element in OpenAI's mission of advancing Artificial General Intelligence (AGI). Our focus is on all OpenAI products and systems handling user data, striving to uphold the highest standards of data privacy and security.\nWe build essential production services, develop novel privacy-preserving techniques, and equip cross-functional engineering and research partners with the necessary tools to ensure responsible data use. Our approach to prioritizing responsible data use is integral to OpenAI's mission of safely introducing AGI that offers widespread benefits.\nAbout The Role\nAs a part of the Privacy Engineering Team, you will work on the frontlines of safeguarding user data while ensuring the usability and efficiency of our AI systems. You will help us understand and implement the latest research in privacy-enhancing technologies such as differential privacy, federated learning, and data memorization. Moreover, you will focus on investigating the interaction between privacy and machine learning, developing innovative techniques to improve data anonymization, and preventing model inversion and membership inference attacks.\nThis position is located in San Francisco. Relocation assistance is available.\nIn This Role, You Will\nDesign and prototype privacy-preserving machine-learning algorithms (e.g., differential privacy, secure aggregation, federated learning) that can be deployed at OpenAI scale.\nMeasure and strengthen model robustness against privacy attacks such as membership inference, model inversion, and data memorization leaks\u2014balancing utility with provable guarantees.\nDevelop internal libraries, evaluation suites, and documentation that make cutting-edge privacy techniques accessible to engineering and research teams.\nLead deep-dive investigations into the privacy\u2013performance trade-offs of large models, publishing insights that inform model-training and product-safety decisions.\nDefine and codify privacy standards, threat models, and audit procedures that guide the entire ML lifecycle\u2014from dataset curation to post-deployment monitoring.\nCollaborate across Security, Policy, Product, and Legal to translate evolving regulatory requirements into practical technical safeguards and tooling.\nYou Might Thrive In This Role If You\nHave hands-on research or production experience with PETs.\nAre fluent in modern deep-learning stacks (PyTorch/JAX) and comfortable turning cutting-edge papers into reliable, well-tested code.\nEnjoy stress-testing models\u2014probing them for private data leakage\u2014and can explain complex attack vectors to non-experts with clarity.\nHave a track record of publishing (or implementing) novel privacy or security work and relish bridging the gap between academia and real-world systems.\nThrive in fast-moving, cross-disciplinary environments where you alternate between open-ended research and shipping production features under tight deadlines.\nCommunicate crisply, document rigorously, and care deeply about building AI systems that respect user privacy while pushing the frontiers of capability.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $380K - $460K", "comp": "$380,000.00", "title": "Research Engineer, Privacy", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4275241920", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nWe bring OpenAI's technology to the world through products like ChatGPT and the OpenAI API.\nWe seek to learn from deployment and distribute the benefits of AI, while ensuring that this powerful tool is used responsibly and safely. Safety is more important to us than unfettered growth.\nAbout The Role\nOpenAI is looking for an experienced Performance Engineer to help us scale the performance, reliability, and efficiency of our systems. In this role, you'll apply deep technical expertise to optimize infrastructure and application-level performance across mission-critical products like ChatGPT and our developer API. You\u2019ll work cross-functionally with teams building core services, training models, and developing real-time user experiences to push our latency, throughput, and cost-efficiency to the next level.\nWe are looking for engineers who thrive in ambiguous environments, value deep systems understanding, and are motivated by delivering measurable impact. This is a highly technical, individual contributor role focused on root-cause analysis, profiling, instrumentation, and architecture-level performance improvements across our stack.\nIn This Role, You Will\nAnalyze and optimize performance across application, middleware, runtime, and infrastructure layers\u2014networking, storage, Python runtime, GPU utilization, and beyond.\nDevelop tooling and metrics that provide deep observability into system performance.\nCollaborate closely with infra, platform, training, and product teams to identify key performance goals and drive systemic improvements.\nInfluence architecture and design decisions to prioritize latency, throughput, and efficiency at scale.\nLead investigations into high-impact performance regressions or scalability issues in production.\nDrive performance testing strategies and help define SLAs/SLOs around latency and throughput for critical systems.\nYou Might Thrive In This Role If You\nHave 7+ years of experience in software engineering with a strong track record in performance or reliability of high-scale distributed systems.\nAre deeply comfortable with performance profiling tools and tracing systems.\nHave experience optimizing performance across one or more layers of the stack (e.g., database, networking, storage, application runtime, GC tuning, Python/Golang internals, GPU utilization).\nHave a strong understanding of OS internals, scheduling, memory management, and IO patterns.\nHave contributed to observability, benchmarking, or performance-focused infrastructure at scale.\nHave demonstrated success navigating ambiguity and aligning stakeholders around performance goals.\nValue simplicity, rigor, and collaboration when solving complex systems problems.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $325K - $405K", "comp": "$325,000.00", "title": "Product Performance Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4286755140", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Scaling team is responsible for the architectural and engineering backbone of OpenAI\u2019s infrastructure. We design and deliver advanced systems that support the deployment and operation of cutting-edge AI models. Our work spans system software, platform architecture, fleet-level monitoring, and performance optimization.\nAbout The Role\nWe're seeking a System Software Engineer to lead the development of next-generation system manageability. In this role, you will design system management interfaces and APIs aligned with industry standards, and collaborate closely with teams focused on orchestration and monitoring.\nYou will act as a key technical liaison between internal teams and external partners, ensuring high standards for security, scalability, and observability. You\u2019ll lead development and integration of core components, guide third-party contributions, and ensure systems are production-ready at scale.\nResponsibilities\nDesign and implement software components supporting system manageability (e.g., boot processes, telemetry, update flows).\nLead architectural efforts for system-level power, thermal, and health monitoring.\nExtend management firmware to integrate with internal tooling and workflows.\nIntegrate monitoring-related software from external sources.\nDefine diagnostics and contribute to system bring-up and factory validation tooling.\nReview external software for compliance, security, and performance.\nSpecify interfaces between system software and hardware management abstractions.\nCollaborate across hardware, software, and platform engineering to deliver cohesive functionality.\nParticipate in hands-on debugging and validation during system bring-up and deployment.\nContribute to improvements in system reliability, availability, and serviceability.\nQualifications\nRequired:\nExperience designing and implementing large-scale system management interfaces and automation.\nStrong skills in C/C++, Python, and shell scripting; Rust is a plus.\nFamiliarity with hardware health and monitoring concepts.\nExperience with provisioning and bootstrapping of systems.\nProven track record of developing scalable system monitoring tools.\nAbility to define software requirements for vendors and assess their work.\nUnderstanding of system security primitives (e.g., secure boot, attestation, root-of-trust).\nAbility to collaborate across multidisciplinary teams.\nNice To Have\nBackground in high-performance or datacenter-scale computing environments.\nFamiliarity with telemetry ingestion and observability systems.\nExperience working with diverse firmware ecosystems across multiple platforms.\nExposure to open management software projects.\nTo comply with U.S. export control laws and regulations, candidates for this role may need to meet certain legal status requirements as provided in those laws and regulations.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "System Software Engineer, Manageability Architecture", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4244036279", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Frontier Evals team builds north star model evaluations to drive progress towards safe AGI/ASI. This team builds ambitious evaluations to measure and steer our models, and creates self-improvement loops to steer our training, safety, and launch decisions. Some of the team's open-sourced evaluations include SWE-bench Verified, MLE-bench, PaperBench, and SWE-Lancer, and the team built and ran frontier evaluations for GPT4o, o1, o3, GPT 4.5, ChatGPT Agent, and GPT5. If you are interested in feeling firsthand the fast progress of our models, and steering them towards good, this is the team for you.\nAbout You\nWe seek exceptional research engineers that can push the boundaries of our frontier models in the finance domain. We are looking for those who will help shape AI evaluations of financial reasoning and related capabilities, and will own individual threads within this endeavor end-to-end.\nIn This Role, You'll\nIdentify important model capabilities, skills, and behaviors that are crucial to financial workflows, and design methods to quantify performance in these areas\nOwn and pursue a research agenda to identify an important model capability (especially as it relates to financial reasoning) and build evals to measure it\nContinuously refine evaluations of frontier AI models to assess the extent of frontier capabilities\nWe Expect You To\nHave strong engineering and statistical analysis skills (with at least 2-3 years of full-time technical experience)\nBe passionate about Excel spreadsheets and/or finance\nBe detail-oriented and thorough\nBe a team player / willing to do a variety of tasks to move the team forward\nBe passionate and knowledgeable about AGI/ASI measurement\nBe able to operate effectively in a dynamic and extremely fast-paced research environment as well as scope and deliver projects end-to-end\nIt Would Be Great If You Also Have\nPrior background / domain expertise in finance, especially investment banking or private equity (e.g., through internships, prior jobs)\nAn ability to work cross-functionally\nExcellent communication skills\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Research Engineer, Frontier Evals - Finance", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4291412008", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "OpenAI is pushing artificial intelligence to an unprecedented scale. We have a huge compute footprint and run some of the biggest GPU clusters in the world. As our scale has grown, so has our threat landscape \u2013 while advanced AI can benefit the world, in the wrong hands, it can also be used maliciously.\nAs a security-focused Distributed Systems engineer, you will build large-scale production-grade distributed systems that secure OpenAIs massive fleet. This requires both providing easy to use, introspectable systems that can promote a fast debugging and development cycle, while also enabling that experience to scale to our newest supercomputers maintaining stability and performance throughout.\nYou will work alongside a team of engineers, developers, and security advisers to design, architect, and drive security improvements across OpenAI. We are a small company, and intend to stay small: as an early member of the team, the decisions you make today will have a significant impact on the organization today and into the future.\nWe\u2019re looking for an engineer with a broad knowledge of distributed systems, software engineering, and infrastructure operations, experienced with a wide variety of real-world issues.\nIn This Role, You Will\nWork across our Go, Python, and Rust stacks\nBuild infrastructure and primitives to secure our bare metal and cloud infrastructure, using modern approaches and technologies, such as trusted computing.\nProfile and optimize and help design for scale, while keeping security as transparent as possible to engineers and researchers.\nYou Might Thrive In This Role If You\nHave designed, implemented, and operated large-scale distributed systems.\nLove figuring out how systems work and continuously come up with ideas for how to make them faster while minimizing complexity and maintenance burden.\nHave strong software engineering skills and are proficient in Python, Go, and/or Rust.\nHave a good understanding of tradeoffs between security, reliability, usability, and performance.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Distributed Systems Engineer, Security", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4208672551", "loc": "United States", "company": "OpenAI"}, {"desc": "About The Team\nWe're hiring across multiple teams, each focused on distinct areas of advancing artificial general intelligence (AGI). As an engineer supporting these teams, you\u2019ll help build the infrastructure that powers our research roadmap. Our goal is to dramatically accelerate research velocity by maximizing the efficiency of our researchers.\nAbout The Role\nWe're looking for infrastructure engineers to help empower our researchers and accelerate research progress.\nIdeally, you've worked with researchers in the past and enjoy the challenges of a dynamic research environment. We're looking for people who love making the teams they work on more productive.\nThis role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nIn This Role, You Will\nBuild tooling or infrastructure to accelerate the teams you work on\nDig into issues across the stack, even if it goes outside your team\u2019s remit\nCollaborate with others to help find the solutions people didn\u2019t know they needed\nMake clever tradeoffs to unblock exploration while maintaining sanity\nDo what it takes to unblock research progress\nYou Might Thrive In This Role If You\nLove figuring out how to make systems work better for people\nHave strong software engineering skills and are proficient in Python\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $325K - $405K", "comp": "$325,000.00", "title": "Infrastructure Generalist", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4298063172", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Safety Systems team is responsible for various safety work to ensure our best models can be safely deployed to the real world to benefit the society, and is at the forefront of OpenAI's mission to build and deploy safe AGI, driving our commitment to AI safety and fostering a culture of trust and transparency.\nThe Safety Oversight Research team aims to fundamentally advance our capabilities to maintain oversight over frontier AI models, and leverage these advances to ensure OpenAI\u2019s deployed models are safe and beneficial. This requires a breadth of new ML research in the areas of human-AI collaboration, reasoning, robustness, and scalable oversight to keep pace with model capabilities. We invest heavily in developing novel model and system-level methods of identifying and mitigating AI misuse and misalignment.\nOur goal is to learn from deployment and distribute the benefits of AI, while ensuring that this powerful tool is used responsibly and safely.\nAbout The Role\nOpenAI is seeking a senior researcher with a passion for AI safety and experience in safety research. Your role will set directions for research to maintain effective oversight of safe AGI and work on research projects to identify and mitigate misuse and misalignment in our AI systems. You will play a critical role in defining how a safe AI system should look in the future at OpenAI, making a significant impact on our mission to build and deploy safe AGI.\nIn This Role, You Will\nDevelop and refine AI monitor models to detect and mitigate known and emerging patterns of misuse and misalignment.\nSet research directions and strategies to make our AI systems safer, more aligned, and more robust.\nEvaluate and design effective red-teaming pipelines to examine the end-to-end robustness of our safety systems, and identify areas for future improvement.\nConduct research to improve models\u2019 ability to reason about questions of human values, and apply these improved models to practical safety challenges.\nCoordinate and collaborate with cross-functional teams, including T&S, legal, policy and other research teams, to ensure that our products meet the highest safety standards.\nYou Might Thrive In This Role If You\nAre excited about OpenAI\u2019s mission of building safe, universally beneficial AGI and are aligned with OpenAI\u2019s charter\nShow enthusiasm for AI safety and dedication to enhancing the safety of cutting-edge AI models for real-world use.\nBring 4+ years of experience in the field of AI safety, especially in areas like RLHF, human-AI collaboration, fairness & biases.\nHold a Ph.D. or other degree in computer science, machine learning, or a related field.\nThrive in environments involving large-scale AI systems.\nPossess 4+ years of research engineering experience and proficiency in Python or similar languages.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Research Engineer / Scientist, Safety Oversight", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201249284", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Future of Computing is an Applied Research team focused on prototyping and exploring how (consumer) computing might holistically evolve as we advance on our mission of building AGI.\nAbout The Role\nAs a Research Engineer on the Future of Computing team, you will work together with \nboth\n the best research scientists in the world and the greatest design talent of our generation to push the frontier of model capabilities.\nThe ideal candidate will have a research background and experience shipping AI products that involve novel sensor inputs (think IMU data or other time-series data).\nThis role is based in San Francisco, CA. We use a hybrid work model of 4 days in the office per week and offer relocation assistance to new employees.\nIn This Role You Will\nTrain and evaluate multimodal SoTA models along axis that are important to our emerging explorations.\nRun through the necessary walls to take nascent research capabilities and turn them into capabilities we can build on top of.\nYou Might Thrive In This Role If You\nLove exposure to a bit of everything \u2013 we\u2019re collaborators with a hugely diverse set of research.\nDo rigorous science (rather than vibes based). We need confidence in the experiments we run to move quickly.\nHave already spent time in the weeds teaching models to speak and perceive.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Senior Research Engineer/Scientist - Sensing, Future of Computing", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4231202174", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Future of Computing is an Applied Research team focused on prototyping and exploring how (consumer) computing might holistically evolve as we advance on our mission of building AGI.\nAbout The Role\nAs a Research Engineer on the Future of Computing team, you will work together with \nboth\n the best research scientists in the world and the greatest design talent of our generation to push the frontier of model capabilities. The ideal candidate will have a research background and experience shipping AI products with models in compute-constrained environments.\nThis role is based in San Francisco, CA. This role is fully onsite 5 days in office per week and offer relocation assistance to new employees.\nIn This Role You Will\nTrain and evaluate multimodal SoTA models along axis that are important to our emerging explorations.\nRun through the necessary walls to take nascent research capabilities and turn them into capabilities we can build on top of.\nYou Might Thrive In This Role If You\nLove exposure to a bit of everything \u2013 we\u2019re collaborators with a hugely diverse set of research.\nDo rigorous science (rather than vibes based). We need confidence in the experiments we run to move quickly.\nHave experience working with compute-constrained hardware for inference.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Senior Research Engineer - Edge, Future of Computing", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201251259", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nOur Robotics team is focused on unlocking general-purpose robotics and pushing towards AGI-level intelligence in dynamic, real-world settings. Working across the entire model stack, we integrate cutting-edge hardware and software to explore a broad range of robotic form factors. We strive to seamlessly blend high-level AI capabilities with the constraints of physical systems to improve peoples\u2019 lives.\nAbout The Role\nWe are seeking a Software Engineer to lead our simulation environments initiative, setting the vision for scaling our virtual environments in coverage, realism, and throughput. In this role, you will harness modern game development practices to leverage and extend industry-leading platforms such as NVIDIA Isaac Sim, Unity, or Unreal Engine to design and deliver synthetic environments that are dynamic, richly interactive, and photorealistic. You will build scalable content pipelines that enable rapid creation of diverse simulation scenarios within these synthetic environments that will allow our research teams to push the boundaries of robotics training and validation.\nYour mission will be to build these simulated environments and associated infrastructure from the ground up. You will be given a high degree of autonomy to do this work. You will select the platform, help source assets and will help build a team of in-house simulation experts. You will collaborate closely with experts across software, hardware, research, and operations to ensure our simulators capture the true complexity of physical interactions while remaining intuitive, extensible, and easy to integrate for other teams.\nThis role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nIn This Role, You Will\nDesign, build, and maintain a high-performance, scalable simulator integrations that meshes cleanly with our existing codebase and data pipelines.\nCurate, convert, and quality-check open-source environment assets so they can be deployed at scale across our simulation farm.\nDevelop domain- and task-randomization frameworks that systematically expose models to diverse visual, physical, and kinematic conditions.\nLead proof-of-concept collaborations with external GPU-accelerated simulation vendors to benchmark new features and influence roadmap priorities.\nEstablish best practices for versioning, testing, and validating simulated scenarios against real-world benchmarks.\nYou Might Thrive In This Role If You\nEnjoy plumbing every layer of a robotics simulation stack\u2014from CAD import and asset optimization to real-time loading, contact dynamics and rendering.\nKeep current with advances in physics engines, differentiable simulation, and synthetic-data generation for robot learning.\nHave led projects that bridge simulation and robotics, including teleoperation or hardware-in-the-loop testing.\nFind satisfaction in building ergonomic tools, templates, and documentation that empower dozens of engineers and researchers to author new tasks quickly.\nHave hands-on experience optimizing GPU pipelines, distributed compute jobs, or large-scale reinforcement-learning workloads.\nHave experience building NVIDIA Isaac sim environments or environments in other open source world simulation engines.\nWant to build creative tasks to challenge cutting edge large action models.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $325K - $405K", "comp": "$325,000.00", "title": "Simulation Environments Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4287169028", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nWithin the OpenAI Security organization, our IT team works to ensure our team of researchers, engineers, and staff have the tools they need to work comfortably, securely, and with minimal interruptions. As an Enterprise Security Engineer, you will work in a highly technical and employee-focused environment.\nOur IT team is a small and nimble team, where you\u2019ll have the opportunity to dive into a wide breadth of areas and build from the ground up. We\u2019re well supported and well resourced, and have a mandate to deliver a world-class enterprise security program to our teams.\nAbout The Role\nAs an Enterprise Security Engineer, you will be responsible for implementing and managing the security of OpenAI's internal information systems\u2019 infrastructure and processes. You will work closely with our IT and Security teams to develop security capabilities, enforce security policies, and monitor internal systems for security threats.\nThis role is open to remote employees, or relocation assistance is available to San Francisco.\nIn This Role, You Will\nDevelop and implement security measures to protect our company's information assets against unauthorized access, disclosure, or misuse.\nMonitor internal and external systems for security threats and respond to alerts.\nContribute to and enforce our company's IT and Security policies and procedures.\nWork closely with our IT department to harden our infrastructure using best practices in AzureAD, GSuite, Github, and other SaaS tooling.\nAdvise our employees on best practices for maintaining the security of their endpoints, and office AV and network infrastructure.\nDevise novel sharing controls and associated monitoring to protect company data, including intelligent groups management, Data Loss Prevention (DLP) and other security controls as appropriate.\nEmploy forward-thinking models like \u201csecure by default\u201d and \u201czero trust\u201d to create sustainably secure environments for knowledge workers and developers.\nIdentify and remediate vulnerabilities in our internal systems, adhering to best practices for data security.\nUse our own AI-driven models to develop systems for improved security detection and response, data classification, and other security-related tasks.\nEducate employees on the importance of data security, and advise them on best practices for maintaining a secure environment.\nContribute to OpenAI's endpoint and cloud security roadmaps by staying up to date with the latest security threats, and making recommendations for improving our security posture.\nYou Might Thrive In This Role If You Have\nExperience in protecting and managing macOS fleets.\nExperience deploying and managing endpoint security solutions (e.g. management frameworks, EDR tools).\nExperience with public cloud service providers (e.g. Amazon AWS, Microsoft Azure).\nExperience with identity and access management frameworks and protocols, including SAML, OAUTH, and SCIM.\nExperience with e-mail security protocols (e.g. SPF, DKIM, DMARC) and controls.\nIntermediate or advanced proficiency with a scripting language (e.g. Python, Bash, or similar).\nKnowledge of modern adversary tactics, techniques, and procedures.\nAbility to empathize and collaborate with colleagues, independently manage and run projects, and prioritize efforts for risk reduction.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Enterprise Security Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4226006335", "loc": "United States", "company": "OpenAI"}, {"desc": "About The Team\nThe team\u2019s mission is to accelerate the secure evolution of agentic AI systems at OpenAI. To achieve this, the team designs, implements, and continuously refines security policies, frameworks, and controls that defend OpenAI\u2019s most critical assets\u2014including the user and customer data embedded within them\u2014against the unique risks introduced by agentic AI.\nAbout The Role\nAs a Security Engineer on the Agent Security Team\n, you will be at the forefront of securing OpenAI\u2019s cutting-edge agentic AI systems. Your role will involve designing and implementing robust security frameworks, policies, and controls to safeguard OpenAI\u2019s critical assets and ensure the safe deployment of agentic systems. You will develop comprehensive threat models, partner tightly with our Agent Infrastructure group to fortify the platforms that power OpenAI\u2019s most advanced agentic systems, and lead efforts to enhance safety monitoring pipelines at scale.\nWe are looking for a versatile engineer who thrives in ambiguity and can make meaningful contributions from day one. You should be prepared to ship solutions quickly while maintaining a high standard of quality and security.\nWe\u2019re looking for people who can drive innovative solutions that will set the industry standard for agent security. You will need to bring your expertise in securing complex systems and designing robust isolation strategies for emerging AI technologies, all while being mindful of usability. You will communicate effectively across various teams and functions, ensuring your solutions are scalable and robust while working collaboratively in an innovative environment. In this fast-paced setting, you will have the opportunity to solve complex security challenges, influence OpenAI\u2019s security strategy, and play a pivotal role in advancing the safe and responsible deployment of agentic AI systems.\nThis role is based in \nSan Francisco, CA\n. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nYou\u2019ll Be Responsible For\nArchitecting security controls for agentic AI \u2013 design, implement, and iterate on identity, network, and runtime-level defenses (e.g., sandboxing, policy enforcement) that integrate directly with the Agent Infrastructure stack.\nBuilding production-grade security tooling \u2013 ship code that hardens safety monitoring pipelines across agent executions at scale.\nCollaborating cross-functionally \u2013 work daily with Agent Infrastructure, product, research, safety, and security teams to balance security, performance, and usability.\nInfluencing strategy & standards \u2013 shape the long-term Agent Security roadmap, publish best practices internally and externally, and help define industry standards for securing autonomous AI.\nWe\u2019re Looking For Someone With\nStrong software-engineering skills in Python or at least one systems language (Go, Rust, C/C++), plus a track record of shipping and operating secure, high-reliability services.\nDeep expertise in modern isolation techniques \u2013 experience with container security, kernel-level hardening, and other isolation methods.\nHands-on network security experience \u2013 implementing identity-based controls, policy enforcement, and secure large-scale telemetry pipelines.\nClear, concise communication that bridges engineering, research, and leadership audiences; comfort influencing roadmaps and driving consensus.\nBias for action & ownership \u2013 you thrive in ambiguity, move quickly without sacrificing rigor, and elevate the security bar company-wide from day one.\nCloud security depth on at least one major provider (Azure, AWS, GCP), including identity federation, workload IAM, and infrastructure-as-code best practices.\nFamiliarity with AI/ML security challenges \u2013 experience addressing risks associated with advanced AI systems (nice-to-have but valuable).\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $325K - $495K", "comp": "$325,000.00", "title": "Security Engineer, Agent Security", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4265497988", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe GTM (Go-To-Market) Innovation team is an internal powerhouse revolutionizing how we engage customers through groundbreaking applications of our technology. As an incubator, we amplify the impact of Sales, Technical Success, Enablement, and Revenue Operations by deploying our technology at scale. This team applies advanced capabilities to real-world interactions \u2014 reshaping conversations with customers, learning from every exchange, and finding novel ways to show the value of our technology.\nAbout The Role\nWe\u2019re looking for product mindset software engineers to join the GTM Innovation team.\nAs a product engineer on this team, you\u2019ll help OpenAI meet the world at scale. You\u2019ll partner closely with go-to-market teams to understand their workflows, identify leverage points, and ship novel solutions using OpenAI\u2019s API platform.\nYou\u2019ll move quickly from prototype to production, and your work will directly shape how customers experience our technology in the field. This role is ideal for engineers who want to be close to users, own end-to-end outcomes, and help define entirely new categories of enterprise software.\nIn This Role, You Will\nBuild high-impact applications and tools that accelerate OpenAI\u2019s go-to-market efforts\nWork across the full product lifecycle for GTM: prototype, iterate, ship, and maintain\nEmbed with Sales, Technical Success, and Revenue Operations to identify user needs and build for them\nApply OpenAI\u2019s models in novel ways to solve real-world customer and internal workflow problems\nTranslate learnings into feedback for Applied and Research teams to inform product development\nYou\u2019ll Thrive In This Role If You\nHave 4+ years of experience as a software/ML/product engineer working on user-facing systems\nFormer founder, or early engineer at a startup who built a product from scratch is a plus\nAre fluent in Python or JavaScript and comfortable building full-stack applications\nHave built or prototyped LLM-powered workflows using the OpenAI API (or similar)\nTake initiative, move quickly, and operate with a strong sense of ownership\nEnjoy working closely with end users and shaping 0\u21921 products\nAre collaborative, curious, and motivated to make an outsized impact at the frontier of AI\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Product Engineer, GTM Innovation", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4303790872", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nOpenAI\u2019s mission is to build safe artificial general intelligence (AGI) which benefits all of humanity. This long-term undertaking brings the world\u2019s best scientists, engineers, and business professionals into one lab together to accomplish this.\nIn pursuit of this mission, our Revenue Operations team is responsible for equipping and enabling the Go To Market (GTM) as they seek to help customers learn how to leverage and deploy our highly capable AI products across their business. The team is made of Sales, Solutions, Customer Success, Support, Marketing, and Partnership professionals that work together to create valuable solutions that will help bring AI to as many users as possible.\nAbout The Role\nWe\u2019re seeking a GTM Systems Engineer with a strong focus on integrations to design, build, and maintain the connections, automations, and workflows that power our GTM operations. This is an execution-driven role for someone eager to work across multiple systems, improve data flows, and ensure our platforms work seamlessly together.\nYou will collaborate with Enterprise Systems Managers, fellow engineers, and cross-functional teams to deliver integration projects, automate key workflows, and enhance the stability and scalability of our GTM tech stack. You\u2019ll contribute to a variety of initiatives, sometimes leading a project from start to finish, other times working as a critical contributor to larger systems engineering efforts.\nThis role is based in New York, NY. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nIn This Role, You'll\nDesign, build, and maintain integrations between GTM platforms, including Salesforce, data warehouses, Retool and other enterprise tools.\nImplement automation and data transformation workflows to improve efficiency and reduce manual work.\nTroubleshoot and resolve integration issues quickly, ensuring minimal disruption to GTM operations.\nCollaborate cross-functionally to gather requirements, refine solutions, and deliver high-quality technical outcomes. Ensure integrations follow best practices for security, scalability, and maintainability.\nYou Might Thrive In This Role If You Have\nProven ability to deliver technical projects in a fast-paced environment.\nExperience with API-based integrations, automation platforms, and enterprise system workflows.\nStrong troubleshooting skills and attention to detail in diagnosing and fixing integration issues\nWorking knowledge of data governance and security practices.\nA willingness to learn new tools and adapt to changing business priorities.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $288K", "comp": "0", "title": "GTM Systems Engineer, Integrations", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4286988129", "loc": "New York, NY", "company": "OpenAI"}, {"desc": "About The Team\nSecurity is at the foundation of OpenAI\u2019s mission to ensure that artificial general intelligence benefits all of humanity.\nThe Security team protects OpenAI\u2019s technology, people, and products. We are technical in what we build but are operational in how we do our work, and are committed to supporting all products and research at OpenAI. Our Security team tenets include: prioritizing for impact, enabling researchers, preparing for future transformative technologies, and engaging a robust security culture.\nAbout The Role\nOpenAI is seeking a Security Engineer to join our Infrastructure Security (InfraSec) team. InfraSec protects the foundations of OpenAI\u2019s research and production environments, spanning GPU supercomputing clusters, multi-cloud infrastructure, datacenters, networking, storage, and the critical services that power our frontier AI models. Our charter includes securing everything from bare-metal hardware and firmware, to Kubernetes clusters and service meshes, to data storage and access pathways for highly sensitive model weights and user data.\nIn This Role, You Will\nDesign and build security controls across diverse layers (e.g., physical hardware, firmware/BMC, OS, Kubernetes, networks, and CI/CD) to defend against sophisticated adversaries and insider threats.\nCollaborate with engineering and security teams to drive deployment of security enhancements and control changes across broad-scale infrastructure.\nTackle high-impact projects such as checkpoint encryption, network isolation, secret management, and machine identity, while continuously raising the security bar for emerging AI workloads.\nTake a generalist approach to building security controls, balancing a mix of security expertise and broad technical skillsets to adapt to evolving challenges.\nYou Will Thrive In This Role If You Have\nDeep understanding of security principles, best practices, and common vulnerabilities.\nA proactive mindset, with the ability to identify and address security gaps or inefficiencies through automation and tooling.\nA track record of delivering scalable solutions and driving impactful changes across infrastructure in real-world projects.\nExpertise in the security of cloud platforms (e.g., Amazon AWS, Microsoft Azure), especially securing multi-cloud networks and infrastructure, and designing cloud agnostic systems.\nExperience securing on-prem deployments and datacenters from construction to multi-tenant use.\nFamiliarity with container security, orchestration security, and authentication/authorization.\nStrong analytical and problem-solving skills, with an ability to think critically and objectively assess security risks.\nExcellent communication skills, with the ability to convey complex security concepts to technical and non-technical stakeholders.\nExcitement about collaborating with cross-functional teams to build secure, reliable systems that scale globally.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Security Engineer, Infrastructure Security", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4309215448", "loc": "New York City Metropolitan Area", "company": "OpenAI"}, {"desc": "About The Team\nThe Safety Systems team is responsible for various safety work to ensure our best models can be safely deployed to the real world to benefit the society and is at the forefront of OpenAI's mission to build and deploy safe AGI, driving our commitment to AI safety and fostering a culture of trust and transparency.\nThe Model Safety Research team aims to fundamentally advance our capabilities for precisely implementing robust, safe behavior in AI models, and to leverage these advances to make OpenAI\u2019s deployed models safe and beneficial. This requires a breadth of new ML research to address the growing set of safety challenges as AI becomes more powerful and used in more settings. Key focus areas include how to enforce nuanced safety policies without trading off helpfulness and capabilities, how to make the model robust to adversaries, how to address privacy and security risks, and how to make the model trustworthy in safety-critical domains.\nWe seek to learn from deployment and distribute the benefits of AI, while ensuring that this powerful tool is used responsibly and safely.\nAbout The Role\nOpenAI is seeking a senior researcher with passion for AI safety and experience in safety research. Your role will set directions for research to enable and empower safe AGI and work on research projects to make our AI systems safer, more aligned and more robust to adversarial or malicious use cases. You will play a critical role in shaping how a safe AI system should look like in the future at OpenAI, making a significant impact on our mission to build and deploy safe AGI.\nIn This Role, You Will\nConduct state-of-the-art research on AI safety topics such as RLHF, adversarial training, robustness, and more.\nImplement new methods in OpenAI\u2019s core model training and launch safety improvements in OpenAI\u2019s products.\nSet the research directions and strategies to make our AI systems safer, more aligned and more robust.\nCoordinate and collaborate with cross-functional teams, including T&S, legal, policy and other research teams, to ensure that our products meet the highest safety standards.\nActively evaluate and understand the safety of our models and systems, identifying areas of risk and proposing mitigation strategies.\nYou Might Thrive In This Role If You\nAre excited about OpenAI\u2019s mission of building safe, universally beneficial AGI and are aligned with OpenAI\u2019s charter\nDemonstrate a passion for AI safety and making cutting-edge AI models safer for real-world use.\nBring 4+ years of experience in the field of AI safety, especially in areas like RLHF, adversarial training, robustness, fairness & biases.\nHold a Ph.D. or other degree in computer science, machine learning, or a related field.\nPossess experience in safety work for AI model deployment\nHave an in-depth understanding of deep learning research and/or strong engineering skills.\nAre a team player who enjoys collaborative work environments.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Research Engineer / Scientist, Robustness & Safety Training", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201252107", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Solutions Architecture team is responsible for ensuring the safe and effective deployment of Generative AI applications for developers and enterprises. We act as a trusted advisor and thought partner for our customers, working to build an effective backlog of GenAI use cases for their industry and drive them to production through strong technical guidance. OpenAI's customers represent a range of diverse backgrounds and maturity, from early-stage startups to established global enterprises.\nAbout The Role\nWe are seeking a technically proficient, business-minded Solutions Architect to help push the frontier of advanced AI with our strategic startup customers. You'll work with some of the most exciting AI startups in the world, guiding them through ideation, development, delivery, and scaling to accelerate and maximize the value of what they build on our platform. You will have the opportunity to work on the most novel and creative use cases being built on our API, serving as a critical partner in collecting and delivering high-fidelity product and model feedback internally. You will collaborate closely with Sales, Solutions Engineering, Applied Research, and Product teams, and you will report to the Startups Solutions Architecture Lead.\nThis role is based in our San Francisco HQ. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nIn This Role, You Will\nPartner closely with strategic startup customers as their technical thought partner to build novel applications on our API, helping them rapidly move from ideation to scale.\nProvide proactive guidance to maximize business impact and accelerate application development.\nExperiment and prototype alongside customers, demonstrating practical use cases.\nContribute to open-source resources and scale the function by sharing knowledge, codifying best practices, and publishing useful resources.\nSynthesize and deliver valuable feedback to the Product and Research teams.\nBuild relationships within the startup ecosystem, serving as a technical partner to both individual customers and the broader community.\nYou\u2019ll Thrive In This Role If You\nHave 5+ years of experience as a software engineer, ML engineer or equivalent, ideally in a startup environment; experience as a founder or founding engineer is highly valued.\nHave passion for startups and a belief in their potential to become future large enterprises.\nAre proficient in Python, JavaScript, and a strong grasp of AI/LLM best practices.\nBuilt and/or delivered prototypes on top of our API platform.\nCan proactively identify opportunities for maximizing our customers\u2019 business value through leveraging the OpenAI API.\nOwn problems end-to-end and are willing to pick up whatever knowledge you're missing to get the job done.\nHave a humble attitude, an eagerness to help your colleagues, and a desire to do whatever it takes to make the team succeed.\nAre an effective, high throughput operator who can drive multiple concurrent projects and prioritize ruthlessly. \nWe are an equal opportunity employer and do not discriminate on the basis of race, religion, national origin, gender, sexual orientation, age, veteran status, disability or any other legally protected status. Pursuant to the San Francisco Fair Chance Ordinance, we will consider qualified applicants with arrest and conviction records.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Solutions Architect, Startups", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4220344243", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Scaling team builds and optimizes large-scale infrastructure to enable next-generation AI workloads.\nAbout The Role\nWe\u2019re looking for a founding/lead Linux kernel developer to join our Scaling team. In this role, you\u2019ll design and develop Linux kernel components, working at the intersection of hardware and software to unlock performance at scale.\nResponsibilities\nLead and bootstrap the development of our Linux kernel stack to support high-performance systems.\nDesign and implement kernel drivers, including for functionality related to DMA, PCIe, NICs, and RDMA.\nDrive end-to-end development of system-scale networking, including required kernel and other low-level software.\nCollaborate with vendors to integrate their technologies within our systems.\nBring up and debug the kernel on new platforms.\nBuild userspace software to support integration, testing, diagnostics, and performance validation.\nQualifications\nProven experience leading development within the Linux kernel.\nDeep knowledge of subsystems relevant to high-performance systems: PCIe, dma-buf, RDMA, P2P, SR-IOV, IOMMU, etc.\nKnowledge of subsystems and frameworks related to scale-out networking: ibverbs, ECN/DCQCN, etc.\nStrong programming skills in C, C++, Python, and Linux shell scripting; Rust experience is a strong plus.\nExperience working directly with engineering teams to define interfaces and tooling.\nTrack record of managing vendor deliverables and technical relationships.\nBackground in embedded systems development (bootloaders, drivers, hardware/software integration).\nAbility to thrive in ambiguity and build systems from scratch.\nTo comply with U.S. export control laws and regulations, candidates for this role may need to meet certain legal status requirements as provided in those laws and regulations.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Linux Kernels Software Lead", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4291458529", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nSecurity is at the foundation of OpenAI\u2019s mission to ensure that artificial general intelligence benefits all of humanity. The Security team protects OpenAI\u2019s technology, people, and products. We are technical in what we build but are operational in how we do our work, and are committed to supporting all products and research at OpenAI. Our Security team tenets include: prioritizing for impact, enabling researchers, preparing for future transformative technologies, and engaging a robust security culture.\nAbout The Role\nTrusted Computing and Cryptography is a core security team at OpenAI focused on deploying high-performance cryptography at scale, secure key management, and trusted hardware enclaves\u2014from boot measurements to GPU confidential computation. As a Hardware Security Engineer, you\u2019ll own hardware security at OpenAI by co-designing secure chipsets and integrating cryptographic techniques into our production systems.\nIn This Role, You Will\nCo-Design Secure Hardware: Collaborate with hardware vendors and cross-functional teams (kernel, compiler, and ML engineers) to design future secure hardware that meets performance and cryptographic needs.\nDevelop Critical Software: Write performance-critical code in Rust, Python, and C/C++ to build cryptographic libraries and secure key management systems.\nIntegrate Security Primitives: Architect and deploy systems using TPM2, Secure Boot, Nitro Enclaves, Intel SGX, AMD-SEV, and other secure hardware technologies.\nDrive Innovation: Engage with internal and external partners to align hardware innovations with OpenAI\u2019s trusted computing and cryptographic requirements.\nYou Might Thrive In This Role If You Have\n10+ years of industry experience in hardware security or hardware\u2013software co-design.\nProven expertise in deploying cryptographic systems at scale and integrating secure hardware primitives.\nStrong coding skills in Rust and/or C/C++, with proficiency in Python.\nProven ability to collaborate across teams, architect solutions, and debug complex production systems.\nA proactive, ownership-driven mindset with a focus on end-to-end problem solving.\nNice to Have\nAdvanced degree in Computer Architecture, Electrical Engineering, or related fields.\nFamiliarity with HPC, low-precision computing, and SIMD architectures.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Hardware Security Engineer, Trusted Computing and Cryptography", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4281718154", "loc": "United States", "company": "OpenAI"}, {"desc": "About The Team\nThe Frontier Systems team at OpenAI builds, launches, and supports the largest supercomputers in the world that OpenAI uses for its most cutting edge model training.\nWe take data center designs, turn them into real, working systems and build any software needed for running large-scale frontier model trainings.\nOur mission is to bring up, stabilize and keep these hyperscale supercomputers reliable and efficient during the training of the frontier models.\nAbout The Role\nAs a Software Engineer on the Frontier Systems team focused on power management, you will work on critical infrastructure to support cutting-edge research. With large-scale supercomputers consuming substantial amounts of power, managing this efficiently is key to maximizing computational capacity. This role is critical to ensuring that our cutting-edge research supercomputing infrastructure runs smoothly, while maintaining reliability and grid-level power stability.\nOur team empowers strong engineers with a high degree of autonomy and ownership, as well as ability to effect change. This role will require a keen focus on system-level comprehensive investigations and the development of automated solutions. We want people who go deep on problems, investigate as thoroughly as possible, and build automation for detection and remediation at scale.\nIn This Role, You Will\nDevelop and implement system-level and software-level solutions to optimize power usage in large-scale supercomputers, ensuring efficient and reliable operations.\nBuild automation to monitor power consumption patterns during training workloads and design algorithms to stabilize these fluctuations, preventing issues with grid reliability.\nWork with researchers and engineers to design tools for real-time monitoring, detection, and remediation of power-related hardware and system faults.\nCollaborate cross-functionally to translate complex electrical system requirements into code, while driving continuous improvements in power management solutions.\nDrive the development of power throttling mechanisms at the IT system level to dynamically adjust power usage based on workload demands and infrastructure limitations.\nCollaborate with hardware design teams to integrate system-level power control requirements into IT hardware design, ensuring seamless coordination between software-driven power management and hardware capabilities.\nYou Might Thrive In This Role If You Have\n7+ years of software engineering experience with a focus on solving large-scale, system-level challenges.\nStrong proficiency in Python and familiarity with automation and scripting tools (e.g., shell scripting).\nExperience with distributed systems to efficiently aggregate and analyze streaming data.\nKnowledge of electrical engineering concepts including digital signal processing, power systems, Fast Fourier Transforms, or related areas.\nExperience in system-level investigations and development of automated solutions to address power management, fault detection, and remediation.\nStrong analytical skills and the ability to dig into noisy data (experience with SQL, PromQL, Pandas, etc.).\nComfort working with both hardware and software teams to solve multidisciplinary problems.\nBonus Points If You Have\nDeep expertise with the power characteristics of synchronous workloads (as seen in supercomputing or model training environments).\nKnowledge of power control requirements in IT hardware design, with the ability to drive cross-functional collaboration to integrate power management features into hardware systems effectively.\nWorking knowledge of control system fundamentals and how physical systems respond to control strategies. \nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $310K - $460K", "comp": "$310,000.00", "title": "Software Engineer, Frontier Systems - Power Management", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4231482931", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Foundations Research team works on high-risk, high-reward ideas that could shape the next decade of AI. Our goal is to advance the science and data that enable our training and scaling efforts, with a particular focus on future frontier models. Pushing the boundaries of data, scaling laws, optimization techniques, model architectures, and efficiency improvements to propel our science.\nAbout The Role\nWe\u2019re looking for a technical research lead to grow and lead our embeddings-focused retrieval efforts. You\u2019ll manage a team of world-class research scientists and engineers developing foundational technology that enables models to retrieve and condition on the right information, at the right time. This includes designing new embedding training objectives, scalable vector store architectures, and dynamic indexing methods.\nThis work will support retrieval across many OpenAI products and internal research efforts, with opportunities for scientific publication and deep technical impact.\nThis role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nResponsibilities\nLead research into embedding models and retrieval systems optimized for grounding, relevance, and adaptive reasoning.\nManage a team of researchers and engineers building end-to-end infrastructure for training, evaluating, and integrating embeddings into frontier models.\nDrive innovation in dense, sparse, and hybrid representation techniques, metric learning, and learning-to-retrieve systems.\nCollaborate closely with Pretraining, Inference, and other Research teams to integrate retrieval throughout the model lifecycle\nContribute to OpenAI\u2019s long-term vision of AI systems with memory and knowledge access capabilities rooted in learned representations.\nYou Might Thrive in This Role If You Have\nProven experience leading high-performance teams of researchers or engineers in ML infrastructure or foundational research.\nDeep technical expertise in representation learning, embedding models, or vector retrieval systems.\nFamiliarity with transformer-based LLMs and how embedding spaces can interact with language model objectives.\nResearch experience in areas such as contrastive learning, supervised or unsupervised embedding learning, or metric learning.\nA track record of building or scaling large machine learning systems, particularly embedding pipelines in production or research contexts.\nA first-principles mindset for challenging assumptions about how retrieval and memory should work for large models.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Research Engineer / Research Scientist - Foundations Retrieval Lead", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4249726257", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe OpenAI for Government team is a dynamic, mission-driven group leveraging frontier AI to transform how governments achieve their missions. Our team works to empower public servants with secure, compliant AI tools (e.g., ChatGPT Enterprise, ChatGPT Gov) and mission-aligned deployments that meet government technical requirements with strong reliability and safety.\nAbout The Role\nForward Deployed Engineers (FDEs) lead complex deployments of frontier models in production. You will embed with our most strategic government and public sector customers\u2014where model performance matters, delivery is urgent, and ambiguity is the default. You\u2019ll map their problems, structure delivery, and ship fast. This includes scoping, sequencing, and building full-stack solutions that create measurable value, while driving clarity across internal and external teams.\nYou will work directly with defense, intelligence, and federal stakeholders as their technical thought partner, guiding adoption, maximizing mission impact, and ensuring successful deployments at scale. Along the way, you\u2019ll identify reusable patterns, codify best practices, and share field signal that influences OpenAI\u2019s roadmap.\nThis role is based in Washington DC. We use a hybrid work model of 3 days in the office per week. We offer relocation assistance. Travel up to 50% is required, including on-site work with customers.\nIn this role you will\nOwn technical delivery across multiple government deployments, from first prototype to stable production.\nDeeply embed with public sector customers to design and build novel applications powered by OpenAI models.\nEnable successful deployments across customer environments by delivering observable systems spanning infrastructure through applications.\nPrototype and build full-stack systems using Python, JavaScript, or comparable stacks that deliver real mission impact.\nProactively guide customers on maximizing business and operational value from their applications.\nForge and manage relationships with customer leadership and stakeholders, ensuring successful deployment and scale.\nScope work, sequence delivery, and remove blockers early\u2014making trade-offs between scope, speed, and quality.\nContribute directly in the code when clarity or momentum depends on it.\nCodify working patterns into tools, playbooks, or building blocks others can use.\nShare field feedback with Research and Product to influence model and product development.\nKeep teams moving through clarity, judgment, and consistent follow-through.\nYou might thrive in this role if you\nBring 5+ years of engineering or technical deployment experience, ideally in customer-facing or government environments.\nActive TS/SCI clearance or equivalent\nHave scoped and delivered complex systems in fast-moving or ambiguous contexts.\nWrite and review production-grade code across frontend and backend, using Python, JavaScript, or similar stacks.\nAre familiar with cloud deployment models (Azure, AWS), Kubernetes, Terraform, and related infrastructure.\nHave experience building or deploying systems powered by LLMs or generative models, and understand how model behavior affects product experience.\nSimplify complexity, make fast, sound decisions under pressure, and communicate clearly across technical and non-technical audiences.\nSpot risks early, adjust without slowing down, and model calm judgment when stakes are high.\nAre humble, collaborative, and eager to help others with empathy.\nOperate with high horsepower, thrive in dynamic environments, and can ruthlessly prioritize across multiple projects.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Forward Deployed Engineer, Gov", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4293654822", "loc": "Washington, DC", "company": "OpenAI"}, {"desc": "About The Team\nOpenAI\u2019s Forward Deployed Engineering team partners with customers to turn research breakthroughs into production systems. We embed deeply with users to solve high-leverage problems. We move quickly from prototype to deployment and surface patterns that shape the platform. We operate at the intersection of customer delivery and core development. We work closely with Product, Research, and Go-To-Market (GTM).\nAbout The Role\nForward Deployed Engineers lead complex deployments of frontier models in production. You will embed with customers where model performance matters, delivery is urgent, and ambiguity is the default. You will use this to map their problems, structure delivery, and ship fast. You will scope, sequence, and build full-stack solutions that create measurable value. You will also drive clarity across internal and external teams. You will identify reusable patterns and share field signal that influences the roadmap.\nSuccess in this role means owning the delivery state across workstreams. You will hold the bar on quality and pace and help OpenAI learn through execution.\nThis role is based in San Francisco. We use a hybrid work model of 3 days in the office per week. We offer relocation assistance. Travel up to 50% is required.\nIn this role you will\nOwn technical delivery across multiple deployments from first prototype to stable production\nBuild full-stack systems that deliver customer value and sharpen how we learn\nEmbed closely with customer teams, understand their needs, and guide adoption of what you build\nScope work, sequence delivery, and remove blockers early\nMake trade-offs between scope, speed, and quality; adjust plans to protect delivery\nContribute directly in the code when progress or clarity depends on it\nCodify working patterns into tools, playbooks, or building blocks that others can use\nShare field feedback that helps Research and Product understand where the models succeed and where they can improve\nKeep teams moving through clarity and follow-through\nYou might thrive in this role if you\nBring 5+ years of engineering or technical deployment experience that includes customer-facing work\nHave scoped and delivered complex systems in fast-moving or ambiguous environments\nWrite and review production-grade code across frontend and backend using Python, JavaScript, or comparable stacks\nHave built or deployed systems powered by LLMs or generative models and understand how model behaviour affects product experience\nSimplify complexity and make fast, sound decisions under pressure\nCommunicate clearly with engineers, product teams, and customer stakeholders\nSpot risks early and adjust without slowing down\nModel calm and judgment when the stakes are high\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $180K - $280K", "comp": "$180,000.00", "title": "Forward Deployed Engineer - SF", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4278857720", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nOpenAI\u2019s Hardware organization develops silicon and system-level solutions designed for the unique demands of advanced AI workloads. The team is responsible for building the next generation of AI-native silicon while working closely with software and research partners to co-design hardware tightly integrated with AI models. In addition to delivering production-grade silicon for OpenAI\u2019s supercomputing infrastructure, the team also creates custom design tools and methodologies that accelerate innovation and enable hardware optimized specifically for AI.\nAbout The Role\nWe\u2019re seeking an experienced Emulation Engineer to help accelerate the development and validation of OpenAI\u2019s custom ML accelerators. In this role, you\u2019ll architect hardware emulation platforms to enable early software development, system-level testing, and fast iteration cycles across hardware and software teams. You\u2019ll be a critical bridge between design, DV, performance, and software teams\u2014enabling scalable, high-fidelity validation of next-generation AI silicon.\nKey Responsibilities\nBuild and maintain pre-silicon emulation platforms using commercial emulators (e.g., Veloce, Palladium, ZeBu)\nWork with RTL and DV teams to bring-up and validate designs on emulation systems.\nDevelop transactors, models, and acceleration-aware testbenches to maximize throughput and observability.\nEnable fast and reliable software bring-up by integrating firmware and drivers with emulated hardware.\nPartner with performance, software, and validation teams to root cause bugs and optimize system behavior.\nSupport continuous regression infrastructure and automation for long-running, system-scale workloads.\nQualifications\nBS/MS in EE/CE/CS or equivalent with 5+ years of experience in emulation or FPGA-based prototyping.\nDeep familiarity with RTL design (SystemVerilog/VHDL), simulation, and emulation flows.\nExperience with at least one major emulation platform (Palladium, Veloce, or ZeBu) and their toolchains.\nExperience with building large scale emulation systems, optimizing build reliability, efficiency and performance.\nExperience with integrating various IO speedbridge and memory components.\nStrong scripting skills (Python, Tcl, Shell) and experience building automation infrastructure.\nAbility to debug complex HW/SW interactions and performance bottlenecks in large systems.\nExperience in ML accelerator or SoC emulation environments is a plus.\nTo comply with U.S. export control laws and regulations, candidates for this role may need to meet certain legal status requirements as provided in those laws and regulations.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Emulation Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4300366101", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nOpenAI\u2019s Hardware organization develops silicon and system-level solutions designed for the unique demands of advanced AI workloads. The team is responsible for building the next generation of AI-native silicon while working closely with software and research partners to co-design hardware tightly integrated with AI models. In addition to delivering production-grade silicon for OpenAI\u2019s supercomputing infrastructure, the team also creates custom design tools and methodologies that accelerate innovation and enable hardware optimized specifically for AI.\nAbout The Role\nWe are seeking a highly-skilled Silicon Implementation Engineer with deep expertise in custom circuits and physical design. This individual-contributor role sits within our Physical Design team and is central to delivering power, performance, and area (PPA)-optimized datapath and interconnect solutions for next-generation AI accelerators.\nYou\u2019ll work closely with RTL and physical implementation teams to define and execute custom circuit and physical design strategies. Your work will directly impact the performance and cost efficiency of the final silicon.\nIn This Role, You Will\nOwn physical implementation of custom datapath and interconnect circuits from floorplanning through final sign-off.\nCollaborate with RTL and physical designers to drive optimal implementation solutions for custom standard cells, SRAMs, and application-specific macro blocks.\nApply custom and semi-custom physical implementation strategies to optimize designs for power, performance, and area.\nQualifications\nBS with 10+ years, MS with 8+ years, or PhD with 3+ years of relevant industry experience in physical implementation of custom digital circuits (PhD highly preferred).\nDemonstrated success taping out complex silicon designs.\nHands-on experience with physical implementation of custom blocks including standard cells, application-specific SRAM macros, and large datapath structures; research or industry experience with techniques such as compute-in-memory is preferred.\nStrong understanding and experience in physical design, circuit design, and scripting/automation; working knowledge of RTL and microarchitecture is preferred.\nHands-on experience building tools, flows, and methodologies for custom circuit and semi-custom physical implementation.\nTo comply with U.S. export control laws and regulations, candidates for this role may need to meet certain legal status requirements as provided in those laws and regulations.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Silicon Implementation Engineer \u2013 Custom Circuits", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4300343648", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Safety Systems team is responsible for various safety work to ensure our best models can be safely deployed to the real world to benefit the society and is at the forefront of OpenAI's mission to build and deploy safe AGI, driving our commitment to AI safety and fostering a culture of trust and transparency.\nThe Safety Research team aims to fundamentally advance our capabilities for precisely implementing robust, safe behavior in AI models and systems. As capabilities continue to advance, it is imperative that our approaches to safety continue to improve and scale to address evolving risks. This is important both for ensuring our systems are robust to prevent harmful misuse as well as ensuring potential misalignment cannot cause harm. We are working on these problems in a way that is grounded in our current models and methods but that generalizes to future systems.\nWe are growing our team to expand our research on methods that will improve safety for AGI and beyond. This will include exploratory research for example, new methods to improve safety common sense and generalizable reasoning, developing new evaluations to elicit or detect misalignment or inner goals of the AI, and new methods to support human oversight of long-running tasks.\nAbout The Role\nAs a tech lead, you will be responsible for developing our strategy in new directions to address potential harms from misalignment or significant mistakes. This will in practice include:\nSetting north star goals and milestones for new research directions, and developing challenging evaluations to track progress.\nPersonally driving or leading research in new exploratory directions to demonstrate feasibility and scalability of the approaches.\nWorking horizontally across safety research and related teams to ensure different technical approaches work together to achieve strong safety results.\nWe\u2019re looking for people who have a strong track record of practical research on safety and alignment, ideally in AI and LLMs, and have led large research efforts in the past.\nThis role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nIn This Role, You Will\nSet the research directions and strategies to make our AI systems safer, more aligned and more robust.\nCoordinate and collaborate with cross-functional teams, including the rest of the research organization, T&S, policy and related alignment teams, to ensure that our AI meets the highest safety standards.\nActively evaluate and understand the safety of our models and systems, identifying areas of risk and proposing mitigation strategies.\nConduct state-of-the-art research on AI safety topics such as RLHF, adversarial training, robustness, and more.\nImplement new methods in OpenAI\u2019s core model training and launch safety improvements in OpenAI\u2019s products.\nYou Might Thrive In This Role If You\nAre excited about OpenAI\u2019s mission of building safe, universally beneficial AGI and are aligned with OpenAI\u2019s charter\nDemonstrate a passion for AI safety and making cutting-edge AI models safer for real-world use.\nBring 4+ years of experience in the field of AI safety, especially in areas like RLHF, adversarial training, robustness, fairness & biases.\nHold a Ph.D. or other degree in computer science, machine learning, or a related field.\nPossess experience in safety work for AI model deployment\nHave an in-depth understanding of deep learning research and/or strong engineering skills.\nAre a team player who enjoys collaborative work environments.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Technical Lead, Safety Research", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4306944755", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nOpenAI\u2019s Hardware organization develops silicon and system-level solutions designed for the unique demands of advanced AI workloads. The team is responsible for building the next generation of AI-native silicon while working closely with software and research partners to co-design hardware tightly integrated with AI models. In addition to delivering production-grade silicon for OpenAI\u2019s supercomputing infrastructure, the team also creates custom design tools and methodologies that accelerate innovation and enable hardware optimized specifically for AI.\nAbout The Role\nWe are seeking a highly skilled cross-stack engineer with deep expertise in making ML systems reliable at scale. This hands-on individual contributor will sit within our hardware team and work closely with chip design, platform design, hardware health, and the broader industry ecosystem to architect, implement, and deploy reliable next-generation AI accelerator systems. This engineer will evaluate system and chip architecture holistically, identify high-ROI opportunities to improve reliability and availability across the stack, and translate those opportunities into strategy and silicon features.\nIn This Role, You Will\nOversee DFX architecture, implementation, and execution in silicon from concept to high-volume deployment, and propose high-ROI features to enhance reliability and fault tolerance. DFX includes design for testability, reliability, availability, and serviceability of high-performance AI hardware.\nBuild system-level reliability models grounded in empirical data to guide organization-wide DFX and reliability strategy. This requires a detailed understanding of chip and system architecture, design, implementation, and component-level reliability.\nCollaborate with chip and platform architecture/design teams to explore and implement DFX features, including the specification and implementation of digital/mixed-signal IP, firmware/system software, and DFX methodology (in partnership with engineering teams).\nPartner with hardware health and platform design teams to continuously improve reliability and fault tolerance in NPI and HVM. This includes optimizing operating conditions, designing experiments, and performing data analysis to drive continuous, data-driven improvements across the stack.\nServe as the DFX/reliability champion and evangelist to align the broader industry ecosystem with OpenAI\u2019s requirements and roadmap.\nQualifications\nBS with 15+ years, MS with 10+ years, or PhD with 3+ years of relevant industry experience focused on reliability across the chip/platform stack.\nHands-on experience with RTL design and DFT is required; physical implementation and/or silicon ATE experience is preferred.\nDetailed understanding of ML chip and platform architecture and ML workload characteristics is required.\nStrong fundamentals in reliability modeling, with hands-on skills in empirical data analysis.\nTo comply with U.S. export control laws and regulations, candidates for this role may need to meet certain legal status requirements as provided in those laws and regulations.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Reliability/DFX Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4300375043", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Strategic Deployment team makes frontier models more capable, reliable, and aligned to transform strategically-important domains. On one hand, this involves deploying models in real-world, high-stakes settings to drive AI-driven transformation and elicit insights\u2014training data, evaluation methods, and techniques\u2014to shape our frontier model development. On the other hand, we leverage these learnings to build the science and engineering of impactful frontier model deployment.\nPut differently, we want to understand: if AGI is viewed as AI being able to majorly transform our economy, how close are we to AGI? What\u2019s still missing? How do we bridge these gaps?\nAbout The Role\nAs a Deployed Researcher on the Strategic Deployment team, you\u2019ll conduct hands-on research and engineering to adapt and evaluate frontier models in real-world, high-impact environments. Your work will drive transformational impact and generate critical insights into model behavior, capability limits, and the interventions needed for a successful AI deployment.\nThis role is based in San Francisco, CA. We follow a hybrid model (3 days/week in-office) and offer relocation support.\nIn This Role, You Will\nHarness frontier models to drive real-world, high-impact tasks and surface key capability gaps.\nBuild evaluations, training data, and infrastructure to support safe, robust deployments.\nConduct research that spans large language model reinforcement learning and fine-tuning, science of evaluations, and data selection\u2014with an emphasis on steering model behavior, improving generalization, and ensuring reliability.\nWork with internal teams and external partners to scope and execute custom frontier model deployments.\nYou Might Thrive In This Role If You\nCare about real-world impact of AI.\nAre excited to drive how frontier models are developed and deployed.\nHave hands-on experience in AI research, systems, or applied science (e.g. RL, fine-tuning, evals).\nHave strong engineering skills, particularly in designing, deploying and optimizing large-scale AI systems.\nAre excited by ambiguous, open-ended problem spaces with high impact and stakes.\nEnjoy working in open-ended problem spaces and high-feedback environments.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Deployed Researcher, Strategic Deployment", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4204726485", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nSafety Systems sits at the forefront of OpenAI\u2019s mission to build and deploy safe AGI, ensuring our most capable models can be released responsibly and for the benefit of society. Within Safety Systems, we are building a misalignment research team to focus on the most pressing problems for the future of AGI. Our mandate is to identify, quantify, and understand future AGI misalignment risks far in advance of when they can pose harm.\nThe Work Of This Research Taskforce Spans Four Pillars\nWorst\u2011Case Demonstrations \u2013 Craft compelling, reality\u2011anchored demos that reveal how AI systems can go wrong. We focus especially on high importance cases where misaligned AGI could pursue goals at odds with human well being.\nAdversarial & Frontier Safety Evaluations \u2013 Transform those demos into rigorous, repeatable evaluations that measure dangerous capabilities and residual risks. Topics of interest include deceptive behavior, scheming, reward hacking, deception in reasoning, and power-seeking, along with other related areas.\nSystem\u2011Level Stress Testing \u2013 Build automated infrastructure to probe entire product stacks, assessing end\u2011to\u2011end robustness under extreme conditions. We treat misalignment as an evolving adversary, escalating tests until we find breaking points even as systems continue to improve.\nAlignment Stress\u2011Testing Research \u2013 Investigate why mitigations break, publishing insights that shape strategy and next\u2011generation safeguards. We collaborate with other labs when useful and actively share misalignment findings to accelerate collective progress.\nAbout The Role\nWe are seeking a Senior Researcher who is passionate about red\u2011teaming and AI safety. In this role you will design and execute cutting\u2011edge attacks, build adversarial evaluations, and advance our understanding of how safety measures can fail\u2014and how to fix them. Your insights will directly influence OpenAI\u2019s product launches and long\u2011term safety roadmap.\nIn this role, you will\nDesign and implement worst\u2011case demonstrations that make AGI alignment risks concrete for stakeholders, focused on high stakes use cases described above.\nDevelop adversarial and system\u2011level evaluations grounded in those demonstrations, driving adoption across OpenAI. \nCreate automated tools and infrastructure to scale automated red\u2011teaming and stress testing.\nConduct research on failure modes of alignment techniques and propose improvements.\nPublish influential internal or external papers that shift safety strategy or industry practice. We aim to concretely reduce existential AI risk.\nPartner with engineering, research, policy, and legal teams to integrate findings into product safeguards and governance processes.\nMentor engineers and researchers, fostering a culture of rigorous, impact\u2011oriented safety work.\nYou might thrive in this role if you\nAlready are thinking about these problems night and day, and share our mission to build safe, universally beneficial AGI and align with the OpenAI Charter.\nHave 4+ years of experience in AI red\u2011teaming, security research, adversarial ML, or related safety fields.\nPossess a strong research track record\u2014publications, open\u2011source projects, or high\u2011impact internal work\u2014demonstrating creativity in uncovering and exploiting system weaknesses.\nAre fluent in modern ML / AI techniques and comfortable hacking on large\u2011scale codebases and evaluation infrastructure.\nCommunicate clearly with both technical and non\u2011technical audiences, translating complex findings into actionable recommendations.\nEnjoy collaboration and can drive cross\u2011functional projects that span research, engineering, and policy.\nHold a Ph.D., master\u2019s degree, or equivalent experience in computer science, machine learning, security, or a related discipline (nice to have but not required).\nWhat We Offer\nA chance to shape safety practices at the frontier of AGI. Your work will directly lower the changes of catastrophic misalignment.\nAccess to cutting\u2011edge models, tooling, and compute resources.\nA highly collaborative, mission\u2011driven environment with world\u2011class colleagues.\nCompetitive compensation, equity, and benefits.\nIf you\u2019re excited to push AI systems to\u2014and beyond\u2014their limits so we can deploy them safely, we\u2019d love to hear from you! Join us in the taking on the most important challenge for the world today.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $380K - $460K", "comp": "$380,000.00", "title": "Senior Researcher \u2014 Safety Systems, Misalignment Research", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4275241921", "loc": "New York, NY", "company": "OpenAI"}, {"desc": "About The Team\nWith Codex we\u2019re building an AI software engineer. One that you can pair with, delegate to, or even ask to take on future tasks proactively. Our team is a fast-moving group within OpenAI, bringing together research, engineering, design, and product. We iteratively build the Codex agent harness and product to get the most out of the model, and we iteratively train the model to be great in the Codex.\nAbout The Role\nAs the product manager on Codex, you will lead the development of a highly technical product designed for a technical audience. Much of the work is 0\u20131, requiring you to shape product direction amid ambiguity and shape what the future of agents will look like. You\u2019ll partner closely with world-class engineers and researchers to bring cutting-edge capabilities into the hands of developers, and you\u2019ll shape how our AI tools support software development workflows.\nThis role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nIn This Role, You Will\nShape product strategy for Codex, from early concepts through launch and iteration.\nCollaborate with engineering and research to translate breakthroughs into usable, high-value developer experiences.\nDeeply understand developer workflows and identify opportunities where AI can make them faster, more intuitive, and more powerful.\nNavigate ambiguity and make thoughtful trade-offs in 0\u20131 product environments.\nPartner with cross-functional teams to deliver quickly while maintaining a high bar for technical quality and user experience.\nYou Might Thrive In This Role If You\nBring a strong technical background and have recently shipped code to production\nHave a deep intuition for developer workflows and a passion for building tools that make coding more productive and enjoyable.\nCan define product direction in ambiguous, 0\u20131 environments and rally teams around it. \nDemonstrate strong product intuition, making thoughtful prioritization and sequencing decisions.\nHave experience driving execution across engineering, design, and research.\nBring an entrepreneurial mindset and adaptability, whether from startup or high-growth company environments.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $255K - $325K", "comp": "$255,000.00", "title": "Product Manager, Codex", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4309215151", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Support Automation team at OpenAI scales the organization by applying cutting-edge AI models to real-world challenges, automating and enhancing work across the organization. From customer operations to engineering, we develop an ecosystem of automation products that empower our colleagues and drive impact. We're passionate about crafting products that serve those around us, blending rapid prototyping with a focus on long-term quality and reliability. By creating reusable solutions, we create patterns that can be applied across diverse domains within OpenAI.\nTLDR: this team leverages OpenAI technology to improve OpenAI, and you\u2019ll have the opportunity to leverage the full extent of our tech (both public and pre-released) to accomplish this mission.\nAbout The Role\nWe\u2019re looking for a \nBackend Software Engineer\n with experience working in ML/LLM-heavy domains to help to design and build an evals infrastructure that measures the quality of OpenAI\u2019s support automation. This is a deeply technical and highly cross-functional role where you\u2019ll build robust systems and backend services that serve as the foundation for how knowledge is created, accessed, and applied across OpenAI. The role will especially focus on working closely with Data Science and Research partners to design and build evals at scale.\nIn This Role, You Will\nDesign eval pipelines that are reliable, reproducible, and extendable\nBuild the infrastructure for continuous eval monitoring frameworks (regression/drift monitoring, building robust golden datasets) along with feedback loops that ultimately strengthen support automation\nDesign, build, and maintain backend services and APIs to support intelligent automation and knowledge systems\nIntegrate and structure data across internal platforms, transforming it into formats optimized for use by downstream systems and AI workflows.\nCollaborate closely with data, research, and engineering teams to integrate OpenAI models into high-leverage workflows\nOwn the full development lifecycle of new backend systems and internal platform capabilities\nBuild with scale and maintainability in mind, while rapidly iterating on new ideas\nYou Might Be a Great Fit If You Have\n4+ years of backend engineering experience at product-driven companies (excluding internships)\nProficiency in backend technologies. Our tech stack includes Python, FastAPI, and Postgres\nExperience designing and scaling distributed systems, APIs, or data processing pipelines\nHave experience building AI agents or applications, including designing evals and improving performance through prompting or scaffolding\nAre familiar with evaluation methods for LLMs and have worked with patterns like multi-agent workflows, tool use, or long context.\nExperience creating production evals and/or measuring performance of ML/LLM models at scale\nA pragmatic mindset. You\u2019re comfortable shipping iteratively while building toward a long-term vision\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $255K - $405K", "comp": "$255,000.00", "title": "Backend Software Engineer (Evals) \u2013 Support Automation Engineering", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4301037275", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Personality & Model Behavior team conducts research on how to shape personalities and guide the behavior of models. We think about topics such as emotional intelligence, reasoning, and how models interact thoughtfully with users. We integrate those research into the final products of OpenAI that are used by hundreds of millions of users.\nAbout The Role\nWe\u2019re looking for people who are experts in the fields such as reinforcement learning, machine learning, natural language processing, etc. Join us if you are passionate about tackling cutting-edge, open-ended research challenges and transforming your findings into real-world products.\nIn This Role, You Will\nConduct research around personality and model behavior, leveraging and developing tools such as synthetic data, reinforcement learning, reasoning to shape the personality and model behavior, including models such as o3, o4-mini, 4o, etc.\nBuild evaluations and pipelines to facilitate the development and research.\nInnovate new post-training methods.\nIntegrate your research into the final product of OpenAI.\nYou Might Thrive In This Role If You\nHave a deep understanding of machine learning and its applications.\nHave prior knowledge in training and optimizing models and building evaluations.\nAre willing to dive into large ML codebases to debug issues.\nThrive in dynamic and technically complex environments.\nHave a track record of delivering innovative, out-of-the-box solutions to address real-world constraints.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.\nCompensation Range: $295K - $530K", "comp": "$295,000.00", "title": "Research Engineer / Scientist, Personality and Model Behavior", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4295514775", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nOpenAI's Training team is responsible for producing the large language models that power our research, our products, and ultimately bring us closer to AGI. Achieving this goal requires combining deep research into improving our current architecture, datasets and optimization techniques, alongside long-term bets aimed at improving the efficiency and capability of future generations of models. We are responsible for integrating these techniques and producing model artifacts used by the rest of the company, and ensuring that these models are world-class in every respect. Recent examples of artifacts with major contributions from our team include GPT4-Turbo, GPT-4o and o1-mini.\nAbout The Role\nAs a member of the architecture team, you will push the frontier of architecture development for OpenAI's flagship models, enhancing intelligence, efficiency, and adding new capabilities.\nIdeal candidates have a deep understanding of LLM architectures, a sophisticated understanding of model inference, and a hands-on empirical approach. A good fit for this role will be equally happy coming up with a creative breakthrough, investing in strengthening a baseline, designing an eval, debugging a thorny regression, or tracking down a bottleneck.\nThis role is based in San Francisco. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.\nIn This Role, You Will\nDesign, prototype and scale up new architectures to improve model intelligence\nExecute and analyze experiments autonomously and collaboratively\nStudy, debug, and optimize both model performance and computational performance\nContribute to training and inference infrastructure\nYou Might Thrive In This Role If You\nHave experience landing contributions to major LLM training runs\nCan thoroughly evaluate and improve deep learning architectures in a self-directed fashion\nAre motivated by safely deploying LLMs in the real world\nAre well-versed in the state of the art transformer modifications for efficiency\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Researcher (Engineer/Scientist), Training Architecture", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4291458528", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "About The Team\nThe Safety Systems team is responsible for various safety work to ensure our best models can be safely deployed to the real world to benefit the society and is at the forefront of OpenAI's mission to build and deploy safe AGI, driving our commitment to AI safety and fostering a culture of trust and transparency.\nWe seek to learn from deployment and distribute the benefits of AI, while ensuring that this powerful tool is used responsibly and safely.\nAbout The Role\nAs the lead researcher for chemical & biological risks, you will design, implement, and oversee an end-to-end mitigation stack to prevent severe chemical and biological misuse across OpenAI\u2019s products. This role demands technical depth, decisive leadership, and cross-company influence to ensure safeguards are enforceable, scalable, and effective. You\u2019ll set the technical strategy, drive execution, and ensure our products cannot be misused for severe harm.\nIn This Role, You Will\nLead the full-stack mitigation strategy and implement solutions for biological and chemical misuse\u2014from prevention to enforcement.\nEnsure safeguards integrate seamlessly across OpenAI products and scale with usage.\nMake decisive calls on technical trade-offs within the bio risk domain.\nPartner with risk modeling leadership to align mitigation design with anticipated risks and coverage.\nDrive rigorous safeguard testing by stress-testing the mitigation stack against evolving threats and product surfaces.\nYou Might Thrive In This Role If You\nHave a passion for AI safety and are motivated to make cutting-edge AI models safer for real-world use.\nBring demonstrated experience in deep learning and transformer models.\nAre proficient with frameworks such as PyTorch or TensorFlow.\nPossess a strong foundation in data structures, algorithms, and software engineering principles.\nAre familiar with methods for training and fine-tuning large language models, including distillation, supervised fine-tuning, and policy optimization.\nExcel at working collaboratively with cross-functional teams across research, policy, product, and engineering.\nShow decisive leadership in high-stakes, ambiguous environments.\nHave significant experience designing and deploying technical safeguards at scale.\n(Nice to have) Bring background knowledge in biosecurity, computational biology, or adjacent technical fields.\nAbout OpenAI\nOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.\nWe are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.\nFor additional information, please see OpenAI\u2019s Affirmative Action and Equal Employment Opportunity Policy Statement.\nQualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.\nTo notify OpenAI that you believe this job posting is non-compliant, please submit a report through this form. No response will be provided to inquiries unrelated to job posting compliance.\nWe are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.\nOpenAI Global Applicant Privacy Policy\nAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.", "comp": "0", "title": "Lead Research Engineer / Scientist, Chemical & Biological Risk", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4302687452", "loc": "San Francisco, CA", "company": "OpenAI"}, {"desc": "Replit is the fastest way to turn ideas into software. With our powerful AI-powered Agent and Assistant, anyone can create and launch apps from natural language in just one click. Build and deploy full-stack applications directly from your browser\u2014no setup required. Never written a line of code in your life? No problem. Replit makes software creation accessible, collaborative, and lightning-fast. Join us in our mission to empower the next generation of builders.\nAbout the role:\nAs a New Grad Software Engineer, you'll join a team of exceptional builders working on products that are reshaping how the world creates software. You'll have the opportunity to work on everything from our AI-powered development platform to the distributed systems that enable real-time collaboration for millions of developers.\nThis is a chance to define your career while defining the future of software development. You'll work on problems that matter, with the autonomy to drive solutions and the support to grow into a technical leader.\nWhat you will build:\nProduct features that delight users and make it possible for anybody to create software\nAI coding agent that understands intent and generates production-ready applications\nCloud infrastructure that provides instant, powerful development environments at global scale\nPlatform features that enable one click deployments and scale to millions of users\nRequired skills and experience:\nRecent graduate (2024-2026) with a degree in Computer Science, Computer Engineering, or related field\nStrong programming skills in a modern language (JavaScript/TypeScript, Python, Go, Rust)\nFull-stack capabilities with experience in React, Node.js, and database technologies\nGrowth orientation - eager to learn new technologies and take on increasing responsibility\nCollaborative spirit - you work well in cross-functional teams and value diverse perspectives\nWhat we value\n:\nProblem-solving mindset: Ability to approach complex operational challenges systematically and devise effective solutions\nSelf-directed and autonomous: Capable of working independently while collaborating effectively with cross-functional teams\nStrong communication skills: Ability to explain complex technical concepts to both technical and non-technical audiences\nContinuous learning: Passion for staying current with industry best practices and new technologies\nFocus on automation: Strong belief in automating repetitive tasks and building self-healing systems\nFull-Time Employee Benefits Include\n:\n\ud83d\udcb0 Competitive Salary & Equity\n\ud83d\udcb9 401(k) Program\n\u2695\ufe0f Health, Dental, Vision and Life Insurance\n\ud83e\ude7c Short Term and Long Term Disability\n\ud83d\udebc Paid Parental, Medical, Caregiver Leave\n\ud83d\ude97 Commuter Benefits\n\ud83d\udcf1 Monthly Wellness Stipend\n\ud83e\uddd1\u200d\ud83d\udcbb Autonoumous Work Environement\n\ud83d\udda5 In Office Set-Up Reimbursement\n\ud83c\udfdd Flexible Time Off (FTO) + Holidays\n\ud83d\ude80 Quarterly Team Gatherings\n\u2615 In Office Amenities\nWant to learn more about what we are up to?\nMeet the Replit Agent\nReplit: Make an app for that\nReplit Blog\nAmjad TED Talk\nInterviewing + Culture at Replit\nOperating Principles\nReasons not to work at Replit\nTo achieve our mission of making programming more accessible around the world, we need our team to be representative of the world. We welcome your unique perspective and experiences in shaping this product. We encourage people from all kinds of backgrounds to apply, including and especially candidates from underrepresented and non-traditional backgrounds.\nThis is a full-time role that can be held from our Foster City, CA office. The hybrid role has an in-office requirement of Monday, Wednesday, and Friday\nCompensation Range: $140K - $220K", "comp": "$140,000.00", "title": "Software Engineer - New Grad (Summer 2026)", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4309048779", "loc": "Foster City, CA", "company": "Replit"}, {"desc": "Replit is the fastest way to turn ideas into software. With our powerful AI-powered Agent and Assistant, anyone can create and launch apps from natural language in just one click. Build and deploy full-stack applications directly from your browser\u2014no setup required. Never written a line of code in your life? No problem. Replit makes software creation accessible, collaborative, and lightning-fast. Join us in our mission to empower the next generation of builders.\nAbout The Role\nAs a Full Stack Engineer at Replit, you'll be at the forefront of building products that empower developers to create software more effectively. You'll help develop intuitive interfaces and powerful backend services that enhance the user experience across our platform. Working closely with cross-functional teams including product managers, designers, and AI engineers, you'll craft solutions that enable our users to build, deploy, and share their applications seamlessly. This role requires both technical expertise and a deep understanding of user needs to deliver features that make an impact.\nIn This Role You Will\nDrive full-stack feature development from conception to deployment, taking ownership of key product initiatives\nCollaborate on design and implementation of user-facing features that improve developer experience\nBuild robust, scalable, and performant web applications using modern frontend and backend technologies\nIdentify opportunities for optimization and enhancement in existing systems\nContribute to architectural decisions that shape the future of our product\nWork cross-functionally with product, design, and platform teams to deliver cohesive user experiences\nRequired Skills And Experience\nSolid full-stack foundation: from building React components to developing APIs to integrating with third party services.\nStrong proficiency with TypeScript, React, and modern frontend development practices\nExperience working directly on user-facing products and understanding user needs\nStrong problem-solving skills and attention to detail\nExcellent communication skills and ability to work cross-functionally\nNice To Have\nExperience with AI/LLM integration in applications\nBackground working with developer tools, IDEs, or programming environments\nPrevious experience at a high-growth startup\nContributions to open-source projects\nTools + Tech Stack for this role:\nReact, TypeScript, GraphQL\nThis Role May Not Be a Fit If\nYou prefer working exclusively on backend systems without user interaction\nYou're uncomfortable with the pace and changing priorities of a startup environment\nYou require highly structured requirements and aren't comfortable with ambiguity\nFull-Time Employee Benefits Include\nCompetitive Salary & Equity\n401(k) Program\n\u2695\ufe0f Health, Dental, Vision and Life Insurance\nShort Term and Long Term Disability\nPaid Parental, Medical, Caregiver Leave\nCommuter Benefits\nMonthly Wellness Stipend\n\u200d Autonoumous Work Environement\nIn Office Set-Up Reimbursement\nFlexible Time Off (FTO) + Holidays\nQuarterly Team Gatherings\n\u2615 In Office Amenities\nWant to learn more about what we are up to?\nMeet the Replit Agent\nReplit: Make an app for that\nReplit Blog\nAmjad TED Talk\nInterviewing + Culture at Replit \nOperating Principles\nReasons not to work at Replit\nTo achieve our mission of making programming more accessible around the world, we need our team to be representative of the world. We welcome your unique perspective and experiences in shaping this product. We encourage people from all kinds of backgrounds to apply, including and especially candidates from underrepresented and non-traditional backgrounds.\nThis is a full-time role that can be held from our Foster City, CA office. The hybrid role has an\n in-office requirement of Monday, Wednesday, and Friday.", "comp": "0", "title": "Software Engineer, Full Stack", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4250724681", "loc": "Foster City, CA", "company": "Replit"}, {"desc": "Replit is the fastest way to turn ideas into software. With our powerful AI-powered Agent and Assistant, anyone can create and launch apps from natural language in just one click. Build and deploy full-stack applications directly from your browser\u2014no setup required. Never written a line of code in your life? No problem. Replit makes software creation accessible, collaborative, and lightning-fast. Join us in our mission to empower the next generation of builders.\nAbout the role:\nJoin our engineering team for a 12-week paid internship where you'll work alongside world-class engineers, designers, and product managers to build the future of software creation. You'll contribute to real features that impact millions of developers worldwide, from our AI-powered development environment to the infrastructure that makes lightning-fast collaboration possible.\nThis isn't just about learning\u2014you'll ship meaningful code that helps democratize software creation. Whether you're optimizing our cloud infrastructure, building intuitive developer tools, or enhancing our AI agents, your work will directly empower creators around the globe.\nYou will:\nShip real features to millions of developers using Replit's platform\nCollaborate cross-functionally with engineers, designers, product managers, and AI researchers\nBuild and optimize developer experiences that make coding accessible to everyone\nWork on cutting-edge AI tools and infrastructure that power the next generation of software creation\nLearn from the best in an environment where your ideas are heard and often implemented\nRequired skills and experience:\nCurrently pursuing a Bachelor's, Master's, or PhD in Computer Science, Computer Engineering, or related technical field\nHave at least one semester of schooling remaining after the internship completion\nProficient in at least one programming language and comfortable with full stack development\nPassionate about developer tools, AI, or making technology more accessible\nThrive in fast-paced environments where you can move quickly and adapt to changing priorities\nWhat we value\n:\nProblem-solving mindset: Ability to approach complex operational challenges systematically and devise effective solutions\nSelf-directed and autonomous: Capable of working independently while collaborating effectively with cross-functional teams\nStrong communication skills: Ability to explain complex technical concepts to both technical and non-technical audiences\nContinuous learning: Passion for staying current with industry best practices and new technologies\nFocus on automation: Strong belief in automating repetitive tasks and building self-healing systems\nWant to learn more about what we are up to?\nMeet the Replit Agent\nReplit: Make an app for that\nReplit Blog\nAmjad TED Talk\nInterviewing + Culture at Replit\nOperating Principles\nReasons not to work at Replit\nTo achieve our mission of making programming more accessible around the world, we need our team to be representative of the world. We welcome your unique perspective and experiences in shaping this product. We encourage people from all kinds of backgrounds to apply, including and especially candidates from underrepresented and non-traditional backgrounds.", "comp": "0", "title": "Software Engineering Intern (Summer 2026)", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4309056199", "loc": "Foster City, CA", "company": "Replit"}, {"desc": "Replit is the fastest way to turn ideas into software. With our powerful AI-powered Agent and Assistant, anyone can create and launch apps from natural language in just one click. Build and deploy full-stack applications directly from your browser\u2014no setup required. Never written a line of code in your life? No problem. Replit makes software creation accessible, collaborative, and lightning-fast. Join us in our mission to empower the next generation of builders.\nAbout the role:\nWe are seeking talented distributed systems engineers who are passionate about building innovative solutions for application deployment. Your mission will be to enhance the capabilities of Replit Infrastructure, optimize performance across global regions, and drive efficiency while delivering an exceptional user experience. If you have a strong foundation in software development, a deep understanding of cloud technologies, and a track record of delivering high-quality code, we want to hear from you.\nIn this role you will:\nExpand Replit's cloud infrastructure offerings: Launch new cloud products to be used by Replit Agent to build complex apps. Collaborate with cross-functional teams to design and implement these features, empowering developers with a comprehensive suite of tools to build and deploy their applications efficiently. \nEnhance reliability and scalability: Identify bottlenecks, optimize critical paths, and implement robust monitoring and alerting systems. Work closely with the SRE team to ensure high availability and minimal downtime. Enable our customers to seamlessly scale their applications to meet the demands of their growing user base. \nImprove utilization of cloud infrastructure: Analyze our infrastructure costs and identify opportunities for optimization. Implement strategies to reduce cloud expenses without compromising performance or reliability. This could involve techniques such as resource provisioning, auto-scaling, cost-aware scheduling, and data lifecycle management. Your efforts will directly contribute to the financial efficiency of our cloud services. \nRequired skills and experience:\nDistributed systems: Track record of working with platform-as-a-service, distributed storage, or information retrieval systems. Experience in designing scalable architectures and optimizing systems for latency or cost. \nProblem-solving mindset: Ability to approach complex challenges pragmatically and devise effective solutions. You think radically but ship incrementally. \nSelf-directed and autonomous: Able to work independently, set priorities, and drive projects forward. You take ownership and initiative. \nVersatility and flexibility: Able to wear multiple hats and tackle a wide range of challenges. You are comfortable working across different layers of the stack and adapting to the needs of the project. \nContinuous learning and adaptability: Passionate about staying up-to-date with industry trends and expanding your skill set. You embrace change and adapt quickly. \nNice to have:\nExperience working on cloud infrastructure or platform products, particularly in the areas of application deployment, serverless computing, or container orchestration. \nFamiliarity with Google Cloud Platform (GCP) services and tools, such as GCE, GKE,, Cloud Run, or Cloud Storage. \nContributions to open-source projects related to cloud technologies, deployment frameworks, or developer tools. We love OSS!\nTools + Tech Stack for this role\nGolang, Rust\nThis role may \nnot\n be a fit if\nYou are a generalist backend engineer who hasn\u2019t built scalable distributed systems. \nYou cannot take part in the oncall rotation of min 6 people. \nYou do not enjoy diving into Linux internals. \nFull-Time Employee Benefits Include:\n\ud83d\udcb0 Competitive Salary & Equity\n\ud83d\udcb9 401(k) Program\n\u2695\ufe0f Health, Dental, Vision and Life Insurance\n\ud83e\ude7c Short Term and Long Term Disability\n\ud83d\udebc Paid Parental, Medical, Caregiver Leave\n\ud83d\ude97 Commuter Benefits\n\ud83d\udcf1 Monthly Wellness Stipend\n\ud83e\uddd1\u200d\ud83d\udcbb Autonoumous Work Environement\n\ud83d\udda5 In Office Set-Up Reimbursement\n\ud83c\udfdd Flexible Time Off (FTO) + Holidays\n\ud83d\ude80 Quarterly Team Gatherings\n\u2615 In Office Amenities\nWant to learn more about what we are up to?\nMeet the Replit Agent\nReplit: Make an app for that\nReplit Blog\nAmjad TED Talk\nInterviewing + Culture at Replit \nOperating Principles\nReasons not to work at Replit\nTo achieve our mission of making programming more accessible around the world, we need our team to be representative of the world. We welcome your unique perspective and experiences in shaping this product. We encourage people from all kinds of backgrounds to apply, including and especially candidates from underrepresented and non-traditional backgrounds.\nThis is a full-time role that can be held from our Foster City, CA office. The hybrid role has an\n in-office requirement of Monday, Wednesday, and Friday.\nCompensation Range: $130K - $290K", "comp": "$130,000.00", "title": "Software Engineer, Distributed Systems", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4201336453", "loc": "Foster City, CA", "company": "Replit"}, {"desc": "Replit is the fastest way to turn ideas into software. With our powerful AI-powered Agent and Assistant, anyone can create and launch apps from natural language in just one click. Build and deploy full-stack applications directly from your browser\u2014no setup required. Never written a line of code in your life? No problem. Replit makes software creation accessible, collaborative, and lightning-fast. Join us in our mission to empower the next generation of builders.\nAbout The Role\n:\nWe recently launched Replit Agent in early access, the first widely accessible coding AI agent that builds and deploys apps based on your ideas. In this new era of personal software, the Replit mobile app enables you to create, prototype, brainstorm personal tools on the go.\nIn this role, you will shape our Agent experience on mobile, build innovative new features and interactions, and enable anyone with a phone to create software for their phones and assist with our mobile UI/UX. Our mobile app is built with Typescript, React, React Native, Expo, and Apollo/GraphQL.\nWho You Are\n:\nWe're looking for mobile-focused developers who can thrive in a React Native environment and are also passionate about mobile UI/UX. You fit this role if you match one of these profiles:\n The React Native Expert\nYou're an experienced React Native developer with a proven track record of shipping mobile apps, with a keen eye for mobile UI/UX.\n The Mobile Web Specialist\nYou have deep experience with mobile web development and understand the unique challenges of mobile interfaces, performance optimization, and responsive design. You're passionate about UX/UI and ready to transition your mobile expertise to React Native development.\n The Native Developer Exploring Cross-Platform\nYou're a skilled mobile native developer (iOS/Android) who's interested in exploring React Native as a cross-platform solution. You bring valuable native platform knowledge and are open to learning TypeScript-based development.\nWhat You Will Do\n:\nCollaborate closely with a team of designers, mobile and UX engineers to streamline the mobile app towards AI-first creation. \nIntroduce new features that make creation on mobile easier and faster. \nImprove the quality and observability of the app. \nProactively identify what our software creators need to make building on mobile delightful. \nRequired Experience\n:\nYou can demonstrate 5+ years of professional software development experience, including:\nExperience optimizing UI rendering performance\nExperience debugging and deploying iOS or Android apps\nYou are comfortable or excited to build with React/CSS and React Native. \nYou are familiar with UI/UX patterns on iOS or Android\nBonus Points\n:\nYou\u2019ve built and shipped your own apps to the world\nFull-Time Employee Benefits Include:\n\ud83d\udcb0 Competitive Salary & Equity\n\ud83d\udcb9 401(k) Program\n\u2695\ufe0f Health, Dental, Vision and Life Insurance\n\ud83e\ude7c Short Term and Long Term Disability\n\ud83d\udebc Paid Parental, Medical, Caregiver Leave\n\ud83d\ude97 Commuter Benefits\n\ud83d\udcf1 Monthly Wellness Stipend\n\ud83e\uddd1\u200d\ud83d\udcbb Autonoumous Work Environement\n\ud83d\udda5 In Office Set-Up Reimbursement\n\ud83c\udfdd Flexible Time Off (FTO) + Holidays\n\ud83d\ude80 Quarterly Team Gatherings\n\u2615 In Office Amenities\nWant to learn more about what we are up to?\nMeet the Replit Agent\nReplit: Make an app for that\nReplit Blog\nAmjad TED Talk\nInterviewing + Culture at Replit \nOperating Principles\nReasons not to work at Replit\nTo achieve our mission of making programming more accessible around the world, we need our team to be representative of the world. We welcome your unique perspective and experiences in shaping this product. We encourage people from all kinds of backgrounds to apply, including and especially candidates from underrepresented and non-traditional backgrounds.\nThis is a full-time role that can be held from our Foster City, CA office. \nThe hybrid role has an in-office requirement of Monday, Wednesday, and Friday.\nCompensation Range: $130K - $290K", "comp": "$130,000.00", "title": "Software Engineer, Mobile", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4174517689", "loc": "Foster City, CA", "company": "Replit"}, {"desc": "Replit is the fastest way to turn ideas into software. With our powerful AI-powered Agent and Assistant, anyone can create and launch apps from natural language in just one click. Build and deploy full-stack applications directly from your browser\u2014no setup required. Never written a line of code in your life? No problem. Replit makes software creation accessible, collaborative, and lightning-fast. Join us in our mission to empower the next generation of builders.\nAI brought millions of first\u2011time builders to software. Replit\u2019s mission is to help them ship. That\u2019s vibe coding: intuitive, AI\u2011assisted development that feels magical.\nThis role exists to bridge vibe coding and engineering best practices so beginners ship safely and experienced builders move faster. You\u2019ll turn software fundamentals into simple, approachable workflows people can copy, remix, and trust.\nDeveloper Relations sits at the intersection of community, content, and product. Your work will span all three.\nWhat You\u2019ll Do\nTechnical Writing & Learning Design\nTranslate best practices: Turn testing, version control, security\u2011by\u2011default, reliability, and accessibility into friendly guides, checklists, and examples\nTeach the why: Publish narrative tutorials, changelogs, and decision guides that explain tradeoffs\u2014not just steps\nShip clarity: Keep docs up\u2011to\u2011date and reduce time\u2011to\u2011first\u2011success for new builders\nKeep our users updated: Share user successes and product updates through email and social channels\nTemplates, Starters, and Reference Apps\nBridge idea \u2192 production: Build starter projects and templates on Replit that feel fun but include the essentials\u2014tests, lint, deploy, observability, secrets, and docs\nPrototype with AI: Create rapid demos that showcase AI workflows and Replit capabilities for consumer and enterprise use cases\nDocument the pattern: Capture reusable architecture and patterns so others can riff with confidence\nCommunity, Feedback, and Advocacy\nBe present: Help builders in the open; share learnings with authenticity\nClose the loop: Turn community feedback into crisp issues, product proposals, and measurable improvements\nRepresent Replit: Speak at meetups, conferences, and hackathons; highlight what people can ship today\nWhat You Bring\nYou\u2019ve shipped software: Personal, open source, or professional\u2014enough to have opinions on reliability, testing, and DX\nYou write to teach: Clear, empathetic communication for different skill levels\nYou\u2019re AI\u2011curious: Hands\u2011on with modern AI coding tools and workflows\nYou care about reuse: You build templates and examples others want to copy\nNice\u2011to\u2011haves\nDeveloper Relations experience, public artifacts (talks, posts, templates)\nFamiliarity with Replit and vibe coding communities\nExperience organizing community events or programs\nWhat Success Looks Like\nAdopted templates: A small library of production\u2011ready starters that thousands of builders use and trust\nFaster first ship: Time\u2011to\u2011first\u2011success drops for new users; docs and guides feel obvious\nTeaching with impact: Tutorials and changelogs that are widely shared and referenced\nCommunity signal: Healthy feedback loops that influence roadmap and improve developer experience\nCredible advocacy: Recognized voice for bridging vibe coding and engineering best practices\nFull-Time Employee Benefits Include:\n\ud83d\udcb0 Competitive Salary & Equity\n\ud83d\udcb9 401(k) Program\n\u2695\ufe0f Health, Dental, Vision and Life Insurance\n\ud83e\ude7c Short Term and Long Term Disability\n\ud83d\udebc Paid Parental, Medical, Caregiver Leave\n\ud83d\ude97 Commuter Benefits\n\ud83d\udcf1 Monthly Wellness Stipend\n\ud83e\uddd1\u200d\ud83d\udcbb Autonoumous Work Environement\n\ud83d\udda5 In Office Set-Up Reimbursement\n\ud83c\udfdd Flexible Time Off (FTO) + Holidays\n\ud83d\ude80 Quarterly Team Gatherings\n\u2615 In Office Amenities\nWant to learn more about what we are up to?\nMeet the Replit Agent\nReplit: Make an app for that\nReplit Blog\nAmjad TED Talk\nInterviewing + Culture at Replit\nOperating Principles\nReasons not to work at Replit\nTo achieve our mission of making programming more accessible around the world, we need our team to be representative of the world. We welcome your unique perspective and experiences in shaping this product. We encourage people from all kinds of backgrounds to apply, including and especially candidates from underrepresented and non-traditional backgrounds.\nThis is a full-time role that can be held from our Foster City, CA office. \nThe role has an in-office requirement of Monday, Wednesday, and Friday.\nCompensation Range: $150K - $235K", "comp": "$150,000.00", "title": "Developer Relations Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4279476576", "loc": "Foster City, CA", "company": "Replit"}, {"desc": "Replit is the fastest way to turn ideas into software. With our powerful AI-powered Agent and Assistant, anyone can create and launch apps from natural language in just one click. Build and deploy full-stack applications directly from your browser\u2014no setup required. Never written a line of code in your life? No problem. Replit makes software creation accessible, collaborative, and lightning-fast. Join us in our mission to empower the next generation of builders.\nAbout the role:\nThis is a Product Engineering role specialized in billing systems, and will lead that space at Replit. It\u2019s a direct line to business impact. But it\u2019s also critical to get right for our users. These are some of the most critical user journeys to get right. Getting them wrong creates the most frustrating experiences for users. So we\u2019re looking for engineers who can build reliable and scalable billing systems and abstractions, while also translating that to an intuitive and friendly user experience.\nYou will:\nLead the design and implementation of all new billing and invoicing systems at Replit. \nCreate seamless user experiences for users related to billing and invoicing, for both consumer and enterprise users. \nBuild new abstractions and APIs for other engineers at Replit to monetize their new products. \nIterate on pricing and packaging tactics to drive revenue growth. Examples include coupon codes and referral systems. \nCreate monitoring and feedback systems so that we can proactively spot problems, fix them, and optimize performance. \nRequired skills and experience:\n4+ years of full stack product experience, with strong skills working on the backend. \nDirect working experience in at least one of the following:\nSubscription invoicing systems\nUsage based billing systems\nSelf-directed and comfortable working autonomously in ambiguous environments. \nExcellent problem-solving skills with ability to debug complex billing issues and edge cases. \nExperience implementing customer-facing billing interfaces that simplify complex pricing structures. \nTools + Tech Stack\n for this role:\nTypeScript, React, Postgres, GraphQL, and Nodejs. \nBonus Points\n:\nExperience working with Orb, Metronome, or Stripe usage based billing. \nExperience with coupons, referral programs, or other monetization growth tactics. \nFull-Time Employee Benefits Include:\n\ud83d\udcb0 Competitive Salary & Equity\n\ud83d\udcb9 401(k) Program\n\u2695\ufe0f Health, Dental, Vision and Life Insurance\n\ud83e\ude7c Short Term and Long Term Disability\n\ud83d\udebc Paid Parental, Medical, Caregiver Leave\n\ud83d\ude97 Commuter Benefits\n\ud83d\udcf1 Monthly Wellness Stipend\n\ud83e\uddd1\u200d\ud83d\udcbb Autonoumous Work Environement\n\ud83d\udda5 In Office Set-Up Reimbursement\n\ud83c\udfdd Flexible Time Off (FTO) + Holidays\n\ud83d\ude80 Quarterly Team Gatherings\n\u2615 In Office Amenities\nWant to learn more about what we are up to?\nMeet the Replit Agent\nReplit: Make an app for that\nReplit Blog\nAmjad TED Talk\nInterviewing + Culture at Replit \nOperating Principles\nReasons not to work at Replit\nTo achieve our mission of making programming more accessible around the world, we need our team to be representative of the world. We welcome your unique perspective and experiences in shaping this product. We encourage people from all kinds of backgrounds to apply, including and especially candidates from underrepresented and non-traditional backgrounds.\nThis is a full-time role that can be held from our Foster City, CA office. The hybrid role has an\n in-office requirement of Monday, Wednesday, and Friday.\nCompensation Range: $130K - $290K", "comp": "$130,000.00", "title": "Senior Software Engineer, Money", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4278654942", "loc": "Foster City, CA", "company": "Replit"}, {"desc": "Replit is the fastest way to turn ideas into software. With our powerful AI-powered Agent and Assistant, anyone can create and launch apps from natural language in just one click. Build and deploy full-stack applications directly from your browser\u2014no setup required. Never written a line of code in your life? No problem. Replit makes software creation accessible, collaborative, and lightning-fast. Join us in our mission to empower the next generation of builders.\nAbout the role:\nJoin our Site Reliability Engineering team and help ensure the reliability, scalability, and performance of Replit's infrastructure that serves millions of developers worldwide. As a Site Reliability Engineer, you will bridge the gap between development and operations, implementing automation and establishing best practices that enable our platform to scale efficiently while maintaining high availability.\nWe are seeking SREs who are passionate about building and maintaining resilient systems at scale. Your mission will be to design and implement robust monitoring solutions, automate operational tasks, and continuously improve our infrastructure's reliability and performance.\nYou will: \nDesign and Implement Observability Solutions: Develop comprehensive monitoring and alerting systems using modern observability tools. Create dashboards and metrics that provide real-time visibility into system health and performance. Implement logging strategies that enable quick problem identification and resolution. \nDrive Automation and Infrastructure as Code: Architect and implement infrastructure automation solutions using tools like Terraform, Ansible, or Pulumi. Design and maintain CI/CD pipelines that enable reliable and consistent deployments. Create self-healing systems that can automatically respond to common failure scenarios. \nEstablish SLOs and SLIs: Work with product and engineering teams to define and implement Service Level Objectives (SLOs) and Service Level Indicators (SLIs). Build systems to track and report on these metrics, ensuring we maintain high reliability standards while balancing innovation speed. \nIncident Management and Response: Lead incident response efforts, conducting thorough post-mortems, and implementing improvements to prevent future occurrences. Develop and maintain runbooks for critical services. Build tools and processes that reduce Mean Time To Recovery (MTTR). \nPerformance Optimization: Identify and resolve performance bottlenecks across our infrastructure. Implement capacity planning strategies and optimize resource utilization. Work on reducing latency and improving system efficiency across global regions. \nRequired skills and experience:\n3+ years of experience in Site Reliability Engineering or similar roles (DevOps, Systems Engineering, Infrastructure Engineering)\nStrong programming skills in languages commonly used for automation (Python, Go, or similar)\nDeep understanding of distributed systems\nExperience with container orchestration platforms (Kubernetes) and cloud-native technologies\nProven track record of implementing and maintaining monitoring/observability solutions\nStrong incident management skills with experience leading incident response\nExperience with infrastructure as code and configuration management tools\nBonus Points:\nExperience with Google Cloud Platform (GCP) services and tools\nKnowledge of modern observability platforms (Prometheus, Grafana, Datadog, etc.)\nWhat we value:\nProblem-solving mindset: Ability to approach complex operational challenges systematically and devise effective solutions\nSelf-directed and autonomous: Capable of working independently while collaborating effectively with cross-functional teams\nStrong communication skills: Ability to explain complex technical concepts to both technical and non-technical audiences\nContinuous learning: Passion for staying current with industry best practices and new technologies\nFocus on automation: Strong belief in automating repetitive tasks and building self-healing systems\nFull-Time Employee Benefits Include:\n\ud83d\udcb0 Competitive Salary & Equity\n\ud83d\udcb9 401(k) Program\n\u2695\ufe0f Health, Dental, Vision and Life Insurance\n\ud83e\ude7c Short Term and Long Term Disability\n\ud83d\udebc Paid Parental, Medical, Caregiver Leave\n\ud83d\ude97 Commuter Benefits\n\ud83d\udcf1 Monthly Wellness Stipend\n\ud83e\uddd1\u200d\ud83d\udcbb Autonoumous Work Environement\n\ud83d\udda5 In Office Set-Up Reimbursement\n\ud83c\udfdd Flexible Time Off (FTO) + Holidays\n\ud83d\ude80 Quarterly Team Gatherings\n\u2615 In Office Amenities\nWant to learn more about what we are up to?\nMeet the Replit Agent\nReplit: Make an app for that\nReplit Blog\nAmjad TED Talk\nInterviewing + Culture at Replit \nOperating Principles\nReasons not to work at Replit\nTo achieve our mission of making programming more accessible around the world, we need our team to be representative of the world. We welcome your unique perspective and experiences in shaping this product. We encourage people from all kinds of backgrounds to apply, including and especially candidates from underrepresented and non-traditional backgrounds.\nThis is a full-time role that can be held from our Foster City, CA office. The hybrid role has an in-office requirement of Monday, Wednesday, and Friday.\nCompensation Range: $160K - $250K", "comp": "$160,000.00", "title": "Site Reliability Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4176196185", "loc": "Foster City, CA", "company": "Replit"}, {"desc": "Replit is the fastest way to turn ideas into software. With our powerful AI-powered Agent and Assistant, anyone can create and launch apps from natural language in just one click. Build and deploy full-stack applications directly from your browser\u2014no setup required. Never written a line of code in your life? No problem. Replit makes software creation accessible, collaborative, and lightning-fast. Join us in our mission to empower the next generation of builders.\nAbout the role:\nWe're seeking a Design Engineer to bridge the gap between design and engineering at Replit. In this role, you'll help shape our design system implementation, architect front-end solutions, and ensure seamless user experiences across our platform. You'll be instrumental in creating the technical foundation that allows us to enable anyone with an idea to create apps.\nWhat You'll Do\nArchitect and implement complex UI components and systems that balance aesthetics with technical performance\nLead the technical implementation and evolution of our design system (Replit UI)\nCreate prototypes to explore new interaction models and validate design concepts\nCollaborate closely with product designers to bring designs to life with pixel-perfect precision\nEstablish best practices for front-end development and component architecture\nMentor engineers on design principles and implementation techniques\nDevelop tools and processes to improve design-to-development workflow\nContribute to design reviews with a focus on technical feasibility and implementation\nChampion accessible, responsive, and performant user interfaces\nRequired Skills & Experience\n8+ years of experience in front-end development with a strong design sensibility\nExpert-level knowledge of HTML, CSS, and JavaScript/TypeScript\nDeep experience with modern front-end frameworks (React preferred)\nStrong understanding of design systems and component-based architecture\nExperience implementing complex UI animations and interactions\nProven ability to translate design concepts into production-ready code\nStrong communication skills to effectively collaborate with both design and engineering teams\nExperience with accessibility standards and best practices\nBonus Qualifications\nActive Replit user and passionate about making software creation more accessible\nExperience building design tools or developer tools\nBackground or interest working with AI\nOpen-source contributions to design systems or UI libraries\nFull-Time Employee Benefits Include:\n\ud83d\udcb0 Competitive Salary & Equity\n\ud83d\udcb9 401(k) Program\n\u2695\ufe0f Health, Dental, Vision and Life Insurance\n\ud83e\ude7c Short Term and Long Term Disability\n\ud83d\udebc Paid Parental, Medical, Caregiver Leave\n\ud83d\ude97 Commuter Benefits\n\ud83d\udcf1 Monthly Wellness Stipend\n\ud83e\uddd1\u200d\ud83d\udcbb Autonoumous Work Environement\n\ud83d\udda5 In Office Set-Up Reimbursement\n\ud83c\udfdd Flexible Time Off (FTO) + Holidays\n\ud83d\ude80 Quarterly Team Gatherings\n\u2615 In Office Amenities\nWant to learn more about what we are up to?\nMeet the Replit Agent\nReplit: Make an app for that\nReplit Blog\nAmjad TED Talk\nInterviewing + Culture at Replit \nOperating Principles\nReasons not to work at Replit\nTo achieve our mission of making programming more accessible around the world, we need our team to be representative of the world. We welcome your unique perspective and experiences in shaping this product. We encourage people from all kinds of backgrounds to apply, including and especially candidates from underrepresented and non-traditional backgrounds.\nThis is a full-time role that can be held from our Foster City, CA office. The hybrid role has an\n in-office requirement of Monday, Wednesday, and Friday.\nCompensation Range: $180K - $290K", "comp": "$180,000.00", "title": "Design Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4190020366", "loc": "Foster City, CA", "company": "Replit"}, {"desc": "Replit is the fastest way to turn ideas into software. With our powerful AI-powered Agent and Assistant, anyone can create and launch apps from natural language in just one click. Build and deploy full-stack applications directly from your browser\u2014no setup required. Never written a line of code in your life? No problem. Replit makes software creation accessible, collaborative, and lightning-fast. Join us in our mission to empower the next generation of builders.\nAbout This Role\nAccelerate engineering velocity and reduce friction in the Replit development experience by stewarding our TypeScript monorepo, tooling, and developer workflows. You will be directly impacting all our engineers working in this monorepo daily. By focusing on developer experience, you will act as a force multiplier across all product development teams, enabling faster feature delivery, happier developers, and reduced operational overhead.\nThe role combines the technical depth needed to navigate a complex monorepo with the product mindset to understand how infrastructure decisions impact developer productivity and ultimately customer value delivery.\nAdditionally, you will be a key decision maker in the Agent\u2019s default stack (Vite + React + Express) and will help the AI team with strategies to improve the Agent\u2019s output and stack.\nThis is a first hire in this area, so you will automatically be in a position of leadership and have an accelerated career path as the team undoubtedly grows.\nYou will:\nMaintain and evolve a complex monorepo structure spanning frontend, backend, npm packages, and tooling. \nOwn the build pipelines and optimize them to minimize build times and improve developer iteration speed. \nImprove and oversee code generation such as GraphQL and Protocol Buffers to ensure our code is type safe. \nSet the standards for code quality using automation tools such as TypeScript, Prettier and Eslint, building custom rules and plugins to enforce Replit-specific requirements. \nStreamline local development setup and onboarding experience. \nWork with platform teams to improve deployment processes, infrastructure integrations, and external tooling. \nKeep things fresh and modern in our codebase by adopting and leading migrations to better and faster tools. \nHelp manage dependencies both internal (public and private) and external, including being the face of the company when interfacing with open-source libraries such as when it comes to sponsorships. \nRequired skills and experience:\nExpertise in TypeScript build systems such as Vite, TypeScript, webpack, and so on. \nProficiency with ESLint, Prettier, testing frameworks, and code generation tools. \nExperience managing monorepos or large-scale codebases\nFull-Time Employee Benefits Include\n:\n\ud83d\udcb0 Competitive Salary & Equity\n\ud83d\udcb9 401(k) Program\n\u2695\ufe0f Health, Dental, Vision and Life Insurance\n\ud83e\ude7c Short Term and Long Term Disability\n\ud83d\udebc Paid Parental, Medical, Caregiver Leave\n\ud83d\ude97 Commuter Benefits\n\ud83d\udcf1 Monthly Wellness Stipend\n\ud83e\uddd1\u200d\ud83d\udcbb Autonoumous Work Environement\n\ud83d\udda5 In Office Set-Up Reimbursement\n\ud83c\udfdd Flexible Time Off (FTO) + Holidays\n\ud83d\ude80 Quarterly Team Gatherings\n\u2615 In Office Amenities\nWant to learn more about what we are up to?\nMeet the Replit Agent\nReplit: Make an app for that\nReplit Blog\nAmjad TED Talk\nInterviewing + Culture at Replit\nOperating Principles\nReasons not to work at Replit\nTo achieve our mission of making programming more accessible around the world, we need our team to be representative of the world. We welcome your unique perspective and experiences in shaping this product. We encourage people from all kinds of backgrounds to apply, including and especially candidates from underrepresented and non-traditional backgrounds.\nThis is a full-time role that can be held from our Foster City, CA office. The hybrid role has an in-office requirement of Monday, Wednesday, and Friday.\nCompensation Range: $180K - $250K", "comp": "$180,000.00", "title": "Software Engineer, Product Infrastructure (TypeScript DevEx)", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4296164363", "loc": "Foster City, CA", "company": "Replit"}, {"desc": "Replit is the fastest way to turn ideas into software. With our powerful AI-powered Agent and Assistant, anyone can create and launch apps from natural language in just one click. Build and deploy full-stack applications directly from your browser\u2014no setup required. Never written a line of code in your life? No problem. Replit makes software creation accessible, collaborative, and lightning-fast. Join us in our mission to empower the next generation of builders.\nAbout the role:\nAs a Staff Product Engineer at Replit, you\u2019ll work closely with other product and platform engineers, designers, sales representative, and product managers to build features that help users collaborate with their team to go from idea to software fast. You\u2019ll be at the forefront of shaping and experimenting on what our tens of millions of users love.\nYou will:\nHelp lead major projects and take new products from 0->1\nIdentify the hardest technical and/or quality problems holding us back, and then build solutions\nChart high level technical direction and follow up to make sure those projects come together to deliver on results\nMentor and develop new senior engineers to help grow the team\nShip new features and build infrastructure using: TypeScript, React, CSS, GraphQL, Node.js, and Postgres\nRequired skills and experience:\nA minimum of 7 years of professional software development experience\nExperience in a technical leadership role, working cross functionally\nWorking experience building full stack applications with TypeScript\nWorking experience building directly for users\nBonus Points\n:\nYou\u2019re excited about the future of programming and have experience working with IDEs, terminals, or other common developer tools\nYou\u2019ve had previous experience working at a startup in a cross-functional engineering role\nFull-Time Employee Benefits Include:\n\ud83d\udcb0 Competitive Salary & Equity\n\ud83d\udcb9 401(k) Program\n\u2695\ufe0f Health, Dental, Vision and Life Insurance\n\ud83e\ude7c Short Term and Long Term Disability\n\ud83d\udebc Paid Parental, Medical, Caregiver Leave\n\ud83d\ude97 Commuter Benefits\n\ud83d\udcf1 Monthly Wellness Stipend\n\ud83e\uddd1\u200d\ud83d\udcbb Autonoumous Work Environement\n\ud83d\udda5 In Office Set-Up Reimbursement\n\ud83c\udfdd Flexible Time Off (FTO) + Holidays\n\ud83d\ude80 Quarterly Team Gatherings\n\u2615 In Office Amenities\nWant to learn more about what we are up to?\nMeet the Replit Agent\nReplit: Make an app for that\nReplit Blog\nAmjad TED Talk\nInterviewing + Culture at Replit \nOperating Principles\nReasons not to work at Replit\nTo achieve our mission of making programming more accessible around the world, we need our team to be representative of the world. We welcome your unique perspective and experiences in shaping this product. We encourage people from all kinds of backgrounds to apply, including and especially candidates from underrepresented and non-traditional backgrounds.\nThis is a full-time role that can be held from our Foster City, CA office. The hybrid role has an\n in-office requirement of Monday, Wednesday, and Friday.\nCompensation Range: $200K - $290K", "comp": "$200,000.00", "title": "Staff Software Engineer, Product", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4219894544", "loc": "Foster City, CA", "company": "Replit"}, {"desc": "Replit is the fastest way to turn ideas into software. With our powerful AI-powered Agent and Assistant, anyone can create and launch apps from natural language in just one click. Build and deploy full-stack applications directly from your browser\u2014no setup required. Never written a line of code in your life? No problem. Replit makes software creation accessible, collaborative, and lightning-fast. Join us in our mission to empower the next generation of builders.\nAbout The Role\nWe\u2019re looking for a Senior Growth Engineer to accelerate the product flywheel across activation, retention, collaboration, and monetization. You\u2019ll own end-to-end experiments and features, instrument product analytics, and ship fast, measurable improvements to core funnels. Expect a tight build\u2013measure-learn loop, deep ownership, and lots of time with real users.\nWhat You\u2019ll Do\nMove the metrics that matter: design and run A/B/n tests to improve sign-up, activation, collaboration, and retention; validate with trustworthy instrumentation and guardrails. \nShip full-stack growth features: onboarding flows, in-product education, checklists, templates, referrals, pricing/paywall UX, and lifecycle triggers (email/in-product). \nBuild growth infra: experiment frameworks, targeting/segmentation, holdouts, attribution, and feature flagging. \nCollaborate deeply: partner with Design, Data, Product, Marketing, and Sales to prioritize hypotheses and land launches that actually change behavior. \nKeep the funnel healthy: anti-abuse, bot/low-quality traffic detection, and experiment ethics. \nWhat You\u2019ll Bring\n5\u20138+ years building and shipping user-facing products with measurable impact; you\u2019ve meaningfully moved activation/retention or revenue metrics at scale. \nFull-stack TypeScript experience across React, APIs and backend. \nStrong product sense + analytical rigor: you write SQL, define success metrics, and know when to pivot or double-down. \nExperience with experimentation platforms (homegrown or vendor), event schemas, and cohort/segmentation analysis. \nBias to action: you prototype quickly, validate with users, and ship. \nNice to Have\nPLG experience in devtools or AI products\nLLM/agents experience (prompting, evals). \nSEO/landing-page systems, referral loops, or collaboration network effects. \nPrior work on enterprise trials, self-serve to enterprise bridges, and sales-assist workflows. \nFull-Time Employee Benefits Include:\n\ud83d\udcb0 Competitive Salary & Equity\n\ud83d\udcb9 401(k) Program\n\u2695\ufe0f Health, Dental, Vision and Life Insurance\n\ud83e\ude7c Short Term and Long Term Disability\n\ud83d\udebc Paid Parental, Medical, Caregiver Leave\n\ud83d\ude97 Commuter Benefits\n\ud83d\udcf1 Monthly Wellness Stipend\n\ud83e\uddd1\u200d\ud83d\udcbb Autonoumous Work Environement\n\ud83d\udda5 In Office Set-Up Reimbursement\n\ud83c\udfdd Flexible Time Off (FTO) + Holidays\n\ud83d\ude80 Quarterly Team Gatherings\n\u2615 In Office Amenities\nWant to learn more about what we are up to?\nMeet the Replit Agent\nReplit: Make an app for that\nReplit Blog\nAmjad TED Talk\nInterviewing + Culture at Replit\nOperating Principles\nReasons not to work at Replit\nTo achieve our mission of making programming more accessible around the world, we need our team to be representative of the world. We welcome your unique perspective and experiences in shaping this product. We encourage people from all kinds of backgrounds to apply, including and especially candidates from underrepresented and non-traditional backgrounds.\nThis is a full-time role that can be held from our Foster City, CA office. The hybrid role has an in-office requirement of Monday, Wednesday, and Friday\nCompensation Range: $180K - $250K", "comp": "$180,000.00", "title": "Growth Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4292075463", "loc": "Foster City, CA", "company": "Replit"}, {"desc": "Replit is the fastest way to turn ideas into software. With our powerful AI-powered Agent and Assistant, anyone can create and launch apps from natural language in just one click. Build and deploy full-stack applications directly from your browser\u2014no setup required. Never written a line of code in your life? No problem. Replit makes software creation accessible, collaborative, and lightning-fast. Join us in our mission to empower the next generation of builders.\nWe're looking for a Partner Engineer to serve as the technical bridge between our platform and our strategic partners. This role combines technical expertise with relationship management skills to help us quickly plan, test, and facilitate key strategic partnerships.\nKey Responsibilities\nTechnical Integration & Support\nLead technical onboarding and integration processes for new strategic partners\nDesign and implement custom demos and applications on Replit for partner demos and events\nTroubleshoot technical issues across partner integrations\nProvide technical guidance and best practices to partner development teams\nPartner Enablement\nConduct technical workshops and training sessions for partner teams\nDevelop technical demos and proof-of-concepts for prospective partners\nHost hackathons for initiatives across the partnership function\nServe as escalation point for complex technical partner issues\nProduct & Platform Development\nCollaborate with engineering teams to build partner-focused features and tools\nDesign and develop partner-specific tooling, dashboards, and monitoring systems\nBuild internal tools to streamline partner management and technical operations\nCross-functional Collaboration\nWork closely with Partnership, Sales, and Marketing teams on technical aspects of deals\nTranslate business requirements into technical solutions and vice versa\nProvide technical input on partnership strategy and go-to-market plans\nSupport sales engineering efforts for strategic partnership opportunities\nRequired Qualifications\n4+ years of software engineering, dev relations, sales engineering, or partner engineering experience\nComfortable speaking in large group settings and hosting hackathons\nStrong proficiency in Python and JavaScript\nKnowledge of Vibe Coding tools and traditional developer tools\nExperience with common integrations and APIs\nPreferred Qualifications\nKnowledge of authentication protocols (OAuth, SAML, JWT)\nBackground in SaaS platforms or B2B integrations\nExtensive portfolio or experience building applications with Replit\nDeep experience with REST APIs, GraphQL, webhooks, and modern integration patterns\nTechnical Skills\nLanguages: Python, JavaScript/TypeScript, Go, or similar\nAPIs & Integration: REST, GraphQL, webhooks, message queues\nDatabases: SQL and NoSQL databases, data modeling\nCloud & Infrastructure: AWS/GCP/Azure, Docker, Kubernetes\nTools: Git, CI/CD pipelines, monitoring and logging tools\nSecurity: Authentication, encryption, secure API design\nThis role is a good fit if you have\u2026\nAn entrepreneurial mindset with ability to operate in ambiguous, fast-moving environments\nGenuine passion for supporting founders and the startup community\nA data-driven approach to partnership development and optimization\nA love for sharing Replit and AI tools\nInterest in travel and working across global regions\nThis role is not a good fit if\u2026\nYou\u2019re looking for a very structured, defined role\nYou have never Vibe Coded or built on Replit\nYou\u2019re not comfortable hosting large hackathons or events\nFull-Time Employee Benefits Include:\n\ud83d\udcb0 Competitive Salary & Equity\n\ud83d\udcb9 401(k) Program\n\u2695\ufe0f Health, Dental, Vision and Life Insurance\n\ud83e\ude7c Short Term and Long Term Disability\n\ud83d\udebc Paid Parental, Medical, Caregiver Leave\n\ud83d\ude97 Commuter Benefits\n\ud83d\udcf1 Monthly Wellness Stipend\n\ud83e\uddd1\u200d\ud83d\udcbb Autonoumous Work Environement\n\ud83d\udda5 In Office Set-Up Reimbursement\n\ud83c\udfdd Flexible Time Off (FTO) + Holidays\n\ud83d\ude80 Quarterly Team Gatherings\n\u2615 In Office Amenities\nWant to learn more about what we are up to?\nMeet the Replit Agent\nReplit: Make an app for that\nReplit Blog\nAmjad TED Talk\nInterviewing + Culture at Replit\nOperating Principles\nReasons not to work at Replit\nTo achieve our mission of making programming more accessible around the world, we need our team to be representative of the world. We welcome your unique perspective and experiences in shaping this product. We encourage people from all kinds of backgrounds to apply, including and especially candidates from underrepresented and non-traditional backgrounds.\nThis is a full-time role that can be held from our Foster City, CA office. The role has an in-office requirement of Monday, Wednesday, and Friday.\nCompensation Range: $150K - $235K", "comp": "$150,000.00", "title": "Partnership Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4294305503", "loc": "Foster City, CA", "company": "Replit"}, {"desc": "Replit is the fastest way to turn ideas into software. With our powerful AI-powered Agent and Assistant, anyone can create and launch apps from natural language in just one click. Build and deploy full-stack applications directly from your browser\u2014no setup required. Never written a line of code in your life? No problem. Replit makes software creation accessible, collaborative, and lightning-fast. Join us in our mission to empower the next generation of builders.\nAs a Support Engineer you are at the forefront of helping those developers create. In a given day you\u2019ll help folks with all sorts of things ranging from general Replit usage questions, identifying and debugging issues on the platform and helping to build and maintain the tools we use. We use tools like Zendesk, Linear, Slack, and Replit itself to get the job done. We also value solving the problems we can ourselves. We have a number of tools we build and maintain ourselves.\nYou will work on a small, global team of support specialists and engineers united by Replit's mission to make the next billion software creators. Together, you'll ensure developers worldwide have the support they need to bring their ideas to life.\nYou Will:\nWork directly with Replit customers via support tickets to solve technical product issues, bugs, and provide technical guidance while meeting daily ticket volume and resolution time targets. \nCollaborate with the rest of the Support team in telling the story of our users to the rest of Replit. \nDirectly contribute to and maintain the Support team's Knowledge Base. \nSupport customer-facing communications for outages and incidents and swiftly report ongoing bugs for Eng to triage and fix. \nRequired Skills and Experience:\nPrior experience in software development or relevant technical support experience\nProven ability to work efficiently in fast-paced, high-volume support environments with strict productivity metrics. \nStrong time management and ticket triage skills with comfort in performance tracking and regular reporting. \nExcellent communication skills with initiative to ask questions when encountered with the unknown. \nExperience with support tools and ticketing systems (e.g. Zendesk)\nBonus Points:\nHas used Replit in the last 3 to 6 months. \nExperience working with IDEs, terminals, or other common developer tools. \nExperience with AI tools (Claude, ChatGPT, etc.)\nWhat we Value:\nProblem-solving mindset: Ability to approach complex operational challenges systematically and devise effective solutions\nSelf-directed and autonomous: Capable of working independently while collaborating effectively with cross-functional teams\nStrong communication skills: Ability to explain complex technical concepts to both technical and non-technical audiences\nContinuous learning: Passion for staying current with industry best practices and new technologies\nFocus on automation: Strong belief in automating repetitive tasks and building self-healing systems\nFull-Time Employee Benefits Include:\n\ud83d\udcb0 Competitive Salary & Equity\n\ud83d\udcb9 401(k) Program\n\u2695\ufe0f Health, Dental, Vision and Life Insurance\n\ud83e\ude7c Short Term and Long Term Disability\n\ud83d\udebc Paid Parental, Medical, Caregiver Leave\n\ud83d\ude97 Commuter Benefits\n\ud83d\udcf1 Monthly Wellness Stipend\n\ud83e\uddd1\u200d\ud83d\udcbb Autonoumous Work Environement\n\ud83d\udda5 In Office Set-Up Reimbursement\n\ud83c\udfdd Flexible Time Off (FTO) + Holidays\n\ud83d\ude80 Quarterly Team Gatherings\n\u2615 In Office Amenities\nWant to learn more about what we are up to?\nMeet the Replit Agent\nReplit: Make an app for that\nReplit Blog\nAmjad TED Talk\nInterviewing + Culture at Replit\nOperating Principles\nReasons not to work at Replit\nTo achieve our mission of making programming more accessible around the world, we need our team to be representative of the world. We welcome your unique perspective and experiences in shaping this product. We encourage people from all kinds of backgrounds to apply, including and especially candidates from underrepresented and non-traditional backgrounds.\nThis is a full-time role that can be held from our Foster City, CA office. The role has an in-office requirement of Monday, Wednesday, and Friday.\nCompensation Range: $110K - $140K", "comp": "$110,000.00", "title": "Support Engineer I", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4288903646", "loc": "Foster City, CA", "company": "Replit"}, {"desc": "Replit is the fastest way to turn ideas into software. With our powerful AI-powered Agent and Assistant, anyone can create and launch apps from natural language in just one click. Build and deploy full-stack applications directly from your browser\u2014no setup required. Never written a line of code in your life? No problem. Replit makes software creation accessible, collaborative, and lightning-fast. Join us in our mission to empower the next generation of builders.\nAs a Support Engineer you are at the forefront of helping those developers create. In a given day you\u2019ll help folks with all sorts of things ranging from general Replit usage questions, identifying and debugging issues on the platform and helping to build and maintain the tools we use. We use tools like Zendesk, Linear, Slack, and Replit itself to get the job done. We also value solving the problems we can ourselves. We have a number of tools we build and maintain ourselves.\nYou will work on a small, global team of support specialists and engineers united by Replit's mission to make the next billion software creators. Together, you'll ensure developers worldwide have the support they need to bring their ideas to life.\nYou will:\nWork directly with Replit customers via support tickets to solve product issues, bugs, and provide technical guidance. \nCollaborate with the rest of the Support team in telling the story of our users to the rest of Replit. \nDirectly contribute to and maintain the Support team\u2019s Knowledge Base. \nLead customer-facing communications for outages and incidents. \nProactively identify and lead initiatives to streamline support operations and improve team efficiency. \nManage complex escalated issues and bugs that are flagged via internal and external channels\nHelp on-board and mentor new members of the support team. \nRequired Skills and Experience:\nPrior experience in software development or systems engineering. \nDemonstrated experience building and debugging applications with Javascript, Python, or similar languages. \nExcellent communication skills with initiative to ask questions when encountered with the unknown. \nInitiative to ask questions when encountered with the unknown. \nExperience with support tools and ticketing systems (e.g. Zendesk)\nBonus Points:\nHas used Replit in the last 3 to 6 months. \nExperience working with IDEs, terminals, or other common developer tools. \nExperience with AI tools (Claude, ChatGPT, etc.)\nWhat we value:\nProblem-solving mindset: Ability to approach complex operational challenges systematically and devise effective solutions\nSelf-directed and autonomous: Capable of working independently while collaborating effectively with cross-functional teams\nStrong communication skills: Ability to explain complex technical concepts to both technical and non-technical audiences\nContinuous learning: Passion for staying current with industry best practices and new technologies\nFocus on automation: Strong belief in automating repetitive tasks and building self-healing systems\nFull-Time Employee Benefits Include:\n\ud83d\udcb0 Competitive Salary & Equity\n\ud83d\udcb9 401(k) Program\n\u2695\ufe0f Health, Dental, Vision and Life Insurance\n\ud83e\ude7c Short Term and Long Term Disability\n\ud83d\udebc Paid Parental, Medical, Caregiver Leave\n\ud83d\ude97 Commuter Benefits\n\ud83d\udcf1 Monthly Wellness Stipend\n\ud83e\uddd1\u200d\ud83d\udcbb Autonoumous Work Environement\n\ud83d\udda5 In Office Set-Up Reimbursement\n\ud83c\udfdd Flexible Time Off (FTO) + Holidays\n\ud83d\ude80 Quarterly Team Gatherings\n\u2615 In Office Amenities\nWant to learn more about what we are up to?\nMeet the Replit Agent\nReplit: Make an app for that\nReplit Blog\nAmjad TED Talk\nInterviewing + Culture at Replit\nOperating Principles\nReasons not to work at Replit\nTo achieve our mission of making programming more accessible around the world, we need our team to be representative of the world. We welcome your unique perspective and experiences in shaping this product. We encourage people from all kinds of backgrounds to apply, including and especially candidates from underrepresented and non-traditional backgrounds.\nThis is a full-time role that can be held from our Foster City, CA office. The role has an in-office requirement of Monday, Wednesday, and Friday.\nCompensation Range: $130K - $165K", "comp": "$130,000.00", "title": "Support Engineer II", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4288904561", "loc": "Foster City, CA", "company": "Replit"}, {"desc": "Replit is the fastest way to turn ideas into software. With our powerful AI-powered Agent and Assistant, anyone can create and launch apps from natural language in just one click. Build and deploy full-stack applications directly from your browser\u2014no setup required. Never written a line of code in your life? No problem. Replit makes software creation accessible, collaborative, and lightning-fast. Join us in our mission to empower the next generation of builders.\nReplit is seeking a Sales Engineer (SE) with strong technical expertise to join our growing sales team. Candidates with solid coding ability, while excelling at communicating with non-technical audiences are ideal, as our primary users are Product Managers, Designers, and Operations professionals who use Replit\u2019s AI coding agent to build business apps and new products.\nThis position encompasses both pre- and post-sales support, working closely with our Account Executive and Account Managers throughout the customer lifecycle and spanning all segments from SMB to Enterprise. A significant portion of the role involves supporting and travelling to prospective customers to run hackathons with non-engineering teams.\nThis role offers a distinctive opportunity for people who excel in client-facing situations and have a passion for solving business challenges with AI. You'll leverage your skills to effectively communicate Replit's value proposition: a world where anyone can create software using natural language.\nWhat You'll Do\nPartner with Account Executives and Account Managers to provide technical expertise throughout both pre-sales and post-sales customer lifecycle\nPlan, coordinate, and facilitate hackathons at prospective customer sites (typically 50-200 attendees per event)\nTravel up to 25% of the time to support on-site customer hackathons and technical engagements\nConduct compelling product demonstrations tailored to non-technical audiences (PMs, Designers, Operations teams)\nLead technical discovery sessions focused on use cases like prototyping, internal tool development, and workflow automation\nArticulate how Replit's AI coding agent empowers non-technical users to build applications without traditional coding\nDesign and present solutions that showcase how teams can leverage Replit for rapid prototyping and internal tooling\nCreate educational content and workshops for hackathon participants and customer teams\nCollaborate with product and engineering teams to address technical questions and gather user feedback\nProvide hands-on technical support during customer implementations and onboarding\nDevelop technical content including demo scripts, hackathon materials, and use case documentation\nStay current with Replit's evolving AI capabilities and new features for non-technical users\nRequired Skills & Experience\n3+ years of experience in a Sales Engineer, Solutions Engineer, or technical sales role, preferably in SaaS or no-code/low-code tools\nStrong coding skills at minimum entry-level/junior software engineer proficiency\nExceptional ability to communicate complex technical concepts to non-technical audiences (PMs, Designers, Operations teams)\nUnderstanding of common business use cases for prototyping, internal tooling, and workflow automation\nExcellent presentation and demonstration skills with business stakeholders and non-technical users\nProven ability to quickly learn and teach AI-powered development tools\nStrong problem-solving skills and ability to guide non-technical users through technical challenges\nComfort with frequent travel (up to 25%) for on-site customer events and hackathons\nSelf-motivated with excellent event planning and organizational skills\nPassion for democratizing software creation and AI-powered development tools\nBonus Points\nYou're an active Replit user\nYou've worked at an early-stage startup or in developer tools\nDegree in Computer Science, Engineering, or a related technical field (or equivalent practical experience)\nTools + Tech Stack for this role\nReplit\nHubspot CRM\nZoomInfo\nClay\nSmartLead\nLinkedIn\nHashboard, Hex\nThis role may \nnot\n be a fit if\nYou\u2019re not based in the Bay area or willing to relocate\nYou lack an understanding of the software development lifecycle; have little to no coding knowledge\nYou\u2019re not passionate about AI\nYou don\u2019t enjoy being in client facing roles where most of your day is talking to others\nYou\u2019re not comfortable with frequent travel (up to one week per month average)\nFull-Time Employee Benefits Include:\n\ud83d\udcb0 Competitive Salary & Equity\n\ud83d\udcb9 401(k) Program\n\u2695\ufe0f Health, Dental, Vision and Life Insurance\n\ud83e\ude7c Short Term and Long Term Disability\n\ud83d\udebc Paid Parental, Medical, Caregiver Leave\n\ud83d\ude97 Commuter Benefits\n\ud83d\udcf1 Monthly Wellness Stipend\n\ud83e\uddd1\u200d\ud83d\udcbb Autonoumous Work Environement\n\ud83d\udda5 In Office Set-Up Reimbursement\n\ud83c\udfdd Flexible Time Off (FTO) + Holidays\n\ud83d\ude80 Quarterly Team Gatherings\n\u2615 In Office Amenities\nWant to learn more about what we are up to?\nMeet the Replit Agent\nReplit: Make an app for that\nReplit Blog\nAmjad TED Talk\nInterviewing + Culture at Replit\nOperating Principles\nReasons not to work at Replit\nTo achieve our mission of making programming more accessible around the world, we need our team to be representative of the world. We welcome your unique perspective and experiences in shaping this product. We encourage people from all kinds of backgrounds to apply, including and especially candidates from underrepresented and non-traditional backgrounds.\nThis is a full-time role that can be held from our Foster City, CA office. The role has an\n in-office requirement of Monday, Wednesday, and Friday.\nCompensation Range: $150K - $235K", "comp": "$150,000.00", "title": "Sales Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4275881833", "loc": "Foster City, CA", "company": "Replit"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAt Anthropic, we believe new AI capabilities are best achieved through secure foundations, not in spite of them. As capabilities grow more advanced, it is critical that progress moves forward safely and for the benefit of all society. It is the reason why security sits at the center of our work, and not as an afterthought.\nWe're specifically looking for a Software Engineer to help us build and maintain new agentic coding tools for developers. The ideal candidate will have a passion for developer tools, extensive knowledge of diverse programming environments and languages, and experience with advanced LLM features like tool-use, chaining and orchestration patterns, and prompt engineering. Curiosity about AI research is a must!\nResponsibilities\nDesign, build, and maintain scalable features and infrastructure for AI-powered development tools\nEngage directly with developers inside and outside Anthropic to gather insights and improve user experience\nCollaborate with researchers to improve model capabilities through shared tools and evals\nStay ahead of advancements in AI-assisted coding by experimenting with new tools, evaluating emerging techniques, and tracking enhancements to existing ones\nContribute across the stack\u2014from front-end UI to back-end infrastructure\u2014to develop new features, fix bugs, and optimize performance\nDive into possibly unfamiliar areas like Python notebooks, VS Code plug-ins, and containerized environments.\nYou May Be a Good Fit If You\nAre excited about AI-assisted coding as a tool to enhance developer productivity and creativity\u2014not replace human ingenuity\nSpend a lot of time refining and customizing your AI workflows\nHave experience building and maintaining dev tools\nAre an expert in React development, including performance optimization, modern patterns (hooks, context, suspense), and component architecture\nSpecialize in user experience engineering but are a capable full stack developer\nHave hands-on experience working with large language models and prompt engineering\nHave worked on projects with stringent safety, security and/or compliance requirements\nCare about the societal impacts and ethics of your work\nStrong Candidates May Also Have Experience With\nBuilding and maintaining CLI tools\nWorking in large codebases and quickly jumping in to unfamiliar development environments\nWorking with container orchestration and cloud infrastructure\nScaling TypeScript projects\nWorking with alternate JavaScript runtimes like Bun and Deno\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$320,000 - $560,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$320,000.00", "title": "Software Engineer, Claude Code", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4274352109", "loc": "San Francisco, CA", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Role\nAnthropic is seeking talented and experienced Infrastructure Engineers to join our team and support the development, scaling, and maintenance of our cutting-edge AI systems. By joining our Infrastructure team, you will have the opportunity to work on groundbreaking AI technologies and contribute to the development of frontier models, supporting Anthropic's mission to create safe and reliable AI systems that benefit humanity.\nWe Have Multiple Teams That Are Currently Hiring. Team Placement Occurs After The Interview Process, Taking Into Account Your Interests And Experience Alongside Organizational Needs. This Flexible Approach Allows Us To Match Talented Engineers With The Infrastructure Teams Where They'll Have The Greatest Impact And Growth Potential\nData Infrastructure: We build and maintain the data systems powering Anthropic's AI research and products. You'll design and optimize data pipelines using tools like Spark, Airflow, and dbt across GCP and AWS. Your work will ensure reliable, scalable data infrastructure while implementing governance best practices and driving continuous improvement.\nCore Infrastructure: The systems team is responsible for supporting some of the largest, most sophisticated clusters in industry used to train, research, and ultimately serve AI models. Your work will be crucial in ensuring Anthropic is able to continue reliably and safely training frontier models. You will be responsible for building systems and running large Kubernetes clusters with GPU/TPU/Trainium workloads.\nObservability: We build and maintain the infrastructure that monitors the health, performance, and efficiency of our AI systems. You'll work across teams to implement monitoring solutions using tools like Prometheus, Splunk, and Grafana, while developing automated approaches for dashboards and alerts. Your work will create reliable, low-maintenance systems that enable proactive monitoring and operational excellence.\nDeveloper Productivity: The Developer Productivity team enables Anthropic researchers and engineers to be maximally effective in securely developing state-of-the-art models, and products that expose those models to users. All of the code written at Anthropic goes through systems/infrastructure built and maintained by our team. We aim to make development at Anthropic secure, efficient, and delightful.\nDeveloper Acceleration:The Developer Acceleration puts Anthropic on the forefront of engineering productivity by deeply integrating Claude at every step and ensuring engineers get well configured, optimized dev environments. We own the development setup for engineers and Claude alike, focusing on deeply integrating Claude everywhere so Claude can do hours of work independently and engineers have a great experience.\nCloud Inference: We scale and optimize Claude to serve the massive audiences of developers and enterprise companies using AWS and GCP. Our team's engineers are extremely high leverage because we simultaneously drive two of our company's largest and fastest growing revenue streams, and we optimize the consumption of one of our most precious resources: compute. Our team ensures our LLMs meet rigorous safety, performance, and security standards and enhance our core infrastructure for packaging, testing, and deploying inference technology. Your work will increase the scale at which our services can operate and accelerate our ability to reliably launch new frontier models and innovative features to customers across all platforms.\nAI Reliability: The AI Reliability Engineering team at Anthropic pioneers the future of systems reliability in the AI era, developing and achieving reliability targets across all our products\u2014from public-facing web, API, and mobile services to backend training infrastructure. We execute engineering projects ensuring service reliability while collaborating cross-functionally with product and research teams to enhance availability, manageability, and functionality of Anthropic's systems. As the team ultimately responsible for all service reliability, we take operational ownership of our largest products while innovating at the intersection of advanced model capabilities and time-tested engineering practices. This is an opportunity to invent new approaches to AI systems reliability at scale that will define the field for years to come.\nResponsibilities\nLead build out of industry-leading AI clusters (thousands to hundreds of thousands of machines), partnering closely with cloud service providers on cluster build out and required features\nConsult with different stakeholders to deeply understand infrastructure, data and compute needs, identifying potential solutions to support frontier research and product development\nSet technical strategy and oversee development of high scale, reliable infrastructure systems.\nMentor top technical talent\nDesign processes (e.g. postmortem review, incident response, on-call rotations) that help the team operate effectively and never fail the same way twice\nYou May Be a Good Fit If You\nHave 8+ years of relevant industry experience, 3+ years leading large scale, complex projects or teams as an engineer or tech lead\nAre obsessed with distributed systems at scale, infrastructure reliability, scalability, security, and continuous improvement\nStrong proficiency in at least one programming language (e.g., Python, Rust, Go, Java)\nStrong problem-solving skills and ability to work independently\nHave a passion for supporting internal partners like research to understand their needs\nHave excellent communication skills to build consensus with stakeholders, both internally and externally\nPossess deep knowledge of modern cloud infrastructure including Kubernetes, Infrastructure as Code, AWS, and GCP\nStrong Candidates May Have\nSecurity and privacy best practice expertise\nExperience with machine learning infrastructure like GPUs, TPUs, or Trainium, as well as supporting networking infrastructure like NCCL\nLow level systems experience, for example linux kernel tuning and eBPF \nTechnical expertise: Quickly understanding systems design tradeoffs, keeping track of rapidly evolving software systems\nDeadline to apply: \nNone. Applications will be reviewed on a rolling basis.\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$300,000 - $485,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$300,000.00", "title": "Software Engineer, Infrastructure (All Levels)", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4211500191", "loc": "Seattle, WA", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Role\nWe are looking for software engineers to help build safety and oversight mechanisms for our AI systems. As a software engineer on the Safeguards team, you will work to monitor models, prevent misuse, and ensure user well-being. This role will focus on building systems to detect unwanted model behaviors and prevent disallowed use of models. You will apply your technical skills to uphold our principles of safety, transparency, and oversight while enforcing our terms of service and acceptable use policies.\nResponsibilities\nDevelop monitoring systems to detect unwanted behaviors from our API partners and potentially take automated enforcement actions; surface these in internal dashboards to analysts for manual review\nBuild abuse detection mechanisms and infrastructure \nSurface abuse patterns to our research teams to harden models at the training stage\nBuild robust and reliable multi-layered defenses for real-time improvement of safety mechanisms that work at scale\nAnalyze user reports of inappropriate content or accounts\nYou May Be a Good Fit If You\nBachelor\u2019s degree in Computer Science, Software Engineering or comparable experience\n3-10+ years of experience in a software engineering position, preferably with a focus on integrity, spam, fraud, or abuse detection.\nProficiency in SQL, Python, and data analysis tools.\nStrong communication skills and ability to explain complex technical concepts to non-technical stakeholders\nStrong Candidates May Also\nHave experience building trust and safety mechanisms for AI/ML systems, such as fraud detection models or security monitoring tools or the infrastructure to support these systems at scale\nHave experience with machine learning frameworks like Scikit-Learn, Tensorflow, or Pytorch, and experience building machine learning models\nHave experience with prompt engineering, jailbreak attacks, and other adversarial inputs\nHave worked closely with operational teams to build custom internal tooling\nDeadline to apply: \nNone. Applications will be reviewed on a rolling basis.\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$300,000 - $405,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$300,000.00", "title": "Software Engineer, Safeguards", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4186432033", "loc": "New York, NY", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Role\nWe are looking for software engineers to help build safety and oversight mechanisms for our AI systems. As a software engineer on the Safeguards Intelligence team, you will work to monitor models, prevent misuse, and ensure user well-being. This role will focus on building systems to deeply understand how users are using our models in novel, harmful ways in the rapidly evolving AI landscape. You will apply your technical skills to uphold our principles of safety, transparency, and responsible oversight.\nResponsibilities\nDevelop monitoring systems to detect unwanted behaviors from our users and potentially take automated enforcement actions\nBuild robust and reliable internal tools for rich data understanding and exploration\nWork closely with our data scientists to maintain situational awareness of our current usage patterns and trends, and with our threat investigators to uplevel their ability to conduct thorough investigations\nBuild integrations with third-party data-enrichment vendors\nCreate infrastructure to power large scale, unsupervised learning techniques to detect novel patterns of abuse.\nYou May Be a Good Fit If You Have\nBachelor\u2019s degree in Computer Science, Software Engineering or comparable experience\n3-10+ years of experience in a software engineering position, preferably with a focus on integrity, spam, fraud, or abuse detection.\nProficiency in Python, SQL, and data analysis tools.\nStrong communication skills and ability to explain complex technical concepts to - and work closely with - non-technical stakeholders\nStrong Candidates May Also\nHave experience building trust and safety mechanisms for and using AI/ML systems, such as fraud-detection models or security monitoring tools or the infrastructure to support these systems at scale\nHave experience with prompt engineering, jailbreak attacks, and other adversarial inputs\nHave worked closely with threat intelligence or investigative teams to build custom internal tooling\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$300,000 - $405,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$300,000.00", "title": "Software Engineer, Data Intelligence", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4262322393", "loc": "New York, NY", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Role\nJoin Anthropic's Languages Team as a foundational member shaping how Python, Rust, and Go are used across one of the world's fastest-growing AI companies. As we scale our engineering and research teams, we are \ncurrently seeking three team members (one each for Python, Go and Rust)\n, who are experts in the respective languages, to help define and build the development ecosystems that power the future of AI development.\nYou'll be responsible for the full lifecycle of how Python, Rust, and Go are used by engineers and researchers across Anthropic - from research experiments to production systems serving millions. This includes building foundational language infrastructure, defining best practices, creating tooling, and ensuring exceptional developer productivity while supporting both cutting-edge AI research and massive-scale deployment.\nWorking at the intersection of language ecosystems and AI development, you'll tackle uniquely complex problems where your architectural decisions directly impact how thousands of engineers develop AI systems safely and efficiently. The infrastructure you build must support diverse workloads - from experimental research code to battle-tested production systems - all while maintaining the highest standards of safety, performance, and developer experience.\nThis is an opportunity to establish the standards and foundations for how modern programming languages enable AI development at unprecedented scale, working alongside some of the brightest minds in AI research and engineering.\nResponsibilities\nDesign and build foundational language infrastructure for Python, Rust, and/or Go that supports both AI research workflows and production-scale systems\nDefine and implement language ecosystem standards, best practices, tooling, libraries, and frameworks that ensure safety, performance, and exceptional developer productivity across diverse AI workloads\nEstablish language-specific CI/CD pipeline integration, testing frameworks, and deployment strategies optimized for AI development cycles\nPartner extensively with infrastructure teams to ensure seamless integration between language-specific tools and broader platform services/infrastructure.\nCollaborate closely with research and engineering teams to understand emerging requirements and translate them into robust, scalable language infrastructure, including cross-language interoperability solutions\nDrive technical strategy for language adoption, migration paths, large-scale cross-cutting changes, and ecosystem evolution as Anthropic scales, while mentoring engineers and researchers on language best practices\nLead incident response and troubleshooting for language-related issues across research and production environments\nYou May Be a Good Fit If You\nHave 5+ years of production software engineering experience with deep expertise in at least one of Python, Rust, or Go\nHave strong experience in developer tooling, build systems, dependency management within a monorepo environment\nAre comfortable working across the stack, including debugging infrastructure issues like Kubernetes problems or optimizing system performance\nHave strong communication and collaboration skills to work effectively with diverse teams including researchers, engineers, and infrastructure specialists\nAre excited about defining foundational systems and processes and are comfortable working independently on ambiguous, high-impact technical challenges\nStrong Candidates May Have\nBuilt core language infrastructure like compilers, interpreters, package ecosystems, or maintained widely-used open-source developer tools with significant adoption\nExpertise in performance optimization across language runtimes or cross-language interop technologies\nExperience with AI/ML research-to-production workflows, understanding the unique challenges of supporting both experimental research code and production model training/serving pipelines\nDeadline to apply: \nNone. Applications will be reviewed on a rolling basis.\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$320,000 - $485,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$320,000.00", "title": "Software Engineer, Languages", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4305762376", "loc": "San Francisco, CA", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Role\nWe're looking for an experienced software engineer to join our Enterprise Engineering team as a key part of our Claude for Work initiative. This role requires deep expertise in developing enterprise software solutions with exceptional security, compliance, and scalability standards. You'll be responsible for building and shipping features that create trustworthy AI experiences meeting the needs of business customers from small teams to large organizations across many enterprise verticals including Finance, Life Sciences, and Healthcare.\nYou will work closely with product, design, sales, customer success, and professional services teams to deliver products that drive adoption and retention of Claude in enterprise environments.\nCore Responsibilities\nDesign, build, and ship enterprise-grade software solutions with high standards for security, reliability, and scalability\nDevelop deep understanding of product use cases in various enterprise verticals and build novel solutions to address needs of largest enterprises\nBuild scalable systems for enterprise deployment, user management, and administrative controls\nWork effectively in a fast-moving, ambiguous environment with minimal direction\nYou Might Be a Good Fit If You Have\n8+ years of experience as a product-minded software engineer, with experience building enterprise software applications\nStrong technical skills in software development with proven success shipping enterprise-grade features\nExperience with identity management, SSO integration, and enterprise security standards\nFamiliarity with compliance frameworks (such as FERPA, HIPAA) and identity protocols (such as SCIM, SSO)\nTrack record of building systems that successfully scale from small business to enterprise customers\nStrong communication skills and ability to work effectively across functions\nComfort working in ambiguous environments with evolving requirements\nStrong Candidates May Also Have\nExperience integrating and working with AI/ML models and understanding their capabilities\nBackground in SaaS platforms with enterprise management features\nExperience with multi-tenant architecture and enterprise deployment models\nStartup experience, particularly in building products from zero to one\nKnowledge of enterprise billing systems and seat management\nExperience collaborating with sales, customer success, and professional services teams to drive enterprise adoption\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$405,000 - $485,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$405,000.00", "title": "Software Engineer, Enterprise", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4299683079", "loc": "New York, NY", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Role\nWe're looking for experienced software engineers to join our Beneficial Deployments Engineering team to help bring Claude to communities that need AI most\u2014nonprofits, educational institutions, healthcare organizations, life sciences researchers, and economic mobility initiatives globally.\nThis role requires strong full-stack engineering skills combined with deep empathy for underserved communities and mission-driven organizations. As an IC engineer on this team, you'll solve unique technical challenges at the intersection of AI accessibility, social impact, and scalable product development, and will help make frontier AI accessible to organizations working on humanity's most pressing challenges.\nCore Responsibilities\nDesign and implement infrastructure that enables accessible, self-serve onboarding and verification systems for global markets\nUnderstand the needs of underserved communities and translate them into scalable technical and product solutions\nBuild flexible pricing, billing, and provisioning systems that balance accessibility with sustainability for resource-constrained organizations\nDevelop MCP integrations that connect Claude with mission-critical tools used by nonprofits, educators, healthcare workers, and researchers\nDevelop multilingual and accessibility capabilities across platforms\nBuild systems to measure and demonstrate social impact at scale\nPartner with product, partnerships, and field teams to rapidly prototype and validate solutions with real communities\nEnsure platform reliability and performance for mission-critical deployments in humanitarian and social impact contexts\nYou Might Be a Good Fit If You\nHave 6+ years of practical experience as a full-stack software engineer \nHave experience building consumer or enterprise products that prioritize accessibility, inclusivity, or served underserved populations\nHave technical expertise in identity management, billing systems, self-serve onboarding flows, or API integrations\nHave a builder mentality with ability to ship products quickly while maintaining quality for diverse user needs\nCare deeply about using technology for social good and want your engineering work to have meaningful impact\nHave excellent collaboration skills and can work effectively with product, partnerships, and field teams\nStrong Candidates May Also\nExperience with international markets, multilingual products, or accessibility features\nBackground in nonprofit technology, social impact startups, or mission-driven organizations\nExperience with AI/ML products and LLM applications\nFamiliarity with building products for resource-constrained environments or emerging markets\nUnderstanding of compliance requirements in regulated sectors\nStartup experience, particularly in scaling products from zero to one\nDeadline to apply: \nNone. Applications will be reviewed on a rolling basis.\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$320,000 - $405,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$320,000.00", "title": "Software Engineer, Beneficial Deployments", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4308875396", "loc": "New York, NY", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAnthropic is at the forefront of AI research, dedicated to developing safe, ethical, and powerful artificial intelligence. Our mission is to ensure that transformative AI systems are aligned with human interests. We are seeking a Research Engineer to join our Pre-training team, responsible for developing the next generation of large language models. In this role, you will work at the intersection of cutting-edge research and practical engineering, contributing to the development of safe, steerable, and trustworthy AI systems.\nKey Responsibilities\nConduct research and implement solutions in areas such as model architecture, algorithms, data processing, and optimizer development\nIndependently lead small research projects while collaborating with team members on larger initiatives\nDesign, run, and analyze scientific experiments to advance our understanding of large language models\nOptimize and scale our training infrastructure to improve efficiency and reliability\nDevelop and improve dev tooling to enhance team productivity\nContribute to the entire stack, from low-level optimizations to high-level model design\nQualifications\nAdvanced degree (MS or PhD) in Computer Science, Machine Learning, or a related field\nStrong software engineering skills with a proven track record of building complex systems\nExpertise in Python and experience with deep learning frameworks (PyTorch preferred)\nFamiliarity with large-scale machine learning, particularly in the context of language models\nAbility to balance research goals with practical engineering constraints\nStrong problem-solving skills and a results-oriented mindset\nExcellent communication skills and ability to work in a collaborative environment\nCare about the societal impacts of your work\nPreferred Experience\nWork on high-performance, large-scale ML systems\nFamiliarity with GPUs, Kubernetes, and OS internals\nExperience with language modeling using transformer architectures\nKnowledge of reinforcement learning techniques\nBackground in large-scale ETL processes\nYou'll Thrive In This Role If You\nHave significant software engineering experience\nAre results-oriented with a bias towards flexibility and impact\nWillingly take on tasks outside your job description to support the team\nEnjoy pair programming and collaborative work\nAre eager to learn more about machine learning research\nAre enthusiastic to work at an organization that functions as a single, cohesive team pursuing large-scale AI research projects\nAre working to align state of the art models with human values and preferences, understand and interpret deep neural networks, or develop new models to support these areas of research\nView research and engineering as two sides of the same coin, and seek to understand all aspects of our research program as well as possible, to maximize the impact of your insights\nHave ambitious goals for AI safety and general progress in the next few years, and you\u2019re working to create the best outcomes over the long-term.\nSample Projects\nOptimizing the throughput of novel attention mechanisms\nComparing compute efficiency of different Transformer variants\nPreparing large-scale datasets for efficient model consumption\nScaling distributed training jobs to thousands of GPUs\nDesigning fault tolerance strategies for our training infrastructure\nCreating interactive visualizations of model internals, such as attention patterns\nAt Anthropic, we are committed to fostering a diverse and inclusive workplace. We strongly encourage applications from candidates of all backgrounds, including those from underrepresented groups in tech.\nIf you're excited about pushing the boundaries of AI while prioritizing safety and ethics, we want to hear from you!\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$340,000 - $425,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$340,000.00", "title": "Research Engineer, Pre-training", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4269077909", "loc": "California, United States", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout Horizons\nThe Horizons team leads Anthropic's reinforcement learning research and development, playing a critical role in advancing our AI systems. We've contributed to all Claude models, with significant impacts on the autonomy and coding capabilities of Claude 3.5 and 3.7 Sonnet. Our work spans several key areas:\nDeveloping systems that enable models to use computers effectively\nAdvancing code generation through reinforcement learning\nPioneering fundamental RL research for large language models\nBuilding scalable RL infrastructure and training methodologies\nEnhancing model reasoning capabilities\nWe collaborate closely with Anthropic's alignment and frontier red teams to ensure our systems are both capable and safe. We partner with the applied production training team to bring research innovations into deployed models, and work hand-in-hand with dedicated RL engineering teams to implement our research at scale. The Horizons team sits at the intersection of cutting-edge research and engineering excellence, with a deep commitment to building high-quality, scalable systems that push the boundaries of what AI can accomplish.\nAbout The Role\nAs a Research Engineer on the Horizons team, you will collaborate with a diverse group of researchers and engineers to advance the capabilities and safety of large language models. This role blends research and engineering responsibilities, requiring you to both implement novel approaches and contribute to the research direction. You'll work on fundamental research in reinforcement learning, creating 'agentic' models via tool use for open-ended tasks such as computer use and autonomous software generation, improving reasoning abilities in areas such as mathematics, and developing prototypes for internal use, productivity, and evaluation.\nRepresentative Projects\nArchitect and optimize core reinforcement learning infrastructure, from clean training abstractions to distributed experiment management across GPU clusters. Help scale our systems to handle increasingly complex research workflows.\nDesign, implement, and test novel training environments, evaluations, and methodologies for reinforcement learning agents which push the state of the art for the next generation of models.\nDrive performance improvements across our stack through profiling, optimization, and benchmarking. Implement efficient caching solutions and debug distributed systems to accelerate both training and evaluation workflows.\nCollaborate across research and engineering teams to develop automated testing frameworks, design clean APIs, and build scalable infrastructure that accelerates AI research.\nYou May Be a Good Fit If You\nAre proficient in Python and async/concurrent programming with frameworks like Trio\nHave experience with machine learning frameworks (PyTorch, TensorFlow, JAX)\nHave industry experience in machine learning research\nCan balance research exploration with engineering implementation\nEnjoy pair programming (we love to pair!)\nCare about code quality, testing, and performance\nHave strong systems design and communication skills\nAre passionate about the potential impact of AI and are committed to developing safe and beneficial systems\nStrong Candidates May Have\nFamiliarity with LLM architectures and training methodologies\nExperience with reinforcement learning techniques and environments\nExperience with virtualization and sandboxed code execution environments\nExperience with Kubernetes\nExperience with distributed systems or high-performance computing\nExperience with Rust and/or C++\nStrong Candidates Need Not Have\nFormal certifications or education credentials\nAcademic research experience or publication history\nDeadline to apply: \nNone. Applications will be reviewed on a rolling basis.\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$280,000 - $425,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$280,000.00", "title": "Research Engineer, Machine Learning (Horizons)", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4307944000", "loc": "New York, NY", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Role\nWe're looking for experienced software engineers to join our Public Sector Engineering team as a key part of our Claude for Government initiative.\nThis role requires strong expertise in developing enterprise software solutions with exceptional security, compliance, and scalability standards. As an IC engineer on this team, you'll solve unique challenges at the intersection of AI, public sector workflows, and mission-critical applications.\nCore Responsibilities\nUnderstand public sector customer needs and translate them into technical and product solutions\nWork with legal and compliance teams to ensure all engineering practices meet government requirements\nDesign and implement infrastructure solutions that meet federal compliance requirements (FedRAMP High, IL5, etc.)\nDevelop automated compliance tooling and monitoring for government-specific security controls\nDevelop MCP integrations while maintaining strict security boundaries\nCreate identity management solutions, including SSO integration and role-based access controls\nImplement security features such as audit logs, encryption, and compliance frameworks\nDesign and build scalable systems for enterprise deployment, user management, and administrative controls\nYou Might Be a Good Fit If You\nHave 5+ years of practical experience as a software engineer\nHave a strong technical background in fullstack product work\nHave experience with identity management, SSO integration, and enterprise security standards\nHave experience with government compliance frameworks\nHave excellent collaboration skills, with ability to work effectively across functions\nHave a track record of delivering high-quality, scalable software in production environments\nStrong Candidates May Also Have\nExperience with multi-tenant architecture and enterprise deployment models\nStartup experience, particularly in scaling products from zero to one\nExperience partnering with sales and customer success teams\nExperience delivering software to government networks\nActive federal security clearance (Secret or above)\nThis position requires verification of U.S. citizenship due to citizenship-based legal restrictions. Specifically, this position supports a United States federal, state, and/or local government agency customer and is subject to certain citizenship-based restrictions where required or permitted by applicable law. To meet this legal requirement, citizenship will be verified via a valid passport, or other approved documents, or verified US government clearance.\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$320,000 - $485,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$320,000.00", "title": "Software Engineer, Public Sector", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4299669489", "loc": "Greater Syracuse-Auburn Area", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Role\nAs a Research Engineer/Scientist within the newly formed Model Welfare program, you will be among the first to work to better understand, evaluate, and address concerns about the potential welfare and moral status of AI systems. You are curious about the intersection of machine learning, ethics, and safety and are adept at navigating technical and philosophical uncertainty. You\u2019ll run technical research projects to investigate model characteristics of plausible relevance to welfare, consciousness, or related properties and will design and implement low-cost interventions to mitigate the risk of welfare harms. Your work will often involve collaboration with other teams, including Interpretability, Finetuning, Alignment Science, and Safeguards.\nOur announcement of the model welfare program, and our welfare assessment of Claude Opus 4 (published in the System Card) give a sense of some of our early work.\nNote: We expect this role to be based in the San Francisco office.\nPossible projects\nInvestigate and improve the reliability of introspective self-reports from models\nCollaborate with Interpretability to explore potentially welfare-relevant features and circuits\nImprove and expand our welfare assessments for future frontier models\nEvaluate the presence of potentially welfare-relevant capabilities and characteristics as a function of model scale\nDevelop strategies for making high-trust/verifiable commitments to models\nExplore possible interventions and deploy them into production (e.g. allowing models to end harmful or distressing interactions)\nYou may be a good fit if you\u2026\nHave significant applied software, ML, or research engineering experience\nHave experience contributing to empirical AI research projects and/or technical AI safety research\nCan reliably turn abstract theories into creative, tractable research hypotheses and experiments\nPrefer to move fast and iterate rather than run long extensive projects\nAre excited to dive into new technical areas on a regular basis\nCare about the possible impacts of AI development on humans and the AI systems themselves\nStrong candidates may also\u2026\nHave authored research papers in machine learning, NLP, AI safety, interpretability, and/or LLM psychology and behavior\nBe familiar with moral philosophy, cognitive science, neuroscience, or related fields (however, such experience will not substitute for technical research engineering skills)\nBe effective science communicators with a track record of public communication\nHave strong project management skills\nCandidates Need Not Have\n100% of the skills needed to perform the job\nFormal certifications or education credentials (please ignore the education requirements below the Logistics heading)\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$315,000 - $340,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$315,000.00", "title": "Research Engineer / Scientist, Model Welfare", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4271546376", "loc": "San Francisco, CA", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Team\nThe Tool Use team within Research is responsible for making Claude the world's most capable, reliable, safe, and efficient model for tool use and agentic applications. The team focuses on the foundational layer - solving core problems such as tool call accuracy, long horizon & complex tool use workflow, large scale & dynamic tools, tool hallucination, tool use safety (e.g. prompt injection robustness), and tool use efficiency. These are foundations to the majority of Anthropic\u2019s customers as well as internal teams building specific agentic capabilities such as coding (including Claude Code), search & deep research, memory, and multi-agents.\nNote: We are currently prioritising growing this team's safety efforts. However, we are leaving this form open as an expression of interest since we expect to be growing the rest of the team in the future, and we will review your application when we do. \nAbout The Role\nWe're looking for Research Engineers/Scientists to help us advance the frontier of tool use research. Today's AI agents handle impressive workflows. With tool use adoption accelerating rapidly across our platform, the next generation requires even more breakthrough research: for example, enabling models to reliably orchestrate vast tool ecosystems, maintain safety in autonomous operations, and scale to handle the increasing complexity of real-world tasks.\nYou'll collaborate with a diverse group of researchers and engineers to advance Claude's tool use capabilities and safety. You'll own the full research lifecycle\u2014from identifying fundamental limitations to implementing solutions that ship in production models. We value diverse perspectives and exceptional depth in specific areas\u2014whether that's groundbreaking RL research, exceptional engineering, or novel approaches from other quantitative fields.\nNote: For this role, we conduct all interviews in Python.\nResponsibilities\nDefine and pursue research agendas that push the boundaries of what's possible\n Design and implement novel reinforcement learning environments and methodologies that push the state of the art of tool use\nBuild rigorous, realistic evaluations that capture the complexity of real-world tool use\nShip research advances that directly impact millions of users\nCollaborate with other frontier research and product teams to drive fundamental breakthroughs in capabilities and safety, and work with teams to ship these into production\nDesign, implement, and debug code across our research and production ML stacks\nContribute to our collaborative research culture through pair programming, technical discussions, and team problem-solving\nYou May Be a Good Fit If You\nAre driven by real-world impact and excited to see research ship in production\nHave strong machine learning research/applied-research experience, or a strong quantitative background such as physics, mathematics, or quant research\nWrite clean, reliable code and have solid software engineering skills\nCommunicate complex ideas clearly to diverse audiences\nAre passionate about building AI systems that are both powerful and safe\nAre hungry to learn and grow, regardless of years of experience\nStrong candidates may also have one or more of the following:\nExperience with reinforcement learning techniques and environments\nExperience with language model training, fine-tuning or evaluation\nExperience building AI agents or autonomous systems\nPublished influential work in relevant ML areas\nDeep expertise in a specific area (e.g., exceptional RL research, systems engineering, or mathematical foundations) even if still developing in other areas\nExperience shipping features or working closely with product teams\nEnthusiasm for pair programming and collaborative research\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$315,000 - $425,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$315,000.00", "title": "[Expression of Interest] Research Engineer / Scientist, Tool Use", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4274351121", "loc": "Seattle, WA", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Role\nAnthropic is looking for an empathetic engineer to build internal tools that enable and increase productivity for our employees, including scenarios for fraud, trust & safety, sales, and support teams, as well as the platforms and data pipelines that power them. You'll collaborate closely with internal users to understand needs and create efficient solutions, often augmenting the tools with Claude for a greater experience and impact. On the Business Technology team, we are passionate about delighting and enabling our users through thoughtful and easy-to-use everyday solutions.\nAt Anthropic, we're building towards an ambitious mission of ensuring AI systems are safe and beneficial to humanity. Our team plays a crucial role in this mission by enabling our teams to work efficiently and securely at scale.\nWe have multiple roles open on this team and are looking for experienced engineers at different stages in their career who are excited about this space and our mission.\nResponsibilities\nRapidly design, prototype and build full-stack internal tools for business-critical use cases\nConsult with different teams to deeply understand their workflows and identify opportunities for improved productivity through engineering\nIterate rapidly based on user feedback to continuously improve our tools\nCreate intuitive interfaces that make complex tasks simple and efficient\nMonitor system reliability, build for operational excellence, and lead incident response when issues arise\nChampion best practices in API design, security, and user experience\nYou May Be a Good Fit If You\nHave 6-10 years experience building production, full-stack software with a focus on usability\nHave experience building and maintaining scalable internal applications and platforms\nExcel at modern web development (React, TypeScript, Node.js, Python)\nBring strong experience with cloud technologies and services (AWS/GCP/Azure)\nDemonstrate a focus on reliability and iterative improvement\nCommunicate with empathy and strive to understand user needs\nStrong Candidates May Also\nEnjoy collaborating cross-team and working with users to gain alignment on requirements and functionality\nHave experience implementing accessibility best practices to ensure products are usable and beneficial for all users\nHave experience balancing trade-offs while maintaining security, privacy, and reliability standards\nCoach and mentor other engineers\nHave experience anticipating changing business needs to create technical road maps\nHave experience with data pipelines\nDeadline to apply: \nNone. Applications will be reviewed on a rolling basis.\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$320,000 - $405,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$320,000.00", "title": "Software Engineer, Business Technology", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4186430074", "loc": "Seattle, WA", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Role\nWhen you look at the responses from today's leading language models, do you wonder, \"How do we align these systems with human values and preferences?\" or \u201cHow can we improve an LLM\u2019s abilities beyond what a human can achieve?\u201d\nThe Reward Modeling team at Anthropic is working to develop sophisticated techniques for teaching AI systems to understand and embody human values, as well as to push forward AI capabilities. We believe that robust reward models are critical to training AI systems that advance the frontier of safety and capabilities. We're looking for engineers to join our efforts to push forward the science of reward modeling\nNote: For this role, we conduct all interviews in Python. We have filled our headcount for 2025. However, we are leaving this form open as an expression of interest since we expect to be growing the team in the future, and we will review your application when we do. As such, you may not hear back on your application to this team until the new year\nResponsibilities\nHelp implement novel reward modeling architectures and techniques\nOptimize training pipelines\nBuild and optimize data pipelines\nCollaborate across teams to integrate reward modeling advances into production systems\nCommunicate engineering progress through internal documentation and potential publications\nYou May Be a Good Fit If You\nHave a strong engineering background in machine learning, with demonstrable expertise in preference learning, reinforcement learning, deep learning, or related areas\nAre proficient in Python, deep learning frameworks, and distributed computing\nAre familiar with modern LLM architectures and alignment techniques\nHave experience with improving model training pipelines and building data pipelines\nAre comfortable with the experimental nature of frontier AI research\nView research and engineering as complementary disciplines and are willing to implement some research ideas\nCan clearly communicate complex technical concepts and research findings\nHave a deep interest in AI alignment and safety\nProficiency in Python and experience with deep learning frameworks is required for this role\nExperience with reward models is not required, but experience with LLMs or other large models is a significant plus. We welcome candidates at various experience levels, with a preference for senior engineers who have hands-on experience with frontier AI systems.\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$315,000 - $340,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$315,000.00", "title": "[Expression of Interest] Research Engineer, Reward Models", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4195682205", "loc": "Seattle, WA", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Role\nWe are looking for ML engineers to help build safety and oversight mechanisms for our AI systems. As a Safeguards Machine Learning Engineer, you will work to train models which detect harmful behaviors and help ensure user well-being. You will apply your technical skills to uphold our principles of safety, transparency, and oversight while enforcing our terms of service and acceptable use policies.\nResponsibilities\nBuild machine learning models to detect unwanted or anomalous behaviors from users and API partners, and integrate them into our production system\nImprove our automated detection and enforcement systems as needed\nAnalyze user reports of inappropriate accounts and build machine learning models to detect similar instances proactively\nSurface abuse patterns to our research teams to harden models at the training stage\nYou May Be a Good Fit If You\nHave 4+ years of experience in a research/ML engineering or an applied research scientist position, preferably with a focus on AI safety.\nHave proficiency in Python, LLMs, SQL and data analysis/data mining tools.\nHave proficiency in building safe AI/ML systems, such as behavioral classifiers or anomaly detection.\nHave strong communication skills and ability to explain complex technical concepts to non-technical stakeholders.\nCare about the societal impacts and long-term implications of your work.\nStrong Candidates May Also Have Experience With\nMachine learning frameworks like Scikit-Learn, TensorFlow, or PyTorch\nHigh-performance, large-scale ML systems\nLanguage modeling with transformers\nReinforcement learning\nLarge-scale ETL\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$340,000 - $425,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$340,000.00", "title": "Machine Learning Engineer, Safeguards", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4186432032", "loc": "San Francisco, CA", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Role\nAs a Research Scientist/Engineer focused on honesty within the Finetuning Alignment team, you'll spearhead the development of techniques to minimize hallucinations and enhance truthfulness in language models. Your work will focus on creating robust systems that are accurate and reflect their true levels of confidence across all domains, and that work to avoid being deceptive or misleading. Your work will be critical for ensuring our models maintain high standards of accuracy and honesty across diverse domains.\nNote: The team is based in New York and so we have a preference for candidates who can be based in New York. \nFor this role, we conduct all interviews in Python. We have filled our headcount for 2025. However, we are leaving this form open as an expression of interest since we expect to be growing the team in the future, and we will review your application when we do. As such, you may not hear back on your application to this team until the new year\nResponsibilities\nDesign and implement novel data curation pipelines to identify, verify, and filter training data for accuracy given the model\u2019s knowledge\nDevelop specialized classifiers to detect potential hallucinations or miscalibrated claims made by the model\nCreate and maintain comprehensive honesty benchmarks and evaluation frameworks\nImplement techniques to ground model outputs in verified information, such as search and retrieval-augmented generation (RAG) systems\nDesign and deploy human feedback collection specifically for identifying and correcting miscalibrated responses\nDesign and implement prompting pipelines to generate data that improves model accuracy and honesty\nDevelop and test novel RL environments that reward truthful outputs and penalize fabricated claims\nCreate tools to help human evaluators efficiently assess model outputs for accuracy\nYou May Be a Good Fit If You\nHave an MS/PhD in Computer Science, ML, or related field\nPossess strong programming skills in Python\nHave industry experience with language model finetuning and classifier training\nShow proficiency in experimental design and statistical analysis for measuring improvements in calibration and accuracy\nCare about AI safety and the accuracy and honesty of both current and future AI systems\nHave experience in data science or the creation and curation of datasets for finetuning LLMs\nAn understanding of various metrics of uncertainty, calibration, and truthfulness in model outputs\nStrong Candidates May Also Have\nPublished work on hallucination prevention, factual grounding, or knowledge integration in language models\nExperience with fact-grounding techniques\nBackground in developing confidence estimation or calibration methods for ML models\nA track record of creating and maintaining factual knowledge bases\nFamiliarity with RLHF specifically applied to improving model truthfulness\nWorked with crowd-sourcing platforms and human feedback collection systems\nExperience developing evaluations of model accuracy or hallucinations\nJoin us in our mission to ensure advanced AI systems behave reliably and ethically while staying aligned with human values.\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$315,000 - $340,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$315,000.00", "title": "[Expression of Interest] Research Scientist/Engineer, Honesty", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4186426883", "loc": "San Francisco, CA", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Role\nAnthropic is looking for a product-minded engineer to build a world-class developer experience for the Anthropic API. You\u2019ll build the tools to accelerate developers from idea to deployment. In particular, you'll help figure out how to leverage Claude to improve developer's usage of the API, such as generating and evaluating prompts. You\u2019ll collaborate closely with other product teams to bring Claude's current and future capabilities to developers.\nWe have multiple roles open on this team and are looking for experienced engineers at different stages in their career who are excited about this space and our mission.\nResponsibilities\nBuild out the frontend and backend for helping developers bring their applications to production \nPartner with partner teams ensure sure new product features are integrated into the developer console in an intuitive way\nUse product sense to propose and implement improvements to the developer experience of using the API\nWork with researchers to understand new model capabilities and design unique products that help users maximize their use of the Anthropic API\nYou Might Be a Good Fit If You\nHave 7-10+ years building production full-stack software with a focus on usability\nHave strong communication skills and user empathy to understand needs\nAre an expert in modern web development stacks (React, Next.js, etc)\nHave demonstrated a strong product mindset and a focus on iterative product development\nStartup experience, building products from zero to one\nExperience building APIs and/or developer products for external developers\nStrong Candidates May Also\nHave experience with React and frontend frameworks\nHave experience with REST APIs\nHave experience building products for developers\nDeadline to apply: \nNone. Applications will be reviewed on a rolling basis.\nLocation Preference:\n Preference will be given to candidates based in the SF or SEA areas as these positions are part of an SF-based team.\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$320,000 - $405,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$320,000.00", "title": "Staff Software Engineer, API Product (Several Teams Hiring)", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4290829334", "loc": "San Francisco, CA", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Role\nAt Anthropic, we're building AI systems that are helpful, harmless, and honest. Our mission is to develop AI that benefits humanity, and we believe the most transformative capabilities emerge when we thoughtfully bridge the gap between research breakthroughs and real-world applications. Every new capability we develop has the potential to reshape how people work, learn, and create.\nFrontier Apps serves as Anthropic's innovation team, exploring how emerging AI capabilities can transform user experiences and unlock entirely new ways for people to interact with AI systems. Within Frontier Apps, the Frontier Prototyping team focuses on rapidly building and testing new user experiences to validate emerging capabilities and gather insights that advance our models.\nWe are seeking a versatile and collaborative Full Stack Engineer to join the Frontier Prototyping team. In this role, you will work closely with both customers and researchers to create innovative interfaces and interactions that unlock new model capabilities while gathering critical feedback. You'll be at the intersection of cutting-edge research and real-world application, building prototypes that shape the future of human-AI interaction.\nResponsibilities\nRapidly prototype full stack applications that showcase emerging AI capabilities in novel user experiences\nCollaborate closely with research teams to understand new model capabilities and translate them into intuitive user interfaces\nBuild and deploy prototypes for internal test users and external partners, shipping early and often to maximize learning\nWork directly with customers and early access partners to gather feedback, iterate quickly, and validate product concepts\nCoordinate across multiple teams at Anthropic to ensure prototypes integrate with existing infrastructure and capabilities\nAdvocate for user experience considerations in the research and development process\nProvide valuable feedback to research teams about the effectiveness of new model capabilities and where model quality can be improved\nGenerate insights and documentation to guide transition of successful prototypes to full product teams\nFlexibly contribute to various frontier initiatives based on organizational priorities and emerging opportunities\nYou Might Be a Good Fit If You\nHave 8+ years of experience building full stack applications with a focus on user experience and rapid iteration\nHave experience with rapid prototyping, including discarding prototypes and ending projects based on what you learn\nThrive in both startup-style zero-to-one environments and larger organizational settings\nHave strong technical skills across modern web development stacks (React, Node.js, Python, etc.)\nAre comfortable working with APIs, databases, and cloud technologies\nPossess strong communication skills and user empathy to translate complex AI capabilities into intuitive experiences\nAre results-oriented with a bias toward flexibility, impact, and continuous learning\nEnjoy collaborating closely with cross-functional teams including researchers, designers, and product managers\nPick up slack, even if it goes outside your job description\nWant exposure to cutting-edge AI research and its practical applications\nCare about the societal impacts and ethics of your work\nStrong Candidates May Also\nHave experience building products that involve AI/ML components or APIs\nHave worked with large language models or other AI technologies\nHave experience collaborating with research teams or researchers in AI/ML environments\nHave experience conducting user research, interviews, and usability testing\nHave experience with real-time applications and WebSocket implementations\nHave worked in customer-facing roles or directly with external partners\nHave experience with design systems and frontend component libraries\nHave background in both B2B and B2C product development\nHave developed products for a variety of audiences in multiple industries\nCandidates Need Not Have\n100% of the skills needed to perform the job\nFormal certifications or education credentials\nDirect machine learning or AI research experience\nDeadline to apply:\n None. Applications will be reviewed on a rolling basis.\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$405,000 - $485,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$405,000.00", "title": "Software Engineer, Frontier Prototyping", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4308529021", "loc": "San Francisco, CA", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Role\nThe Safeguards Research Team (part of the larger Alignment Science team) conducts critical safety research and engineering to ensure AI systems can be deployed safely. Our work is fundamental to Anthropic's ability to release advanced models\u2014without the safety systems we build, models like Claude Opus 4 simply couldn't be deployed. We're not just another ML team; we work at the frontier of AI safety, directly enabling Anthropic to fulfill its Responsible Scaling Policy commitments.\nAs a Machine Learning Engineer on our team, you'll bridge the gap between research and engineering, developing robust end-to-end pipelines and ML systems that directly support our safety initiatives. You'll work on building scalable infrastructure for evaluating safety systems, implementing efficient training pipelines for safeguards, and creating automated systems to help us understand and mitigate risks in advanced AI systems. Your applied ML engineering work will have immediate, measurable impact\u2014determining whether Anthropic can release its next generation of models while maintaining our safety guarantees.\nYou bring both ML fundamentals and strong engineering practices to the team. You're comfortable training and fine-tuning language models, have intuitions about hyperparameter optimization, and can implement efficient data processing pipelines. You take a pragmatic approach to ML engineering, preferring simple, effective solutions over complex ones. You'll collaborate closely with researchers to translate experimental concepts into production-quality ML systems that address both immediate safety challenges and support longer-term research initiatives.\nRepresentative Projects\nDesign and implement ML pipelines for training and evaluating safety classifiers and detection models\nBuild infrastructure for hyperparameter optimization and model selection across safety experiments\nCreate flexible interfaces and dashboards for researchers to interact with models and experimental setups\nCreate efficient data processing pipelines that can handle large-scale model outputs and training datasets\nDevelop tooling to automate the generation, analysis, and classification of jailbreak attempts\nYou May Be a Good Fit If You\nUnderstand fundamental ML concepts like overfitting and regularization\nHave practical experience with improving and evaluating ML models \nAre proficient with ML frameworks (e.g., PyTorch, TensorFlow, JAX) and can implement custom training loops\nHave strong software engineering skills, particularly with Python\nExcel at building scalable data pipelines, interpretable dashboards, and ML infrastructure\nAre experienced with prompting and working with large language models\nPrefer implementing simple, reliable solutions over complex ones\nAre comfortable working in a fast-paced, collaborative research environment\nCare deeply about the impacts of AI\nStrong Candidates May Also\nHave experience building systems that integrate with large language models\nHave worked on distributed computing systems or parallel processing\nHave implemented data processing pipelines at scale\nHave contributed to open-source machine learning or AI safety tools\nHave experience with cloud infrastructure and containerization\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$315,000 - $340,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$315,000.00", "title": "Machine Learning Systems Engineer, Safeguards Research", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4196434545", "loc": "San Francisco, CA", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Role\nWe're looking for experienced software engineers to join teams focused on automating vertical use cases using Claude, particularly in financial services and healthcare. The two teams currently hiring are:\nFinancial Services: From data retrieval and analysis to predictive intelligence and institutional-quality report generation, we are creating AI experiences that meet the unique standards of the world's largest financial institutions, including investment banks, hedge funds, and asset managers.\nHealthcare: From clinical documentation and prior authorization to care coordination, quality reporting, and patient management, these AI experiences need to balance solving critical challenges for healthcare systems, physicians, and patients while ensuring accuracy and compliance requirements.\nIn both teams, you will work closely with research, product, design, and go-to-market teams to deliver products that drive adoption and retention of Claude.\nCore Responsibilities\nDevelop deep understanding of critical workflows in these verticals and build novel AI solutions to address the needs of our most important customers\nDesign and build enterprise-grade products with high standards for security, reliability, and regulatory compliance\nDevelop features that enable Claude to learn from workflow patterns, market feedback loops, and process transformation data unique to these verticals\nWork closely with research teams, including post-training, to ensure Claude is uniquely capable of enabling complex workflows in these areas\nYou Might Be a Good Fit If You Have\n \n8+ years of experience as a product-minded software engineer, with experience building financial services or healthcare software applications\nFor Financial Services:\nExperience with financial data providers, trading systems, or other capital markets technology platforms\nTrack record of building systems that handle sensitive financial data and complex analytical workflows\nExperience with financial modeling, spreadsheet manipulation, or document generation systems\nFor Healthcare:\nExperience with clinical workflows or building products for handling health records and clinical documentation\nStrong communication skills and ability to work effectively across functions in a fast-moving environment\nStrong Candidates May Also Have\nExperience integrating and working with AI/ML models and understanding their capabilities, particularly for financial or healthcare use cases\nStartup experience, particularly in building products from zero to one\nDeadline to apply:\n None. Applications will be reviewed on a rolling basis.\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$320,000 - $485,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$320,000.00", "title": "Software Engineer, Verticals (Healthcare & Financial Services)", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4308283223", "loc": "New York, NY", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nRole Summary\nA systems-level engineer specializing in network infrastructure and network optimization, with expertise in building and maintaining software that interacts with networks. You will be responsible for writing and maintaining software that interfaces between our accelerators and our high-speed networks. This role requires deep technical knowledge of network protocols, kernel-space and/or user-space networks, interfacing with hardware, and the ability to debug and optimize distributed software at the network level.\nNetworking Systems Engineering\nYou may be a good fit if you have:\nExpert-level proficiency with network protocols and networking concepts\nDeep kernel networking: TCP/IP stack internals, XDP, eBPF, io_uring, and epoll\nUser-space networking: DPDK, RDMA, kernel bypass techniques\nUnderstanding of how to build higher-level abstractions like collectives and RPC\nSkilled at diagnosing and resolving networking issues in distributed systems, especially at OSI model layers 2-4\nLow-Level Systems And OS Programming\nStrong programming skills in a systems programming language, including memory management, lock-free data structures, and NUMA-aware programming\nSoftware, driver, and OS performance optimization tools and techniques\nComfort with or desire to learn Rust\nStrong Candidates May Have\nUnderstanding of ML accelerators and accelerator drivers\nDemonstrated ability to design new network protocols\nExperience with PCIe and drivers for PCIe devices\nExpertise in algorithms used in networking, including compression and graph algorithms\nExperience programming on SmartNICs\n5+ years of experience in systems programming or network programming\nOften comes from backgrounds in: HPC, telecommunications, host networking software, OS/kernel engineering, or embedded systems\nStrong debugging mindset with patience for complex, multi-layered issues\nRepresentative Projects\nBuild a system for accelerator-initiated tensor movement over the network\nBenchmark software for a new networking environment\nImplement a new collective algorithm to improve latency\nOptimize congestion control algorithms for large-scale synchronous workloads\nDebug kernel-level network latency spikes\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$315,000 - $560,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$315,000.00", "title": "Software Engineer, ML Networking", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4304342307", "loc": "Seattle, WA", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Role\nAs a Research Engineer on the Model Performance team, you will help solve one of our greatest challenges: systematically understanding and monitoring model quality in real-time. This role blends research and engineering responsibilities, requiring you to train production models, develop robust monitoring systems, and create novel evaluation methodologies.\nNote: For this role, we conduct all interviews in Python.\nRepresentative Projects\nBuild comprehensive training observability systems - Design and implement monitoring infrastructure to keep an eye on how model behaviors evolve throughout training.\nDevelop next-generation evaluation frameworks - Move beyond traditional benchmarks to create evaluations that capture real-world utility. \nCreate automated quality assessment pipelines - Build custom classifiers to continuously monitor RL transcripts for complex issues\nBridge research and production - Partner with research teams to translate cutting-edge evaluation techniques into production-ready systems, and work with engineering teams to ensure our monitoring infrastructure scales with increasingly complex training workflows.\nYou May Be a Good Fit If You\nAre proficient in Python and have experience building production ML systems\nHave experience with training, evaluating, or monitoring large language models\nAre energized by the high stakes and intensity of production training, and ready to jump in wherever needed. \nAre naturally curious about debugging complex, distributed systems and thinking about failure modes\nEnjoy collaborative problem-solving and working across diverse teams - you\u2019ll work on virtually all stages of our model training pipeline\nCan balance research exploration with engineering rigor.\nHave strong analytical skills for interpreting training metrics and model behavior\nWant to directly impact the quality and safety of deployed AI systems\nStrong Candidates May Have\nExperience with reinforcement learning and language model training pipelines\nExperience designing and implementing evaluation frameworks or benchmarks\nBackground in production monitoring, observability, and incident response\nExperience with statistical analysis and experimental design\nKnowledge of AI safety and alignment research\nStrong Candidates Need Not Have\nFormal certifications or education credentials\nAcademic research experience or publication history\nPrior experience in AI safety or evaluation specifically\nWe're looking for thoughtful engineers who are excited about the challenge of measuring and monitoring capabilities we're still discovering. This role offers the opportunity to shape how the field approaches model quality assessment while working on systems that will be critical as AI capabilities continue to advance.\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$315,000 - $340,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$315,000.00", "title": "Research Engineer, Model Performance & Quality", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4274352112", "loc": "Seattle, WA", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Role\nAnthropic's production models undergo sophisticated post-training processes to enhance their capabilities, alignment, and safety. As a Research Engineer on our Post-Training team, you'll train our base models through the complete post-training stack to deliver the production Claude models that users interact with.\nYou'll work at the intersection of cutting-edge research and production engineering, implementing, scaling, and improving post-training techniques like Constitutional AI, RLHF, and other alignment methodologies. Your work will directly impact the quality, safety, and capabilities of our production models.\nNote: For this role, we conduct all interviews in Python. This role may require responding to incidents on short-notice, including on weekends.\nResponsibilities\nImplement and optimize post-training techniques at scale on frontier models\nConduct research to develop and optimize post-training recipes that directly improve production model quality\nDesign, build, and run robust, efficient pipelines for model fine-tuning and evaluation\nDevelop tools to measure and improve model performance across various dimensions\nCollaborate with research teams to translate emerging techniques into production-ready implementations\nDebug complex issues in training pipelines and model behavior\nHelp establish best practices for reliable, reproducible model post-training\nYou May Be a Good Fit If You\nThrive in controlled chaos and are energised, rather than overwhelmed, when juggling multiple urgent priorities\nAdapt quickly to changing priorities\nMaintain clarity when debugging complex, time-sensitive issues\nHave strong software engineering skills with experience building complex ML systems\nAre comfortable working with large-scale distributed systems and high-performance computing\nHave experience with training, fine-tuning, or evaluating large language models\nCan balance research exploration with engineering rigor and operational reliability\nAre adept at analyzing and debugging model training processes\nEnjoy collaborating across research and engineering disciplines\nCan navigate ambiguity and make progress in fast-moving research environments\nStrong Candidates May Also\nHave experience with LLMs\nHave a keen interest in AI safety and responsible deployment\nWe welcome candidates at various experience levels, with a preference for senior engineers who have hands-on experience with frontier AI systems. However, proficiency in Python, deep learning frameworks, and distributed computing is required for this role.\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$315,000 - $340,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$315,000.00", "title": "Research Engineer, Production Model Post Training", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4195679376", "loc": "Seattle, WA", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Role\nYou want to build and run elegant and thorough machine learning experiments to help us understand and steer the behavior of powerful AI systems. You care about making AI helpful, honest, and harmless, and are interested in the ways that this could be challenging in the context of human-level capabilities. You could describe yourself as both a scientist and an engineer. As a Research Engineer on Alignment Science, you'll contribute to exploratory experimental research on AI safety, with a focus on risks from powerful future systems (like those we would designate as ASL-3 or ASL-4 under our Responsible Scaling Policy), often in collaboration with other teams including Interpretability, Fine-Tuning, and the Frontier Red Team.\nOur blog provides an overview of topics that the Alignment Science team is either currently exploring or has previously explored. Our current topics of focus include...\nScalable Oversight: Developing techniques to keep highly capable models helpful and honest, even as they surpass human-level intelligence in various domains.\nAI Control: Creating methods to ensure advanced AI systems remain safe and harmless in unfamiliar or adversarial scenarios.\nAlignment Stress-testing: Creating model organisms of misalignment to improve our empirical understanding of how alignment failures might arise.\nAutomated Alignment Research: Building and aligning a system that can speed up & improve alignment research.\nAlignment Assessments: Understanding and documenting the highest-stakes and most concerning emerging properties of models through pre-deployment alignment and welfare assessments (see our Claude 4 System Card), misalignment-risk safety cases, and coordination with third-party evaluators.\nSafeguards Research: Developing robust defenses against adversarial attacks, comprehensive evaluation frameworks for model safety, and automated systems to detect and mitigate potential risks before deployment.\nModel Welfare: Investigating and addressing potential model welfare, moral status, and related questions. See our program announcement and welfare assessment in the Claude 4 system card for more.\nNote: For this role, we conduct all interviews in Python and prefer candidates to be based in the Bay Area.\nRepresentative Projects\nTesting the robustness of our safety techniques by training language models to subvert our safety techniques, and seeing how effective they are at subverting our interventions.\nRun multi-agent reinforcement learning experiments to test out techniques like AI Debate.\nBuild tooling to efficiently evaluate the effectiveness of novel LLM-generated jailbreaks.\nWrite scripts and prompts to efficiently produce evaluation questions to test models\u2019 reasoning abilities in safety-relevant contexts.\nContribute ideas, figures, and writing to research papers, blog posts, and talks.\nRun experiments that feed into key AI safety efforts at Anthropic, like the design and implementation of our Responsible Scaling Policy.\nYou May Be a Good Fit If You\nHave significant software, ML, or research engineering experience\nHave some experience contributing to empirical AI research projects\nHave some familiarity with technical AI safety research\nPrefer fast-moving collaborative projects to extensive solo efforts\nPick up slack, even if it goes outside your job description\nCare about the impacts of AI\nStrong Candidates May Also\nHave experience authoring research papers in machine learning, NLP, or AI safety\nHave experience with LLMs\nHave experience with reinforcement learning\nHave experience with Kubernetes clusters and complex shared codebases\nCandidates Need Not Have\n100% of the skills needed to perform the job\nFormal certifications or education credentials\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$315,000 - $340,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$315,000.00", "title": "Research Engineer / Scientist, Alignment Science", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4208818324", "loc": "San Francisco, CA", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Role\nYou want to build the cutting-edge systems that train AI models like Claude. You're excited to work at the frontier of machine learning, implementing and improving advanced techniques to create ever more capable, reliable and steerable AI. As an ML Systems Engineer on our Reinforcement Learning Engineering team, you'll be responsible for the critical algorithms and infrastructure that our researchers depend on to train models. Your work will directly enable breakthroughs in AI capabilities and safety. You'll focus obsessively on improving the performance, robustness, and usability of these systems so our research can progress as quickly as possible. You're energized by the challenge of supporting and empowering our research team in the mission to build beneficial AI systems.\nOur finetuning researchers train our production Claude models, and internal research models, using RLHF and other related methods. Your job will be to build, maintain, and improve the algorithms and systems that these researchers use to train models. You\u2019ll be responsible for improving the speed, reliability, and ease-of-use of these systems.\nYou May Be a Good Fit If You\nHave 4+ years of software engineering experience\nLike working on systems and tools that make other people more productive\nAre results-oriented, with a bias towards flexibility and impact\nPick up slack, even if it goes outside your job description\nEnjoy pair programming (we love to pair!)\nWant to learn more about machine learning research\nCare about the societal impacts of your work\nStrong Candidates May Also Have Experience With\nHigh performance, large scale distributed systems\nLarge scale LLM training\nPython\nImplementing LLM finetuning algorithms, such as RLHF\nRepresentative Projects\nProfiling our reinforcement learning pipeline to find opportunities for improvement\nBuilding a system that regularly launches training jobs in a test environment so that we can quickly detect problems in the training pipeline\nMaking changes to our finetuning systems so they work on new model architectures\nBuilding instrumentation to detect and eliminate Python GIL contention in our training code\nDiagnosing why training runs have started slowing down after some number of steps, and fixing it\nImplementing a stable, fast version of a new training algorithm proposed by a researcher\nDeadline to apply: \nNone. Applications will be reviewed on a rolling basis.\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$300,000 - $405,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$300,000.00", "title": "Machine Learning Systems Engineer, RL Engineering", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4186425953", "loc": "San Francisco, CA", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Role\nAccounts Platform: \nWe build and maintain the critical infrastructure that powers identity and authentication across Anthropic's product suite. We work closely with product teams, security, support, and trust & safety as customers. We create scalable solutions for user authentication, authorization, role-based access control, and single sign-on that form the backbone of our company's identity management operations. We maintain a user-centric approach, building reliable systems that our users and company can depend on as we tackle complex challenges at the intersection of security, scalability, and user experience.\nResponsibilities\nBuild and scale platform components to handle Anthropic\u2019s rapid growth\nDesign and architect platform components that are composable and deliver value for a variety of use cases\nCollaborate closely with product teams to understand their needs and build platform capabilities that accelerate their feature delivery\nMake build vs buy decisions, evaluating and implementing 3rd party solutions when most impactful\nSet technical direction and vision for various product and platform features\nPartner with research to quickly prototype and launch new capabilities based on research breakthroughs\nYou Might Be a Good Fit If You\nHave 6+ years of practical experience as a backend or platform engineer building scalable distributed systems \nHave strong coding skills and experience with service-oriented architectures\nHave worked in early start-up or otherwise fast moving, rapidly evolving environments, and have ideally built products from 0 to 1 \nTake full ownership of your work, navigate ambiguity effectively, and proactively overcome obstacles to deliver results\nAre comfortable diving into any part of the system, whether it's infrastructure, services, or product frontends, to deliver effective solutions\nEnjoy working with a fast-paced team tackling cutting-edge problems in AI safety and conversational AI\nTake a product-focused approach and care about building solutions that are robust, scalable, and easy to use\nEnjoy pair programming (we love to pair!)\nHave a Bachelor\u2019s degree in Computer Science, Software Engineering or comparable experience\nStrong Candidates May Also\nHave worked with NLP and ML models and understand their capabilities and limitations\nHave experience with REST APIs\nHave experience with React and Frontend frameworks\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$320,000 - $405,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$320,000.00", "title": "Staff Software Engineer, Accounts Platform", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4186429255", "loc": "New York, NY", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Role\nYou want to build the cutting-edge systems that train AI models like Claude. You're excited to work at the frontier of machine learning, implementing and improving advanced techniques to create ever more capable, reliable and steerable AI. As an ML Systems Engineer on our Research Tools team, you'll be responsible for the critical algorithms and infrastructure that our researchers depend on to train models. Your work will directly enable breakthroughs in AI capabilities and safety. You'll focus obsessively on improving the performance, robustness, and usability of these systems so our research can progress as quickly as possible. You're energized by the challenge of supporting and empowering our research team in the mission to build beneficial AI systems.\nOur finetuning researchers train our production Claude models, and internal research models, using RLHF and other related methods. Your job will be to build, maintain, and improve the algorithms and systems that these researchers use to train models. You\u2019ll be responsible for improving the speed, reliability, and ease-of-use of these systems.\nYou May Be a Good Fit If You\nHave 2+ years of software engineering experience\nLike working on systems and tools that make other people more productive\nAre results-oriented, with a bias towards flexibility and impact\nPick up slack, even if it goes outside your job description\nEnjoy pair programming (we love to pair!)\nWant to learn more about machine learning research\nCare about the societal impacts of your work\nStrong Candidates May Also Have Experience With\nHigh performance, large scale distributed systems\nKubernetes\nPython\nImplementing LLM finetuning algorithms, such as RLHF\nRepresentative Projects\nProfiling our reinforcement learning pipeline to find opportunities for improvement\nBuilding a system that regularly launches training jobs in a test environment so that we can quickly detect problems in the training pipeline\nMaking changes to our finetuning systems so they work on new model architectures\nBuilding instrumentation to detect and eliminate Python GIL contention in our training code\nDiagnosing why training runs have started slowing down after some number of steps, and fixing it\nImplementing a stable, fast version of a new training algorithm proposed by a researcher\nDeadline to apply: \nNone. Applications will be reviewed on a rolling basis.\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$300,000 - $405,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$300,000.00", "title": "Machine Learning Systems Engineer, Research Tools", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4271861096", "loc": "New York, NY", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Role\nAs a Research Scientist/Engineer on the Alignment Finetuning team at Anthropic, you'll lead the development and implementation of techniques aimed at training language models that are more aligned with human values: that demonstrate better moral reasoning, improved honesty, and good character. You'll work to develop novel finetuning techniques and to use these to demonstrably improve model behavior.\nNote: For this role, we conduct all interviews in Python. We have filled our headcount for 2025. However, we are leaving this form open as an expression of interest since we expect to be growing the team in the future, and we will review your application when we do. As such, you may not hear back on your application to this team until the new year\nResponsibilities\nDevelop and implement novel finetuning techniques using synthetic data generation and advanced training pipelines\nUse these to train models to have better alignment properties including honesty, character, and harmlessness\nCreate and maintain evaluation frameworks to measure alignment properties in models\nCollaborate across teams to integrate alignment improvements into production models\nDevelop processes to help automate and scale the work of the team\nYou May Be a Good Fit If You\nHave an MS/PhD in Computer Science, ML, or related field, or equivalent experience\nPossess strong programming skills, especially in Python\nHave experience with ML model training and experimentation\nHave a track record of implementing ML research\nDemonstrate strong analytical skills for interpreting experimental results\nHave experience with ML metrics and evaluation frameworks\nExcel at turning research ideas into working code\nCan identify and resolve practical implementation challenges\nStrong Candidates May Also Have\nExperience with language model finetuning\nBackground in AI alignment research\nPublished work in ML or alignment\nExperience with synthetic data generation\nFamiliarity with techniques like RLHF, constitutional AI, and reward modeling\nTrack record of designing and implementing novel training approaches\nExperience with model behavior evaluation and improvement\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$315,000 - $340,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$315,000.00", "title": "[Expression of Interest] Research Scientist/Engineer, Alignment Finetuning", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4186431049", "loc": "San Francisco, CA", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Role\nAs a TPU Kernel Engineer, you'll be responsible for identifying and addressing performance issues across many different ML systems, including research, training, and inference. A significant portion of this work will involve designing and optimizing kernels for the TPU. You will also provide feedback to researchers about how model changes impact performance. Strong candidates will have a track record of solving large-scale systems problems and low-level optimization.\nYou May Be a Good Fit If You\nHave significant experience optimizing ML systems for TPUs, GPUs, or other accelerators\nAre results-oriented, with a bias towards flexibility and impact\nPick up slack, even if it goes outside your job description\nEnjoy pair programming (we love to pair!)\nWant to learn more about machine learning research\nCare about the societal impacts of your work\nStrong Candidates May Also Have Experience With\nHigh performance, large-scale ML systems\nDesigning and implementing kernels for TPUs or other ML accelerators\nUnderstanding accelerators at a deep level, e.g. a background in computer architecture\nML framework internals\nLanguage modeling with transformers\nRepresentative Projects\nImplement low-latency, high-throughput sampling for large language models\nAdapt existing models for low-precision inference\nBuild quantitative models of system performance\nDesign and implement custom collective communication algorithms\nDebug kernel performance at the assembly level\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$280,000 - $560,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$280,000.00", "title": "TPU Kernel Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4233503439", "loc": "Seattle, WA", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Role\nWhen you see what modern language models are capable of, do you wonder, \"How do these things work? How can we trust them?\"\nThe Interpretability team at Anthropic is working to reverse-engineer how trained models work because we believe that a mechanistic understanding is the most robust way to make advanced systems safe. We\u2019re looking for researchers and engineers to join our efforts.\nPeople mean many different things by \"interpretability\". We're focused on mechanistic interpretability, which aims to discover how neural network parameters map to meaningful algorithms. Some useful analogies might be to think of us as trying to do \"biology\" or \"neuroscience\" of neural networks using \u201cmicroscopes\u201d we build, or as treating neural networks as binary computer programs we're trying to \"reverse engineer\".\nA few places to learn more about our work and team at a high level are this introduction to Interpretability from our research lead, Chris Olah; a discussion of our work on the Hard Fork podcast produced by the New York Times, and this blog post (and accompanying video) sharing more about some of the engineering challenges we\u2019d had to solve to get these results. Some of our team's notable publications include A Mathematical Framework for Transformer Circuits, In-context Learning and Induction Heads, Toy Models of Superposition, Scaling Monosemanticity, and our Circuits\u2019 Methods and Biology papers. This work builds on ideas from members' work prior to Anthropic such as the original circuits thread, Multimodal Neurons, Activation Atlases, and Building Blocks.\nWe aim to create a solid foundation for mechanistically understanding neural networks and making them safe (see our vision post). In the short term, we have focused on resolving the issue of \"superposition\" (see Toy Models of Superposition, Superposition, Memorization, and Double Descent, and our May 2023 update), which causes the computational units of the models, like neurons and attention heads, to be individually uninterpretable, and on finding ways to decompose models into more interpretable components. Our subsequent work found millions of features in Sonnet, one of our production language models, represents progress in this direction. In our most recent work, we develop methods that allow us to build circuits using features and use this circuits to understand the mechanisms associated with a model's computation and study specific examples of multi-hop reasoning, planning, and chain-of-thought faithfulness on Haiku 3.5, one of our production models.\u201d This is a stepping stone towards our overall goal of mechanistically understanding neural networks.\nWe often collaborate with teams across Anthropic, such as Alignment Science and Societal Impacts to use our work to make Anthropic\u2019s models safer. We also have an Interpretability Architectures project that involves collaborating with Pretraining.\nResponsibilities\nImplement and analyze research experiments, both quickly in toy scenarios and at scale in large models\nSet up and optimize research workflows to run efficiently and reliably at large scale\nBuild tools and abstractions to support rapid pace of research experimentation\nDevelop and improve tools and infrastructure to support other teams in using Interpretability\u2019s work to improve model safety\nYou May Be a Good Fit If You\nHave 5-10+ years of experience building software\nAre highly proficient in at least one programming language (e.g., Python, Rust, Go, Java) and productive with python\nHave some experience contributing to empirical AI research projects\nHave a strong ability to prioritize and direct effort toward the most impactful work and are comfortable operating with ambiguity and questioning assumptions.\nPrefer fast-moving collaborative projects to extensive solo efforts\nWant to learn more about machine learning research and its applications and collaborate closely with researchers\nCare about the societal impacts and ethics of your work\nStrong Candidates May Also Have Experience With\nDesigning a code base so that anyone can quickly code experiments, launch them, and analyze their results without hitting bugs\nOptimizing the performance of large-scale distributed systems\nCollaborating closely with researchers\nLanguage modeling with transformers\nGPUs or Pytorch\nRepresentative Projects\nBuilding Garcon, a tool that allows researchers to easily access LLMs internals from a jupyter notebook\nSetting up and optimizing a pipeline to efficiently collect petabytes of transformer activations and shuffle them.\nProfiling and optimizing ML training, including parallelizing to many GPUs\nMake launching ML experiments and manipulating+analyzing the results fast and easy\nCreating an interactive visualization of attention between tokens in a language model\nRole Specific Location Policy:\nThis role is based in San Francisco office; however, we are open to considering exceptional candidates for remote work on a case-by-case basis.\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$315,000 - $560,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$315,000.00", "title": "Research Engineer, Interpretability", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4186427431", "loc": "San Francisco, CA", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Team\nThe Tool Use Team within Research is responsible for making Claude the world's most capable, safe, reliable, and efficient model for tool use and agentic applications. The team focuses on the foundational layer - solving core problems such as tool use safety (e.g. prompt injection robustness), tool call accuracy, long horizon & complex tool use workflow, large scale & dynamic tools, and tool use efficiency. These are foundations to the majority of Anthropic\u2019s customers as well as internal teams building specific agentic applications such as Claude for Chrome, Computer Use, Claude Code, Search.\nAbout The Role\nWe're looking for Research Engineers/Scientists to help us advance the frontier of safe tool use. With tool use adoption accelerating rapidly across our platform, the next generation requires even more breakthrough research to enable us to scale responsibly: for example, training Claude to be extremely robust against sophisticated prompt injection, preventing data exfiltration attempts through tool misuse, defending against adversarial attacks in realistic multi-turn agent conversations, and ensuring safety when agents operate autonomously for longer horizons with access to a large number of tools.\nYou'll collaborate with a diverse group of researchers and engineers to advance safe tool use in Claude. You'll own the full research lifecycle\u2014from identifying fundamental limitations to implementing solutions that ship in production models. This work is critical for derisking our model\u2019s increasing capabilities and empowering Claude to more autonomously assist users.\nNote: For this role, we conduct all interviews in Python.\nResponsibilities\n Design and implement novel and scalable reinforcement learning methodologies that push the state of the art of tool use safety\nDefine and pursue research agendas that push the boundaries of what's possible\nBuild rigorous, realistic evaluations that capture the complexity of real-world tool use safety challenges\nShip research advances that directly impact and protect millions of users\nCollaborate with other safety research (e.g. Safeguards, Alignment Science), capabilities research, and product teams to drive fundamental breakthroughs in safety, and work with teams to ship these into production\nDesign, implement, and debug code across our research and production ML stacks\nContribute to our collaborative research culture through pair programming, technical discussions, and team problem-solving\nYou May Be a Good Fit If You\nPassionate about our safety mission\nAre driven by real-world impact and excited to see research ship in production\nHave strong machine learning research/applied-research experience, or a strong quantitative background such as physics, mathematics, or quantitative finance research\nWrite clean, reliable code and have solid software engineering skills\nCommunicate complex ideas clearly to diverse audiences\nAre hungry to learn and grow, regardless of years of experience\nStrong candidates may also have one or more of the following:\nExperience with tool use/agentic safety, trust & safety, or security\nExperience with reinforcement learning techniques and environments\nExperience with language model training, fine-tuning or evaluation\nExperience building AI agents or autonomous systems \nPublished influential work in relevant ML areas, especially around LLM safety & alignment\nDeep expertise in a specialized area (e.g., RL, security, or mathematical foundations), even if still developing breadth in adjacent areas\nExperience shipping features or working closely with product teams\nEnthusiasm for pair programming and collaborative research\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$315,000 - $425,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$315,000.00", "title": "Research Engineer / Scientist, Tool Use Safety", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4305403576", "loc": "New York, NY", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Role\nRunning machine learning (ML) algorithms at our scale often requires solving novel systems problems. As a Performance Engineer, you'll be responsible for identifying these problems, and then developing systems that optimize the throughput and robustness of our largest distributed systems. Strong candidates here will have a track record of solving large-scale systems problems and will be excited to grow to become an expert in ML also.\nYou May Be a Good Fit If You\nHave significant software engineering or machine learning experience, particularly at supercomputing scale\nAre results-oriented, with a bias towards flexibility and impact\nPick up slack, even if it goes outside your job description\nEnjoy pair programming (we love to pair!)\nWant to learn more about machine learning research\nCare about the societal impacts of your work\nStrong Candidates May Also Have Experience With\nHigh performance, large-scale ML systems\nGPU/Accelerator programming\nML framework internals\nOS internals\nLanguage modeling with transformers\nRepresentative Projects\nImplement low-latency high-throughput sampling for large language models\nImplement GPU kernels to adapt our models to low-precision inference\nWrite a custom load-balancing algorithm to optimize serving efficiency\nBuild quantitative models of system performance\nDesign and implement a fault-tolerant distributed system running with a complex network topology\nDebug kernel-level network latency spikes in a containerized environment\nDeadline to apply: \nNone. Applications will be reviewed on a rolling basis.\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$315,000 - $560,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$315,000.00", "title": "Performance Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4186431053", "loc": "Seattle, WA", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Role:\nPioneering the next generation of AI requires breakthrough innovations in GPU performance and systems engineering. As a GPU Performance Engineer, you'll architect and implement the foundational systems that power Claude and push the frontiers of what's possible with large language models. You'll be responsible for maximizing GPU utilization and performance at unprecedented scale, developing cutting-edge optimizations that directly enable new model capabilities and dramatically improve inference efficiency.\nWorking at the intersection of hardware and software, you'll implement state-of-the-art techniques from custom kernel development to distributed system architectures. Your work will span the entire stack\u2014from low-level tensor core optimizations to orchestrating thousands of GPUs in perfect synchronization.\nStrong candidates will have a track record of delivering transformative GPU performance improvements in production ML systems and will be excited to shape the future of AI infrastructure alongside world-class researchers and engineers.\nYou Might Be a Good Fit If You:\nHave deep experience with GPU programming and optimization at scale\nAre impact-driven, passionate about delivering measurable performance breakthroughs\nCan navigate complex systems from hardware interfaces to high-level ML frameworks\nEnjoy collaborative problem-solving and pair programming\nWant to work on state-of-the-art language models with real-world impact\nCare about the societal impacts of your work\nThrive in ambiguous environments where you define the path forward\nStrong Candidates May Also Have Experience With:\nGPU Kernel Development: CUDA, Triton, CUTLASS, Flash Attention, tensor core optimization\nML Compilers & Frameworks: PyTorch/JAX internals, torch.compile, XLA, custom operators\nPerformance Engineering: Kernel fusion, memory bandwidth optimization, profiling with Nsight\nDistributed Systems: NCCL, NVLink, collective communication, model parallelism\nLow-Precision: INT8/FP8 quantization, mixed-precision techniques\nProduction Systems: Large-scale training infrastructure, fault tolerance, cluster orchestration\nRepresentative Projects:\nCo-design attention mechanisms and algorithms for next-generation hardware architectures\nDevelop custom kernels for emerging quantization formats and mixed-precision techniques\nDesign distributed communication strategies for multi-node GPU clusters\nOptimize end-to-end training and inference pipelines for frontier language models\nBuild performance modeling frameworks to predict and optimize GPU utilization\nImplement kernel fusion strategies to minimize memory bandwidth bottlenecks\nCreate resilient systems for planet-scale distributed training infrastructure\nProfile and eliminate performance bottlenecks in production serving infrastructure\nPartner with hardware vendors to influence future accelerator capabilities and software stacks\nDeadline to apply:\n None. Applications will be reviewed on a rolling basis.\nAnnual Salary:\nThe expected salary range for this position is:\n$315,000 - $560,000 USD\nLogistics\nEducation requirements:\n We require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow we're different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. Guidance on\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary:\n$315,000 - $560,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$315,000.00", "title": "Performance Engineer - GPU", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4303692444", "loc": "Seattle, WA", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Team\nOur team is organized around the north star goal of building an AI scientist \u2013 a system capable of solving the long term reasoning challenges and basic capabilities necessary to push the scientific frontier. Our team likes to think across the whole model stack. Currently the team is focused on improving models' abilities to use computers \u2013 as a laboratory for long horizon tasks and a key blocker to many scientific workflows.\nAbout The Role\nAs a Research Engineer on our team you will work end to end, identifying and addressing key blockers on the path to scientific AGI. Strong candidates should have familiarity with language model training, evaluation, and inference, be comfortable triaging research ideas and diagnosing problems and enjoy working collaboratively. Familiarity with performance optimization, distributed systems, vm/sandboxing/container deployment, and large scale data pipelines is highly encouraged.\nJoin us in our mission to develop advanced AI systems that are both powerful and beneficial for humanity.\nResponsibilities\nWorking across the full stack to identify and remove bottlenecks preventing progress toward scientific AGI\nDevelop approaches to address long-horizon task completion and complex reasoning challenges essential for scientific discovery\nScaling research ideas from prototype to production\nCreate benchmarks and evaluation frameworks to measure model capabilities in scientific workflows and computer use\nImplement distributed training systems and performance optimizations to support large-scale model development\nYou May Be a Good Fit If You\nHave 8+ years of ML research experience\nAre familiar with large scale language model training, evaluation, and inference pipelines\nEnjoy obsessively iterating on immediate blockers towards longterm goals\nThrive working collaboratively to solve problems\nHave expertise in performance optimization and distributed computing systems\nShow strong problem-solving skills and ability to identify technical bottlenecks in complex systems\nCan translate research concepts into scalable engineering solutions\nHave a track record of shipping ML systems that tackle challenging multi-step reasoning problems\nStrong Candidates May Also Have\nExpertise with performance optimization for language model inference and training\nExperience with computer use automation and agentic AI systems\nA history working on reinforcement learning approaches for complex task completion\nKnowledge of containerization technologies (Docker, Kubernetes) and cloud deployment at scale\nDemonstrated ability to work across multiple domains (language modeling, systems engineering, scientific computing)\nHave experience with VM/sandboxing/container deployment and large-scale data processing\nExperience working with large scale data problem solving and infrastructure\nPublished research or practical experience in scientific AI applications or long-horizon reasoning\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$340,000 - $425,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$340,000.00", "title": "Staff Research Engineer, Discovery Team", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4214156729", "loc": "San Francisco, CA", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAt Anthropic, we are pioneering new frontiers in AI that have the potential to greatly benefit society. However, developing advanced AI also comes with risks if not properly safeguarded. That's why we are seeking an exceptional Detection and Response engineer that will be on the frontlines to build solutions to monitor for threats, rapidly investigate incidents, and coordinate response efforts with other teams. In this role, you will have the opportunity to shape our security capabilities from the ground up alongside our world-class research and security teams.\nResponsibilities\nLead cybersecurity Incident Response efforts covering diverse domains from external attacks to insider threats involving all layers of Anthropic\u2019s technology stack\nDevelop and deploy novel tooling that may leverage Large Language Models to enhance detection, investigation, and response capabilities \nCreate and optimize detections, playbooks, and workflows to quickly identify and respond to potential incidents\nReview Incident Response metrics and procedures and drive continuous improvement \nWork cross functionally with other security and engineering teams\nNote: This position will require participation in an on-call rotation\nYou May Be a Good Fit If You\n3+ years of software engineering experience, with security experience a plus and/or\n5+ years of detection engineering, incident response, or threat hunting experience\nA solid understanding of cloud environments and operations\nExperience working with engineering teams in a SaaS environment\nExceptional communication and collaboration skills\nAn ability to lead projects with little guidance\nThe ability to pick up new languages and technologies quickly\nExperience handling security incidents and investigating anomalies as part of a team\nKnowledge of EDR, SIEM, SOAR, or related security tools\nStrong Candidates May Also Have Experience With\nExperience performing security operations or investigations involving large-scale Kubernetes environments\nA high level of proficiency in Python and query languages such as SQL\nExperience analyzing attack behavior and prototyping high quality detections\nExperience with threat intelligence, malware analysis, infrastructure as code, detection engineering, or forensics\nExperience contributing to a high growth startup environment\nDeadline to apply: \nNone. Applications will be reviewed on a rolling basis.\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$300,000 - $405,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$300,000.00", "title": "Security Engineer: Detection and Response", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4189707611", "loc": "Greater Syracuse-Auburn Area", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Role\nAnthropic's ML Performance and Scaling team trains our production pretrained models, work that directly shapes the company's future and our mission to build safe, beneficial AI systems. As a Research Engineer on this team, you'll ensure our frontier models train reliably, efficiently, and at scale. This is demanding, high-impact work that requires both deep technical expertise and a genuine passion for the craft of large-scale ML systems.\nThis role lives at the boundary between research and engineering. You'll work across our entire production training stack: performance optimization, hardware debugging, experimental design, and launch coordination. During launches, the team works in tight lockstep, responding to production issues that can't wait for tomorrow.\nResponsibilities\nOwn critical aspects of our production pretraining pipeline, including model operations, performance optimization, observability, and reliability\nDebug and resolve complex issues across the full stack\u2014from hardware errors and networking to training dynamics and evaluation infrastructure\nDesign and run experiments to improve training efficiency, reduce step time, increase uptime, and enhance model performance\nRespond to on-call incidents during model launches, diagnosing problems quickly and coordinating solutions across teams\nBuild and maintain production logging, monitoring dashboards, and evaluation infrastructure\nAdd new capabilities to the training codebase, such as long context support or novel architectures\nCollaborate closely with teammates across SF and London, as well as with Tokens, Architectures, and Systems teams\nContribute to the team's institutional knowledge by documenting systems, debugging approaches, and lessons learned\nYou May Be a Good Fit If You\nHave hands-on experience training large language models, or deep expertise with JAX, TPU, PyTorch, or large-scale distributed systems\nGenuinely enjoy both research and engineering work\u2014you'd describe your ideal split as roughly 50/50 rather than heavily weighted toward one or the other\nAre excited about being on-call for production systems, working long days during launches, and solving hard problems under pressure\nThrive when working on whatever is most impactful, even if that changes day-to-day based on what the production model needs\nExcel at debugging complex, ambiguous problems across multiple layers of the stack\nCommunicate clearly and collaborate effectively, especially when coordinating across time zones or during high-stress incidents\nAre passionate about the work itself and want to refine your craft as a research engineer\nCare about the societal impacts of AI and responsible scaling\nStrong Candidates May Also Have\nPrevious experience training LLM\u2019s or working extensively with JAX/TPU, PyTorch, or other ML frameworks at scale\nContributed to open-source LLM frameworks (e.g., open_lm, llm-foundry, mesh-transformer-jax)\nPublished research on model training, scaling laws, or ML systems\nExperience with production ML systems, observability tools, or evaluation infrastructure\nBackground as a systems engineer, quant, or in other roles requiring both technical depth and operational excellence\nWhat Makes This Role Unique\nThis is not a typical research engineering role. The work is highly operational\u2014you'll be deeply involved in keeping our production models training smoothly, which means being responsive to incidents, flexible about priorities, and comfortable with uncertainty. During launches, the team often works extended hours and may need to respond to issues on evenings and weekends.\nHowever, this operational intensity comes with extraordinary learning opportunities. You'll gain hands-on experience with some of the largest, most sophisticated training runs in the industry. You'll work alongside world-class researchers and engineers, and the institutional knowledge you build will compound in ways that can't be easily transferred. For people who thrive on this type of work, it's uniquely rewarding.\nWe're building a close-knit team of people who genuinely care about doing excellent work together. If you're someone who wants to be part of training the models that will define the future of AI\u2014and you're excited about the full reality of what that entails\u2014we'd love to hear from you.\nLocation:\nThis role requires working in-office 5 days per week in San Francisco.\nDeadline to apply:\n None. Applications will be reviewed on a rolling basis.\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$315,000 - $560,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$315,000.00", "title": "Research Engineer, Pretraining Scaling", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4307306662", "loc": "San Francisco, CA", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Role\nWe're looking for experienced engineers to build and scale the database infrastructure that powers both Claude's product offerings and Anthropic's research initiatives. As a Staff Software Engineer on the Infrastructure team, you will architect and operate database systems that both enable millions of users to interact with Claude and support cutting-edge AI research.\nThis is a unique opportunity to tackle database challenges at unprecedented scale. You'll develop the database strategy for Anthropic, design systems that handle billions of API requests, create storage solutions that work seamlessly across GCP, AWS, and diverse deployment models, and build the reliable data layer that accelerates research experimentation.\nResponsibilities\nSet the technical direction for database solutions used across Product and Research\nDesign and implement database solutions that scale to support millions of users across Claude's product ecosystem\nBuild and scale database systems through 100x+ growth while maintaining reliability and performance\nArchitect data storage solutions that work seamlessly across GCP, AWS, first-party deployments, third-party deployments, and other environments\nDevelop database infrastructure that serves both product and research workloads with different performance characteristics\nPartner with product and research teams to understand data requirements and build infrastructure that accelerates innovation\nOptimize database performance, reliability, and cost efficiency at massive scale\nMake critical build vs. buy decisions for database technologies\nYou Might Be a Good Fit If You\nHave 8+ years of experience building and scaling database systems\nPossess deep expertise in distributed database architectures and OLTP systems at scale\nHave successfully scaled databases through massive growth at high-growth companies\nCan balance the speed of a startup environment with the reliability needs of production systems\nExcel at technical leadership and cross-functional collaboration\nAre passionate about building the data layer that enables next-generation AI capabilities\nStrong Candidates May Also Have\nDeep expertise scaling PostgreSQL, MySQL, DynamoDB, or similar database systems\nExperience with Redis, Temporal, vector databases, or async job processing frameworks\nExperience building multi-cloud or hybrid cloud database solutions\nKnowledge of database orchestration and automation at scale\nBackground at companies known for database excellence\nNote: Prior AI/ML infrastructure experience is not required. We value deep infrastructure/databases expertise from any domain.\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$320,000 - $485,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$320,000.00", "title": "Staff Software Engineer, Databases", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4288258051", "loc": "San Francisco, CA", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Role\nAs a Research Engineer on the Clio team, you'll be responsible for maintaining and enhancing the critical infrastructure that powers Anthropic's research efforts. You'll work with systems that process data at large scales and serve many internal teams across the organization. Your work will directly enable researchers, safety teams, and other colleagues to achieve their goals by ensuring our research tools are reliable, efficient, and privacy-preserving.\nIn this role, you'll collaborate extensively with teams across Anthropic\u2014from Finetuning, RL Research, and Societal Impacts to Safeguards, Communications, and customer success\u2014to understand their diverse needs and translate them into robust technical solutions. You'll be responsible for the full lifecycle of research tools, from enhancing monitoring capabilities to improving user interfaces, all while maintaining the highest standards for data privacy and system reliability.\nResponsibilities\nEnable Anthropic researchers to analyze large sets of Claude usage while preserving user privacy.\nMaintain systems that perform challenging dataset clustering and hierarchy-building.\nDebug data processing pipelines that may encounter difficult issues, such as concurrency inefficiencies or errors obscured by inter-process communications.\nImplement monitoring systems for tools that process large datasets.\nWork with internal users across teams to understand their needs and prioritize fixes and features.\nWork toward intuitive interfaces \u2014 both command-line and frontend \u2014 for research tools.\nOptimize research tools for speed and efficient resource usage.\nEnhance user data privacy protections, ensuring clear and auditable data handling practices.\nWrite and maintain related documentation.\nYou May Be a Good Fit If You\nHave 5+ years of software engineering experience with a track record of building and maintaining production systems; note that a machine learning-specific background is not critical\nAre highly proficient in Python\nHave experience with data infrastructure and large datasets in production environments\nAre comfortable working independently while maintaining collaborative relationships across teams\nHave excellent communication skills and enjoy working with diverse stakeholders to understand and solve their technical challenges\nHave experience with cloud infrastructure platforms such as AWS or GCP\nThink naturally in terms of helping move the entire organization forward, even when that means taking on work outside your primary responsibilities\nAre committed to developing AI systems responsibly and care about the societal impacts of your work\nStrong Candidates May Also Have Experience With\nHigh-performance, large-scale ML systems and distributed computing\nKubernetes and container orchestration platforms\nGPU computing and optimization for specialized hardware\nHighly concurrent systems\nProductizing research tools and transitioning from research prototypes to production systems\nPrivacy-preserving technologies and secure data handling practices\nDeadline to apply:\n None. Applications will be reviewed on a rolling basis.\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$340,000 - $425,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$340,000.00", "title": "Research Engineer, CLIO", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4275250942", "loc": "San Francisco, CA", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Role\nWe are seeking an experienced Machine Learning Systems Engineer to join our Encodings and Tokenization team at Anthropic. This cross-functional role will be instrumental in developing and optimizing the encodings and tokenization systems used throughout our Finetuning workflows. As a bridge between our Pretraining and Finetuning teams, you'll build critical infrastructure that directly impacts how our models learn from and interpret data. Your work will be foundational to Anthropic's research progress, enabling more efficient and effective training of our AI systems while ensuring they remain reliable, interpretable, and steerable.\nResponsibilities\nDesign, develop, and maintain tokenization systems used across Pretraining and Finetuning workflows\nOptimize encoding techniques to improve model training efficiency and performance\nCollaborate closely with research teams to understand their evolving needs around data representation\nBuild infrastructure that enables researchers to experiment with novel tokenization approaches\nImplement systems for monitoring and debugging tokenization-related issues in the model training pipeline\nCreate robust testing frameworks to validate tokenization systems across diverse languages and data types\nIdentify and address bottlenecks in data processing pipelines related to tokenization\nDocument systems thoroughly and communicate technical decisions clearly to stakeholders across teams\nYou May Be a Good Fit If You\nHave significant software engineering experience with demonstrated machine learning expertise\nAre comfortable navigating ambiguity and developing solutions in rapidly evolving research environments\nCan work independently while maintaining strong collaboration with cross-functional teams\nAre results-oriented, with a bias towards flexibility and impact\nHave experience with machine learning systems, data pipelines, or ML infrastructure\nAre proficient in Python and familiar with modern ML development practices\nHave strong analytical skills and can evaluate the impact of engineering changes on research outcomes\nPick up slack, even if it goes outside your job description\nEnjoy pair programming (we love to pair!)\nCare about the societal impacts of your work and are committed to developing AI responsibly\nStrong Candidates May Also Have Experience With\nWorking with machine learning data processing pipelines\nBuilding or optimizing data encodings for ML applications\nImplementing or working with BPE, WordPiece, or other tokenization algorithms\nPerformance optimization of ML data processing systems\nMulti-language tokenization challenges and solutions\nResearch environments where engineering directly enables scientific progress\nDistributed systems and parallel computing for ML workflows\nLarge language models or other transformer-based architectures (not required)\nDeadline to apply:\n None. Applications will be reviewed on a rolling basis.\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$320,000 - $405,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$320,000.00", "title": "Machine Learning Systems Engineer, Encodings and Tokenization", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4259923656", "loc": "San Francisco, CA", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Role\nAs an MCP Engineer on Anthropic's Enterprise team, you will be a hands-on technical bridge between Anthropic and our strategic partners developing Model Context Protocol (MCP) servers. You will serve as the first line of technical defense for consulting with partners, resolving their technical challenges, and helping accelerate enterprise deployments in critical verticals like Financial Services, Life Sciences, and Healthcare. This role directly impacts our Enterprise business by ensuring partner success in building and deploying MCP integrations at scale.\nResponsibilities\nReview and validate partner MCP server architectures for security, scalability, and enterprise compliance requirements\nGuide partners through OAuth and enterprise authentication implementations\nProvide technical consultation on deployment models (remote vs local), infrastructure patterns, and hosting architectures\nDebug partner integration issues and provide hands-on technical support\nTriage technical issues and escalate appropriately to relevant teams at Anthropic\nHelp bolster self-serve resources and documentation based on partner feedback\nCollaborate with product teams to systematize partner feedback for MCP protocol evolution\nParticipate in partner technical forums, developer communities, and industry events\nTechnically contribute to joint solution development and reference architecture creation\nYou May Be a Good Fit If You Have\n4+ years of experience in technical partner-facing or customer-facing engineering roles \nStrong programming skills with ability to debug across multiple languages and frameworks\nDeep understanding of authentication protocols (OAuth 2.0, SAML, OpenID Connect) and enterprise identity management\nDeep Experience with API integrations, SDKs, and developer tools\nExperience developing local and remote MCPs \nExperience with enterprise deployment patterns, containerization, and cloud infrastructure\nPassion for developer experience and partner success\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$300,000 - $320,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$300,000.00", "title": "MCP Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4301132363", "loc": "New York, NY", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Team\nThe Security Engineering team's mission is to safeguard our AI systems and maintain the trust of our users and society at large. Whether we're developing critical security infrastructure, building secure development practices, or partnering with our research and product teams, we are committed to operating as a world-class security organization and keeping the safety and trust of our users at the forefront of everything we do.\nResponsibilities\nBuild security for large-scale AI clusters, implementing robust cloud security architecture including IAM, network segmentation, and encryption controls\nDesign secure-by-design workflows, secure CI/CD pipelines across our services, help build secure cloud infrastructure, with expertise in various cloud environments, Kubernetes security, container orchestration and identity management\nShip and operate secure, high-reliability services using Infrastructure-as-Code (IaC) practices and GitOps workflows\nApply deep expertise in threat modeling and risk assessment to secure complex cloud environments\nMentor engineers and contribute to hiring and growth of the Security team\nYou May Be a Good Fit If You Have\n5-15+ years of software engineering experience implementing and maintaining critical systems at scale\nBachelor's degree in Computer Science/Software Engineering or equivalent industry experience\nStrong software engineering skills in Python or at least one systems language (Go, Rust, C/C++)\nExperience managing infrastructure at scale with DevOps and cloud automation best practices\nTrack record of driving engineering excellence through high standards, constructive code reviews, and mentorship\nProven ability to lead cross-functional security initiatives and navigate complex organizational dynamics\nOutstanding communication skills, translating technical concepts effectively across all organizational levels\nDemonstrated success in bringing clarity and ownership to ambiguous technical problems\nStrong systems thinking with ability to identify and mitigate risks in complex environments\nLow ego, high empathy engineer who attracts talent and supports diverse, inclusive teams\nExperience supporting fast-paced startup engineering teams\nPassionate about AI safety and alignment, with keen interest in making AI systems more interpretable and aligned with human values\nStrong Candidates May Also\nDesigning and hardening CI/CD pipelines against supply chain attacks through isolated environments, signed attestations, dependency verification, and automated policy enforcement\nBuilding secure development workflows through hardened remote environments\nImplementing network segmentation and access controls in cloud environments\nManaging infrastructure through automated configuration and policy enforcement\nHardening containerized applications and enforcing security policies\nDeadline to apply: \nNone. Applications will be reviewed on a rolling basis.\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$300,000 - $405,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$300,000.00", "title": "AI Platform Security Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4308268996", "loc": "New York, NY", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nWe're seeking an exceptional engineer to join Anthropic's Detection Platform team to build and scale our next-generation security analytics infrastructure. In this role, you'll architect and implement data pipelines that process massive amounts of security telemetry, develop ML-powered detection systems, and create innovative solutions that leverage Claude to transform security operations.\nResponsibilities\nDesign and implement scalable data pipelines for ingesting and processing security telemetry across our rapidly growing infrastructure\nBuild and optimize ML-powered detection systems, including user behavior analytics (UEBA) and anomaly detection capabilities\nArchitect solutions for storing and efficiently querying large volumes of security-relevant data\nCreate rapid prototypes and proof-of-concepts for new security tooling and analytics capabilities\nDevelop systems that leverage Claude and other ML models to enhance our detection and response capabilities\nWork closely with security and infrastructure teams to understand requirements and deliver solutions\nMentor engineers and contribute to hiring and growth of the Security team\nParticipate in on-call shifts\nYou May Be a Good Fit If You\n \n7+ years of experience in software engineering with a focus on security, infrastructure and/or data pipelines\nTrack record of building and maintaining internal developer tools or security platforms\nStrong understanding of data processing pipelines and experience working with large-scale logging systems\nExperience with:\nTest-driven software development and/or CI/CD (plus for direct experience with Detection-as-code workflows)\nInfrastructure-as-code (Terraform, CloudFormation)\nQuery optimization for large datasets\nExperience with building stable and scalable services on cloud infrastructure and serverless architectures \nAbility to write maintainable and secure code in Python\nExperience working with security teams and translating requirements into technical solutions\nAbility to lead technical projects with minimal guidance\nTrack record of driving engineering excellence through high standards, constructive code reviews, and mentorship\nProven ability to lead cross-functional security initiatives and navigate complex organizational dynamics\nOutstanding communication skills, translating technical concepts effectively across all organizational levels\nDemonstrated success in bringing clarity and ownership to ambiguous technical problems\nStrong systems thinking with ability to identify and mitigate risks in complex environments\nStrong Candidates May Also Have Experience With\n \nExperience building security tooling from the ground up\nBackground in implementing security monitoring solutions (SIEM, log aggregation, EDR)\nBackground in detection engineering or security operations\nExperience with:\nSOAR platform/automation development\nData lake / Database architecture\nAPI design and internal platform creation\nTrack record of applying ML/AI to security problems\nExperience scaling security operations in a high-growth environment\nDeadline to apply: \nNone. Applications will be reviewed on a rolling basis.\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$320,000 - $405,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$320,000.00", "title": "Security Software Engineer: Detection Platform Infrastructure", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4189351241", "loc": "San Francisco, CA", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Role\nWe are seeking a Senior Finance Systems Engineer to join our Finance Systems team at Anthropic. In this role, you will be responsible for managing the NetSuite financial ERP and its interactions with other platforms, ensuring the health, configuration, and change management processes of these systems to support our growing global business. You will drive customizations and integrations into the ERP system, collaborating closely with Data Infrastructure, Business Technology, and Engineering teams to implement innovative technology solutions. This role offers the opportunity to take full ownership of complex problems, working with passionate engineers and stakeholders to architect and implement innovative solutions that propel Anthropic towards its mission of creating safe and beneficial AI systems.\nResponsibilities\nNetSuite ERP Management: Own the day-to-day operations, health monitoring, configuration, and change management processes of our NetSuite financial ERP system and its interactions with other platforms\nCustomizations & Integrations: Drive customizations and integrations into the ERP system, collaborating closely with Data Infrastructure, Business Technology, and Engineering teams to deliver enhanced functionality\nComplex Problem Ownership: Take full ownership of complex technical problems, collaborating with passionate engineers and stakeholders with diverse perspectives to architect and implement solutions that propel Anthropic towards its objectives\nIntegration Troubleshooting: Troubleshoot and improve integrations between NetSuite and subledger systems, collaborating closely with software engineers and stakeholders to ensure data completeness, timeliness, and integrity\nRequirements & Solution Design: Partner with stakeholders to gather requirements, design solutions, and implement new features and customizations to streamline processes and support our growth\nUser Experience Optimization: Work with users to understand their needs and challenges, identify and execute enhancements, and resolve issues to optimize user experience\nSystem Upgrades & Releases: Manage system upgrades and releases to ensure minimal disruption to operations while maintaining system stability and performance\nProcess Automation: Identify opportunities to automate manual finance processes through system integration, configuration, and AI technologies\nPerformance Monitoring: Monitor system performance, troubleshoot issues, and implement improvements to ensure reliability and efficiency\nDocumentation & Training: Create comprehensive technical documentation and provide training to finance teams on system functionality and best practices\nSecurity & Compliance: Ensure finance systems maintain appropriate security controls and compliance with regulatory requirements\nInnovation & Strategy: Stay current with emerging finance technology trends and recommend innovative solutions to enhance our systems capabilities\nYou May Be a Good Fit If You\nHave 8+ years of experience in finance systems engineering, ERP administration, or related technical roles\nPossess deep expertise with NetSuite ERP system, including configuration, customization, and integration capabilities\nHave strong experience with system integration, ETL processes (Airflow, DBT), and data management in finance environments\nTechnical expertise in Python scripting, RESTful API development, and iPaaS enterprise integration platforms for financial systems automation\nAre skilled in troubleshooting complex integrations between ERP and subledger systems\nHave experience working with cross-functional technical teams including Data Infrastructure, Business Technology, and Engineering\nPossess strong analytical and problem-solving skills with the ability to translate business requirements into technical solutions\nHave experience with financial processes including close, reporting, budgeting, and compliance workflows\nHave strong communication skills and can effectively collaborate with both technical and business stakeholders\nAre comfortable working in a fast-paced, high-growth environment with evolving requirements\nTake ownership of complex problems and can work collaboratively with diverse stakeholders to find solutions\nStrong Candidates May Also Have\nExperience with modern cloud-based finance platforms and SaaS integrations\nExperience with other SaaS ERP systems besides NetSuite, such as Oracle Fusion and Workday \nKnowledge of financial reporting standards (GAAP, IFRS) and how they translate to system requirements\nExperience with business intelligence tools and financial data visualization platforms\nBackground in software development or systems engineering outside of finance\nExperience with infrastructure as code and DevOps practices\nFamiliarity with AI/ML applications in finance and accounting\nUnderstanding of startup financial operations and scaling challenges\nExperience with financial planning and analysis (FP&A) systems and processes\nKnowledge of procurement, expense management, and revenue recognition systems\nExperience in technology companies or other high-growth environments\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$205,000 - $265,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$205,000.00", "title": "Finance Systems Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4278496384", "loc": "San Francisco, CA", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Role\nAs a Software Engineer focusing on Insider Risk tooling, you will join the Detection Platform Engineering team and leverage the systems and tooling we are building to suit the needs of the Insider Risk team. You will combine investigative acumen with detection engineering expertise to build systems and integrations that allow the team to proactively detect and respond to potential insider risk incidents. You will play a critical role in developing and tuning detection pipelines, improving our risk posture and fostering a security-conscious culture.\nResponsibilities\nSupport detection engineering for insider risk, contributing to the design and maintenance of detection rules, alerting logic and automation.\nServe as an engineering resource for Insider Risk investigators, translating business requirements into tooling\nDevelop, refine, and operationalize insider threat indicators, scenarios, and mitigation strategies.\nPartner with engineering, IT and security teams to close visibility gaps and ensure telemetry coverage across endpoints, identity systems and collaboration tools\nDesign, implement, and oversee data loss prevention (DLP) controls to safeguard sensitive information.\nPartner with investigators on technical investigations into suspicious activities, and generate high-quality investigative reports, assessments, and briefings on findings.\nYou May Be a Good Fit If You Have\nEducational Background: Bachelor\u2019s degree in a relevant field or equivalent experience.\nProfessional Experience: 5+ years in software engineering with a focus on security (anomaly detection, insider threat analysis, security operations, or a related domain), with hands on experience building or maintaining detection tooling and pipelines.\nTechnical Proficiency: Engineering experience with DLP, SIEM, EDR, NDR, and SOAR technologies: You have on-boarded logs and built custom detections/automations for complex environments.\nInvestigation Expertise: strong ability to perform forensic analysis, correlate disparate data sources and uncover meaningful patterns of anomalous behavior\nCommunication Skills: Ability to convey complex security issues to both technical and non-technical stakeholders with clarity and impact.\nCollaborative Mindset: A team player who thrives in cross-functional environments and values diverse perspectives.\nStrong Candidates May Also Have\nDirect experience building insider risk tooling \nExperience with large-scale data pipelines and anomaly detection\nTrack record of applying ML/AI to security problems\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$320,000 - $405,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$320,000.00", "title": "Security Software Engineer: Detection Platform (Insider Risk)", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4240707098", "loc": "San Francisco, CA", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Role\nWe are seeking a Machine Learning Infrastructure Engineer to join our Safeguards organization, where you'll build and scale the critical infrastructure that powers our AI safety systems. You'll work at the intersection of machine learning, large-scale distributed systems, and AI safety, developing the platforms and tools that enable our safeguards to operate reliably at scale.\nAs part of the Safeguards team, you'll design and implement ML infrastructure that powers Claude safety. Your work will directly contribute to making AI systems more trustworthy and aligned with human values, ensuring our models operate safely as they become more capable.\nResponsibilities\nDesign and build scalable ML infrastructure to support real-time and batch classifier and safety evaluations across our model ecosystem\nBuild monitoring and observability tools to track model performance, data quality, and system health for safety-critical applications\nCollaborate with research teams to productionize safety research, translating experimental safety techniques into robust, scalable systems\nOptimize inference latency and throughput for real-time safety evaluations while maintaining high reliability standards\nImplement automated testing, deployment, and rollback systems for ML models in production safety applications\nPartner with Safeguards, Security, and Alignment teams to understand requirements and deliver infrastructure that meets safety and production needs\nContribute to the development of internal tools and frameworks that accelerate safety research and deployment\nYou May Be a Good Fit If You\nHave 5+ years of experience building production ML infrastructure, ideally in safety-critical domains like fraud detection, content moderation, or risk assessment\nAre proficient in Python and have experience with ML frameworks like PyTorch, TensorFlow, or JAX\nHave hands-on experience with cloud platforms (AWS, GCP) and container orchestration (Kubernetes)\nUnderstand distributed systems principles and have built systems that handle high-throughput, low-latency workloads\nHave experience with data engineering tools and building robust data pipelines (e.g., Spark, Airflow, streaming systems)\nAre results-oriented, with a bias towards reliability and impact in safety-critical systems\nEnjoy collaborating with researchers and translating cutting-edge research into production systems\nCare deeply about AI safety and the societal impacts of your work\nStrong Candidates May Have Experience With\nWorking with large language models and modern transformer architectures\nImplementing A/B testing frameworks and experimentation infrastructure for ML systems\nDeveloping monitoring and alerting systems for ML model performance and data drift\nBuilding automated labeling systems and human-in-the-loop workflows\nExperience in trust & safety, fraud prevention, or content moderation domains\nKnowledge of privacy-preserving ML techniques and compliance requirements\nContributing to open-source ML infrastructure projects\nDeadline to apply: \nNone. Applications will be reviewed on a rolling basis.\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$320,000 - $405,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$320,000.00", "title": "ML Infrastructure Engineer, Safeguards", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4255929103", "loc": "San Francisco, CA", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Role\nA systems-level engineer specializing in build infrastructure and low-level systems optimization, with expertise in maintaining and improving non-trivial C/C++ builds and other host level systems. This role requires deep technical knowledge of compilation processes, hardware-software interfaces, build systems, and the ability to debug and optimize at the system level.\nResponsibilities\nBuild Systems & Toolchains\nExpert-level proficiency with build/packaging systems (Nix, pip, uv, CMake, Bazel, Make, etc\u2026) \nNix experience in particular is a huge plus\nExperience managing complex builds and interacting in non-trivial ways with CI\nSkilled in diagnosing and resolving linking issues, symbol resolution problems, and toolchain/ABI incompatibilities\nLow-Level Systems/Embedded Programming\nStrong C/C++ debugging skills, especially nice if in embedded systems or in dealing with cross compiling/linking\nComfortable with system calls, POSIX APIs, and kernel interfaces\nExperience with toolchain debugging tools like readelf, bloaty, c++filt, nm, etc\u2026\nCompiler & Toolchain Experience\nBasic knowledge of compilers (understanding things like passes, having multiples levels of IR, what kinds of operations are done on it, etc\u2026)\nExperience with cross-compilers (compiling code for target devices)\nExperience with detailed compiler flags optimization and custom toolchain configuration\nUnderstanding of linking processes, object file formats (ELF, DWARF), and ABI compatibility\nStrong Candidates May Have\nMachine Learning Infrastructure\nBasic understanding of deep learning frameworks (PyTorch, Jax) from a systems perspective\nUnderstanding of tensor operations\nExperience with distributed training infrastructure is a plus\nYou May Be a Good Fit If You Have\n5+ years of experience in systems programming or infrastructure roles\nOften comes from backgrounds in: HPC, game engine development, embedded systems, OS, or compiler teams\nStrong debugging mindset with patience for complex, multi-layered issues\nSelf-directed problem solver who can navigate large, legacy codebases\nThis profile would be ideal for roles in ML infrastructure teams, HPC environments, or any organization dealing with non-trivial C/C++ systems that need optimization at the build and runtime level.\nDeadline to apply: \nNone. Applications will be reviewed on a rolling basis.\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$315,000 - $405,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$315,000.00", "title": "Build Infrastructure Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4310060086", "loc": "San Francisco, CA", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Role\nThe mission of the Compute team is to provide input into our company-wide cloud infrastructure strategy and efficiency deliverables, advise on key decisions affecting budget, and provide capacity planning and performance expertise to various anthropic-wide stakeholders in finance and engineering leadership. As an early member of this team, you would be required to work with engineering teams to ensure optimal operation and growth of our infrastructure from both a cost and technology perspective and collaborate cross-functionally with finance and data science partners to analyze and forecast growth.\nResponsibilities\nDevelop self-service tools and processes to enable anthropic engineers to understand their capacity, efficiency, and costs\nDesign, develop, and lead necessary automation to help capacity plan for both near and long term outcomes\nInstitute and design governance workflows to help manage additional capacity request approvals\nInvestigate new capacity requests to ensure the best use of resources and that instances are sized appropriately\nBuild and drive cost to serve analytics programs to guide engineering, finance, and leadership on the total cost (TCO) and infrastructure impact of our scaling factors. Inform pricing conversations through customer profile sensitive gross margin analysis.\nTech lead with outside vendors to manage anthropic capacity needs\nProactively identify infrastructure inefficiency opportunities, document proposal and be a key contributor in driving a positive outcome\nServe as an advisor to engineering and finance functions and executive team for one of the largest areas of expenditure\nWork closely with TPMs on special efficiency projects and help deliver committed outcomes\nYou May Be a Good Fit If You\n5+ years experience in capacity engineering\n5+ years experience in a technical role\nIntermediate knowledge of various public cloud providers\nExperience with data modeling for public cloud\nExperience with budgeting, capacity planning experience, and cloud efficiency optimization workflows\nExperience in scripting and building automation tools \nSelf-disciplined and thrives in fast paced environments\nExcellent communication skills\nFamiliarity with cloud compute, storage, network, and services\nAttention to detail and a passion for correctness\nDeadline to apply:\n None. Applications will be reviewed on a rolling basis. \nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$320,000 - $405,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$320,000.00", "title": "Capacity Engineer, Compute", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4264675375", "loc": "Seattle, WA", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Team\nOur team is organized around the north star goal of building an AI scientist \u2013 a system capable of solving the long term reasoning challenges and basic capabilities necessary to push the scientific frontier. Our team likes to think across the whole model stack. Currently the team is focused on improving models' abilities to use computers \u2013 as a laboratory for long horizon tasks and a key blocker to many scientific workflows.\nAbout The Role\nAs a Staff Infrastructure Engineer on our team you will work end to end, identifying and addressing key infra blockers on the path to scientific AGI. Strong candidates should have familiarity with performance optimization, distributed systems, vm/sandboxing/container deployment, and large scale data pipelines. Familiarity with language model training, evaluation, and inference is highly encouraged.\nJoin us in our mission to develop advanced AI systems that are both powerful and beneficial for humanity.\nResponsibilities\nDesign and implement large-scale infrastructure systems to support AI scientist training, evaluation, and deployment across distributed environments\nIdentify and resolve infrastructure bottlenecks impeding progress toward scientific capabilities\nDevelop robust and reliable evaluation frameworks for measuring progress towards scientific AGI.\nBuild scalable and performant VM/sandboxing/container architectures to safely execute long-horizon AI tasks and scientific workflows\nCollaborate to translate experimental requirements into production-ready infrastructure\nDevelop large scale data pipelines to handle advanced language model training requirements\nOptimize large scale training and inference pipelines for stable and efficient reinforcement learning\nYou May Be a Good Fit If You\nHave 6+ years of highly relevant experience in infrastructure engineering with demonstrated expertise in large-scale distributed systems\nAre a strong communicator and enjoy working collaboratively\nPossess deep knowledge of performance optimization techniques and system architectures for high-throughput ML workloads\nHave experience with containerization technologies (Docker, Kubernetes) and orchestration at scale\nHave proven track record of building large-scale data pipelines and distributed storage systems\nExcel at diagnosing and resolving complex infrastructure challenges in production environments\nCan work effectively across the full ML stack from data pipelines to performance optimization\nHave experience collaborating with other researchers to scale experimental ideas\nStrong Candidates May Also Have\nExperience with language model training infrastructure and distributed ML frameworks (PyTorch, JAX, etc.)\nBackground in building infrastructure for AI research labs or large-scale ML organizations\nKnowledge of GPU/TPU architectures and language model inference optimization\nExperience with cloud platforms (AWS, GCP) at enterprise scale\nFamiliarity with VM and container orchestration.\nExperience with workflow orchestration tools and experiment management systems\nHistory working with large scale reinforcement learning\nComfort with large scale data pipelines (Beam, Spark, Dask, \u2026)\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$340,000 - $425,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$340,000.00", "title": "Staff Infrastructure Engineer, Discovery Team", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4227907368", "loc": "San Francisco, CA", "company": "Anthropic"}, {"desc": "About Anthropic\nAnthropic\u2019s mission is to create reliable, interpretable, and steerable AI systems. We want AI to be safe and beneficial for our users and for society as a whole. Our team is a quickly growing group of committed researchers, engineers, policy experts, and business leaders working together to build beneficial AI systems.\nAbout The Role\nOur Inference team is responsible for building and maintaining the critical systems that serve Claude to millions of users worldwide. We bring Claude to life by serving our models via the industry's largest compute-agnostic inference deployments. We are responsible for the entire stack from intelligent request routing to fleet-wide orchestration across diverse AI accelerators.\nThe team has a dual mandate: \nmaximizing compute efficiency\n to serve our explosive customer growth, while \nenabling breakthrough research\n by giving our scientists the high-performance inference infrastructure they need to develop next-generation models. We tackle complex, distributed systems challenges across multiple accelerator families and emerging AI hardware running in multiple cloud platforms.\nYou May Be a Good Fit If You\nHave significant software engineering experience, particularly with distributed systems\nAre results-oriented, with a bias towards flexibility and impact\nPick up slack, even if it goes outside your job description\nEnjoy pair programming (we love to pair!)\nWant to learn more about machine learning systems and infrastructure\nThrive in environments where technical excellence directly drives both business results and research breakthroughs\nCare about the societal impacts of your work\nStrong Candidates May Also Have Experience With\nHigh-performance, large-scale distributed systems\nImplementing and deploying machine learning systems at scale\nLoad balancing, request routing, or traffic management systems\nLLM inference optimization, batching, and caching strategies\nKubernetes and cloud infrastructure (AWS, GCP)\nPython or Rust\nRepresentative Projects\nDesigning intelligent routing algorithms that optimize request distribution across thousands of accelerators\nAutoscaling our compute fleet to dynamically match supply with demand across production, research, and experimental workloads\nBuilding production-grade deployment pipelines for releasing new models to millions of users\nIntegrating new AI accelerator platforms to maintain our hardware-agnostic competitive advantage\nContributing to new inference features (e.g., structured sampling, prompt caching)\nSupporting inference for new model architectures\nAnalyzing observability data to tune performance based on real-world production workloads\nManaging multi-region deployments and geographic routing for global customers\nDeadline to apply: \nNone. Applications will be reviewed on a rolling basis.\nThe expected base compensation for this position is below. Our total compensation package for full-time employees includes equity, benefits, and may include incentive compensation.\nAnnual Salary\n$300,000 - $485,000 USD\nLogistics\nEducation requirements: \nWe require at least a Bachelor's degree in a related field or equivalent experience.\nLocation-based hybrid policy:\n Currently, we expect all staff to be in one of our offices at least 25% of the time. However, some roles may require more time in our offices.\nVisa sponsorship:\n We do sponsor visas! However, we aren't able to successfully sponsor visas for every role and every candidate. But if we make you an offer, we will make every reasonable effort to get you a visa, and we retain an immigration lawyer to help with this.\nWe encourage you to apply even if you do not believe you meet every single qualification.\n Not all strong candidates will meet every single qualification as listed. Research shows that people who identify as being from underrepresented groups are more prone to experiencing imposter syndrome and doubting the strength of their candidacy, so we urge you not to exclude yourself prematurely and to submit an application if you're interested in this work. We think AI systems like the ones we're building have enormous social and ethical implications. We think this makes representation even more important, and we strive to include a range of diverse perspectives on our team.\nHow We're Different\nWe believe that the highest-impact AI research will be big science. At Anthropic we work as a single cohesive team on just a few large-scale research efforts. And we value impact \u2014 advancing our long-term goals of steerable, trustworthy AI \u2014 rather than work on smaller and more specific puzzles. We view AI research as an empirical science, which has as much in common with physics and biology as with traditional efforts in computer science. We're an extremely collaborative group, and we host frequent research discussions to ensure that we are pursuing the highest-impact work at any given time. As such, we greatly value communication skills.\nThe easiest way to understand our research directions is to read our recent research. This research continues many of the directions our team worked on prior to Anthropic, including: GPT-3, Circuit-Based Interpretability, Multimodal Neurons, Scaling Laws, AI & Compute, Concrete Problems in AI Safety, and Learning from Human Preferences.\nCome work with us!\nAnthropic is a public benefit corporation headquartered in San Francisco. We offer competitive compensation and benefits, optional equity donation matching, generous vacation and parental leave, flexible working hours, and a lovely office space in which to collaborate with colleagues. \nGuidance on Candidates' AI Usage:\n Learn about our policy for using AI in our application process", "comp": "$300,000.00", "title": "Senior / Staff Engineer, Inference", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4267332068", "loc": "New York, NY", "company": "Anthropic"}, {"desc": "At Scale, our mission is to accelerate the development of AI applications. For 8 years, Scale has been the leading AI data foundry, helping fuel the most exciting advancements in AI, including: generative AI, defense applications, and autonomous vehicles. With our recent Series F round, we\u2019re accelerating the abundance of frontier data to pave the road to Artificial General Intelligence (AGI), and building upon our prior model evaluation work with enterprise customers and governments, to deepen our capabilities and offerings for both public and private evaluations.\nExample Projects:\nShip tools to accelerate the growth of new qualified contributors on Scale\u2019s labeling platform\nBuild methodical fraud-detection systems to remove bad actors and keep Scale\u2019s contributor base safe and trusted. \nUse models to estimate the quality of tasks and labelers, and guarantee quality on requests at large scale.\nDevise advanced matching algorithms to match labelers to customers for optimal turnaround and accuracy.\nBuild methods to automatically measure, train, and optimally match labelers to tasks based on performance\nCreate optimized and efficient UI/UX tooling, in combination with ML algorithms, for 100k+ labelers to complete billions of complex tasks\nDevelop new AI infrastructure products to visualize, query, and explore Scale data\nCreate a customer service RAG application that handles 1000s of questions a day\nIntegrate a cutting-edge ML model that predicts churn with a customer's retention system\nRequirements:\nA graduation date in Fall 2025 or Spring 2026 with a Bachelor\u2019s degree (or equivalent) in a relevant field (Computer Science, EECS, Computer Engineering, Statistics) \nProduct engineering experience such as building web apps full-stack, integrating with relevant APIs and services, talking to customers, figuring out \u2018what\u2019 to build and then iterating\nPrevious Product/Software Engineering Internship experience \nTrack record of shipping high-quality products and features at scale\nExperience building systems that process large volumes of data\nExperience with Typescript, React, Python and/or MongoDB\nCompensation packages at Scale for eligible roles include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Scale employees in eligible roles are also granted equity based compensation, subject to Board of Director approval. Your recruiter can share more about the specific salary range for your preferred location during the hiring process, and confirm whether the hired role will be eligible for equity grant. You\u2019ll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.\nPlease reference the job posting's subtitle for where this position will be located. For pay transparency purposes, the base salary range for this full-time position in the locations of San Francisco, New York, Seattle is:\n$124,000\u2014$150,000 USD\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, our mission is to develop reliable AI systems for the world's most important decisions. Our products provide the high-quality data and full-stack technologies that power the world's leading models, and help enterprises and governments build, deploy, and oversee AI applications that deliver real impact. We work closely with industry leaders like Meta, Cisco, DLA Piper, Mayo Clinic, Time Inc., the Government of Qatar, and U.S. government agencies including the Army and Air Force. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.", "comp": "0", "title": "Software Engineer - New Grad", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4297642437", "loc": "San Francisco Bay Area", "company": "Scale AI"}, {"desc": "At Scale, our mission is to accelerate the development of AI applications. For 9 years, Scale has been the leading AI data foundry, helping fuel the most exciting advancements in AI, including: generative AI, defense applications, and autonomous vehicles. With our recent Series F round, we\u2019re accelerating the abundance of frontier data to pave the road to Artificial General Intelligence (AGI), and building upon our prior model evaluation work with enterprise customers and governments, to deepen our capabilities and offerings for both public and private evaluations.\nExample Projects:\nShip tools to accelerate the growth of new qualified contributors on Scale\u2019s labeling platform\nBuild methodical fraud-detection systems to remove bad actors and keep Scale\u2019s contributor base safe and trusted. \nUse models to estimate the quality of tasks and labelers, and guarantee quality on requests at large scale.\nDevise advanced matching algorithms to match labelers to customers for optimal turnaround and accuracy.\nBuild methods to automatically measure, train, and optimally match labelers to tasks based on performance\nCreate optimized and efficient UI/UX tooling, in combination with ML algorithms, for 100k+ labelers to complete billions of complex tasks\nDevelop new AI infrastructure products to visualize, query, and explore Scale data \nRequirements:\nA graduation date in Fall 2026 or Spring 2027 with a Bachelor\u2019s degree (or equivalent) in a relevant field (Computer Science, EECS, Computer Engineering, Statistics) \nProduct engineering experience such as building web apps full-stack, integrating with relevant APIs and services, talking to customers, figuring out \u2018what\u2019 to build and then iterating\nPrevious Computer Science/Software Engineering Internship experience \nTrack record of shipping high-quality products and features at scale\nExperience building systems that process large volumes of data\nExperience with Typescript, React, Python and/or MongoDB\nBe available for a Summer 2026 (May/June start dates) internship\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, our mission is to develop reliable AI systems for the world's most important decisions. Our products provide the high-quality data and full-stack technologies that power the world's leading models, and help enterprises and governments build, deploy, and oversee AI applications that deliver real impact. We work closely with industry leaders like Meta, Cisco, DLA Piper, Mayo Clinic, Time Inc., the Government of Qatar, and U.S. government agencies including the Army and Air Force. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.", "comp": "0", "title": "Software Engineering Intern (Summer 2026)", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4297654154", "loc": "San Francisco Bay Area", "company": "Scale AI"}, {"desc": "Scale AI is seeking highly skilled and motivated Software Engineers to join our dynamic Federal Engineering team. As a part of this team, you will play a critical role in delivering high-impact AI-powered mission solutions for government customers. Our scalable and high-performance platform forms the foundation for these solutions, and your expertise will be instrumental in designing and implementing systems that can handle billions of data points with exceptional performance.\nYou will: \nDesign and implement scalable backend systems for Federal customers, leveraging Scale's modern and cloud-native AI infrastructure\nCollaborate with cross-functional teams to define and execute the vision for backend solutions, ensuring they meet the unique needs of government agencies operating in secure environments\nDevelop distributed systems, data-intensive applications, and machine learning infrastructure to enable real impact for mission owners\nBuild robust and reliable backend systems that can serve as standalone products, empowering customers to accelerate their own AI ambitions\nParticipate actively in customer engagements, working closely with stakeholders to understand requirements and deliver innovative solutions\nContribute to the platform roadmap and product strategy for Scale AI's Federal business, playing a key role in shaping the future direction of our offerings\nThis role will require an active TS/SCI security clearance or the ability to obtain a security clearance.\nIdeally you'd have: \nFull Stack Development: Proficiency in both front-end and back-end development, including experience with modern web development frameworks, programming languages, and databases\nCloud-Native Technologies: Familiarity with cloud platforms (e.g., AWS, Azure, GCP) and experience in developing and deploying applications in a cloud-native environment. Understanding of containerization (e.g., Docker) and container orchestration (e.g., Kubernetes) is a plus\nData Engineering: Knowledge of ETL (Extract, Transform, Load) processes and experience in building data pipelines to integrate and process diverse data sources. Understanding of data modeling, data warehousing, and data governance principles\nMachine Learning Infrastructure: Familiarity with machine learning frameworks (e.g., TensorFlow, PyTorch) and experience in designing and implementing machine learning infrastructure. Understanding of model serving, monitoring, and deployment strategies is beneficial\nProblem Solving: Strong analytical and problem-solving skills to understand complex challenges and devise effective solutions. Ability to think critically, identify root causes, and propose innovative approaches to overcome technical obstacles\nCollaboration and Communication: Excellent interpersonal and communication skills to effectively collaborate with cross-functional teams, stakeholders, and customers. Ability to clearly articulate technical concepts to non-technical audiences and foster a collaborative work environment\nAdaptability and Learning Agility: Willingness to embrace new technologies, learn new skills, and adapt to evolving project requirements. Ability to quickly grasp and apply new concepts and stay up-to-date with emerging trends in software engineering\nCompensation packages at Scale for eligible roles include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Scale employees in eligible roles are also granted equity based compensation, subject to Board of Director approval. Your recruiter can share more about the specific salary range for your preferred location during the hiring process, and confirm whether the hired role will be eligible for equity grant. You\u2019ll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.\nPlease reference the job posting's subtitle for where this position will be located. For pay transparency purposes, the base salary range for this full-time position in the locations of San Francisco, New York, Seattle is:\n$184,000\u2014$292,560 USD\nThe base salary range for this full-time position in the locations of Washington DC, Texas, Colorado is:\n$165,600\u2014$263,304 USD\nThe base salary range for this full-time position in the location of Hawaii/St. Louis is:\n$138,000\u2014$219,420 USD\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, our mission is to develop reliable AI systems for the world's most important decisions. Our products provide the high-quality data and full-stack technologies that power the world's leading models, and help enterprises and governments build, deploy, and oversee AI applications that deliver real impact. We work closely with industry leaders like Meta, Cisco, DLA Piper, Mayo Clinic, Time Inc., the Government of Qatar, and U.S. government agencies including the Army and Air Force. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.", "comp": "0", "title": "Software Engineer, Public Sector", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4196125615", "loc": "San Francisco Bay Area", "company": "Scale AI"}, {"desc": "About Scale\nAt Scale AI, our mission is to accelerate the development of AI applications. For 8 years, Scale has been the leading AI data foundry, helping fuel the most exciting advancements in AI, including: generative AI, defense applications, and autonomous vehicles. With our recent Series F round, we\u2019re accelerating the abundance of frontier data to pave the road to Artificial General Intelligence (AGI), and building upon our prior model evaluation work with enterprise customers and governments to deepen our capabilities and offerings for both public and private evaluations.\nAbout This Role\nThis role will lead the development of machine learning systems powering internal and external customer use cases across Scale\u2019s GenAI platform. As a core part of our Generative AI data engine, these systems are critical to ensuring the usability, reliability, and value of our end-to-end ML workflows.\nYou will build scalable ML services that incorporate both classical models and advanced LLM-based techniques. This is a high-impact, product-focused role where you\u2019ll collaborate across engineering, product, and operations teams to clarify specifications, define practical implementation plans, and rapidly iterate toward effective deployed solutions.\nIf you\u2019re excited about solving real-world ML problems, deploying iteratively, and collaborating closely with cross-functional teams to deliver value fast, we\u2019d love to hear from you.\nYou will:\nDesign and deploy machine learning models to power core customer-facing and internal GenAI features\nBuild real-time and batch ML systems that analyze structured and unstructured signals\nCombine traditional ML techniques with LLMs and neural networks to improve task performance and reliability\nCreate robust evaluation frameworks and iterate quickly based on performance and feedback\nCollaborate closely with product and engineering teams to embed ML systems into production workflows and infrastructure\nIdeally you\u2019d have:\n3+ years of experience building and deploying ML models in production environments\nExperience delivering ML solutions that serve real-world user or customer needs\nProficiency in ML and deep learning frameworks such as scikit-learn, PyTorch, TensorFlow, or JAX\nFamiliarity with LLMs and experience applying foundation models for structured downstream tasks\nStrong software engineering fundamentals and experience building ML systems in microservice architectures (e.g., using AWS or GCP)\nExcellent communication skills and a proven ability to work cross-functionally across product, ops, and engineering\nNice to have:\nHands-on experience rapidly prototyping and iterating on ML systems with changing requirements\nFamiliarity with data quality pipelines or internal evaluation frameworks\nContributions to open-source LLM fine-tuning efforts or internal LLM alignment projects\nResearch or published work in top ML venues (e.g., NeurIPS, ICML, ICLR, ACL, EMNLP)\nCompensation packages at Scale for eligible roles include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Scale employees in eligible roles are also granted equity based compensation, subject to Board of Director approval. Your recruiter can share more about the specific salary range for your preferred location during the hiring process, and confirm whether the hired role will be eligible for equity grant. You\u2019ll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.\nPlease reference the job posting's subtitle for where this position will be located. For pay transparency purposes, the base salary range for this full-time position in the locations of San Francisco, New York, Seattle is:\n$172,000\u2014$260,000 USD\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, our mission is to develop reliable AI systems for the world's most important decisions. Our products provide the high-quality data and full-stack technologies that power the world's leading models, and help enterprises and governments build, deploy, and oversee AI applications that deliver real impact. We work closely with industry leaders like Meta, Cisco, DLA Piper, Mayo Clinic, Time Inc., the Government of Qatar, and U.S. government agencies including the Army and Air Force. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.", "comp": "0", "title": "Machine Learning Engineer, GenAI Applied ML", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4196120826", "loc": "San Francisco Bay Area", "company": "Scale AI"}, {"desc": "The goal of a Machine Learning Engineer at Scale is to leverage techniques in the fields of generative AI, computer vision, reinforcement learning, and agentic AI to improve Scale's products and customer experience in production environments. Our machine learning engineers take advantage of robust internal infrastructure and unique access to massive datasets to deliver improvements to our customers.\nOur Public Sector Machine Learning team is focused on deploying cutting-edge models to mission-critical government systems through products like Donovan and Thunderforge. Our work spans multiple modalities, with a strong focus on both large language models and computer vision. On the LLM side, we are developing agentic systems that help solve complex operational and planning challenges for government partners. This includes building agent frameworks that integrate with custom retrieval pipelines and production APIs, as well as evaluation tools to benchmark and refine agent behavior. We're also advancing research in areas like reinforcement learning for agentic LLMs, with successful deployment into real-world operational environments. On the computer vision front, we're training advanced models to increase labeling throughput and automate perception tasks. Our efforts include building large-scale fine-tuning pipelines, training models across multiple modalities, and developing generalizable vision foundation models to support a wide range of defense applications.\nYou will:\nTake state of the art models developed internally and from the community, use them in production to solve problems for our customers and taskers.\nImprove and maintain production models through retraining, hyperparameter tuning, and architectural updates, while preserving core performance characteristics\nCollaborate with product and research teams to identify and prototype ML-driven product enhancements, including for upcoming product lines\nWork with massive datasets to develop both generic models as well as fine tune models for specific products\nBuild scalable machine learning infrastructure to automate and optimize our ML services\nServe as a cross-functional representative and advocate for machine learning techniques across engineering and product organizations\nBe comfortable learning new technologies quickly and managing multiple priorities in a fast-paced environment\nThis role will require an active security clearance or the ability to obtain a security clearance.\nIdeally You\u2019d Have:\nExtensive experience using computer vision, deep learning and deep reinforcement Learning, or natural language processing in a production environment\nSolid background in algorithms, data structures, and object-oriented programming\nStrong programing skills in Python, experience in Tensorflow or PyTorch\nNice to Haves:\nGraduate degree in Computer Science, Machine Learning or Artificial Intelligence specialization\nExperience working with cloud platforms (eg. AWS or GCP) and deploying machine learning models in cloud environments\nExperience with computer vision, generative AI models, large language models, or agentic systems\nFamiliarity with ML evaluation frameworks and agentic model design\nCompensation packages at Scale for eligible roles include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Scale employees in eligible roles are also granted equity based compensation, subject to Board of Director approval. Your recruiter can share more about the specific salary range for your preferred location during the hiring process, and confirm whether the hired role will be eligible for equity grant. You\u2019ll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.\nPlease reference the job posting's subtitle for where this position will be located. For pay transparency purposes, the base salary range for this full-time position in the locations of San Francisco, New York, Seattle is:\n$208,000\u2014$300,000 USD\nPlease reference the job posting's subtitle for where this position will be located. For pay transparency purposes, the base salary range for this full-time position in the locations of Washington DC, Texas, Colorado is:\n$187,000\u2014$270,000 USD\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, our mission is to develop reliable AI systems for the world's most important decisions. Our products provide the high-quality data and full-stack technologies that power the world's leading models, and help enterprises and governments build, deploy, and oversee AI applications that deliver real impact. We work closely with industry leaders like Meta, Cisco, DLA Piper, Mayo Clinic, Time Inc., the Government of Qatar, and U.S. government agencies including the Army and Air Force. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.", "comp": "0", "title": "Machine Learning Engineer, Public Sector", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4298157763", "loc": "Washington, DC", "company": "Scale AI"}, {"desc": "At \nScale\n, our Machine Learning Research team is focused on building the foundation for the next generation of AI systems\u2014pushing the boundaries of what\u2019s possible with frontier models while ensuring safety, reliability, and alignment at every step. Our work spans across generative AI, advanced post-training methods, scalable oversight, synthetic data pipelines, red teaming, and evaluation science.\nWe are developing a large-scale hybrid human-machine system to power machine learning pipelines for dozens of industry-leading customers. These models and systems form the backbone of Scale\u2019s long-term strategy, enabling billions of tasks monthly and supporting some of the most complex and advanced use cases in the AI ecosystem.\nYou\u2019ll be working on a combination of deeply technical ML applications in production and cutting-edge research problems, with the opportunity to collaborate with leading research teams across industry and academia.\nExample Projects\nMeasuring the dangerous capabilities of frontier models and conducting preparedness research\nResearch on the science and creation of new benchmarks for frontier models\nResearch and develop new methods for training models to excel on extremely difficult reasoning problems that require long chains of thought\nResearch scalable oversight protocols that enable humans to produce and quality control reasoning chains beyond their native capabilities\nStudying the boundaries of model generalization and capabilities to inform data-driven advancements.\nResearch on synthetic data and hybrid data with humans in the loop to scale up high-quality data generation.\nTake models currently in production, identify areas for improvement, improve them using retraining and hyperparameter searches, then deploy without regressing on core model characteristics.\nCreate post-training or agentic solutions that integrate into our ability to deliver applications for our enterprise clients\nRequired to have:\nCurrently enrolled in a BS/MS/PhD Program with a focus on Machine Learning, Deep Learning, Natural Language Processing or Computer Vision with a graduation date in Fall 2026 or Spring 2027\nPrior experience or track record of research publications on LLMs, NLP, Multimodal, agents, safety, evaluation, alignment or a related field\nExperience with one or more general purpose programming languages, including: Python, Javascript, or similar\nAbility to speak and write in English fluently\nBe available for a Summer 2026 (May/June starts) internship \nIdeally you\u2019d have:\nHave had a previous internship around Machine Learning, Deep Learning, Computer Vision, Natural Language Processing, Adversarial Robustness, Alignment, Evaluation and Agent\nExperience as a researcher, including internships, full-time, or at a lab\nPublications in top-tier journals such as NeurIPS, ICML, ICLR, CVPR, AAAI, etc. or contributions to open source projects\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, our mission is to develop reliable AI systems for the world's most important decisions. Our products provide the high-quality data and full-stack technologies that power the world's leading models, and help enterprises and governments build, deploy, and oversee AI applications that deliver real impact. We work closely with industry leaders like Meta, Cisco, DLA Piper, Mayo Clinic, Time Inc., the Government of Qatar, and U.S. government agencies including the Army and Air Force. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.", "comp": "0", "title": "Machine Learning Research Intern (Summer 2026)", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4297648330", "loc": "San Francisco Bay Area", "company": "Scale AI"}, {"desc": "Scale GP (Scale Generative AI Platform) is an enterprise-grade AI platform providing APIs for knowledge retrieval, inference, evaluation, and more. We are looking for a frontend-focused full-stack engineer to help build AI-powered applications that redefine enterprise workflows and push the boundaries of interactive AI. This role is ideal for someone who thrives in a fast-paced environment, enjoys working on a diverse set of projects, and has a passion for crafting high-quality, intuitive user experiences.\nAt Scale, you'll work on a mix of cutting-edge customer-facing AI applications and internal SaaS products. Our engineering team powers projects like \nTIME\u2019s Person of the Year AI experience\n (see it in action), where our AI technology helped shape one of the most iconic features in media. You'll also contribute to \nScale\u2019s GenAI Platform\n (SGP), a powerful system that enables businesses to build and deploy AI agents at scale. Whether it\u2019s developing interactive AI assistants, enterprise-grade web applications, or refining our core SaaS platform, you\u2019ll play a crucial role in shaping how AI integrates into real-world applications.\nYou Will:\nBuild and enhance user-facing AI applications for major enterprise customers, including high-profile media and Fortune 500 companies\nDevelop and refine features for Scale\u2019s GenAI Platform, empowering businesses to build, deploy, and manage AI-driven agents\nDesign, build, and optimize polished, high-performance UIs using Next.js, React, TypeScript, and Tailwind\nWork closely with product managers, designers, and AI/ML teams to create seamless, intuitive, and impactful user experiences\nIntegrate frontend applications with backend services, working with APIs, authentication systems, and cloud-based infrastructure\nShip features at a rapid pace while maintaining a high level of code quality, performance, and accessibility\nIdeally, You Have:\n2+ years of experience developing frontend or fullstack applications in a modern tech stack\nStrong proficiency in Next.js, React, TypeScript, and Tailwind, with an eye for building polished, user-friendly interfaces\nExperience working on high-visibility, customer-facing applications and making trade-offs between speed and quality in fast-paced environments\nA passion for AI and experience working on interactive AI applications, agent-based systems, or data-rich web platforms\nFamiliarity with backend technologies such as FastAPI, PostgreSQL, GraphQL, and cloud infrastructure like AWS, Azure, or GCP\nA track record of collaborating cross-functionally with design, product, and ML teams to bring AI-powered applications to life\nThis role is a unique opportunity to \nshape the future of AI-powered user experiences\n, working on projects that impact millions of users while developing tools that empower businesses to deploy AI at scale. If you\u2019re excited by the intersection of AI, frontend engineering, and product design, we\u2019d love to hear from you.\nThe base salary range for this full-time position in our hub locations of San Francisco, New York, or Seattle is $160,000 - $192,000. Compensation packages at Scale include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process. Scale employees are also granted Stock Options that are awarded upon board of director approval. You\u2019ll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.\nCompensation packages at Scale for eligible roles include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Scale employees in eligible roles are also granted equity based compensation, subject to Board of Director approval. Your recruiter can share more about the specific salary range for your preferred location during the hiring process, and confirm whether the hired role will be eligible for equity grant. You\u2019ll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.\nPlease reference the job posting's subtitle for where this position will be located. For pay transparency purposes, the base salary range for this full-time position in the locations of San Francisco, New York, Seattle is:\n$188,000\u2014$235,000 USD\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, our mission is to develop reliable AI systems for the world's most important decisions. Our products provide the high-quality data and full-stack technologies that power the world's leading models, and help enterprises and governments build, deploy, and oversee AI applications that deliver real impact. We work closely with industry leaders like Meta, Cisco, DLA Piper, Mayo Clinic, Time Inc., the Government of Qatar, and U.S. government agencies including the Army and Air Force. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.", "comp": "0", "title": "Senior Software Engineer, Full-Stack - Enterprise Gen AI", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4196121789", "loc": "San Francisco Bay Area", "company": "Scale AI"}, {"desc": "The next frontier for AI is the physical world. At Scale, we're pioneering this shift, moving artificial intelligence from digital spaces into robotics and autonomous systems. Our Robotics team is building the data platform that will power the future of Physical AI. We are looking for a pivotal Solutions Engineer to join this team.\nAs a Solutions Engineer, you'll be a trusted technical partner, building deep relationships with some of the world's most innovative model builders and renowned robotics companies. You will partner closely with Product, Sales and Machine Learning Engineers to guide prospective customers through the pre-sales process, delivering customized demos and pilots that secure the \"technical win.\" You'll define customer technical requirements, develop actionable Statements of Work, and collaborate with the delivery team on initial implementation. Your relentless curiosity about customer needs, combined with your expert knowledge of Scale's products will allow you to design creative and impactful solutions.\nThis is a critical role that directly influences multi-million dollar contracts and initiatives. You'll travel globally to conduct on-site technical workshops and scope new projects, while also leading demos and pilots for new prospects. You'll be part of a tight-knit, specialized team, influencing a rapidly growing business that is expanding into new product areas.\nIn this role, you will:\nPartner with Scale Account Executives and Engagement Managers to deliver new customer pilots and grow technical relationships with existing clients.\nWork with Product Engineering and Product Management to influence our product roadmap based on your frontline insights.\nBecome a domain expert in next-generation Robotics and physical AI (e.g. VLMs, VLAs, World Models)\nBe accountable for the technical customer experience and commercial growth, expanding relationships and use cases with existing customers.\nCollaborate with highly technical engineers at our customer sites to ensure satisfaction with our data, software platforms, and workflows.\nDesign and develop playbooks, demos, and other tools to ensure efficient and successful pilots and customer expansions.\nEvangelize Scale by interacting with customers at major industry events and academic conferences.\nYou have:\nA strong engineering background, preferably in Robotics, Mechatronics, Computer Science, Mathematics, or other Engineering fields.\n3+ years of experience developing with Python, C++, Java, and/or other scripting languages.\nHands-on experience in Robotics and Physical AI\nExceptional project management and interpersonal skills, strong attention to detail, and a strong sense of ownership.\nThe presentation skills and technical credibility to speak confidently with a variety of stakeholders, from executives to front-line engineers.\nA high level of comfort communicating effectively across internal and external organizations.\nRegular travel within the Bay Area.\nInternational travel approximately once every two months.\nIntellectual curiosity, empathy, and the ability to operate with a high degree of autonomy.\nBonus points if you have:\nPrior sales, solutions engineering, or partnership experience with a track record of successfully achieving quota.\nIdeally would have experience selling complex technical solutions to enterprises with deal sizes of $500K to $5M+.\nCompensation packages at Scale for eligible roles include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Scale employees in eligible roles are also granted equity based compensation, subject to Board of Director approval. Your recruiter can share more about the specific salary range for your preferred location during the hiring process, and confirm whether the hired role will be eligible for equity grant. You\u2019ll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.\nThe base salary range for this full-time position in the location of San Francisco is:\n$132,000\u2014$165,000 USD\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, our mission is to develop reliable AI systems for the world's most important decisions. Our products provide the high-quality data and full-stack technologies that power the world's leading models, and help enterprises and governments build, deploy, and oversee AI applications that deliver real impact. We work closely with industry leaders like Meta, Cisco, DLA Piper, Mayo Clinic, Time Inc., the Government of Qatar, and U.S. government agencies including the Army and Air Force. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.", "comp": "0", "title": "Solutions Engineer - Robotics", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4290268075", "loc": "San Francisco Bay Area", "company": "Scale AI"}, {"desc": "Scale is looking for an experienced Software Engineer to help shape the developer experience. The ideal candidate is someone who can design and develop automation frameworks and efficient workflows for the developer population at Scale. You will be responsible for building and maintaining automated frameworks, feature testing, code promotion, code review, and documentation, among other expectations\nWhat we are looking for:\nStrong proficiency in programming languages such as Python, Java, or Go\nExperience with cloud platforms such as AWS, GCP, or Azure\nFamiliarity with containerization technologies such as Docker and Kubernetes\nUnderstanding of infrastructure-as-code tools such as Terraform, CloudFormation, and Ansible\nKnowledge of build systems such as Bazel, Gradle, Maven or Make\nExperience with version control systems such as Git\nFamiliarity with continuous integration and deployment tools such as Jenkins, CircleCI or Github Actions Proficiency in database technologies such as MySQL, Postgres, or MongoDB\nFamiliarity with monitoring and logging tools such as Prometheus, Grafana, or ELK stack\nExperience with Agile methodologies and project management tools such as JIRA or Asana\nStrong leadership experience\nWhat You\u2019ll Do\nWork with a team of technically sophisticated engineers who make developer experience their first priority.\nSolve problems for fellow Scale engineers by understanding their needs and coming up with both tactical and strategic solutions.\nUtilize qualitative and quantitative metrics to prioritize tasks and evaluate outcomes\nProvide practical, dependable self-service tools and procedures to Scale's engineering team.\nDevelop and maintain infrastructure for artifact publishing, codegen, and import of schemas across all Scale repositories.\nBalance and prioritize conflicting objectives while working with stakeholders throughout Scale.\nProvide mentorship and lead the developer experience team.\nResponsibilities:\nImprove how Scale engineers develop, share, review, and merge code through best practices, automated testing, infrastructure, and processes.\nDeveloping tooling to make it easier and safer for Scale developers to build and evolve schemas, regardless of the use case, language, or repository they work in.\nDevelop better tooling and metrics so that we, and our users, understand the health of our systems.\nWork with developers to resolve their day-to-day issues doing development and build scalable solutions to fix or mitigate them.\nCompensation packages at Scale for eligible roles include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Scale employees in eligible roles are also granted equity based compensation, subject to Board of Director approval. Your recruiter can share more about the specific salary range for your preferred location during the hiring process, and confirm whether the hired role will be eligible for equity grant. You\u2019ll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.\nPlease reference the job posting's subtitle for where this position will be located. For pay transparency purposes, the base salary range for this full-time position in the locations of San Francisco, New York, Seattle is:\n$216,000\u2014$270,000 USD\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, our mission is to develop reliable AI systems for the world's most important decisions. Our products provide the high-quality data and full-stack technologies that power the world's leading models, and help enterprises and governments build, deploy, and oversee AI applications that deliver real impact. We work closely with industry leaders like Meta, Cisco, DLA Piper, Mayo Clinic, Time Inc., the Government of Qatar, and U.S. government agencies including the Army and Air Force. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.", "comp": "0", "title": "Staff Software Engineer - Developer Experience", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4196120821", "loc": "San Francisco Bay Area", "company": "Scale AI"}, {"desc": "Scale GP (Scale Generative AI Platform) is an enterprise-grade Generative AI platform that provides APIs for knowledge retrieval, inference, evaluation, and more. We are looking for a strong engineer to join our team and help us build and scale our product in a fast-paced environment. The ideal candidate will have a strong understanding of software engineering principles and practices, as well as experience with large-scale distributed systems. You will be responsible for owning large new areas within our product, working across backend, frontend, and interacting with LLMs and ML models. You will solve hard engineering problems in scalability and reliability.\nYou will:\nOwn large new areas within our product\nWork across backend, frontend, and interacting with LLMs and ML models\nDeliver experiments at a high velocity and level of quality to engage our customers\nWork across the entire product lifecycle from conceptualization through production\nBe able, and willing, to multi-task and learn new technologies quickly\nIdeally you'd have:\n4+ years of full-time engineering experience, post-graduation\nExperience scaling products at hyper growth startups\nExperience tinkering with or productizing LLMs, vector databases, and the other latest AI technologies\nProficient in Python or Javascript/Typescript, and SQL\nExperience with Kubernetes\nExperience with major cloud providers (AWS, Azure, GCP)\nCompensation packages at Scale for eligible roles include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Scale employees in eligible roles are also granted equity based compensation, subject to Board of Director approval. Your recruiter can share more about the specific salary range for your preferred location during the hiring process, and confirm whether the hired role will be eligible for equity grant. You\u2019ll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.\nPlease reference the job posting's subtitle for where this position will be located. For pay transparency purposes, the base salary range for this full-time position in the locations of San Francisco, New York, Seattle is:\n$156,000\u2014$195,000 USD\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, our mission is to develop reliable AI systems for the world's most important decisions. Our products provide the high-quality data and full-stack technologies that power the world's leading models, and help enterprises and governments build, deploy, and oversee AI applications that deliver real impact. We work closely with industry leaders like Meta, Cisco, DLA Piper, Mayo Clinic, Time Inc., the Government of Qatar, and U.S. government agencies including the Army and Air Force. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.", "comp": "0", "title": "Software Engineer, Enterprise AI", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4289167568", "loc": "San Francisco Bay Area", "company": "Scale AI"}, {"desc": "Scale is looking for an AI/ML Infrastructure Engineer to join our Machine Learning Infrastructure team to build out our Training Platform. You will partner closely with Machine Learning researchers to understand their requirements and apply your own domain expertise and our compute resources to accelerate experimentation throughput.\nThe ideal candidate is someone who has strong fundamentals in machine learning, backend system design, and has prior ML Infrastructure experience. You should also be comfortable with infrastructure and large scale system design, as well as diagnosing both model performance and system failures.\nYou will:\nBuild highly available, observable, performant, and cost-effective APIs for model training.\nParticipate in our team\u2019s on call process to ensure the availability of our services.\nOwn projects end-to-end, from requirements, scoping, design, to implementation, in a highly collaborative and cross-functional environment.\nExercise good taste in building systems and tools and know when to make build vs. buy tradeoffs, with an eye for cost efficiency.\nIdeally you'd have:\n4+ years of experience building machine learning training pipelines or inference services in a production setting.\nExperience with distributed training techniques such as DeepSpeed, FSDP, etc.\nExperience building, deploying, and monitoring complex microservice architectures.\nExperience with Python, Docker, Kubernetes, and Infrastructure as code (e.g. terraform).\nNice to haves:\nExperience with LLM inference latency optimization techniques, e.g. kernel fusion, quantization, dynamic batching, etc.\nExperience working with a cloud technology stack (eg. AWS or GCP).\nCompensation packages at Scale for eligible roles include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Scale employees in eligible roles are also granted equity based compensation, subject to Board of Director approval. Your recruiter can share more about the specific salary range for your preferred location during the hiring process, and confirm whether the hired role will be eligible for equity grant. You\u2019ll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.\nPlease reference the job posting's subtitle for where this position will be located. For pay transparency purposes, the base salary range for this full-time position in the locations of San Francisco, New York, Seattle is:\n$160,000\u2014$225,600 USD\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, our mission is to develop reliable AI systems for the world's most important decisions. Our products provide the high-quality data and full-stack technologies that power the world's leading models, and help enterprises and governments build, deploy, and oversee AI applications that deliver real impact. We work closely with industry leaders like Meta, Cisco, DLA Piper, Mayo Clinic, Time Inc., the Government of Qatar, and U.S. government agencies including the Army and Air Force. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.", "comp": "0", "title": "Software Engineer, ML Infrastructure - Training Platform", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4199021040", "loc": "San Francisco Bay Area", "company": "Scale AI"}, {"desc": "Scale\u2019s ML platform (RLXF) team builds our internal distributed framework for large language model training and inference. The platform has been powering MLEs, researchers, data scientists and operators for fast and automatic training and evaluation of LLM's, as well as evaluation of data quality.\nScale is uniquely positioned at the heart of the field of AI as an indispensable provider of training and evaluation data and end-to-end solutions for the ML lifecycle. You will work closely across Scale\u2019s ML teams and researchers to build the foundation platform that supports all our ML research and development. You will be building and optimizing the platform to enable our next generation of LLM training, inference and data curation.\nIf you are excited about shaping the future AI via fundamental innovations, we would love to hear from you!\nYou will:\nBuild, profile and optimize our training and inference framework\nCollaborate with ML teams to accelerate their research and development and enable them to develop the next generation of models and data curation\nResearch and integrate state-of-the-art technologies to optimize our ML system\nIdeally you\u2019d have:\nStrong excitement about system optimization\nExperience with multi-node LLM training and inference\nExperience with developing large-scale distributed ML systems\nStrong software engineering skills, proficient in frameworks and tools such as CUDA, Pytorch, transformers, flash attention, etc. \nStrong written and verbal communication skills and the ability to operate in a cross functional team environment\nNice to haves:\nDemonstrated expertise in post-training methods &/or next generation use cases for large language models including instruction tuning, RLHF, tool use, reasoning, agents, and multimodal, etc.\nCompensation packages at Scale for eligible roles include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Scale employees in eligible roles are also granted equity based compensation, subject to Board of Director approval. Your recruiter can share more about the specific salary range for your preferred location during the hiring process, and confirm whether the hired role will be eligible for equity grant. You\u2019ll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.\nPlease reference the job posting's subtitle for where this position will be located. For pay transparency purposes, the base salary range for this full-time position in the locations of San Francisco, New York, Seattle is:\n$200,800\u2014$251,000 USD\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, our mission is to develop reliable AI systems for the world's most important decisions. Our products provide the high-quality data and full-stack technologies that power the world's leading models, and help enterprises and governments build, deploy, and oversee AI applications that deliver real impact. We work closely with industry leaders like Meta, Cisco, DLA Piper, Mayo Clinic, Time Inc., the Government of Qatar, and U.S. government agencies including the Army and Air Force. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.", "comp": "0", "title": "ML Research Engineer, ML Systems", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4196120844", "loc": "San Francisco Bay Area", "company": "Scale AI"}, {"desc": "Scale\u2019s Robotics business unit is dedicated to solving the data bottleneck in Physical AI. This position will be a key contributor in conducting applied research in Robotics and developing ML pipelines for training and fine-tuning on data collected by Scale. In this role, you will have the opportunity to advance Robotic research, shape Scale\u2019s robotics offerings, and expand the frontier of Robotics data and model evaluation.\nYou will:\nCollaborate closely with Robotics customers to drive the industry forward in using VLA data\nDevelop ML pipelines to train/fine-tune models using Scale\u2019s data\nConduct research on robotics data collection, cross-embodiment training, and policy fine-tuning\nDevelop novel methods for evaluating VLA models, including new robotics industry benchmarks\nPartner with cross-functional stakeholders and Scale\u2019s customers to improve data collection\nCollaborate with product teams to bring ML outcomes to Scale\u2019s platform\nYou have:\nPractical experience building training VLA models and/or building robotics data\n3+ years of relevant industry experience in areas relating to: robotics, computer vision, embodied AI, sim-to-real, imitation learning, reinforcement learning, and vision language actions models \nPhD or equivalent experience in Machine Learning or Robotics\nA track record of published research in robotics\nExperience conducting data collection and performing evaluations\nStrong written and verbal communication skills and the ability to work with cross-functional teams and customers\nIntellectual curiosity, empathy, and ability to operate with a high degree of autonomy\nNice to haves:\nExperience working with robotics hardware platforms (robotic arms, perception systems, etc.)\nExperience deploying machine learning models on robotic systems in the field\nExperience with teleoperated or human-driven data for robotics (ALOHA, UMI, hand tracking, etc.)\nCompensation packages at Scale for eligible roles include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Scale employees in eligible roles are also granted equity based compensation, subject to Board of Director approval. Your recruiter can share more about the specific salary range for your preferred location during the hiring process, and confirm whether the hired role will be eligible for equity grant. You\u2019ll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.\nThe base salary range for this full-time position in the location of San Francisco is:\n$208,000\u2014$260,000 USD\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, our mission is to develop reliable AI systems for the world's most important decisions. Our products provide the high-quality data and full-stack technologies that power the world's leading models, and help enterprises and governments build, deploy, and oversee AI applications that deliver real impact. We work closely with industry leaders like Meta, Cisco, DLA Piper, Mayo Clinic, Time Inc., the Government of Qatar, and U.S. government agencies including the Army and Air Force. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.", "comp": "0", "title": "Machine Learning Research Engineer - Robotics", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4290264646", "loc": "San Francisco Bay Area", "company": "Scale AI"}, {"desc": "Scale AI is seeking a highly skilled and motivated \nSoftware Engineer, AI Infrastructure & Security \n to join our dynamic Public Sector Engineering team. As a part of this team, you will play a critical role in delivering high-impact AI-powered mission solutions for government customers. Our scalable and high-performance platform forms the foundation for these solutions, and your expertise will be instrumental in designing and implementing systems that can handle billions of data points with exceptional performance.\nYou will:\nDesign and implement secure scalable backend systems for Public Sector customers, leveraging Scale's modern and cloud-native AI infrastructure.\nOwn services or systems and define their long-term health goals, while also improving the health of surrounding components\nImprove our high engineering standards, tooling, and process\nCollaborate with cross-functional teams to define and execute the vision for backend solutions, ensuring they meet the unique needs of government agencies operating in secure environments.\nParticipate actively in customer engagements, working closely with stakeholders to understand requirements and deliver innovative solutions.\nContribute to the platform roadmap and product strategy for Scale AI's Public Sector business, playing a key role in shaping the future direction of our offerings.\nIdeally you'd have: \nAn active security clearance, and the ability to obtain a TS/SCI with CI Poly. This is a requirement and candidates will not be considered who do not hold this level of clearance\nFull Stack Development: Proficiency in both front-end and back-end development, including experience with modern web development frameworks, programming languages, and databases. Experience with developing & delivering software to air-grapped & isolated environments is a plus.\nCloud-Native Technologies: Understanding of containerization (e.g., Docker) and container orchestration (e.g., Kubernetes) is desired. Familiarity with cloud platforms (e.g., AWS, Azure, GCP) and experience in developing and deploying applications in a cloud-native environment. \nSecurity Focused: Experience with Federal Compliance frameworks, and requirements(e.g, Cloud SRG, FedRAMP, STIG Benchmarks, etc). Experience developing software & technical solutions that meet strict security & regulatory compliance requirements.\nProblem Solving: Strong analytical and problem-solving skills to understand complex challenges and devise effective solutions. Ability to think critically, identify root causes, and propose innovative approaches to overcome technical obstacles.\nCollaboration and Communication: Excellent interpersonal and communication skills to effectively collaborate with cross-functional teams, stakeholders, and customers. Ability to clearly articulate technical concepts to non-technical audiences and foster a collaborative work environment.\nAdaptability and Learning Agility: Willingness to embrace new technologies, learn new skills, and adapt to evolving project requirements. Ability to quickly grasp and apply new concepts and stay up-to-date with emerging trends in software engineering.\nMust be able to support work 3-4 days a week from the DC or STL office.\nCompensation packages at Scale for eligible roles include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Scale employees in eligible roles are also granted equity based compensation, subject to Board of Director approval. Your recruiter can share more about the specific salary range for your preferred location during the hiring process, and confirm whether the hired role will be eligible for equity grant. You\u2019ll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.\nPlease reference the job posting's subtitle for where this position will be located. For pay transparency purposes, the base salary range for this full-time position in the locations of San Francisco, New York, Seattle is:\n$184,000\u2014$259,440 USD\nThe base salary range for this full-time position in the locations of Washington DC, Texas, Colorado is:\n$165,600\u2014$233,496 USD\nThe base salary range for this full-time position in the location of Hawaii/St. Louis is:\n$138,000\u2014$194,580 USD\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, our mission is to develop reliable AI systems for the world's most important decisions. Our products provide the high-quality data and full-stack technologies that power the world's leading models, and help enterprises and governments build, deploy, and oversee AI applications that deliver real impact. We work closely with industry leaders like Meta, Cisco, DLA Piper, Mayo Clinic, Time Inc., the Government of Qatar, and U.S. government agencies including the Army and Air Force. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.", "comp": "0", "title": "Infrastructure Software Engineer, Public Sector", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4196126145", "loc": "San Francisco Bay Area", "company": "Scale AI"}, {"desc": "Solutions Engineer - Public Sector \nOur customer base is growing exponentially, and you will be on the front lines to ensure that the world's most innovative companies and governments become passionate, committed Scale partners. No two days at Scale are the same and we\u2019re looking for creative, action-oriented Solutions Engineers who are excited to solve tough problems with an AI-first mindset. Solutions Engineers at Scale ensure our customers' first experiences with our products and technology are flawless, and coordinate across the organization to ensure successful long-term partnerships. As a Solutions Engineer, you will drive growth in our federal business by enhancing existing initiatives and creating new opportunities for dual-use technologies that serve both commercial and government needs.\nWhat you'll do:\nBe an expert on Scale products and technologies.\nCreate tailored demonstrations and collateral for federal and select international stakeholders across the executive to analyst level.\nPartner with Scale Deployment Strategists to build relationships, advance business opportunities, and deliver customer pilots guided by their requirements.\nInteract with customers on a day-to-day basis to understand their pain points and design solutions. To understand and anticipate their priorities, you will research their problem space and procure relevant data to build impactful and relatable demonstrations of Scale product offerings. \nLeverage creative problem-solving skills to design and implement innovative solutions that push the boundaries of Generative AI and Computer Vision technologies, transforming complex challenges into actionable applications. \nWork with internal product and engineering teams to turn customer requirements into Scale capabilities through prototyping, product management, and collaboration with engineering teams.\nUnderstand public sector mission sets and strategic objectives to best showcase Scale\u2019s products.\nIdeally you'd have:\nTechnical background, preferably in statistics, mathematics, machine learning, computer science or other quantitative fields. \nCreative bias - able to think outside the box, connect cross-domain ideas, and develop unique solutions to technical challenges, all while grounding innovation in solid technical expertise. \nStrong communication skills - ability to interact with both technical and non-technical customers at all levels. \nAt ease with technology, able to quickly pick up new tech stacks and troubleshoot complex systems.\nPrevious experience working with Public Sector customers - our business is diverse and growing across National Security, Federal Civilian, and International partner communities. \nProficiency in common scripting languages such as Python, YAML, or other data analysis / application builder programming languages.\nA strong desire to roll up your sleeves and help build a business in an extremely fast-paced environment.\nStrong preference for a SE based in Washington, DC area. Open to considering candidates in other locales.\nAbility to travel up to 30% of the time.\nNice to have:\nBackground working in applied AI/ML, particularly Generative AI / Large Language Models or Computer Vision\nActive US Government Security Clearance\nCompensation packages at Scale for eligible roles include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Scale employees in eligible roles are also granted equity based compensation, subject to Board of Director approval. Your recruiter can share more about the specific salary range for your preferred location during the hiring process, and confirm whether the hired role will be eligible for equity grant. You\u2019ll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.\nThe base salary range for this full-time position in the location of Washington DC is:\n$140,000\u2014$175,000 USD\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, our mission is to develop reliable AI systems for the world's most important decisions. Our products provide the high-quality data and full-stack technologies that power the world's leading models, and help enterprises and governments build, deploy, and oversee AI applications that deliver real impact. We work closely with industry leaders like Meta, Cisco, DLA Piper, Mayo Clinic, Time Inc., the Government of Qatar, and U.S. government agencies including the Army and Air Force. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.", "comp": "0", "title": "Solutions Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4292035460", "loc": "Washington, DC", "company": "Scale AI"}, {"desc": "Scale AI is seeking a highly skilled and motivated Mission Software Engineer to join our dynamic Federal Engineering team. As a part of this team, you will play a critical role in supporting Scale\u2019s government customers by scoping and developing onsite solutions. Our scalable, high-performance platform is the foundation for these customer solutions, and your expertise will be instrumental in designing and implementing systems that can handle interactions with existing customer systems to help our products integrate into existing customer workflows.\nYou will:\nWork directly with customers to understand their problems and translate those into features in Scale\u2019s platform.\nBe open to >50% travel or relocation to a key customer geographic location.\nCollaborate with cross-functional teams to define and execute the vision for backend solutions, ensuring they meet the unique needs of government agencies operating in secure environments.\nImplement end-to-end data integrations, syncing customer\u2019s data to Scale\u2019s platform and back\nDeploy and maintain Scale software at customer sites\nDevelop customer requested features and work closely with them to ensure that they win customer love.\nBuild robust and reliable backend systems that can serve as standalone products, empowering customers to accelerate their own AI ambitions.\nParticipate actively in customer engagements, working closely with stakeholders to understand requirements and deliver innovative solutions.\nThis role will require an active TS/SCI security clearance or the ability to obtain a security clearance.\nIdeally you have:\nTrack record of success as a hybrid customer facing engineer, forward deployed software engineer, and ability to quickly adapt to different roles.\nPrior experience developing with Python and JavaScript, or other modern software languages. Familiarity with Node and React is a plus.\nCloud-Native Technologies: Familiarity with cloud platforms (e.g., AWS, Azure, GCP) and experience in developing and deploying applications in a cloud-native environment. Understanding of containerization (e.g., Docker) and container orchestration (e.g., Kubernetes) is a plus\nLinux experience: Understanding of shell scripting, operating systems, etc\nNetworking experience: Understanding of networking technologies, configuration (ports, protocols, etc) \nData Engineering: Knowledge of ETL (Extract, Transform, Load) processes and experience in building data pipelines to integrate and process diverse data sources. Understanding of data modeling, data warehousing, and data governance principles\nProblem Solving: Strong analytical and problem-solving skills to understand complex challenges and devise effective solutions. Ability to think critically, identify root causes, and propose innovative approaches to overcome technical obstacles\nCompensation packages at Scale for eligible roles include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Scale employees in eligible roles are also granted equity based compensation, subject to Board of Director approval. Your recruiter can share more about the specific salary range for your preferred location during the hiring process, and confirm whether the hired role will be eligible for equity grant. You\u2019ll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.\nPlease reference the job posting's subtitle for where this position will be located. For pay transparency purposes, the base salary range for this full-time position in the locations of San Francisco, New York, Seattle is:\n$184,000\u2014$292,560 USD\nThe base salary range for this full-time position in the locations of Washington DC, Texas, Colorado is:\n$165,600\u2014$263,304 USD\nThe base salary range for this full-time position in the location of Hawaii/St. Louis is:\n$138,000\u2014$219,420 USD\nCompensation packages at Scale for eligible roles include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Scale employees in eligible roles are also granted equity based compensation, subject to Board of Director approval. Your recruiter can share more about the specific salary range for your preferred location during the hiring process, and confirm whether the hired role will be eligible for equity grant. You\u2019ll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.\nThe base salary range for this full-time position in the location of Honolulu, Hawaii is:\n$138,000\u2014$219,420 USD\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, our mission is to develop reliable AI systems for the world's most important decisions. Our products provide the high-quality data and full-stack technologies that power the world's leading models, and help enterprises and governments build, deploy, and oversee AI applications that deliver real impact. We work closely with industry leaders like Meta, Cisco, DLA Piper, Mayo Clinic, Time Inc., the Government of Qatar, and U.S. government agencies including the Army and Air Force. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.", "comp": "0", "title": "Mission Software Engineer, Public Sector", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4196126148", "loc": "San Francisco Bay Area", "company": "Scale AI"}, {"desc": "As Scale's product portfolio and customer base expand, we are seeking skilled \nDevOps Engineers, Public Sector\n to be at the forefront of building out and enhancing our CI/CD pipelines. You will play a crucial role in streamlining our Software Development Life Cycle (SDLC) through collaborative efforts, moving us from a state of manual, disparate deployments to a more unified and automated system.\nThese engineers will gain a deep understanding of our core products' architecture and composition, enabling them to effectively deploy and manage these systems when needed. A critical aspect of this role will be seamlessly integrating various machine learning (ML) tasks and updates into our SDLC, transforming currently separate ML components into a cohesive and automated workflow. While direct ML expertise is not required, a desire to learn and integrate ML components into the lifecycle is essential.\nYou will:\nDesign, develop, and maintain robust CI/CD pipelines to automate the deployment of our lowside and highside products.\nCollaborate closely with product and engineering teams to enhance existing application code for improved compatibility and streamlined integration within automated pipelines.\nContribute to the overall architecture and design of our deployment systems, bringing new ideas to life for increased efficiency and reliability.\nTroubleshoot and resolve complex deployment issues, ensuring minimal disruption to development cycles.\nDevelop a deep understanding of our product and ML architectures to facilitate seamless integration and deployment.\nDocument pipeline processes and configurations to ensure maintainability and knowledge transfer.\nProactively incorporate security best practices into all stages of the CI/CD pipeline, building security into our development processes.\nDrive standardization and foster collaboration across different product teams to achieve a unified and efficient SDLC.\nIdeally you'd have:\n2-3 years of experience as a DevOps Engineer, DevSecOps Engineer, Software Engineer with a strong focus on CI/CD, or a similar role.\nProven track record of building or significantly enhancing CI/CD pipelines.\nExperience configuring and adapting application code to integrate seamlessly with evolving CI/CD environments.\nStrong proficiency in scripting and automation (e.g., Python, Bash, PowerShell).\nFamiliarity with various CI/CD platforms (e.g., Jenkins, GitLab CI, GitHub Actions, Azure DevOps).\nKnowledge of software architecture, system design, and version control systems.\nComfort with rapidly changing, fast-paced environments and a passion for finding automated solutions to complex problems.\nBasic understanding of security best practices in software development and an eagerness to integrate them.\nA hunger for learning new technologies, particularly in the realm of integrating ML into automated workflows.\nStrong problem-solving, analytical, collaboration, and communication skills.\nPossession of an active Secret or TS/SCI clearance is beneficial, but not a requirement, for this Public Sector position.\nNice to haves:\nFamiliarity with cloud platforms (e.g., AWS, Azure, GCP).\nExperience with containerization technologies (e.g., Docker, Kubernetes).\nExposure to machine learning lifecycles or MLOps concepts.\nPrior experience in classified environments.\nCompensation packages at Scale for eligible roles include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Scale employees in eligible roles are also granted equity based compensation, subject to Board of Director approval. Your recruiter can share more about the specific salary range for your preferred location during the hiring process, and confirm whether the hired role will be eligible for equity grant. You\u2019ll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.\nPlease reference the job posting's subtitle for where this position will be located. For pay transparency purposes, the base salary range for this full-time position in the locations of San Francisco, New York, Seattle is:\n$156,000\u2014$195,000 USD\nPlease reference the job posting's subtitle for where this position will be located. For pay transparency purposes, the base salary range for this full-time position in the locations of Washington DC, Texas, Colorado is:\n$140,000\u2014$176,000 USD\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, our mission is to develop reliable AI systems for the world's most important decisions. Our products provide the high-quality data and full-stack technologies that power the world's leading models, and help enterprises and governments build, deploy, and oversee AI applications that deliver real impact. We work closely with industry leaders like Meta, Cisco, DLA Piper, Mayo Clinic, Time Inc., the Government of Qatar, and U.S. government agencies including the Army and Air Force. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.", "comp": "0", "title": "DevOps Engineer, Public Sector", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4289333662", "loc": "San Francisco Bay Area", "company": "Scale AI"}, {"desc": "Software is eating the world, but AI is eating software. We live in unprecedented times \u2013 AI has the potential to exponentially augment human intelligence. Every person will have a personal tutor, coach, assistant, personal shopper, travel guide, and therapist throughout life. As the world adjusts to this new reality, leading platform companies are scrambling to build LLMs at billion scale, while large enterprises figure out how to add it to their products. To make them safe, aligned and actually useful, these models need human eval and reinforcement learning through human feedback (RLHF) during pre-training, fine-tuning, and production evaluations. This is the main innovation that\u2019s enabled ChatGPT to get such a large headstart among competition.\nAt Scale, our products include the Generative AI Data Engine, SGP, Donovan, and others that power the most advanced LLMs and generative models in the world through world-class RLHF, human data generation, model evaluation, safety, and alignment. The data we are producing is some of the most important work for how humanity will interact with AI.\nAt the foundation of these products is the Platform Engineering team. In this role, you will help support the design and development of core platforms and software systems, while supporting identity, access management, authorization, and authentication. You\u2019ll also get widespread exposure to the forefront of the AI race as Scale sees it in enterprises, startups, governments, and large tech companies.\nYou will:\nDrive the architecture, design, and implementation of our foundational platforms and systems, working closely with stakeholders and internal customers to understand and refine requirements.\nDirectly manage or mentor small teams of software engineers ranging from new grads to experienced engineers.\nCollaborate with cross-functional teams to define, design, and deliver new features.\nProactively identify opportunities for, and driving improvements to, current programming practices, including process enhancements and tool upgrades.\nPresent technical information to teams and stakeholders, providing guidance and insight on development processes and technologies.\nIdeally you\u2019d have:\n8+ years of full-time engineering experience, post-graduation with specialities in back-end systems.\nExtensive experience in software development and a deep understanding of distributed systems and public cloud platforms (AWS preferred).\nShow a track record of independent ownership of successful engineering projects.\nPossess excellent communication and collaboration skills, and the ability to translate complex technical concepts to non-technical stakeholders.\nExperience working fluently with standard containerization & deployment technologies like Kubernetes, Terraform, Docker, etc.\nExperience with modern web frameworks like NodeJS, NextJS, etc.\nExperience with cloud networking with Kubernetes and service mesh (istio).\nExperience with orchestration platforms, such as Temporal and AWS Step Functions.\nStrong knowledge of software engineering best practices and CI/CD tooling (CircleCI, ArgoCD).\nNice to haves:\nExperience with data warehouses (Snowflake, Firebolt) and data pipeline/ETL tools (Dagster, dbt).\nExperience with authentication/authorization systems (Zanzibar, Authz, etc.)\nExperience scaling products at hyper-growth startups.\nExcitement to work with AI technologies.\nCompensation packages at Scale for eligible roles include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Scale employees in eligible roles are also granted equity based compensation, subject to Board of Director approval. Your recruiter can share more about the specific salary range for your preferred location during the hiring process, and confirm whether the hired role will be eligible for equity grant. You\u2019ll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.\nThe base salary range for this full-time position in the location of San Francisco is:\n$216,000\u2014$270,000 USD\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, our mission is to develop reliable AI systems for the world's most important decisions. Our products provide the high-quality data and full-stack technologies that power the world's leading models, and help enterprises and governments build, deploy, and oversee AI applications that deliver real impact. We work closely with industry leaders like Meta, Cisco, DLA Piper, Mayo Clinic, Time Inc., the Government of Qatar, and U.S. government agencies including the Army and Air Force. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.", "comp": "0", "title": "Staff Software Engineer, Platform", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4289337194", "loc": "San Francisco Bay Area", "company": "Scale AI"}, {"desc": "AI is becoming vitally important in every function of our society. At Scale, our mission is to accelerate the development of AI applications. For 8 years, Scale has been the leading AI data foundry, helping fuel the most exciting advancements in AI, including: generative AI, defense applications, and autonomous vehicles. With our recent Series F round, we\u2019re accelerating the usage of frontier data and models by building complex agents for enterprises around the world through our Scale Generative Platform (SGP).\nThe SGP ML team works on the front lines of this AI revolution. We interface directly with clients to build cutting edge products using the arsenal of proprietary research and resources developed at Scale. As an Applied AI Engineer, you\u2019ll work with clients to create ML solutions to satisfy their business needs. Your work will range from building next-generation AI cybersecurity firewalls to creating transformative AI experiences in journalism to applying foundation genomic models making predictions about life-saving drug proteins. Daily data-driven experiments will provide key insights around model strengths and inefficiencies which you\u2019ll use to improve your product\u2019s performance. If you are excited about shaping the future of the modern AI movement, we would love to hear from you!\nYou will:\nOwn, plan, and optimize the AI behind our Enterprise customer\u2019s deepest technical problems\nLeverage SGP to build the most advanced AI agents across the industry including multimodal functionality, tool-calling, and more\nHave experience gathering business requirements and translating them into technical solutions \nMeet regularly with customer teams onsite and virtually, collaborating cross-functionally with all teams responsible for their data and ML needs\nPush production code in multiple development environments, writing and debugging code directly in both our customer\u2019s and Scale\u2019s codebases.\nBe able and willing to multi-task and learn new technologies quickly\nIdeally you'd have:\nA love for solving deeply complex technical problems with ambiguity using state of the art research and AI to accomplish your client\u2019s business goals\nStrong engineering background: a Bachelor\u2019s degree in Computer Science, Mathematics, or another quantitative field or equivalent strong engineering background.\nDeep familiarity with a data-driven approach when iterating on machine learning models and how changes in datasets can influence model results\nExperience working with cloud technology stack (eg. AWS or GCP) and developing machine learning models in a cloud environment\nProficiency in Python to write, test and debug code using common libraries (ie numpy, pandas)\nNice to haves:\nStrong knowledge of software engineering best practices\nHave built applications taking advantage of Generative AI in real, production use cases\nFamiliarity with state of the art LLMs and their strengths/weaknesses\nCompensation packages at Scale for eligible roles include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Scale employees in eligible roles are also granted equity based compensation, subject to Board of Director approval. Your recruiter can share more about the specific salary range for your preferred location during the hiring process, and confirm whether the hired role will be eligible for equity grant. You\u2019ll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.\nPlease reference the job posting's subtitle for where this position will be located. For pay transparency purposes, the base salary range for this full-time position in the locations of San Francisco, New York, Seattle is:\n$168,200\u2014$248,500 USD\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, our mission is to develop reliable AI systems for the world's most important decisions. Our products provide the high-quality data and full-stack technologies that power the world's leading models, and help enterprises and governments build, deploy, and oversee AI applications that deliver real impact. We work closely with industry leaders like Meta, Cisco, DLA Piper, Mayo Clinic, Time Inc., the Government of Qatar, and U.S. government agencies including the Army and Air Force. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.", "comp": "0", "title": "Applied AI Engineer, Enterprise GenAI", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4196119841", "loc": "San Francisco Bay Area", "company": "Scale AI"}, {"desc": "As a Software Engineer on the ML Infrastructure team, you will design and build platforms for scalable, reliable, and efficient serving of LLMs. Our platform powers cutting-edge research and production systems, supporting both internal and external use cases across various environments.\nThe ideal candidate combines strong ML fundamentals with deep expertise in backend system design. You\u2019ll work in a highly collaborative environment, bridging research and engineering to deliver seamless experiences to our customers and accelerate innovation across the company.\nYou will:\nBuild and maintain fault-tolerant, high-performance systems for serving LLMs workloads at scale.\nBuild an internal platform to empower LLM capability discovery.\nCollaborate with researchers and engineers to integrate and optimize models for production and research use cases.\nConduct architecture and design reviews to uphold best practices in system design and scalability.\nDevelop monitoring and observability solutions to ensure system health and performance.\nLead projects end-to-end, from requirements gathering to implementation, in a cross-functional environment. \nIdeally you'd have:\n4+ years of experience building large-scale, high-performance backend systems.\nStrong programming skills in one or more languages (e.g., Python, Go, Rust, C++).\nExperience with LLM serving and routing fundamentals (e.g. rate limiting, token streaming, load balancing, budgets, etc.)\nExperience with LLM capabilities and concepts such as reasoning, tool calling, prompt templates, etc.\nExperience with containers and orchestration tools (e.g., Docker, Kubernetes).\nFamiliarity with cloud infrastructure (AWS, GCP) and infrastructure as code (e.g., Terraform).\nProven ability to solve complex problems and work independently in fast-moving environments.\nNice to haves:\nExperience with modern LLM serving frameworks such as vLLM, SGLang, TensorRT-LLM, or text-generation-inference.\nCompensation packages at Scale for eligible roles include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Scale employees in eligible roles are also granted equity based compensation, subject to Board of Director approval. Your recruiter can share more about the specific salary range for your preferred location during the hiring process, and confirm whether the hired role will be eligible for equity grant. You\u2019ll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.\nPlease reference the job posting's subtitle for where this position will be located. For pay transparency purposes, the base salary range for this full-time position in the locations of San Francisco, New York, Seattle is:\n$175,000\u2014$220,000 USD\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, our mission is to develop reliable AI systems for the world's most important decisions. Our products provide the high-quality data and full-stack technologies that power the world's leading models, and help enterprises and governments build, deploy, and oversee AI applications that deliver real impact. We work closely with industry leaders like Meta, Cisco, DLA Piper, Mayo Clinic, Time Inc., the Government of Qatar, and U.S. government agencies including the Army and Air Force. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.", "comp": "0", "title": "AI Infrastructure Engineer, Model Serving Platform", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4196120822", "loc": "San Francisco Bay Area", "company": "Scale AI"}, {"desc": "Scale plays a vital role in the development of AI applications. Our customer base is growing exponentially, and you will be on the front lines, ensuring that the world's most innovative companies become passionate, lifelong Scale customers.\nSolutions Engineers partner closely with AEs, Product, and MLEs to lead prospective customers through pre-sales, delivering customized demos and pilots to secure the \u201ctechnical win\u201d. Solutions Engineers scope customer technical requirements and develop an actionable SOW. They will work closely with the delivery team to help with initial implementation. Solutions Engineers are relentlessly curious about customer needs and pain points. They employ their expert Scale product knowledge and GenAI knowledge to design solutions that best address these needs. Solutions Engineers are strong relationship builders, great project managers, and provide technical expertise.\nYou will:\nPartner with Scale AEs on the customer journey, delivering tailored demos and prototypes according to the customer's requirements.\nDevelop technical domain expertise in Generative AI / large language model applications for Enterprise use cases, including customers in financial services, insurance, SaaS, and similar enterprises.\nBe accountable for securing the \u201ctechnical win\u201d by unblocking technical challenges\nInteract with customers daily to understand their needs and design solutions to better serve them.\nDesign and develop \u201cScopes of Work\u201d by breaking down customer challenges into a project plan\nWork closely with forward-deployed Software and Machine learning Engineers to develop agents in the initial post-sales stage\nWork with AEs and PMs to identify customer-specific feature requests.\nDrive strategic initiatives to improve the efficiency and effectiveness of the Solution Engineering team.\nIdeally, you'd have:\nStrong engineering background with prior experience working with clients in a pre or post-sales capacity to realize business goals.\nPrior experience developing with Python, Java and/or other web development languages.\nExperience working in enterprise SaaS, cloud tech, finance, fintech or similar industries in a technical capacity with end-customer engagement.\nA track record as a self-starter, motivated to independently unblock technical issues in the field with the customer, away from the mothership.\nPresentation skills with a high degree of technical credibility when speaking with executives and front-line engineers.\nHigh level of comfort communicating effectively across internal and external organizations.\nIntellectual curiosity, empathy, and ability to operate with high velocity.\nNice to haves:\nGenAI Experience\nForward deployed engineering experience\nMachine Learning Experience\nCompensation packages at Scale for eligible roles include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Scale employees in eligible roles are also granted equity based compensation, subject to Board of Director approval. Your recruiter can share more about the specific salary range for your preferred location during the hiring process, and confirm whether the hired role will be eligible for equity grant. You\u2019ll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.\nPlease reference the job posting's subtitle for where this position will be located. For pay transparency purposes, the base salary range for this full-time position in the locations of San Francisco, New York, Seattle is:\n$156,000\u2014$195,000 USD\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, our mission is to develop reliable AI systems for the world's most important decisions. Our products provide the high-quality data and full-stack technologies that power the world's leading models, and help enterprises and governments build, deploy, and oversee AI applications that deliver real impact. We work closely with industry leaders like Meta, Cisco, DLA Piper, Mayo Clinic, Time Inc., the Government of Qatar, and U.S. government agencies including the Army and Air Force. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.", "comp": "0", "title": "Solutions Engineer, Enterprise", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4215019919", "loc": "San Francisco Bay Area", "company": "Scale AI"}, {"desc": "As a Software Engineer on the ML Infrastructure team, you will design and build the platform for our agent sandboxing platform: the secure, high-performance code execution layer powering our agentic workflows. This system underpins critical applications and research initiatives, and is deployed across both internal and customer-managed environments.\nThis position requires deep expertise in systems engineering: operating systems, virtualization, networking, containers, and performance optimization. Your work will directly enable agents to execute untrusted or user-submitted code safely, efficiently, and repeatedly, and with fast startup times, strong isolation guarantees, and support for snapshotting and inspection.\nYou will:\nDesign and build the sandboxing platform for code execution across containerized and virtualized environments.\nEnsure strong isolation, security, and reproducibility of execution across user sessions and workloads.\nOptimize for cold-start latency, memory footprint, and resource utilization at scale.\nCollaborate across security, infra, and product teams to support both internal research use cases and enterprise customer deployments.\nLead architecture reviews and own projects from design through deployment in fast-paced, cross-functional settings.\nIdeally you'd have:\n3+ years of experience building high-performance systems software (e.g. OS, container runtime, VMM, networking stack).\nDeep understanding of Linux internals, process isolation, memory management, cgroups, namespaces, etc.\nExperience with containerization and virtualization technologies (e.g., Docker, Firecracker, gVisor, QEMU, Kata Containers).\nProficiency in a systems programming language such as Go, Rust, or C/C++.\nFamiliarity with networking, security hardening, sandboxing techniques, and kernel-level performance tuning.\nComfort working across infrastructure layers, from kernel modules to orchestration frameworks (e.g., Kubernetes).\nStrong debugging skills and the ability to make performance/security tradeoffs in production systems.\nNice to haves:\nFamiliarity with LLM agents and agent frameworks (e.g., OpenHands, Agent2Agent, MCP).\nExperience running secure workloads in multi-tenant or untrusted environments (e.g., FaaS, CI sandboxes, remote notebooks).\nExposure to snapshotting and restore techniques (e.g., CRIU, VM snapshots, overlayfs).\nCompensation packages at Scale for eligible roles include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Scale employees in eligible roles are also granted equity based compensation, subject to Board of Director approval. Your recruiter can share more about the specific salary range for your preferred location during the hiring process, and confirm whether the hired role will be eligible for equity grant. You\u2019ll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.\nPlease reference the job posting's subtitle for where this position will be located. For pay transparency purposes, the base salary range for this full-time position in the locations of San Francisco, New York, Seattle is:\n$156,000\u2014$225,600 USD\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, our mission is to develop reliable AI systems for the world's most important decisions. Our products provide the high-quality data and full-stack technologies that power the world's leading models, and help enterprises and governments build, deploy, and oversee AI applications that deliver real impact. We work closely with industry leaders like Meta, Cisco, DLA Piper, Mayo Clinic, Time Inc., the Government of Qatar, and U.S. government agencies including the Army and Air Force. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.", "comp": "0", "title": "AI Infrastructure Engineer, Agents", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4279952557", "loc": "New York City Metropolitan Area", "company": "Scale AI"}, {"desc": "Scale works with the industry\u2019s leading AI labs to provide high quality data and accelerate progress in GenAI research. We are looking for Research Scientists and Research Engineers with expertise in LLM post-training (SFT, RLHF, reward modeling). This role will focus on optimizing data curation and eval to enhance LLM capabilities in both text and multimodal modalities.\nIn this role, you will develop novel methods to improve the alignment and generalization of large-scale generative models. You will collaborate with researchers and engineers to define best practices in data-driven AI development. You will also partner with top foundation model labs to provide both technical and strategic input on the development of the next generation of generative AI models.\nYou will:\nResearch and develop novel post-training techniques, including SFT, RLHF, and reward modeling, to enhance LLM core capabilities in both text and multimodal modalities.\nDesign and experiment new approaches to preference optimization.\nAnalyze model behavior, identify weaknesses, and propose solutions for bias mitigation and model robustness.\nPublish research findings in top-tier AI conferences.\nIdeally you\u2019d have:\nPh.D. or Master's degree in Computer Science, Machine Learning, AI, or a related field.\nDeep understanding of deep learning, reinforcement learning, and large-scale model fine-tuning.\nExperience with post-training techniques such as RLHF, preference modeling, or instruction tuning.\nExcellent written and verbal communication skills\nPublished research in areas of machine learning at major conferences (NeurIPS, ICML, ICLR, ACL, EMNLP, CVPR, etc.) and/or journals\nPrevious experience in a customer facing role.\nCompensation packages at Scale for eligible roles include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Scale employees in eligible roles are also granted equity based compensation, subject to Board of Director approval. Your recruiter can share more about the specific salary range for your preferred location during the hiring process, and confirm whether the hired role will be eligible for equity grant. You\u2019ll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.\nPlease reference the job posting's subtitle for where this position will be located. For pay transparency purposes, the base salary range for this full-time position in the locations of San Francisco, New York, Seattle is:\n$220,000\u2014$325,000 USD\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, our mission is to develop reliable AI systems for the world's most important decisions. Our products provide the high-quality data and full-stack technologies that power the world's leading models, and help enterprises and governments build, deploy, and oversee AI applications that deliver real impact. We work closely with industry leaders like Meta, Cisco, DLA Piper, Mayo Clinic, Time Inc., the Government of Qatar, and U.S. government agencies including the Army and Air Force. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.", "comp": "0", "title": "Machine Learning Research Scientist / Research Engineer, Post-Training", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4292969772", "loc": "San Francisco Bay Area", "company": "Scale AI"}, {"desc": "AI is becoming vitally important in every function of our society. At Scale, our mission is to accelerate the development of AI applications. For 8 years, Scale has been the leading AI data foundry, helping fuel the most exciting advancements in AI, including generative AI, defense applications, and autonomous vehicles. With our recent Series F round, we\u2019re accelerating the usage of frontier data and models by building complex agents for enterprises around the world through our Scale Generative AI Platform (SGP).\nThe SGP ML team works on the front lines of this AI revolution. We interface directly with clients to build cutting edge products using the arsenal of proprietary research and resources developed at Scale. As an ML Researcher, you\u2019ll work with clients to train ML models to satisfy their business needs. Your work will range from training next-generation AI cybersecurity firewall LLMs to training foundation genomic models making predictions about life-saving drug proteins. Having a deep curiosity about the hardest questions about LLMs will also motivate various research opportunities on how to apply ML to the forefront of enterprise data. If you are excited about shaping the future of the modern AI movement, we would love to hear from you!\nYou will: \nTrain state of the art models, developed both internally and from the community, in production to solve problems for our enterprise customers. \nWork with product and research teams to identify opportunities for ongoing and upcoming services.\nExplore approaches that integrate human feedback and assisted evaluation into existing product lines. \nCreate state of the art techniques to integrate tool-calling into production-serving LLMs.\nIdeally you\u2019d have:\nAt least 1-3 years of model training, deployment and maintenance experience in a production environment\nStrong skills in NLP, LLMs and deep learning \nSolid background in algorithms, data structures, and object-oriented programming\nExperience working with a cloud technology stack (eg. AWS or GCP) and developing machine learning models in a cloud environment\nPhD or Masters in Computer Science or a related field\nNice to haves:\nExperience in dealing with large scale AI problems, ideally in the generative-AI field\nDemonstrated expertise in large vision-language models for diverse real-world applications, e.g. classification, detection, question-answering, etc. \nPublished research in areas of machine learning at major conferences (NeurIPS, ICML, EMNLP, CVPR, etc.) and/or journals\nStrong high-level programming skills (e.g., Python), frameworks and tools such as DeepSpeed, Pytorch lightning, kubeflow, TensorFlow, etc. \nStrong written and verbal communication skills to operate in a cross functional team environment\nCompensation packages at Scale for eligible roles include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Scale employees in eligible roles are also granted equity based compensation, subject to Board of Director approval. Your recruiter can share more about the specific salary range for your preferred location during the hiring process, and confirm whether the hired role will be eligible for equity grant. You\u2019ll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.\nPlease reference the job posting's subtitle for where this position will be located. For pay transparency purposes, the base salary range for this full-time position in the locations of San Francisco, New York, Seattle is:\n$176,000\u2014$300,000 USD\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, our mission is to develop reliable AI systems for the world's most important decisions. Our products provide the high-quality data and full-stack technologies that power the world's leading models, and help enterprises and governments build, deploy, and oversee AI applications that deliver real impact. We work closely with industry leaders like Meta, Cisco, DLA Piper, Mayo Clinic, Time Inc., the Government of Qatar, and U.S. government agencies including the Army and Air Force. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.", "comp": "0", "title": "Machine Learning Research Engineer, Enterprise GenAI", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4196120837", "loc": "San Francisco Bay Area", "company": "Scale AI"}, {"desc": "About Scale\nAt Scale AI, our mission is to accelerate the development of AI applications. For 8 years, Scale has been the leading AI data foundry, helping fuel the most exciting advancements in AI, including: generative AI, defense applications, and autonomous vehicles. With our recent Series F round, we\u2019re accelerating the abundance of frontier data to pave the road to Artificial General Intelligence (AGI), and building upon our prior model evaluation work with enterprise customers and governments, to deepen our capabilities and offerings for both public and private evaluations.\nAbout The ACE Team\nThe Agent Capabilities & Environments (ACE) team, part of Scale\u2019s Research organization, brings together customer-facing Researchers and Applied AI Engineers. Our core mission includes research on agent environments and RL reward signals, benchmarking autonomous agent performance across real-world scenarios and environments, creating robust data programs to improve Large Language Models (LLMs) agentic capabilities and building foundational tools and frameworks for evaluating models as agents. ACE focuses on autonomous agents that dynamically interact with diverse external environments, including code repositories, GUI interfaces, browsers, and more.\nAbout This Role\nThis role is at the intersection of cutting-edge AI research and practical application, with a focus on studying the data types essential for building state-of-the-art agents, such as browser and SWE agents. The ideal candidate will explore the data landscape needed to advance intelligent, adaptable AI agents, guiding the data strategy at Scale to drive innovation. This position requires not only expertise in LLM agents and planning algorithms but also creativity in addressing novel challenges related to data, interaction, and evaluation. You will contribute to impactful research publications on agents, collaborate with customer researchers, and work alongside the engineering team to translate these advancements into real-world, scalable solutions.\nIdeally you\u2019d have: \nPractical experience working with LLMs, with proficiency in frameworks like Pytorch, Jax, or Tensorflow. You should also be adept at interpreting research literature and quickly turning new ideas into prototypes.\nA track record of published research in top ML venues (e.g., ACL, EMNLP, NAACL, NeurIPS, ICML, ICLR, COLM, etc.)\nAt least three years of experience addressing sophisticated ML problems, either in a research setting or product development.\nStrong written and verbal communication skills and the ability to operate cross-functionally. \nNice to have:\nHands-on experience with open source LLM fine-tuning or involvement in bespoke LLM fine-tuning projects using Pytorch/Jax. \nHands-on experience and publications in building applications and evaluations related to AI agents such as tool-use, text2SQL, browser agents, coding agents and GUI agents.\nHands-on experience with agent frameworks such as OpenHands, Swarm, LangGraph, etc.\nFamiliarity with agentic reasoning methods such as STaR and PLANSEARCH \nExperience working with cloud technology stack (eg. AWS or GCP) and developing machine learning models in a cloud environment.\nOur research interviews are crafted to assess candidates' skills in practical ML prototyping and debugging, their grasp of research concepts, and their alignment with our organizational culture. We will not ask any LeetCode-style questions.\nCompensation packages at Scale for eligible roles include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Scale employees in eligible roles are also granted equity based compensation, subject to Board of Director approval. Your recruiter can share more about the specific salary range for your preferred location during the hiring process, and confirm whether the hired role will be eligible for equity grant. You\u2019ll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.\nPlease reference the job posting's subtitle for where this position will be located. For pay transparency purposes, the base salary range for this full-time position in the locations of San Francisco, New York, Seattle is:\n$220,000\u2014$325,000 USD\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, our mission is to develop reliable AI systems for the world's most important decisions. Our products provide the high-quality data and full-stack technologies that power the world's leading models, and help enterprises and governments build, deploy, and oversee AI applications that deliver real impact. We work closely with industry leaders like Meta, Cisco, DLA Piper, Mayo Clinic, Time Inc., the Government of Qatar, and U.S. government agencies including the Army and Air Force. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.", "comp": "0", "title": "Machine Learning Research Scientist/ Engineer, Agents", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4196123720", "loc": "San Francisco Bay Area", "company": "Scale AI"}, {"desc": "Software is eating the world, but AI is eating software. We live in unprecedented times \u2013 AI has the potential to exponentially augment human intelligence. Every person will have a personal tutor, coach, assistant, personal shopper, travel guide, and therapist throughout life. As the world adjusts to this new reality, leading platform companies are scrambling to build LLMs at billion scale, while large enterprises figure out how to add it to their products. To make them safe, aligned and actually useful, these models need human eval and reinforcement learning through human feedback (RLHF) during pre-training, fine-tuning, and production evaluations. This is the main innovation that\u2019s enabled ChatGPT to get such a large head start among competition.\nAbout Data Engine\nAt Scale, our Generative AI Data Engine powers the most advanced LLMs and generative models in the world through world-class RLHF, human data generation, model evaluation, safety, and alignment. The data we are producing is some of the most important work for how humanity will interact with AI.\nAbout Our Analytics Team\nThe Data Analytics team is responsible for centralized data, experimentation and reporting across all areas of Scale. We are building out the critical data pipelines, platforms and reporting, to support data-driven decision making and strategy for the company, including support for financial reporting, experimentations, and AI enabled insights.. The team are strong relationship builders and work in close collaboration with delivery, operations, finance, and engineering. You\u2019ll be deeply invoiced in building flexible new systems to support experimentation across the company, and we are looking for engineers who are relentlessly curious and thrive on building systems from ambiguity.\nResponsibilities:\nProvide critical input in the Data Engineering team\u2019s roadmap and technical direction\nDeliver flexible and accurate experimentation systems\nWork across backend and frontend systems\nDeliver at a high velocity and level of quality to engage our customers\nWork across the entire product lifecycle from conceptualization through production\nBe able, and willing, to multi-task and learn new technologies quickly\nWork closely with cross-functional partners like finance, product, software engineers, and operations to identify opportunities for business impact, understand, refine and prioritize requirements for Data engineering\nRequirements:\n5+ years of full-time engineering experience post-graduation, with specialties in production back-end services\nExperience delivering products within the data engineering, data science and experimentation domains\nExperience developing and deploying software using industry-standard cloud-based tooling and frameworks\nExperience scaling products at hyper-growth startups and excitement to work with AI technologies\nStrong written and verbal communication skills\nStrong problem-solving skills, and be able to work independently or as part of a team\nNice to haves:\nStrong knowledge of software engineering best practices and CI/CD tooling (CircleCI)\nExperience scaling products at hyper-growth startups\nExcitement to work with AI technologies\nCompensation packages at Scale for eligible roles include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Scale employees in eligible roles are also granted equity based compensation, subject to Board of Director approval. Your recruiter can share more about the specific salary range for your preferred location during the hiring process, and confirm whether the hired role will be eligible for equity grant. You\u2019ll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.\nThe base salary range for this full-time position in the location of San Francisco is:\n$188,000\u2014$235,000 USD\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, our mission is to develop reliable AI systems for the world's most important decisions. Our products provide the high-quality data and full-stack technologies that power the world's leading models, and help enterprises and governments build, deploy, and oversee AI applications that deliver real impact. We work closely with industry leaders like Meta, Cisco, DLA Piper, Mayo Clinic, Time Inc., the Government of Qatar, and U.S. government agencies including the Army and Air Force. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.", "comp": "0", "title": "Senior Software Engineer, Data Experience", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4274672954", "loc": "San Francisco Bay Area", "company": "Scale AI"}, {"desc": "Solutions Engineer - Cleared\nOur customer base is growing exponentially, and you will be on the front lines to ensure that the world's most innovative companies and governments become passionate, committed Scale partners. No two days at Scale are the same and we\u2019re looking for creative, action-oriented Solutions Engineers who are excited to solve tough problems with an AI-first mindset. Solutions Engineers at Scale ensure our customers' first experiences with our products and technology are flawless and lead to successful long-term partnerships. As a Solutions Engineer, you will drive growth in our federal business by enhancing existing initiatives and creating new opportunities for dual-use technologies that serve both commercial and government needs.\nWhat you'll do:\nBe an expert on Scale products and technologies.\nCreate tailored demonstrations and collateral for federal and select international stakeholders across the executive to analyst level.\nPartner with Scale Deployment Strategists to build relationships, advance business opportunities, and deliver customer pilots guided by their requirements.\nInteract with customers on a day-to-day basis to understand their pain points and design solutions. To understand and anticipate their priorities, you will research their problem space and procure relevant data to build impactful and relatable demonstrations of Scale product offerings. \nLeverage creative problem-solving skills to design and implement innovative solutions that push the boundaries of Generative AI and Computer Vision technologies, transforming complex challenges into actionable applications. \nWork with internal product and engineering teams to turn customer requirements into Scale capabilities through prototyping, product management, and collaboration with engineering teams.\nUnderstand public sector mission sets and strategic objectives to best showcase Scale\u2019s products.\nIdeally you'd have:\nActive US Government Security Clearance\nStrong preference for a SE based in Washington, DC area. Open to considering candidates in other locales.\nTechnical background, preferably in computer science, statistics, mathematics, machine learning, or other quantitative fields. \nCreative bias - able to think outside the box, connect cross-domain ideas, and develop unique solutions to technical challenges, all while grounding innovation in solid technical expertise. \nStrong communication skills - ability to interact with both technical and non-technical customers at all levels. \nAt ease with technology, able to quickly pick up new tech stacks and troubleshoot complex systems.\nPrevious experience working with Public Sector customers - our business is diverse and growing across National Security, Federal Civilian, and International partner communities. \nProficiency in common scripting languages such as Python, YAML, or other data analysis / application builder programming languages.\nA strong desire to roll up your sleeves and help build a business in an extremely fast-paced environment.\nAbility to travel up to 30% of the time.\nNice to have:\nBackground working in applied AI/ML, particularly Generative AI / Large Language Models or Computer Vision\nCompensation packages at Scale for eligible roles include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Scale employees in eligible roles are also granted equity based compensation, subject to Board of Director approval. Your recruiter can share more about the specific salary range for your preferred location during the hiring process, and confirm whether the hired role will be eligible for equity grant. You\u2019ll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.\nThe base salary range for this full-time position in the location of Washington DC is:\n$132,000\u2014$170,775 USD\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, our mission is to develop reliable AI systems for the world's most important decisions. Our products provide the high-quality data and full-stack technologies that power the world's leading models, and help enterprises and governments build, deploy, and oversee AI applications that deliver real impact. We work closely with industry leaders like Meta, Cisco, DLA Piper, Mayo Clinic, Time Inc., the Government of Qatar, and U.S. government agencies including the Army and Air Force. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.", "comp": "0", "title": "Solutions Engineer (Clearance required)", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4236192265", "loc": "Washington, DC", "company": "Scale AI"}, {"desc": "Scale GP (Scale Generative AI Platform) is an enterprise-grade Generative AI platform that provides APIs for knowledge retrieval, inference, evaluation, and more. We are looking for a strong engineer to join our team and help us build and scale our product in a fast-paced environment. The ideal candidate will have a strong understanding of software engineering principles and practices, as well as experience with large-scale distributed systems. You will be responsible for owning large new areas within our product, working across backend, frontend, and interacting with LLMs and ML models. You will solve hard engineering problems in scalability and reliability.\nYou will:\nOwn large new areas within our product\nWork across backend, frontend, and interacting with LLMs and ML models\nDeliver experiments at a high velocity and level of quality to engage our customers\nWork across the entire product lifecycle from conceptualization through production\nBe able, and willing, to multi-task and learn new technologies quickly\nIdeally you'd have:\n5+ years of full-time engineering experience, post-graduation\nExperience scaling products at hyper growth startups\nExperience tinkering with or productizing LLMs, vector databases, and the other latest AI technologies\nProficient in Python or Javascript/Typescript, and SQL\nExperience with Kubernetes\nExperience with major cloud providers (AWS, Azure, GCP)\nCompensation packages at Scale for eligible roles include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Scale employees in eligible roles are also granted equity based compensation, subject to Board of Director approval. Your recruiter can share more about the specific salary range for your preferred location during the hiring process, and confirm whether the hired role will be eligible for equity grant. You\u2019ll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.\nPlease reference the job posting's subtitle for where this position will be located. For pay transparency purposes, the base salary range for this full-time position in the locations of San Francisco, New York, Seattle is:\n$188,000\u2014$235,000 USD\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, our mission is to develop reliable AI systems for the world's most important decisions. Our products provide the high-quality data and full-stack technologies that power the world's leading models, and help enterprises and governments build, deploy, and oversee AI applications that deliver real impact. We work closely with industry leaders like Meta, Cisco, DLA Piper, Mayo Clinic, Time Inc., the Government of Qatar, and U.S. government agencies including the Army and Air Force. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.", "comp": "0", "title": "Senior Software Engineer, Enterprise GenAI", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4239139041", "loc": "San Francisco Bay Area", "company": "Scale AI"}, {"desc": "About Scale\nAt Scale AI, our mission is to accelerate the development of AI applications. For 8 years, Scale has been the leading AI data foundry, fueling the most exciting advancements in AI, including generative AI, defense applications, and autonomous vehicles. With our recent Series F round, we\u2019re amplifying access to high-quality data to drive progress toward Artificial General Intelligence (AGI). Building on our history of model evaluation with enterprise and government customers, we are expanding our capabilities to set new standards for both public and private evaluations.\nAbout This Role\nThis role operates at the forefront of AI research and real-world implementation, with a strong focus on reasoning within large language models (LLMs). The ideal candidate will study the data types critical for advancing LLM-based agents, including browser and software engineering (SWE) agents. You will play a key role in shaping Scale\u2019s data strategy by identifying the most effective data sources and methodologies for improving LLM reasoning. Success in this role requires a deep understanding of LLMs, planning algorithms, and novel approaches to agentic reasoning, as well as creativity in tackling challenges related to data generation, model interaction, and evaluation. \nYou will contribute to impactful research on language model reasoning\n, collaborate with external researchers, and work closely with engineering teams to bring state-of-the-art advancements into scalable, real-world solutions.\nIdeally, you\u2019d have:\nPractical experience working with LLMs, with proficiency in frameworks like PyTorch, JAX, or TensorFlow. You should also be skilled at rapidly interpreting research literature and turning new ideas into working prototypes. \nA track record of published research in top ML and NLP venues (e.g., ACL, EMNLP, NAACL, NeurIPS, ICML, ICLR, CoLLM, etc.). \nAt least three years of experience solving complex ML challenges, either in a research setting or product development, particularly in areas related to LLM capabilities and reasoning. \nStrong written and verbal communication skills, along with the ability to work effectively across teams. \nNice to have:\nHands-on experience fine-tuning open-source LLMs or leading bespoke LLM fine-tuning projects using PyTorch/JAX. \nResearch and practical experience in building applications and evaluations related to LLM-based agents, including tool-use, text-to-SQL, browser agents, coding agents, and GUI agents. \nExperience with agent frameworks such as OpenHands, Swarm, LangGraph, or similar. \nFamiliarity with advanced agentic reasoning techniques such as STaR and PLANSEARCH. \nProficiency in cloud-based ML development, with experience in AWS or GCP environments. \nOur research interviews are designed to assess candidates' ability to prototype and debug ML models, their depth of understanding in research concepts, and their alignment with our organizational culture. \nWe do not conduct LeetCode-style problem-solving assessments.\nCompensation packages at Scale for eligible roles include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Scale employees in eligible roles are also granted equity based compensation, subject to Board of Director approval. Your recruiter can share more about the specific salary range for your preferred location during the hiring process, and confirm whether the hired role will be eligible for equity grant. You\u2019ll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.\nPlease reference the job posting's subtitle for where this position will be located. For pay transparency purposes, the base salary range for this full-time position in the locations of San Francisco, New York, Seattle is:\n$220,000\u2014$325,000 USD\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, our mission is to develop reliable AI systems for the world's most important decisions. Our products provide the high-quality data and full-stack technologies that power the world's leading models, and help enterprises and governments build, deploy, and oversee AI applications that deliver real impact. We work closely with industry leaders like Meta, Cisco, DLA Piper, Mayo Clinic, Time Inc., the Government of Qatar, and U.S. government agencies including the Army and Air Force. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.", "comp": "0", "title": "Machine Learning Research Scientist / Engineer, Reasoning", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4296145239", "loc": "Seattle, WA", "company": "Scale AI"}, {"desc": "About Scale\nSoftware is eating the world, but AI is eating software. We live in unprecedented times \u2013 AI has the potential to exponentially augment human intelligence. Every person will have a personal tutor, coach, assistant, personal shopper, travel guide, and therapist throughout life. As the world adjusts to this new reality, leading platform companies are scrambling to build LLMs at billion scale, while large enterprises figure out how to add it to their products. To make them safe, aligned and actually useful, these models need human eval and reinforcement learning through human feedback (RLHF) during pre-training, fine-tuning, and production evaluations. This is the main innovation that\u2019s enabled ChatGPT to get such a large head start among competition.\nAbout Data Engine\nAt Scale, our Generative AI Data Engine powers the most advanced LLMs and generative models in the world through world-class RLHF, human data generation, model evaluation, safety, and alignment. The data we are producing is some of the most important work for how humanity will interact with AI.\nAbout Our Analytics Team\nThe Data Analytics team is responsible for centralized data, experimentation and reporting across all areas of Scale. We are building out the critical data pipelines, platforms and reporting, to support data-driven decision making and strategy for the company, including support for financial reporting, experimentation, and AI enabled insights. The team are strong relationship builders and work in close collaboration with delivery, operations, finance, and engineering. You'll be deeply involved in building flexible new systems to support experimentation across the company, and we are looking for engineers who are relentlessly curious and thrive on building systems from ambiguity.\nResponsibilities:\nProvide critical input in the Data Engineering team\u2019s roadmap and technical direction\nContinually improve ongoing data pipelines and simplify self-service support for business stakeholders\nPerform regular system audits, and create data quality tests to ensure complete and accurate reporting of data/metrics\nDesign and implement and deploy data engineering frameworks\nManage and optimize data pipelines, warehouses and costs\nDeliver at a high velocity and level of quality to engage our customers.\nWork across the entire product lifecycle from conceptualization through production\nBe able, and willing, to multi-task and learn new technologies quickly\nWork closely with cross-functional partners like finance, product, software engineers, and operations to identify opportunities for business impact, understand, refine and prioritize requirements for Data engineering. \nRequirements:\n6+ years of relevant work experience in a role requiring application of data modeling, warehouse optimization and automation skills.\nAbility to create extensible and scalable data schema and pipelines that lay the foundation for downstream analysis using SQL and Python\nExperience building a reliable transformation layer and pipelines from ambiguous business processes using tools such DBT to create a foundation for data insights. \nExperience partnering with engineering, and business stakeholders to automate manual data workflows\nExperience in best practices for query and cost optimization in Snowflake.\nStrong written and verbal communication skills\nStrong problem-solving skills, and be able to work independently or as part of a team.\nNice to haves:\nStrong knowledge of software engineering best practices and CI/CD tooling (CircleCI).\nExperience developing and deploying data engineering tooling \nExcitement to work with AI technologies.\nCompensation packages at Scale for eligible roles include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Scale employees in eligible roles are also granted equity based compensation, subject to Board of Director approval. Your recruiter can share more about the specific salary range for your preferred location during the hiring process, and confirm whether the hired role will be eligible for equity grant. You\u2019ll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.\nThe base salary range for this full-time position in the location of San Francisco is:\n$180,000\u2014$225,000 USD\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, our mission is to develop reliable AI systems for the world's most important decisions. Our products provide the high-quality data and full-stack technologies that power the world's leading models, and help enterprises and governments build, deploy, and oversee AI applications that deliver real impact. We work closely with industry leaders like Meta, Cisco, DLA Piper, Mayo Clinic, Time Inc., the Government of Qatar, and U.S. government agencies including the Army and Air Force. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.", "comp": "0", "title": "Senior Data Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4283706182", "loc": "San Francisco Bay Area", "company": "Scale AI"}, {"desc": "At Scale, our mission is to accelerate the development of AI applications. For 8 years, Scale has been the leading AI data foundry, helping fuel the most exciting advancements in AI, including: generative AI, defense applications, and autonomous vehicles. With our recent Series F round, we\u2019re accelerating the development of autonomous AI agents in frontier labs through agentic data and evaluations, paving the road to Artificial General Intelligence (AGI).'\nAbout The ACE Team\nThe Agent Capabilities & Environments (ACE) team, part of Scale\u2019s Research organization, brings together customer-facing Researchers and Applied AI Engineers. Our core mission includes benchmarking autonomous agent performance across real-world scenarios and environments, creating robust data programs to improve Large Language Models (LLMs) agentic capabilities, and building foundational tools and frameworks for evaluating models as agents. ACE focuses on autonomous agents that dynamically interact with diverse external environments, including code repositories, GUI interfaces, browsers, and more.\nAbout The Role\nAs a Senior/Staff Applied AI Engineer on the ACE team, you\u2019ll play a crucial role bridging state-of-the-art generative AI research, practical agent development, and the specialized data required to advance agentic systems.\nYou will:\nDevelop frameworks and tools to benchmark and evaluate advanced agent capabilities.\nConstruct realistic environments for training and evaluating autonomous agents.\nDesign agent-focused data programs leveraging supervised fine-tuning (SFT) and reinforcement learning (RL) methodologies.\nCreate robust data pipelines and novel agentic data types from diverse environments, including code repositories, web browsers, and computer systems.\nCollaborate closely with customers to understand requirements, guide model development, and achieve product objectives.\nImplement and adapt popular open-source agent libraries and benchmarks using proprietary datasets and models\nIdeally you\u2019d have:\nMin. 5+ years of practical experience building AI applications for real-world use cases.\nStrong engineering and AI fundamentals, supported by a Bachelors\u2019s and/or Master\u2019s degree or equivalent experience in Computer Science, Machine Learning, AI, or a closely related field.\nDeep understanding of modern deep learning methods, LLM technologies, and data-centric AI methodologies.\nProven proficiency in Python, with experience writing, testing, and debugging code using standard data science libraries (e.g., NumPy, Pandas).\nPrevious experience in customer-facing roles, effectively translating complex requirements into actionable development goals.\nPassion for solving ambiguous, complex technical challenges using cutting-edge research.\nNice-to-haves:\nHands-on experience developing AI applications within the modern Generative AI stack (OpenAI APIs, commercial or open-source LLMs).\nExperience building autonomous agents that leverage external tools, produce structured outputs, and interact with various environments.\nFamiliarity with agent benchmarking datasets such as SWE-Bench, tau-bench, and OS-World.\nCompensation packages at Scale for eligible roles include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Scale employees in eligible roles are also granted equity based compensation, subject to Board of Director approval. Your recruiter can share more about the specific salary range for your preferred location during the hiring process, and confirm whether the hired role will be eligible for equity grant. You\u2019ll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.\nPlease reference the job posting's subtitle for where this position will be located. For pay transparency purposes, the base salary range for this full-time position in the locations of San Francisco, New York, Seattle is:\n$216,000\u2014$270,000 USD\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, our mission is to develop reliable AI systems for the world's most important decisions. Our products provide the high-quality data and full-stack technologies that power the world's leading models, and help enterprises and governments build, deploy, and oversee AI applications that deliver real impact. We work closely with industry leaders like Meta, Cisco, DLA Piper, Mayo Clinic, Time Inc., the Government of Qatar, and U.S. government agencies including the Army and Air Force. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.", "comp": "0", "title": "Senior/Staff Applied AI Engineer, Agents", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4241015104", "loc": "San Francisco Bay Area", "company": "Scale AI"}, {"desc": "Data Engineer, Public Sector\nAs a Data Engineer for the Public Sector business unit, you will build Scale's analytical and business-intelligence infrastructure. Scale's customers process millions of tasks through our APIs, and we're looking for a talented Data Engineer to build scalable solutions to support this growth. You will have widespread purview, with responsibility for understanding, mining, aggregating, and exposing data across the entire business unit to support timely and efficient decision-making and data exploration. You will also implement Scale's data warehouse, data mart, and business intelligence reporting environments, and help users transition their workflows to these systems.\nThis role requires collaboration with leadership and cross-functional teams to solve complex problems and develop sustainable, scalable data solutions. Your responsibilities will include both ad-hoc analyses and the creation of core data models and pipelines, directly impacting how Scale operates and evaluates its performance.\nYou will:\nWork with operations, finance, and engineering to drive the development of pipelines that provide single-source-of-truth foundational accuracy\nContinually improve ongoing data pipelines and simplify self-service support for business stakeholders\nPerform regular system audits, and create data quality tests to ensure complete and accurate reporting of data/metrics\nDevelop repeatable, scalable analytical solutions, such as data models, improved pipelines, or better underlying tables\nHave an active Secret security clearance (Top Secret preferred)\nIdeally You\u2019d Have:\n2+ years of relevant work experience in a role requiring application of data modeling and analytic skills\nAbility to create extensible and scalable data schema and pipelines that lay the foundation for downstream analysis\nMastery of SQL and relational databases; experience with programming languages (e.g., Python/R)\nExperience building a reliable transformation layer and pipelines from ambiguous business processes using tools such DBT to create a foundation for data insights\nCompensation packages at Scale for eligible roles include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Scale employees in eligible roles are also granted equity based compensation, subject to Board of Director approval. Your recruiter can share more about the specific salary range for your preferred location during the hiring process, and confirm whether the hired role will be eligible for equity grant. You\u2019ll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.\nThe base salary range for this full-time position in the location of Washington DC is:\n$119,000\u2014$155,000 USD\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, our mission is to develop reliable AI systems for the world's most important decisions. Our products provide the high-quality data and full-stack technologies that power the world's leading models, and help enterprises and governments build, deploy, and oversee AI applications that deliver real impact. We work closely with industry leaders like Meta, Cisco, DLA Piper, Mayo Clinic, Time Inc., the Government of Qatar, and U.S. government agencies including the Army and Air Force. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.", "comp": "0", "title": "Data Engineer, Public Sector (security clearance required)", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4281906169", "loc": "Washington, DC", "company": "Scale AI"}, {"desc": "We are seeking a Security Engineer with a specialty in Detection and Incident Response to join our Security Engineering team. This role is crucial in ensuring the rapid and effective response to digital security incidents across Scale. You will investigate incidents, implement response strategies, and strengthen our detection and response capabilities. Your skills in forensics, threat hunting, and incident response tools will be essential in identifying and mitigating potential threats. You will also structure investigations, analyze root causes, and clearly communicate the significance of security incidents, their impact, and recommended remediation steps.\nYou will:\nPerform digital incident investigations to identify and contain potential security breaches. \nEnhance incident response capabilities through new tools, playbooks, and process improvements. \nConduct digital forensics and malware analysis to understand attack vectors and adversary methodologies. \nUtilize threat intelligence platforms to improve hunting, detection, and response workflows. \nPartner with IT and security teams to identify and remediate logging or forensics gaps. \nClearly explain the significance and impact of incidents, providing actionable recommendations to stakeholders. \nIdeally, you\u2019d have:\n3\u20135+ years of experience as a Security Engineer with an emphasis on Detection, Incident Response, or Investigations. \nPractical experience with SIEM and EDR tools. \nStrong understanding of modern cyber threats and common attack techniques. \nFamiliarity with digital forensics tools and malware analysis techniques. \nExposure to threat intelligence platforms and integrating intel into investigations. \nStrong communication skills, with the ability to present findings clearly to both technical and non-technical stakeholders. \nRelevant security certifications (e.g., GCIH, GCFA, GCIA) are a plus. \nCompensation packages at Scale for eligible roles include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Scale employees in eligible roles are also granted equity based compensation, subject to Board of Director approval. Your recruiter can share more about the specific salary range for your preferred location during the hiring process, and confirm whether the hired role will be eligible for equity grant. You\u2019ll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.\nPlease reference the job posting's subtitle for where this position will be located. For pay transparency purposes, the base salary range for this full-time position in the locations of San Francisco, New York, Seattle is:\n$172,000\u2014$215,000 USD\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, our mission is to develop reliable AI systems for the world's most important decisions. Our products provide the high-quality data and full-stack technologies that power the world's leading models, and help enterprises and governments build, deploy, and oversee AI applications that deliver real impact. We work closely with industry leaders like Meta, Cisco, DLA Piper, Mayo Clinic, Time Inc., the Government of Qatar, and U.S. government agencies including the Army and Air Force. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.", "comp": "0", "title": "Security Engineer, Detection & Incident Response", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4298034600", "loc": "San Francisco Bay Area", "company": "Scale AI"}, {"desc": "Scale GP is building the next generation of enterprise-grade Generative AI products. Our platform provides APIs for knowledge retrieval, inference, and evaluation, enabling customers to build and deploy powerful \nAgentic workflows\n for Enterprise use cases. We're looking for a \nSenior Infrastructure Software Engineer\n to build and scale our core infrastructure in a fast-paced environment. This team is key to our mission, directly enabling the deployment of these agentic flows for our customers.This is a unique opportunity for an infrastructure leader who is passionate about defining the future of AI deployments. You will be at the forefront of the industry, solving complex, bleeding-edge problems in scalability, security, and developer efficiency. You will architect and implement solutions across multiple cloud providers (GCP, Azure, AWS) for customers in diverse, highly-regulated industries like healthcare, telecom, finance, and retail.\nWhat You'll Do:\nDefine the architectural patterns for our multi-cloud infrastructure to support secure, reliable, and scalable Agentic workflows for enterprise customers.\nLead the infrastructure roadmap with a strong focus on compliance, privacy, and security standards, including designing change management and data isolation strategies.\nOwn the development and maintenance of our best-in-class Agentic observability platform (logging, metrics, tracing, and analytics) to proactively ensure system health and enable rapid incident response.\nDrive developer efficiency by building automated tooling and championing Infrastructure-as-Code (IaC) paradigms throughout the engineering organization.\nSolve the toughest engineering problems related to multi-tenancy, data isolation, and high-performance inference at a massive scale, taking end-to-end ownership across the full product lifecycle.\nWhat We're Looking For:\nProven experience in a senior role, with 5+ years of full-time software engineering experience.\nDeep understanding of modern infrastructure practices, including CI/CD, IaC (e.g., Terraform, Helm Charts), container orchestration (e.g., Kubernetes) and observability platforms (e.g., Datadog, Prometheus, Grafana).\nExtensive experience with at least one major cloud provider (AWS, Azure, or GCP).\nStrong knowledge of security and compliance in enterprise environments, with a focus on access management, data isolation, and customer-specific VPC setups.\nProficiency in Python or JavaScript/TypeScript, and SQL.\nBonus points: Hands-on experience and a passion for working with Agents, LLMs, vector databases, and other emerging AI technologies.\nCompensation packages at Scale for eligible roles include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Scale employees in eligible roles are also granted equity based compensation, subject to Board of Director approval. Your recruiter can share more about the specific salary range for your preferred location during the hiring process, and confirm whether the hired role will be eligible for equity grant. You\u2019ll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.\nPlease reference the job posting's subtitle for where this position will be located. For pay transparency purposes, the base salary range for this full-time position in the locations of San Francisco, New York, Seattle is:\n$188,000\u2014$235,000 USD\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, our mission is to develop reliable AI systems for the world's most important decisions. Our products provide the high-quality data and full-stack technologies that power the world's leading models, and help enterprises and governments build, deploy, and oversee AI applications that deliver real impact. We work closely with industry leaders like Meta, Cisco, DLA Piper, Mayo Clinic, Time Inc., the Government of Qatar, and U.S. government agencies including the Army and Air Force. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.", "comp": "0", "title": "Senior Infrastructure Software Engineer, Enterprise AI", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4289169380", "loc": "San Francisco Bay Area", "company": "Scale AI"}, {"desc": "PLEASE NOTE: This is a fully remote contract opportunity, with an estimated duration of 6 months. To be eligible, you must have authorization to work in the U.S. \nAbout The Program\nThe Human Frontier Collective (HFC) at Scale AI engages talented researchers, analysts, PhDs, and postdocs to support advanced generative AI research. As an HFC Fellow, you'll be instrumental in driving AI advancements tailored to customer objectives by leveraging your domain knowledge to create and evaluate complex problem sets.\nWhat You'll Do\nDevelop and Critique Complex Problem Sets: Craft challenging, domain-specific problems and datasets designed to rigorously test AI models, and provide expert evaluations to enhance model accuracy and robustness.\nModel Response Evaluations: Review and critically assess AI model outputs, delivering insightful feedback that directly improves model performance.\nContribute to Research Publications: Opportunity to co-author technical reports and research papers, expanding your academic visibility and professional recognition.\nWho Should Apply\nEducational Background: Advanced graduate students, PhDs, postdocs, or professionals with domain knowledge in mathematics, chemistry, physics, biology, engineering, computer science, cognitive sciences, or related STEM fields.\nTechnical Competence: Proven analytical skills, experience in creating challenging problem sets, and enthusiasm for applied AI research.\nProfessional Mindset: Collaborative, detail-oriented, self-motivated individuals interested in applied AI research.\nWhy Join the HFC?\nDirect Impact: Your expertise will directly influence the advancement of generative AI research.\nProfessional Development: Expand your research experience and contribute meaningfully to impactful projects.\nCompetitive Compensation: Earn attractive hourly compensation ($80-120/hour) aligned with your expertise.\nCareer Opportunities: Gain experience and build relationships that may lead to extended collaboration or future opportunities at Scale AI.\nHow to Apply\nSubmit your CV along with relevant experience or research highlights. Selected candidates will undergo an interview process assessing domain expertise and analytical capabilities.\nAdvance the Frontiers of Generative AI\nJoin the Human Frontier Collective as an HFC Fellow and contribute your expertise to meaningful AI research and practical industry challenges.\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, our mission is to develop reliable AI systems for the world's most important decisions. Our products provide the high-quality data and full-stack technologies that power the world's leading models, and help enterprises and governments build, deploy, and oversee AI applications that deliver real impact. We work closely with industry leaders like Meta, Cisco, DLA Piper, Mayo Clinic, Time Inc., the Government of Qatar, and U.S. government agencies including the Army and Air Force. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.", "comp": "0", "title": "Human Frontier Collective Fellow - GenAI (US - Remote)", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4305927429", "loc": "United States", "company": "Scale AI"}, {"desc": "At Scale AI, we are accelerating the development of artificial intelligence by providing the essential, data-centric infrastructure for building and deploying advanced AI systems. We are looking for a Forward Deployed Data Scientist/Engineer to architect and build the sophisticated data solutions that solve our customers' most complex challenges. This role is for a first-principles thinker who thrives on ambiguity, enjoys solving novel customer problems, and has a passion for applying rigorous data science to deliver measurable business impact.\nYou'll work on a mix of cutting-edge, customer-facing AI implementations. Our team powers projects like TIME\u2019s Person of the Year AI experience, where our technology helped shape one of the most iconic features in media. Leveraging Scale's powerful data infrastructure, you will build bespoke evaluation frameworks, deploy custom statistical models, and architect data pipelines. Your work will play a crucial role in shaping how AI delivers measurable value in real-world applications for industry-leading companies.\nYou'll be exposed to the cutting edge of the Generative AI industry while directly interfacing with leading enterprise organizations, including top industry leaders in telecommunications, e-commerce, finance, education, publication, insurance, and health.\nResponsibilities:\nDrive Impact: Directly contribute to the advancement of AI by delivering critical data science infrastructure and insights for leading AI innovators and enterprise customers.\nCustomer Collaboration: Interact daily with our technical customers, deeply understanding their unique challenges and translating ambiguous business problems into concrete data-driven solutions and robust statistical models.\nEnd-to-End Data Solution Development: Design, build, and deploy solutions across the entire data lifecycle\u2014from data ingestion and pipeline construction to statistical modeling, experimentation, model evaluation, and insight generation.\nRapid Experimentation: Design and deliver high-quality experiments (e.g., A/B tests, marketplace modeling), iterating quickly to validate hypotheses, meet customer needs, and drive innovation.\nStrategic Influence: Act as the voice of the customer to our internal Product, Engineering, and Data Science teams, channeling real-world insights to influence our product roadmap and technical strategy.\nDiverse Projects: Engage in a dynamic mix of designing and deploying cutting-edge data solutions, from building LLM evaluation frameworks to adapting statistical models for novel economic and business problems.\nLeadership Growth: This role offers a unique opportunity to lead critical customer-facing projects, shape our data culture, and accelerate your career growth. You'll be positioned to become a future leader in a company defining the next era of technology.\nRequirements:\n5+ years of relevant industry experience in a highly analytical role (e.g., Data Science, ML Engineering, Quantitative Analysis).\nProven track record of shipping high-quality data products, models, or features at scale.\nStrong problem-solving skills and the ability to turn abstract business and product ideas into concrete data science and engineering solutions.\nExpert-level coding abilities in Python for data science (e.g., Pandas, NumPy, Scikit-learn) and mastery of complex SQL across large datasets.\nAbility to effectively communicate complex technical concepts to both technical and non-technical audiences.\nDesire to thrive in a fast-paced, dynamic environment and adapt quickly to the ever-changing world of Generative AI.\nExcited to join a dynamic, hybrid team in either San Francisco or New York City.\nPreferred Qualifications:\nExperience in a client-facing or consultative role (e.g., Forward Deployed Engineer, Solutions Architect, Data Science Consultant).\nDeep expertise in designing metrics, diagnosing data inconsistencies, and building evaluation frameworks for ML/LLM systems.\nExperience with large-scale data processing frameworks and distributed systems (e.g., Spark, Ray).\nFamiliarity with marketplace experimentation, causal inference, and advanced statistical modeling.\nExperience with cloud-based infrastructure and data warehousing (e.g., AWS, GCP, Snowflake, BigQuery).\nCompensation packages at Scale for eligible roles include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Scale employees in eligible roles are also granted equity based compensation, subject to Board of Director approval. Your recruiter can share more about the specific salary range for your preferred location during the hiring process, and confirm whether the hired role will be eligible for equity grant. You\u2019ll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.\nPlease reference the job posting's subtitle for where this position will be located. For pay transparency purposes, the base salary range for this full-time position in the locations of San Francisco, New York, Seattle is:\n$180,000\u2014$225,000 USD\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, our mission is to develop reliable AI systems for the world's most important decisions. Our products provide the high-quality data and full-stack technologies that power the world's leading models, and help enterprises and governments build, deploy, and oversee AI applications that deliver real impact. We work closely with industry leaders like Meta, Cisco, DLA Piper, Mayo Clinic, Time Inc., the Government of Qatar, and U.S. government agencies including the Army and Air Force. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.", "comp": "0", "title": "Sr. Forward Deployed Data Scientist/Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4302223564", "loc": "San Francisco Bay Area", "company": "Scale AI"}, {"desc": "About Scale AI\nScale GP (Scale Generative AI Platform) is an enterprise-grade AI platform providing APIs for knowledge retrieval, inference, evaluation, and more. We are looking for a full-stack engineer to help build AI-powered applications that redefine enterprise workflows and push the boundaries of interactive AI. This role is ideal for someone who thrives in a fast-paced environment, enjoys working on a diverse set of projects, and has a passion for crafting high-quality, intuitive user experiences.\nAt Scale, you'll work on a mix of cutting-edge customer-facing AI applications and internal SaaS products. Our engineering team powers projects like \nTIME\u2019s Person of the Year AI experience\n (see it in action), where our AI technology helped shape one of the most iconic features in media. You'll also contribute to \nScale\u2019s GenAI Platform\n (SGP), a robust system that enables businesses to build and deploy AI agents at scale. Whether it\u2019s developing interactive AI assistants, enterprise-grade web applications, or refining our core SaaS platform, you\u2019ll play a crucial role in shaping how AI integrates into real-world applications.\nYou'll be exposed to the cutting edge of the Generative AI industry while directly interfacing with the leading enterprise organizations, including top industry leaders in telecommunications, e-commerce, finance, education, publication, insurance and health.\nResponsibilities:\nDrive Impact: Directly contribute to the advancement of AI by delivering critical data solutions for leading AI innovators and government agencies.\nCustomer Collaboration: Interact daily with our technical customers, understanding their unique challenges and translating them into impactful solutions.\nEnd-to-End Development: Design, build, and deploy features across the entire stack, from front-end interfaces to back-end systems and infrastructure.\nRapid Experimentation: Deliver high-quality experiments quickly, iterating quickly to meet customer needs and drive innovation.\nStrategic Influence: Play a key role in shaping our engineering culture, values, and processes, contributing to the growth of our team and the evolution of our product.\nDiverse Projects: Engage in a dynamic mix of designing and deploying cutting-edge data solutions, collaborating with leading AI researchers, and directly influencing the product roadmap. You'll work on everything from large-scale system architecture to customer-facing front-end application design.\nLeadership Growth: This role offers a unique opportunity to lead critical projects, shape our engineering culture, and accelerate your career growth in the rapidly evolving field of Generative AI. You'll be positioned to become a future leader in a company defining the next era of technology.\nRequirements:\nAt least 2 years of relevant experience is preferred\nProven track record of shipping high-quality products and features at scale.\nStrong problem-solving skills and the ability to work independently or as part of a collaborative team.\nDesire to thrive in a fast-paced, dynamic environment.\nAbility to turn business and product ideas into engineering solutions.\nStrong coding abilities and the ability to effectively communicate complex technical concepts to both technical and non-technical audiences.\nAbility to adapt quickly to the ever-changing world of generative AI.\nExcited to join a dynamic, hybrid team in either San Francisco or New York City.\nPreferred Qualifications:\nExperience with large-scale data processing and distributed systems.\nFamiliarity with machine learning and AI concepts.\nExperience working directly with enterprise customers.\nExperience with cloud-based infrastructure.\nCompensation packages at Scale for eligible roles include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Scale employees in eligible roles are also granted equity based compensation, subject to Board of Director approval. Your recruiter can share more about the specific salary range for your preferred location during the hiring process, and confirm whether the hired role will be eligible for equity grant. You\u2019ll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.\nPlease reference the job posting's subtitle for where this position will be located. For pay transparency purposes, the base salary range for this full-time position in the locations of San Francisco and New York, is:\n$156,000 - $235,000 USD\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, we believe that the transition from traditional software to AI is one of the most important shifts of our time. Our mission is to make that happen faster across every industry, and our team is transforming how organizations build and deploy AI. Our products power the world's most advanced LLMs, generative models, and computer vision models. We are trusted by generative AI companies such as OpenAI, Meta, and Microsoft, government agencies like the U.S. Army and U.S. Air Force, and enterprises including GM and Accenture. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.\nCompensation packages at Scale for eligible roles include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Scale employees in eligible roles are also granted equity based compensation, subject to Board of Director approval. Your recruiter can share more about the specific salary range for your preferred location during the hiring process, and confirm whether the hired role will be eligible for equity grant. You\u2019ll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.\nPlease reference the job posting's subtitle for where this position will be located. For pay transparency purposes, the base salary range for this full-time position in the locations of San Francisco, New York, Seattle is:\n$156,000\u2014$235,000 USD\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, our mission is to develop reliable AI systems for the world's most important decisions. Our products provide the high-quality data and full-stack technologies that power the world's leading models, and help enterprises and governments build, deploy, and oversee AI applications that deliver real impact. We work closely with industry leaders like Meta, Cisco, DLA Piper, Mayo Clinic, Time Inc., the Government of Qatar, and U.S. government agencies including the Army and Air Force. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.", "comp": "0", "title": "Senior Forward Deployed Engineer, Enterprise Application", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4289169378", "loc": "San Francisco Bay Area", "company": "Scale AI"}, {"desc": "About This Role\nThis role drives the end-to-end execution of the Applied ML team\u2019s initiatives: ensuring data quality, contributor marketplace efficiency, and extending horizontal ML capabilities across business units. You\u2019ll own program delivery from scoping to measurable adoption, while serving as the communication backbone across engineering, product, and leadership. You will be accountable for measurable outcomes: higher data quality, faster contributor onboarding, and adoption of horizontal ML capabilities across BUs.\nYou will manage the entire lifecycle of our cutting-edge GenAI initiatives, from initial scoping and prototyping to deployment of LLM-based techniques in production. This is a high-impact, cross-functional role requiring a deep understanding of ML engineering processes, risk management, and rapid iteration in a demanding AI environment. You will ensure the MLE team maintains focus, resolves dependencies, and rapidly delivers reliable, high-value ML solutions at scale.\nYou will:\nOwn the end-to-end planning, scheduling, and execution for multiple GenAI ML programs, ensuring high-quality, on-time delivery against product goals.\nCollaborate closely with Product Managers and ML Engineers/Scientists to translate vision into clear, iterative execution plans.\nEnsure our ML systems move from prototype to production smoothly, by aligning engineering, research, and product teams around clear milestones, risks, and delivery standards.\nTranslate technical complexity into concise, actionable updates for executive and cross-functional stakeholders. Drive clarity across teams by ensuring everyone understands priorities, risks, and outcomes.\nProactively identify, track, and mitigate technical risks unique to GenAI development (e.g., model drift, prompt engineering evolution, data security/privacy, resource contention on large-scale compute).\nManage dependencies and communication across core teams (e.g., Platform Infrastructure, Data Engineering, Product) to seamlessly integrate ML services into production microservice architectures.\nProvide clear, concise, and structured status reports to all stakeholders, including executive leadership, detailing project health, roadblocks, and delivery forecasts.\nIdeally you\u2019d have:\n5+ years of experience as a Technical Program Manager or similar technical leadership role managing complex software or machine learning development projects.\n2+ years of experience managing programs specifically focused on Applied Machine Learning, MLOps, or Data Science.\nFamiliarity with the Generative AI lifecycle, including the application of LLMs (Large Language Models) for structured downstream tasks, model fine-tuning, and performance evaluation.\nAbility to reason about system architecture, data flow, and key technical challenges in building scalable ML services in cloud environments (e.g., using AWS, GCP, or similar microservice infrastructure).\nExperience with Agile methods and tools (e.g., Jira, Linear).\nExcellent verbal and written communication skills with a proven ability to translate complex technical challenges into clear program risks and business impacts for executive audiences.\nInterest in learning and engaging with modern ML/GenAI practices.\nNice to have:\nHands-on familiarity with high-performance compute infrastructure for ML training and deployment in real-world products..\nFamiliarity with data quality pipelines or internal evaluation frameworks\nStrong software engineering fundamentals, ideally having prior experience as an engineer or developer before transitioning into program management.\nExperience driving adoption of technical platforms across multiple product lines or business units.\nCompensation packages at Scale for eligible roles include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Scale employees in eligible roles are also granted equity based compensation, subject to Board of Director approval. Your recruiter can share more about the specific salary range for your preferred location during the hiring process, and confirm whether the hired role will be eligible for equity grant. You\u2019ll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.\nPlease reference the job posting's subtitle for where this position will be located. For pay transparency purposes, the base salary range for this full-time position in the locations of San Francisco, New York, Seattle is:\n$1\u2014$1 USD\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, our mission is to develop reliable AI systems for the world's most important decisions. Our products provide the high-quality data and full-stack technologies that power the world's leading models, and help enterprises and governments build, deploy, and oversee AI applications that deliver real impact. We work closely with industry leaders like Meta, Cisco, DLA Piper, Mayo Clinic, Time Inc., the Government of Qatar, and U.S. government agencies including the Army and Air Force. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.", "comp": "0", "title": "Technical Program Manager, Applied ML", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4311196240", "loc": "San Francisco Bay Area", "company": "Scale AI"}, {"desc": "Scale\u2019s AI Infrastructure team supports both R&D and applied Generative AI initiatives, driving breakthroughs in areas of post-training research such as AI safety, agents, and evaluating state-of-the-art model performance.\nAs a Data Infrastructure Engineer on the AI Infrastructure team, you will design, build, and scale the data platform that powers all R&D and applied ML initiatives at Scale. Collaborating closely with product engineering, platform engineering, and ML researchers, you will build robust and easy-to-use APIs and data pipelines. Your work will play a critical role in advancing frontier ML research, accelerating the data sales cycle, and improving data quality - all while optimizing infrastructure costs.\nYou will:\nDesign, implement, and maintain scalable data platforms to support diverse R&D and applied ML workloads.\nPartner with ML researchers, product engineers, and operations teams to align data infrastructure with organizational goals.\nCollaborate with ML researchers to build data access tools that help advance the state of frontier post-training research.\nParticipate in our team\u2019s on call process to ensure the availability of our services.\nOwn projects end-to-end, from requirements, scoping, design, to implementation, in a highly collaborative and cross-functional environment.\nIdeally you'd have:\n2+ years of experience in building and operating large-scale distributed data systems that support ML workloads.\nExpertise in modern data platform technologies.\nExperience working with standard containerization & deployment technologies like Kubernetes, Helm, Terraform, Docker, etc.\nStrong problem solving skills and the ability to work effectively in a fast paced, dynamic environment.\nNice to haves:\nFamiliarity with ML development tools such as PyTorch, HuggingFace, or Weights & Biases.\nExperience with a variety of storage systems: object (S3), document (MongoDB), relational (Postgres), and distributed (Redis, Elasticsearch).\nExposure to orchestration platforms like Temporal, Airflow, or AWS Step Functions.\nExperience supporting post-training workflows such as evaluation, fine-tuning, and RLHF in LLM systems.\nExperience working in a fast-moving startup or high-scale ML infra environment.\nCompensation packages at Scale for eligible roles include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Scale employees in eligible roles are also granted equity based compensation, subject to Board of Director approval. Your recruiter can share more about the specific salary range for your preferred location during the hiring process, and confirm whether the hired role will be eligible for equity grant. You\u2019ll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.\nPlease reference the job posting's subtitle for where this position will be located. For pay transparency purposes, the base salary range for this full-time position in the locations of San Francisco, New York, Seattle is:\n$188,000\u2014$225,600 USD\nPLEASE NOTE: \nOur policy requires a 90-day waiting period before reconsidering candidates for the same role. This allows us to ensure a fair and thorough evaluation of all applicants.\nAbout Us:\nAt Scale, our mission is to develop reliable AI systems for the world's most important decisions. Our products provide the high-quality data and full-stack technologies that power the world's leading models, and help enterprises and governments build, deploy, and oversee AI applications that deliver real impact. We work closely with industry leaders like Meta, Cisco, DLA Piper, Mayo Clinic, Time Inc., the Government of Qatar, and U.S. government agencies including the Army and Air Force. We are expanding our team to accelerate the development of AI applications.\nWe believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status. \nWe are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's \nKnow Your Rights poster\n for additional information.\nWe comply with the United States Department of Labor's \nPay Transparency provision\n. \nPLEASE NOTE: \nWe collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants\u2019 needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data. Please see our privacy policy for additional information.", "comp": "0", "title": "AI Infrastructure Engineer, ML Data Platform", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4218868368", "loc": "San Francisco Bay Area", "company": "Scale AI"}, {"desc": "About Glean\nFounded in 2019, Glean is an innovative AI-powered knowledge management platform designed to help organizations quickly find, organize, and share information across their teams. By integrating seamlessly with tools like Google Drive, Slack, and Microsoft Teams, Glean ensures employees can access the right knowledge at the right time, boosting productivity and collaboration. The company\u2019s cutting-edge AI technology simplifies knowledge discovery, making it faster and more efficient for teams to leverage their collective intelligence.\nGlean was born from Founder & CEO Arvind Jain\u2019s deep understanding of the challenges employees face in finding and understanding information at work. Seeing firsthand how fragmented knowledge and sprawling SaaS tools made it difficult to stay productive, he set out to build a better way - an AI-powered enterprise search platform that helps people quickly and intuitively access the information they need. Since then, Glean has evolved into the leading Work AI platform, combining enterprise-grade search, an AI assistant, and powerful application- and agent-building capabilities to fundamentally redefine how employees work.\nAbout The Role\nAre you a recent university graduate with a passion for software engineering and a desire to make a difference in the tech world? We are seeking highly motivated and creative graduates to join our team in various software engineering roles: Backend Engineer, Product Engineer, and ML Engineer. As a University Graduate Software Engineer, you will participate in designing, developing, and maintaining software solutions that power our products and services. Team placements will be made at the end of the process based on interest and open roles.\nYou Will\nOwn impactful infrastructure problems from inception and architecture to production launch\nWrite well thought out design documents and ship robust, high-quality, well-tested code\nWork collaboratively with a strong team to identify the most impactful projects we should be prioritizing in our roadmap\nMentor more junior engineers and learn from experienced ones\nYou Are\nUndergraduate/graduate degree in Computer Science, or related degree - degree must be completed before joining\nStrong coding skills (e.g., Go, Python, Java, Javascript, or C++) with solid understanding of data structures, algorithms, and software design principles\nExperience working on infrastructure for distributed systems or cloud-native applications\nExperience building and shipping ML models and/or solving NLP problems\nA team player who thrives in a fast-paced, customer-focused environment, with a passion for learning and staying current with industry trends\nLocation:\nThis role is hybrid (3-4 days a week in our Palo Alto or San Francisco office)\nBenefits\nThe standard base salary range for this position is $140,000 - $150,000 annually. Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for variable compensation, equity, and benefits.\nWe offer a comprehensive benefits package including competitive compensation, Medical, Vision, and Dental coverage, generous time-off policy, and the opportunity to contribute to your 401k plan to support your long-term goals. When you join, you'll receive a home office improvement stipend, as well as an annual education and wellness stipends to support your growth and wellbeing. We foster a vibrant company culture through regular events, and provide healthy lunches daily to keep you fueled and focused.\nWe are a diverse bunch of people and we want to continue to attract and retain a diverse range of people into our organization. We're committed to an inclusive and diverse company. We do not discriminate based on gender, ethnicity, sexual orientation, religion, civil or family status, age, disability, or race.", "comp": "$140,000.00", "title": "Software Engineer, University Grad", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4295123743", "loc": "Palo Alto, CA", "company": "Glean"}, {"desc": "About Glean\nFounded in 2019, Glean is an innovative AI-powered knowledge management platform designed to help organizations quickly find, organize, and share information across their teams. By integrating seamlessly with tools like Google Drive, Slack, and Microsoft Teams, Glean ensures employees can access the right knowledge at the right time, boosting productivity and collaboration. The company\u2019s cutting-edge AI technology simplifies knowledge discovery, making it faster and more efficient for teams to leverage their collective intelligence.\nGlean was born from Founder & CEO Arvind Jain\u2019s deep understanding of the challenges employees face in finding and understanding information at work. Seeing firsthand how fragmented knowledge and sprawling SaaS tools made it difficult to stay productive, he set out to build a better way - an AI-powered enterprise search platform that helps people quickly and intuitively access the information they need. Since then, Glean has evolved into the leading Work AI platform, combining enterprise-grade search, an AI assistant, and powerful application- and agent-building capabilities to fundamentally redefine how employees work.\nAbout The Role\nGlean is looking for creative engineers to launch beautiful, smooth user facing features from within a modern React and TypeScript codebase. In a rapidly growing startup, this entails developing ideas with product designers to best balance constraints with requirements, delivering best-in-class user interfaces that run in modern mobile and desktop browsers, as well as creating frontend infrastructure to support rapid experimentation and development.\nYou Will\nBuild delightful user interfaces with React.js in collaboration with stellar product designers and backend engineers\nOversee the entirety of your features from inception to launch and beyond\nWrite robust code that\u2019s easy to read, maintain and test\nPush the boundaries of platform constraints to integrate an instant Glean experience into every workflow\nMentor more junior engineers or learn from battle tested ones\nAbout You\nBA/BS in computer science, or related degree\nExperience with a highly polished consumer grade React.js app, or 4+ with any web app\nThrive in a customer-focused, tight-knit and cross-functional environment\nA proactive and positive attitude to lead, learn, troubleshoot and take ownership of both small tasks and large features\nPassionate about using open web technologies (HTML5/CSS/JS) to build pixel perfect, zero-latency, 60FPS user interfaces that run on all devices \nComfortable in TypeScript, or JavaScript and type-curious\nExperienced in or desire to master one or more of: Progressive Web Apps (PWA), Web Extensions, Electron, Capacitor, React, Redux, Webpack\nLocation:\nThis role is hybrid (3 days a week in either our San Francisco or Palo Alto office)\nCompensation & Benefits\nThe standard base salary range for this position is $115,000 - $260,000 annually. Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for variable compensation, equity, and benefits.\nWe offer a comprehensive benefits package including competitive compensation, Medical, Vision, and Dental coverage, generous time-off policy, and the opportunity to contribute to your 401k plan to support your long-term goals. When you join, you'll receive a home office improvement stipend, as well as an annual education and wellness stipends to support your growth and wellbeing. We foster a vibrant company culture through regular events, and provide healthy lunches daily to keep you fueled and focused.\nWe are a diverse bunch of people and we want to continue to attract and retain a diverse range of people into our organization. We're committed to an inclusive and diverse company. We do not discriminate based on gender, ethnicity, sexual orientation, religion, civil or family status, age, disability, or race.", "comp": "$115,000.00", "title": "Software Engineer, Frontend", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4195258183", "loc": "San Francisco Bay Area", "company": "Glean"}, {"desc": "About Glean\nFounded in 2019, Glean is an innovative AI-powered knowledge management platform designed to help organizations quickly find, organize, and share information across their teams. By integrating seamlessly with tools like Google Drive, Slack, and Microsoft Teams, Glean ensures employees can access the right knowledge at the right time, boosting productivity and collaboration. The company\u2019s cutting-edge AI technology simplifies knowledge discovery, making it faster and more efficient for teams to leverage their collective intelligence.\nGlean was born from Founder & CEO Arvind Jain\u2019s deep understanding of the challenges employees face in finding and understanding information at work. Seeing firsthand how fragmented knowledge and sprawling SaaS tools made it difficult to stay productive, he set out to build a better way - an AI-powered enterprise search platform that helps people quickly and intuitively access the information they need. Since then, Glean has evolved into the leading Work AI platform, combining enterprise-grade search, an AI assistant, and powerful application- and agent-building capabilities to fundamentally redefine how employees work.\nAbout The Role\nGlean is looking for creative engineers to own and launch delightful user facing features. In a rapidly growing startup, this entails developing ideas with product managers and designers to best balance engineering constraints with requirements, delivering intuitive experiences that run in modern mobile and desktop browsers.\nYou Will\nOversee the entirety of your greenfield features from inception to implementation, experimentation, launch and beyond\nWork with designers, product managers, data scientists, and other engineers to understand our problem space and create elegant solutions\nArchitect REST APIs that are backed by stable, scalable server side implementations and maximize web client flexibility for rapidly meeting evolving product requirements\nWrite robust code that\u2019s efficient, easy to read, maintain and test\nMentor more junior engineers or learn from battle tested ones\nAbout You\nBA/BS in computer science, or related degree\nExperience of building and shipping scalable features across frontend and backend\nThrive in a customer-focused, tight-knit and cross-functional environment\nA proactive and positive attitude to lead, learn, troubleshoot and take ownership of both small tasks and large features\nA user-centric and empathetic mentality for building products\nExperience on a consumer grade web app frontend, preferably React based\nLove authoring easy-to-hold and future-proof REST APIs, OpenAPI is a plus\nExperience building distributed CRUD level functionality, ideally both SQL and NoSQL\nComfortable in or desire to master Golang, Java and TypeScript\nLocation:\nThis role is hybrid (3 days a week in either our San Francisco or Palo Alto office)\nCompensation & Benefits\nThe standard base salary range for this position is $140,000 - $265,000 annually. Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for variable compensation, equity, and benefits.\nWe offer a comprehensive benefits package including competitive compensation, Medical, Vision, and Dental coverage, generous time-off policy, and the opportunity to contribute to your 401k plan to support your long-term goals. When you join, you'll receive a home office improvement stipend, as well as an annual education and wellness stipends to support your growth and wellbeing. We foster a vibrant company culture through regular events, and provide healthy lunches daily to keep you fueled and focused.\nWe are a diverse bunch of people and we want to continue to attract and retain a diverse range of people into our organization. We're committed to an inclusive and diverse company. We do not discriminate based on gender, ethnicity, sexual orientation, religion, civil or family status, age, disability, or race.", "comp": "$140,000.00", "title": "Software Engineer, Fullstack", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4195259082", "loc": "San Francisco Bay Area", "company": "Glean"}, {"desc": "About Glean\nFounded in 2019, Glean is an innovative AI-powered knowledge management platform designed to help organizations quickly find, organize, and share information across their teams. By integrating seamlessly with tools like Google Drive, Slack, and Microsoft Teams, Glean ensures employees can access the right knowledge at the right time, boosting productivity and collaboration. The company\u2019s cutting-edge AI technology simplifies knowledge discovery, making it faster and more efficient for teams to leverage their collective intelligence.\nGlean was born from Founder & CEO Arvind Jain\u2019s deep understanding of the challenges employees face in finding and understanding information at work. Seeing firsthand how fragmented knowledge and sprawling SaaS tools made it difficult to stay productive, he set out to build a better way - an AI-powered enterprise search platform that helps people quickly and intuitively access the information they need. Since then, Glean has evolved into the leading Work AI platform, combining enterprise-grade search, an AI assistant, and powerful application- and agent-building capabilities to fundamentally redefine how employees work.\nAbout The Role\nAs a Software Engineer intern, you will participate in designing, developing, and maintaining software solutions that power our products and services.\nYou Will\nOwn a scoped, high-impact project end to end - from defining the problem and writing a design, to building, testing, launching, and measuring outcomes\nShip production-quality code that is reliable, well-tested, and maintainable, with thoughtful code reviews and iterative feedback\nLearn quickly and contribute across the stack based on your interests - backend services, product engineering, ML/AI/search, infrastructure, security, and more\nWork closely with people both within and beyond your team while having fun along the way\nAbout You\nGraduating in Fall 2026 or Spring 2027 with a B.S., M.S. or Ph.D. in Computer Science or equivalent program\nA team player, a strong desire to learn, and an owner mentality\nComfortable working in a fast paced, data-driven environment\nInterested in something in the realm of Backend, Infrastructure, Security, UI/full-stack, or ML/NLP/Search\nPrior internship experience in one or more of the areas above\nStrong foundation in CS and software development fundamentals\nLocation:\nThis role is hybrid (3-4 days a week in our Palo Alto or San Francisco office)\nCompensation & Benefits\nThe hourly pay range for this position is $57 - $69. Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for variable compensation, equity, and benefits.\nWe are a diverse bunch of people and we want to continue to attract and retain a diverse range of people into our organization. We're committed to an inclusive and diverse company. We do not discriminate based on gender, ethnicity, sexual orientation, religion, civil or family status, age, disability, or race.", "comp": "$57.00/hr", "title": "Software Engineer, Intern (Summer)", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4295127351", "loc": "Palo Alto, CA", "company": "Glean"}, {"desc": "About Glean\nFounded in 2019, Glean is an innovative AI-powered knowledge management platform designed to help organizations quickly find, organize, and share information across their teams. By integrating seamlessly with tools like Google Drive, Slack, and Microsoft Teams, Glean ensures employees can access the right knowledge at the right time, boosting productivity and collaboration. The company\u2019s cutting-edge AI technology simplifies knowledge discovery, making it faster and more efficient for teams to leverage their collective intelligence.\nGlean was born from Founder & CEO Arvind Jain\u2019s deep understanding of the challenges employees face in finding and understanding information at work. Seeing firsthand how fragmented knowledge and sprawling SaaS tools made it difficult to stay productive, he set out to build a better way - an AI-powered enterprise search platform that helps people quickly and intuitively access the information they need. Since then, Glean has evolved into the leading Work AI platform, combining enterprise-grade search, an AI assistant, and powerful application- and agent-building capabilities to fundamentally redefine how employees work.\nAbout The Role\nGlean is looking for Backend/Infrastructure engineers to build a highly performant, scalable, secure, permissions-aware system that makes all the relevant enterprise knowledge readily available to employees in all contexts of their work. The role provides ample opportunities to work on various aspects of building a modern cloud-native application stack using the latest best practices - examples of some technical challenges you can work on are building a scalable, reliable distributed system and underlying storage, a unified application framework and data model that makes it easy to index diverse sources of information, end-to-end aspects of security - application layer, platform layer as well as IT security, laser focus on making the experience feel instant, while at the same time balancing the system cost implications, and tooling for comprehensive monitoring and deployment of the system in multiple cloud environments.\nYou Will\nOwn impactful infrastructure problems from inception and architecture to production launch\nWrite well thought out design documents and robust, high-quality and well-tested code\nWork collaboratively with a strong team to identify the most impactful projects we should be prioritizing in our roadmap\nMentor more junior engineers or learn from battle tested ones\nYou Are\n3+ years of experience\nBA/BS in computer science, or related degree\nExperience working on infrastructure for distributed systems or cloud-native applications\nKey Knowledge And Skills\nThrive in a customer-focused, tight-nit and cross-functional environment - being a team player and willing to take on whatever is most impactful for the company is a must\nA proactive and positive attitude to lead, learn, troubleshoot and take ownership of both small tasks and large features\nStrong coding skills (for example in Go/Python/Java/C++ etc) with an emphasis on designing for reliability and scale, and writing well-tested components\nFamiliarity with cloud native development practices in GCP/AWS/Azure is a plus\nLocation:\nThis role is hybrid (3-4 days a week in one of our SF Bay Area offices)\nCompensation & Benefits\nThe standard base salary range for this position is $140,000 - $265,000 annually. Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for variable compensation, equity, and benefits.\nWe offer a comprehensive benefits package including competitive compensation, Medical, Vision, and Dental coverage, generous time-off policy, and the opportunity to contribute to your 401k plan to support your long-term goals. When you join, you'll receive a home office improvement stipend, as well as an annual education and wellness stipends to support your growth and wellbeing. We foster a vibrant company culture through regular events, and provide healthy lunches daily to keep you fueled and focused.\nWe are a diverse bunch of people and we want to continue to attract and retain a diverse range of people into our organization. We're committed to an inclusive and diverse company. We do not discriminate based on gender, ethnicity, sexual orientation, religion, civil or family status, age, disability, or race.", "comp": "$140,000.00", "title": "Software Engineer, Backend", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4258382945", "loc": "San Francisco Bay Area", "company": "Glean"}, {"desc": "About Glean\nFounded in 2019, Glean is an innovative AI-powered knowledge management platform designed to help organizations quickly find, organize, and share information across their teams. By integrating seamlessly with tools like Google Drive, Slack, and Microsoft Teams, Glean ensures employees can access the right knowledge at the right time, boosting productivity and collaboration. The company\u2019s cutting-edge AI technology simplifies knowledge discovery, making it faster and more efficient for teams to leverage their collective intelligence.\nGlean was born from Founder & CEO Arvind Jain\u2019s deep understanding of the challenges employees face in finding and understanding information at work. Seeing firsthand how fragmented knowledge and sprawling SaaS tools made it difficult to stay productive, he set out to build a better way - an AI-powered enterprise search platform that helps people quickly and intuitively access the information they need. Since then, Glean has evolved into the leading Work AI platform, combining enterprise-grade search, an AI assistant, and powerful application- and agent-building capabilities to fundamentally redefine how employees work.\nAbout The Role\nGlean is looking for engineers to help build the world\u2019s best search and assistant product for work. Our engineers work on a range of systems across the stack, including query understanding, document understanding, domain-adapted language models, natural language question-answering, evaluation, and experimentation. We interact regularly with customers, deeply understand their pain points, and use whatever tool is necessary, simple or complex, to solve their problems.\nYou Will\nInvent new signals to improve the personalization of our search engine\nTrain a model to capture interactions between signals in our ranking system\nDesign smarter ways to domain-adapt language models to each customer\u2019s corpus\nDiscover new ways of combining LLMs with search engines to answer complex questions\nWrite robust code that\u2019s easy to read, maintain, and test\nMentor more junior engineers, or learn from battle-tested ones\nAbout You\n2+ years of experience\nBA/BS in computer science, math, sciences, or a related degree\nExperience working with search, recommendation, natural language processing, or other large systems involving machine learning\nStrong analytical skills and ability to work with data\nProven ability to design, build, and ship production-ready models\nProficiency in your ML framework of choice\nStrong coding skills (Python, Go, Java, C++, ...)\nThrive in a customer-focused, tight-knit and cross-functional environment - being a team player and willing to take on whatever is most impactful for the company is a must\nA proactive and positive attitude to lead, learn, troubleshoot and take ownership of both small tasks and large features\nLocation:\nThis role is hybrid (3-4 days a week in one of our SF Bay Area offices)\nCompensation & Benefits\nThe standard base salary range for this position is $140,000 - $265,000 annually. Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for variable compensation, equity, and benefits.\nWe offer a comprehensive benefits package including competitive compensation, Medical, Vision, and Dental coverage, generous time-off policy, and the opportunity to contribute to your 401k plan to support your long-term goals. When you join, you'll receive a home office improvement stipend, as well as an annual education and wellness stipends to support your growth and wellbeing. We foster a vibrant company culture through regular events, and provide healthy lunches daily to keep you fueled and focused.\nWe are a diverse bunch of people and we want to continue to attract and retain a diverse range of people into our organization. We're committed to an inclusive and diverse company. We do not discriminate based on gender, ethnicity, sexual orientation, religion, civil or family status, age, disability, or race.", "comp": "$140,000.00", "title": "Software Engineer, Machine Learning", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4195257196", "loc": "San Francisco Bay Area", "company": "Glean"}, {"desc": "About Glean\nFounded in 2019, Glean is an innovative AI-powered knowledge management platform designed to help organizations quickly find, organize, and share information across their teams. By integrating seamlessly with tools like Google Drive, Slack, and Microsoft Teams, Glean ensures employees can access the right knowledge at the right time, boosting productivity and collaboration. The company\u2019s cutting-edge AI technology simplifies knowledge discovery, making it faster and more efficient for teams to leverage their collective intelligence.\nGlean was born from Founder & CEO Arvind Jain\u2019s deep understanding of the challenges employees face in finding and understanding information at work. Seeing firsthand how fragmented knowledge and sprawling SaaS tools made it difficult to stay productive, he set out to build a better way - an AI-powered enterprise search platform that helps people quickly and intuitively access the information they need. Since then, Glean has evolved into the leading Work AI platform, combining enterprise-grade search, an AI assistant, and powerful application- and agent-building capabilities to fundamentally redefine how employees work.\nAbout The Role\nGlean is looking for creative engineers to own and launch delightful user facing features. In a rapidly growing startup, this entails developing ideas with product managers and designers to best balance engineering constraints with requirements.\nYou Will\nOversee the entirety of your greenfield features from inception to implementation, experimentation, launch and beyond\nWork with designers, product managers, data scientists, and other engineers to understand our problem space and create elegant solutions\nArchitect REST APIs that are backed by stable, scalable server side implementations and maximize web client flexibility for rapidly meeting evolving product requirements\nWrite robust code that\u2019s efficient, easy to read, maintain and test\nMentor more junior engineers or learn from battle tested ones\nAbout You\nBA/BS in computer science, or related degree\nExperience of building and shipping scalable features in the backend\nKey Knowledge And Skills\nThrive in a customer-focused, tight-knit and cross-functional environment\nA proactive and positive attitude to lead, learn, troubleshoot and take ownership of both small tasks and large features\nA user-centric and empathetic mentality for building products\nExperience in building scalable & maintainable backend systems\nLove authoring easy-to-hold and future-proof REST APIs, OpenAPI is a plus\nExperience building distributed CRUD level functionality, ideally both SQL and NoSQL\nComfortable in or desire to master Golang and Java \nCompensation & Benefits\nThe standard base salary range for this position is $140,000 - $265,000 annually. Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for variable compensation, equity, and benefits.\nWe offer a comprehensive benefits package including competitive compensation, Medical, Vision, and Dental coverage, generous time-off policy, and the opportunity to contribute to your 401k plan to support your long-term goals. When you join, you'll receive a home office improvement stipend, as well as an annual education and wellness stipends to support your growth and wellbeing. We foster a vibrant company culture through regular events, and provide healthy lunches daily to keep you fueled and focused.\nWe are a diverse bunch of people and we want to continue to attract and retain a diverse range of people into our organization. We're committed to an inclusive and diverse company. We do not discriminate based on gender, ethnicity, sexual orientation, religion, civil or family status, age, disability, or race.", "comp": "$140,000.00", "title": "Software Engineer, Product Backend", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4195260019", "loc": "San Francisco Bay Area", "company": "Glean"}, {"desc": "About Glean\nFounded in 2019, Glean is an innovative AI-powered knowledge management platform designed to help organizations quickly find, organize, and share information across their teams. By integrating seamlessly with tools like Google Drive, Slack, and Microsoft Teams, Glean ensures employees can access the right knowledge at the right time, boosting productivity and collaboration. The company\u2019s cutting-edge AI technology simplifies knowledge discovery, making it faster and more efficient for teams to leverage their collective intelligence.\nGlean was born from Founder & CEO Arvind Jain\u2019s deep understanding of the challenges employees face in finding and understanding information at work. Seeing firsthand how fragmented knowledge and sprawling SaaS tools made it difficult to stay productive, he set out to build a better way - an AI-powered enterprise search platform that helps people quickly and intuitively access the information they need. Since then, Glean has evolved into the leading Work AI platform, combining enterprise-grade search, an AI assistant, and powerful application- and agent-building capabilities to fundamentally redefine how employees work.\nAbout The Role\nWe are looking for a Software Engineer, Developer Productivity to shape the way our engineers build, test, and ship software. Our codebase is large and multi-language, powered by Bazel, with pipelines running on GitHub Actions and cloud remote execution.\nIn this role, you will design and optimize build systems, CI/CD pipelines, and developer tooling, while also enabling engineers to effectively leverage AI-powered coding and productivity tools. Your work will reduce friction in everyday workflows, scale our infrastructure, and help the entire engineering team move faster with confidence.\nYou Will\nBuild Systems & Tooling\nDevelop and maintain our Bazel monorepo with support for multiple languages.\nImprove build hermeticity, caching, reproducibility, and dependency management.\nExtend Bazel with custom rules, macros, and integrations.\nCI/CD Engineering\nOperate and optimize pipelines on GitHub Actions, Kubernetes, and cloud runners.\nReduce CI latency through remote execution, caching, and parallelization.\nInstrument pipelines with telemetry and dashboards to measure speed, reliability, and cost.\nDeveloper Enablement\nBuild tools and workflows (CLI utilities, IDE plugins, GitHub bots) that improve day-to-day developer experience.\nAutomate debugging of flaky tests and CI failures.\nSimplify onboarding and local dev environments.\nAI Adoption & Productivity\nEnable engineers to integrate AI-powered coding assistants (e.g. GitHub Copilot, Cursor, Claude) into daily workflows.\nBuild agentic tooling that automates CI failure analysis, PR triage, and code review support.\nCollect usage insights, build dashboards, and iterate on adoption strategies to maximize developer ROI from AI.\nAdditionally\nYou\u2019ll work on critical build and CI/CD systems that touch every engineer\u2019s workflow.\nYou\u2019ll have a direct impact on the speed, reliability, and cost of software delivery.\nYou\u2019ll be at the frontier of AI adoption in engineering teams, shaping how humans and AI collaborate in development.\nYou\u2019ll have opportunities to contribute to open source (Bazel, rules projects, CI tooling) and share learnings at conferences\nAbout You\nStrong software engineering background (Java, Go, Python, or similar).\nExperience with build systems (Bazel strongly preferred; Buck, Blaze, Gradle, or Maven acceptable).\nHands-on with CI/CD systems (GitHub Actions, Buildkite, Jenkins, etc.).\nFamiliarity with Docker/Kubernetes, cloud runners, and distributed build/test environments.\nExperience integrating or enabling AI developer tools is a plus.\nStrong debugging skills and an interest in solving workflow bottlenecks.\nPassion for multiplying the effectiveness of other engineers.\nLocation:\nThis role is hybrid (3-4 days a week in one of our SF Bay Area offices)\nCompensation & Benefits\nThe standard base salary range for this position is $140,000 - $265,000 annually. Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for variable compensation, equity, and benefits.\nWe offer a comprehensive benefits package including competitive compensation, Medical, Vision, and Dental coverage, generous time-off policy, and the opportunity to contribute to your 401k plan to support your long-term goals. When you join, you'll receive a home office improvement stipend, as well as an annual education and wellness stipends to support your growth and wellbeing. We foster a vibrant company culture through regular events, and provide healthy lunches daily to keep you fueled and focused.\nWe are a diverse bunch of people and we want to continue to attract and retain a diverse range of people into our organization. We're committed to an inclusive and diverse company. We do not discriminate based on gender, ethnicity, sexual orientation, religion, civil or family status, age, disability, or race.", "comp": "$140,000.00", "title": "Software Engineer, Developer Productivity", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4308502697", "loc": "San Francisco Bay Area", "company": "Glean"}, {"desc": "About Glean\nFounded in 2019, Glean is an innovative AI-powered knowledge management platform designed to help organizations quickly find, organize, and share information across their teams. By integrating seamlessly with tools like Google Drive, Slack, and Microsoft Teams, Glean ensures employees can access the right knowledge at the right time, boosting productivity and collaboration. The company\u2019s cutting-edge AI technology simplifies knowledge discovery, making it faster and more efficient for teams to leverage their collective intelligence.\nGlean was born from Founder & CEO Arvind Jain\u2019s deep understanding of the challenges employees face in finding and understanding information at work. Seeing firsthand how fragmented knowledge and sprawling SaaS tools made it difficult to stay productive, he set out to build a better way - an AI-powered enterprise search platform that helps people quickly and intuitively access the information they need. Since then, Glean has evolved into the leading Work AI platform, combining enterprise-grade search, an AI assistant, and powerful application- and agent-building capabilities to fundamentally redefine how employees work.\nAbout The Role\nGlean is seeking a Backend/Infrastructure Engineer to build and evolve the Storage layer that powers a highly available, performant, secure, and cost-effective suite of storage options for all data at Glean.\nYou\u2019ll own the storage systems that handle Glean\u2019s most sensitive data \u2014 from enterprise documents and permission hierarchies to user behavioral signals and real-time query path data. Your work will directly enable organizations at scale to discover and act on their critical knowledge, supporting millions of searches, chat interactions, and agent workflows.\nYou\u2019ll deliver robust uptime guarantees, autoscaling, and reliable alerting/monitoring for a key component that runs across multiple cloud providers. As part of the Storage team, you\u2019ll be responsible for a critical piece of Glean\u2019s infrastructure, working closely with several other teams to support their workloads.\nYou\u2019ll also work across the stack to abstract cloud differences, reduce human intervention through self-healing systems, and drive real business impact by enabling Glean\u2019s ever-growing scale.\nYou Will\nOwn impactful infrastructure problems from inception and architecture to production launch\nWrite well thought out design documents and robust, high-quality and well-tested code\nWork collaboratively with a strong team to identify the most impactful projects we should be prioritizing in our roadmap\nMentor more junior engineers or learn from battle tested ones\nYou Are\n3+ years of experience\nBA/BS in computer science, or related degree\nExperience working on infrastructure for distributed systems or cloud-native applications\nExperience with storage systems (e.g., databases, object stores, or distributed file systems)\nKey Knowledge And Skills\nThrive in a customer-focused, tight-nit and cross-functional environment - being a team player and willing to take on whatever is most impactful for the company is a must\nA proactive and positive attitude to lead, learn, troubleshoot and take ownership of both small tasks and large features\nStrong coding skills (for example in Go/Python/Java/C++ etc) with an emphasis on designing for reliability and scale, and writing well-tested components\nFamiliarity with cloud native development practices in GCP/AWS/Azure is a plus\nLocation:\nThis role is hybrid (3-4 days a week in one of our SF Bay Area offices)\nCompensation & Benefits\nThe standard base salary range for this position is $140,000 - $265,000 annually. Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for variable compensation, equity, and benefits.\nWe offer a comprehensive benefits package including competitive compensation, Medical, Vision, and Dental coverage, generous time-off policy, and the opportunity to contribute to your 401k plan to support your long-term goals. When you join, you'll receive a home office improvement stipend, as well as an annual education and wellness stipends to support your growth and wellbeing. We foster a vibrant company culture through regular events, and provide healthy lunches daily to keep you fueled and focused.\nWe are a diverse bunch of people and we want to continue to attract and retain a diverse range of people into our organization. We're committed to an inclusive and diverse company. We do not discriminate based on gender, ethnicity, sexual orientation, religion, civil or family status, age, disability, or race.", "comp": "$140,000.00", "title": "Software Engineer, Storage", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4302477597", "loc": "San Francisco Bay Area", "company": "Glean"}, {"desc": "About Glean\nFounded in 2019, Glean is an innovative AI-powered knowledge management platform designed to help organizations quickly find, organize, and share information across their teams. By integrating seamlessly with tools like Google Drive, Slack, and Microsoft Teams, Glean ensures employees can access the right knowledge at the right time, boosting productivity and collaboration. The company\u2019s cutting-edge AI technology simplifies knowledge discovery, making it faster and more efficient for teams to leverage their collective intelligence.\nGlean was born from Founder & CEO Arvind Jain\u2019s deep understanding of the challenges employees face in finding and understanding information at work. Seeing firsthand how fragmented knowledge and sprawling SaaS tools made it difficult to stay productive, he set out to build a better way - an AI-powered enterprise search platform that helps people quickly and intuitively access the information they need. Since then, Glean has evolved into the leading Work AI platform, combining enterprise-grade search, an AI assistant, and powerful application- and agent-building capabilities to fundamentally redefine how employees work.\nAbout The Role\nGlean is looking for senior engineers who will provide expert-level individual contributions and thought leadership to help us build the next generation of intelligent enterprise AI assistants and autonomous AI agents. We are reimagining how LLMs and agents can reason, plan, and act to solve complex, multi-step enterprise workflows. You will work at the intersection of applied research and production engineering in areas such as agentic frameworks, LLM orchestration, low latency LLM inference and optimization, domain adapted and memory augmented LLMs, reinforcement learning, building evaluation frameworks for complex enterprise tasks. We work closely with our customers, deeply understand their pain points, and use the right mix of research-driven and pragmatic engineering approaches to solve them.\nYou Will\nBuild frameworks for LLM-powered agents to use tools and knowledge sources effectively\nInvent new agentic architectures and signals to improve reasoning, planning, and personalization in workplace AI assistants\nDesign and optimize reinforcement learning and fine-tuning approaches to improve the quality of agentic systems\nLead development of scalable evaluation, benchmarking, and optimization loops for agents in production\nDrive technical strategy and mentor other engineers, raising the technical bar across the team\nWrite robust, maintainable, and well-tested code that powers enterprise-grade assistants and agents\nAbout You\n2+ years as a Staff Engineer, Principal Engineer, or equivalent\n5+ years of industry experience in AI or Machine Learning Engineering\nExperience working with agentic frameworks, reinforcement learning, natural language processing, or other large systems involving machine learning\nProven ability to design, build, and ship production-ready systems\nProficiency in your ML framework of choice\nStrong coding skills (Python, Go, Java, C++, ...)\nThrive in a customer-focused, tight-knit and cross-functional environment - being a team player and willing to take on whatever is most impactful for the company\nA proactive and positive attitude to lead, learn, troubleshoot, and take ownership of both small tasks and large features\nLocation:\nThis role is hybrid (3-4 days a week in one of our SF Bay Area offices)\nCompensation & Benefits\nThe standard base salary range for this position is $240,000 - $300,000 annually. Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for variable compensation, equity, and benefits.\nWe offer a comprehensive benefits package including competitive compensation, Medical, Vision, and Dental coverage, generous time-off policy, and the opportunity to contribute to your 401k plan to support your long-term goals. When you join, you'll receive a home office improvement stipend, as well as an annual education and wellness stipends to support your growth and wellbeing. We foster a vibrant company culture through regular events, and provide healthy lunches daily to keep you fueled and focused.\nWe are a diverse bunch of people and we want to continue to attract and retain a diverse range of people into our organization. We're committed to an inclusive and diverse company. We do not discriminate based on gender, ethnicity, sexual orientation, religion, civil or family status, age, disability, or race.", "comp": "$240,000.00", "title": "Machine Learning Engineer - AI Assistant + Autonomous AI Agents", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4293940655", "loc": "San Francisco Bay Area", "company": "Glean"}, {"desc": "About Glean\nFounded in 2019, Glean is an innovative AI-powered knowledge management platform designed to help organizations quickly find, organize, and share information across their teams. By integrating seamlessly with tools like Google Drive, Slack, and Microsoft Teams, Glean ensures employees can access the right knowledge at the right time, boosting productivity and collaboration. The company\u2019s cutting-edge AI technology simplifies knowledge discovery, making it faster and more efficient for teams to leverage their collective intelligence.\nGlean was born from Founder & CEO Arvind Jain\u2019s deep understanding of the challenges employees face in finding and understanding information at work. Seeing firsthand how fragmented knowledge and sprawling SaaS tools made it difficult to stay productive, he set out to build a better way - an AI-powered enterprise search platform that helps people quickly and intuitively access the information they need. Since then, Glean has evolved into the leading Work AI platform, combining enterprise-grade search, an AI assistant, and powerful application- and agent-building capabilities to fundamentally redefine how employees work.\nAbout The Role\nGlean is seeking a talented security-focused software engineer to join our growing team. In this role, you will play a critical role in developing and maintaining the security foundation of our platform. You will be responsible for designing, implementing, and testing security features across various software components.\nYou Will\n \nDesign, develop, and maintain secure software for core platform functionalities, particularly focusing on:\nAuthentication and authorization systems\nSecure communication channels between services (e.g., API security)\nSecure data storage and access controls\nCollaborate with cross-functional teams (engineering, product) to integrate security best practices throughout the development lifecycle.\nStay up-to-date on the latest security threats, vulnerabilities, and mitigation strategies.\nConduct security code reviews and identify potential security risks in existing codebases.\nDevelop and implement automated security testing procedures.\nRespond to security incidents and participate in incident response procedures.\nContinuously improve the platform's security posture by identifying and implementing security enhancements.\nDocument security processes, procedures, and best practices.\nAbout You\nBA/BS in computer science, or related degree, MS a strong plus\nMinimum 5+ years of experience in software development with a strong focus on security aspects\nProven experience in designing and implementing secure authentication and authorization systems\nIn-depth understanding of secure coding principles and best practices (e.g., OWASP Top 10)\nExperience with secure communication protocols (e.g., TLS/SSL)\nFamiliarity with security testing tools and methodologies (e.g., static code analysis, penetration testing)\nExcellent problem-solving and analytical skills\nStrong communication and collaboration skills\nAbility to work independently and as part of a cross-functional team\nPassion for security and a commitment to building secure and reliable systems\nKey Knowledge And Skills\nThrive in a customer-focused, tight-nit and cross-functional environment - being a team player and willing to take on whatever is most impactful for the company is a must.\nA proactive and positive attitude to lead, learn, troubleshoot and take ownership of both small tasks and large features.\nAn interest/desire to learn and own various aspects of security. \nStrong coding skills (for example in Go/Python/Java/C++ etc) with an emphasis on designing for reliability and scale, and writing well-tested components.\nExperience with cloud security principles and tools (AWS Security, GCP Security)\nExperience with container security (Docker Security, Kubernetes Security)\nLocation:\nThis role is hybrid (3-4 days a week in one of our SF Bay Area offices)\nCompensation & Benefits\nThe standard base salary range for this position is $185,000 - $280,000 annually. Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for variable compensation, equity, and benefits.\nWe offer a comprehensive benefits package including competitive compensation, Medical, Vision, and Dental coverage, generous time-off policy, and the opportunity to contribute to your 401k plan to support your long-term goals. When you join, you'll receive a home office improvement stipend, as well as an annual education and wellness stipends to support your growth and wellbeing. We foster a vibrant company culture through regular events, and provide healthy lunches daily to keep you fueled and focused.\nWe are a diverse bunch of people and we want to continue to attract and retain a diverse range of people into our organization. We're committed to an inclusive and diverse company. We do not discriminate based on gender, ethnicity, sexual orientation, religion, civil or family status, age, disability, or race.", "comp": "$185,000.00", "title": "Software Engineer, Security", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4195256513", "loc": "San Francisco Bay Area", "company": "Glean"}, {"desc": "About Glean\nFounded in 2019, Glean is an innovative AI-powered knowledge management platform designed to help organizations quickly find, organize, and share information across their teams. By integrating seamlessly with tools like Google Drive, Slack, and Microsoft Teams, Glean ensures employees can access the right knowledge at the right time, boosting productivity and collaboration. The company\u2019s cutting-edge AI technology simplifies knowledge discovery, making it faster and more efficient for teams to leverage their collective intelligence.\nGlean was born from Founder & CEO Arvind Jain\u2019s deep understanding of the challenges employees face in finding and understanding information at work. Seeing firsthand how fragmented knowledge and sprawling SaaS tools made it difficult to stay productive, he set out to build a better way - an AI-powered enterprise search platform that helps people quickly and intuitively access the information they need. Since then, Glean has evolved into the leading Work AI platform, combining enterprise-grade search, an AI assistant, and powerful application- and agent-building capabilities to fundamentally redefine how employees work.\nGlean is looking for driven engineers to solve cutting edge problems in data and AI security and governance. In a rapidly growing startup, this entails empathizing with customer needs, understanding the problems and research in the domain to come up with novel solutions to challenging problems. Engineers are expected to develop ideas with product managers and designers to best balance engineering constraints with requirements, delivering intuitive experiences that enterprises can rely on to keep their users safe.\nYou Will\nOversee the entirety of your greenfield features from inception to implementation, experimentation, launch and beyond\nProvide leadership and mentor more junior engineers\nWork with designers, product managers, data scientists, and other engineers to understand our problem space and create elegant solutions\nArchitect data pipelines, AI models, and REST APIs that are backed by stable, scalable server side implementations and maximize product flexibility for rapidly meeting evolving domain requirements\nWrite robust code that\u2019s efficient, easy to read, maintain and test\nAbout You\n5+ years of experience in product engineering\nExperience developing enterprise security products\nExperience in using AI/ML in the product \nBA/BS in computer science, or related degree\nExperience building and shipping scalable features across the frontend and backend\nThrive in a customer-focused, tight-knit and cross-functional environment\nA proactive and positive attitude to lead, learn, troubleshoot and take ownership of both small tasks and large features\nA user-centric and empathetic mentality for product development \nLove authoring easy-to-hold and future-proof REST APIs, OpenAPI is a plus\nExperience building distributed CRUD level functionality, ideally both SQL and NoSQL\nComfortable with or desire to master Golang, Java and TypeScript\nComfortable with effective use of AI tools for development\nLocation:\nThis role is hybrid (4 days a week in our Palo Alto office)\nCompensation & Benefits\nThe standard base salary range for this position is $140,000 - $265,000 annually. Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for variable compensation, equity, and benefits.\nWe offer a comprehensive benefits package including competitive compensation, Medical, Vision, and Dental coverage, generous time-off policy, and the opportunity to contribute to your 401k plan to support your long-term goals. When you join, you'll receive a home office improvement stipend, as well as an annual education and wellness stipends to support your growth and wellbeing. We foster a vibrant company culture through regular events, and provide healthy lunches daily to keep you fueled and focused.\nWe are a diverse bunch of people and we want to continue to attract and retain a diverse range of people into our organization. We're committed to an inclusive and diverse company. We do not discriminate based on gender, ethnicity, sexual orientation, religion, civil or family status, age, disability, or race.", "comp": "$140,000.00", "title": "Software Engineer, AI and Security", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4293948449", "loc": "Palo Alto, CA", "company": "Glean"}, {"desc": "About Glean\nFounded in 2019, Glean is an innovative AI-powered knowledge management platform designed to help organizations quickly find, organize, and share information across their teams. By integrating seamlessly with tools like Google Drive, Slack, and Microsoft Teams, Glean ensures employees can access the right knowledge at the right time, boosting productivity and collaboration. The company\u2019s cutting-edge AI technology simplifies knowledge discovery, making it faster and more efficient for teams to leverage their collective intelligence.\nGlean was born from Founder & CEO Arvind Jain\u2019s deep understanding of the challenges employees face in finding and understanding information at work. Seeing firsthand how fragmented knowledge and sprawling SaaS tools made it difficult to stay productive, he set out to build a better way - an AI-powered enterprise search platform that helps people quickly and intuitively access the information they need. Since then, Glean has evolved into the leading Work AI platform, combining enterprise-grade search, an AI assistant, and powerful application- and agent-building capabilities to fundamentally redefine how employees work.\nAbout The Role\nGlean is looking for engineers to help build the world\u2019s best search and assistant product for work. Our engineers work on a range of systems across the stack, including generative AI, RAG, query understanding, document understanding, domain-adapted language models, natural language question-answering, evaluation, and experimentation. We interact regularly with customers, deeply understand their pain points, and use whatever tool is necessary, simple or complex, to solve their problems.\nYou Will\nDesign, build, and improve ML systems and Data pipelines infrastructure\nWork with and enable other ML engineers focused on modeling\nWrite robust code that\u2019s easy to read, maintain, and test\nMentor more junior engineers, or learn from battle-tested ones\nAbout You\n5+ years of experience\nBA/BS in computer science, math, sciences, or a related degree\nExperience working with ML infrastructure and engineering for search, recommendation, natural language processing, or something similar\nProven ability to design, build, and ship production-ready software, ideally around ML infrastructure (pipelines, serving, GenAI)\nStrong Experience working with Apache Spark and hands-on experience with building, scaling, and operating large batch data pipelines\nStrong coding skills (Python, Go, Java, C++, ...)\nThrive in a customer-focused, tight-knit and cross-functional environment - being a team player and willing to take on whatever is most impactful for the company is a must\nA proactive and positive attitude to lead, learn, troubleshoot and take ownership of both small tasks and large features\nLocation:\nThis role is hybrid (3-4 days a week in one of our SF Bay Area offices)\nCompensation & Benefits\nThe standard base salary range for this position is $200,000 - $280,000 annually. Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for variable compensation, equity, and benefits.\nWe offer a comprehensive benefits package including competitive compensation, Medical, Vision, and Dental coverage, generous time-off policy, and the opportunity to contribute to your 401k plan to support your long-term goals. When you join, you'll receive a home office improvement stipend, as well as an annual education and wellness stipends to support your growth and wellbeing. We foster a vibrant company culture through regular events, and provide healthy lunches daily to keep you fueled and focused.\nWe are a diverse bunch of people and we want to continue to attract and retain a diverse range of people into our organization. We're committed to an inclusive and diverse company. We do not discriminate based on gender, ethnicity, sexual orientation, religion, civil or family status, age, disability, or race.", "comp": "$200,000.00", "title": "Software Engineer, Machine Learning (Infrastructure)", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4283317485", "loc": "San Francisco Bay Area", "company": "Glean"}, {"desc": "About Glean:\nFounded in 2019, Glean is an innovative AI-powered knowledge management platform designed to help organisations quickly find, organise, and share information across their teams. By integrating seamlessly with tools like Google Drive, Slack, and Microsoft Teams, Glean ensures employees can access the right knowledge at the right time, boosting productivity and collaboration. The company\u2019s cutting-edge AI technology simplifies knowledge discovery, making it faster and more efficient for teams to leverage their collective intelligence.\nGlean\n was born from Founder & CEO Arvind Jain\u2019s deep understanding of the challenges employees face in finding and understanding information at work. Seeing firsthand how fragmented knowledge and sprawling SaaS tools made it difficult to stay productive, he set out to build a better way. This AI-powered enterprise search platform helps people quickly and intuitively access the information they need. Since then, Glean has evolved into the leading Work AI platform, combining enterprise-grade search, an AI assistant, and powerful application- and agent-building capabilities to redefine how employees work fundamentally.\nYou will:\nPartner with Account Executives to navigate complex, multi-stakeholder deal cycles with C-level executives\nCreate and demo custom environments based off of customer industry and line of business\nRun and manage a technical POC cycle\nPerform customer facing activities including technical discovery calls\nLead security based conversations to make customers comfortable with Glean\u2019s security posture\nWork cross functionally with product and engineering to deliver customer request and be a voice of the customer\nDevelop ROI and business justification reports and presentations\nAbout you:\n5+ years of sales engineering or solution consulting experience in a SaaS organization\nBachelor's degree in CS or a related field\nExcellent written and verbal communication skills\nHighly motivated, driven and self-starting individual\nAbility to work in a fast paced, team environment\nClear examples of partnering with AEs to run technical deal cycles with Enterprise customers\nA consultative approach with solving your customer\u2019s business challenges and having a track record of successfully overcoming technical and security objections\nFamiliarity with any cloud environment (GCP, AWS, Azure)\nProficiency in Python or Java\nAbility to configure, monitor, and maintain API based integrations\n \nLocation:\nThis role is hybrid for Bay Area based candidates \nCompensation & Benefits:\nThe standard OTE range for this position is $110,000 - $235,000 annually. Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for variable compensation, equity, and benefits.\nWe offer a comprehensive benefits package including competitive compensation, Medical, Vision, and Dental coverage, generous time-off policy, and the opportunity to contribute to your 401k plan to support your long-term goals. When you join, you'll receive a home office improvement stipend, as well as an annual education and wellness stipends to support your growth and wellbeing. We foster a vibrant company culture through regular events, and provide healthy lunches daily to keep you fueled and focused.\nWe are a diverse bunch of people and we want to continue to attract and retain a diverse range of people into our organization. We're committed to an inclusive and diverse company. We do not discriminate based on gender, ethnicity, sexual orientation, religion, civil or family status, age, disability, or race.", "comp": "$110,000.00", "title": "Solutions Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4306634449", "loc": "Palo Alto, CA", "company": "Glean"}, {"desc": "About Glean\nFounded in 2019, Glean is an innovative AI-powered knowledge management platform designed to help organizations quickly find, organize, and share information across their teams. By integrating seamlessly with tools like Google Drive, Slack, and Microsoft Teams, Glean ensures employees can access the right knowledge at the right time, boosting productivity and collaboration. The company\u2019s cutting-edge AI technology simplifies knowledge discovery, making it faster and more efficient for teams to leverage their collective intelligence.\nGlean was born from Founder & CEO Arvind Jain\u2019s deep understanding of the challenges employees face in finding and understanding information at work. Seeing firsthand how fragmented knowledge and sprawling SaaS tools made it difficult to stay productive, he set out to build a better way - an AI-powered enterprise search platform that helps people quickly and intuitively access the information they need. Since then, Glean has evolved into the leading Work AI platform, combining enterprise-grade search, an AI assistant, and powerful application- and agent-building capabilities to fundamentally redefine how employees work.\nAbout The Role\nGlean is looking for an experienced \nApplication Security Engineer\n with a primary focus on ensuring that our entire technology stack is free of software vulnerabilities (CVEs). This role is responsible for securing our base OS images, ensuring all open-source software (OSS) dependencies are scanned and patched, and integrating cutting-edge security tools into our CI/CD pipeline. The ideal candidate will drive the adoption of solutions like Google\u2019s Assured Open Source Software (OSS) and explore alternative approaches to enhance software security.\nThis role will lead the vulnerability management charter at Glean, identifying, evaluating, and implementing new security technologies and processes to proactively protect our infrastructure.\nYou Will\nOwn and lead the vulnerability management lifecycle, ensuring our entire tech stack is free from known CVEs.\nImplement and manage secure base OS images, ensuring all underlying systems remain hardened against security threats.\nContinuously scan, monitor, and patch OSS dependencies to mitigate supply chain risks and enforce best practices for dependency management.\nResearch and evaluate trusted open-source security solutions like Google\u2019s Assured Open Source Software and recommend their adoption where applicable.\nWork closely with engineering teams to integrate state-of-the-art SAST, DAST, and dependency scanning tools into the CI/CD pipeline to detect and remediate vulnerabilities early.\nDefine and maintain best practices for secure coding to ensure all code developed by Glean engineers is free from vulnerabilities.\nDevelop automated security validation tests to enforce vulnerability-free deployments across the stack.\nLead the adoption and, if necessary, develop custom security solutions to manage and mitigate security risks at scale.\nProvide security guidance, training, and mentorship to engineering teams to foster a security-first culture at Glean.\nAbout You\nBA/BS in Computer Science, Cybersecurity, or a related field (or equivalent industry experience).\n5+ years of experience in application security and vulnerability management.\nDeep understanding of software security vulnerabilities, including CVEs, OWASP Top 10, and supply chain risks.\nExperience with SAST, DAST, dependency scanning, and vulnerability management tools (e.g., Snyk, GitHub Dependabot, Trivy, Clair, Burp Suite, OWASP ZAP).\nStrong familiarity with package managers (npm, pip, Maven, Go modules) and securing open-source dependencies.\nCoding experience in languages such as Go, Python, Java, or C++ to develop security test cases and tooling.\nHands-on experience with cloud-native security best practices across AWS, GCP, or Azure.\nKnowledge of container security, Kubernetes security, and securing microservices architectures.\nAbility to lead cross-functional initiatives and drive security adoption within engineering teams.\nKey Knowledge & Skills\nA strong proactive approach to security, identifying risks before they become problems.\nExcellent problem-solving skills and the ability to balance security with performance and usability.\nExperience working in fast-paced, highly collaborative environments where security is a shared responsibility.\nPassion for open-source security and keeping up with the latest trends in software vulnerability management.\nWhy Join Us?\nAt Glean, we believe in \nempowering individuals\n to do their best work in an inclusive and diverse environment. We do not discriminate based on gender, ethnicity, sexual orientation, religion, civil or family status, age, disability, or race. We\u2019re building a culture that values curiosity, collaboration, and impact.\nIf you\u2019re excited about leading the charge in securing a cutting-edge AI-powered search platform, we\u2019d love to hear from you! \ud83d\ude80\nBenefits\nCompetitive compensation\nMedical, Vision and Dental coverage\nFlexible work environment and time-off policy\n401k\nCompany events\nA home office improvement stipend when you first join\nAnnual education stipend\nWellness stipend\nHealthy lunches and dinners provided daily\nLocation: \nThis role is hybrid (3-4 days a week in one of our SF Bay Area offices)\nFor California Based Applicants\nThe standard base salary range for this position is $185,000 - $280,000 annually. \nCompensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for variable compensation, equity, and benefits.\nWe are a diverse bunch of people and we want to continue to attract and retain a diverse range of people into our organization. We're committed to an inclusive and diverse company. We do not discriminate based on gender, ethnicity, sexual orientation, religion, civil or family status, age, disability, or race.", "comp": "$185,000.00", "title": "Software Engineer, Application Security", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4195254614", "loc": "San Francisco Bay Area", "company": "Glean"}, {"desc": "About Glean\nFounded in 2019, Glean is an innovative AI-powered knowledge management platform designed to help organizations quickly find, organize, and share information across their teams. By integrating seamlessly with tools like Google Drive, Slack, and Microsoft Teams, Glean ensures employees can access the right knowledge at the right time, boosting productivity and collaboration. The company\u2019s cutting-edge AI technology simplifies knowledge discovery, making it faster and more efficient for teams to leverage their collective intelligence.\nGlean was born from Founder & CEO Arvind Jain\u2019s deep understanding of the challenges employees face in finding and understanding information at work. Seeing firsthand how fragmented knowledge and sprawling SaaS tools made it difficult to stay productive, he set out to build a better way - an AI-powered enterprise search platform that helps people quickly and intuitively access the information they need. Since then, Glean has evolved into the leading Work AI platform, combining enterprise-grade search, an AI assistant, and powerful application- and agent-building capabilities to fundamentally redefine how employees work.\nAbout The Role\nAs a Corporate Solutions Engineer, you\u2019ll partner closely with Account Executives to lead technical discovery, tailor and demo custom environments, and guide customers through the pilot lifecycle to successful outcomes. You\u2019ll act as the trusted technical advisor during the sales process, addressing business and technical challenges, configuring API-based integrations, and helping organizations unlock value from Glean\u2019s AI-powered platform. This role is highly collaborative and customer-facing, requiring strong problem-solving skills and a consultative approach to drive adoption and satisfaction.\nYou Will\nPartner with Account Executives to navigate fast-paced deal-cycles with C-level executives\nCreate and demo custom environments based off of customer industry and line of business\nPerform customer facing activities including technical discovery calls\nLead security based conversations to make customers comfortable with Glean\u2019s security posture\nWork cross functionally with product and engineering to deliver customer request and be a voice of the customer\nAbout You\nBachelor's degree in CS or a related field\nExcellent written and verbal communication skills\nTeam-centric mindset and demonstrated ability to work well in a collaborative environment\nAbility to work in a fast-paced environment - excellent time management skills and ability to juggle multiple priorities \nA consultative approach with solving your customer\u2019s business challenges and having a track record of successfully overcoming technical and security objections\nFamiliarity with any cloud environment (GCP, AWS, Azure)\nAbility to configure, monitor and maintain API based integrations\nPreferred Experience\n1-2+ years of sales engineering or solution consulting experience in a SaaS organization\nTechnical experience working with AI systems (examples being ChatGPT, Claude, Gemini, Perplexity, etc.)\nStartup and SaaS experience is a plus\nExperience in engaging with customers and ability to resolve challenges effectively \nProven track record of success and collaboration (i.e. clear examples of partnering with AEs to run technical deal cycles)\nProficiency in Python or Java\nLocation: \nThis role is hybrid, based in our Nashville office.\nCompensation & Benefits\nThe standard On-Target-Earnings for this position is $110,000 - $182,000 annually. Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for variable compensation, equity, and benefits.\nWe offer a comprehensive benefits package including competitive compensation, Medical, Vision, and Dental coverage, generous time-off policy, and the opportunity to contribute to your 401k plan to support your long-term goals. When you join, you'll receive a home office improvement stipend, as well as an annual education and wellness stipends to support your growth and wellbeing. We foster a vibrant company culture through regular events, and provide healthy lunches daily to keep you fueled and focused.\nWe are a diverse bunch of people and we want to continue to attract and retain a diverse range of people into our organization. We're committed to an inclusive and diverse company. We do not discriminate based on gender, ethnicity, sexual orientation, religion, civil or family status, age, disability, or race.", "comp": "$110,000.00", "title": "Solutions Engineer, Corporate", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4264974057", "loc": "Nashville, TN", "company": "Glean"}, {"desc": "About Glean\nFounded in 2019, Glean is an innovative AI-powered knowledge management platform designed to help organizations quickly find, organize, and share information across their teams. By integrating seamlessly with tools like Google Drive, Slack, and Microsoft Teams, Glean ensures employees can access the right knowledge at the right time, boosting productivity and collaboration. The company\u2019s cutting-edge AI technology simplifies knowledge discovery, making it faster and more efficient for teams to leverage their collective intelligence.\nGlean was born from Founder & CEO Arvind Jain\u2019s deep understanding of the challenges employees face in finding and understanding information at work. Seeing firsthand how fragmented knowledge and sprawling SaaS tools made it difficult to stay productive, he set out to build a better way - an AI-powered enterprise search platform that helps people quickly and intuitively access the information they need. Since then, Glean has evolved into the leading Work AI platform, combining enterprise-grade search, an AI assistant, and powerful application- and agent-building capabilities to fundamentally redefine how employees work.\nYou Will\nPartner with Account Executives to navigate complex, multi-stakeholder deal cycles with C-level executives\nCreate and demo custom environments based off of customer industry and line of business\nRun and manage a technical POC cycle\nPerform customer facing activities including technical discovery calls\nLead security based conversations to make customers comfortable with Glean\u2019s security posture\nWork cross functionally with product and engineering to deliver customer request and be a voice of the customer\nDevelop ROI and business justification reports and presentations\nAbout You\n5+ years of sales engineering or solution consulting experience in a SaaS organization\nBachelor's degree in CS or a related field\nExcellent written and verbal communication skills\nHighly motivated, driven and self-starting individual\nAbility to work in a fast paced, team environment\nClear examples of partnering with AEs to run technical deal cycles with Enterprise customers\nA consultative approach with solving your customer\u2019s business challenges and having a track record of successfully overcoming technical and security objections\nFamiliarity with any cloud environment (GCP, AWS, Azure)\nProficiency in Python or Java\nAbility to configure, monitor and maintain API based integrations \nLocation:\nThis role is remote-based in the East region of the U.S.\nCompensation & Benefits\nThe standard OTE range for this position is $110,000 - $235,000 annually. Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for variable compensation, equity, and benefits.\nWe offer a comprehensive benefits package including competitive compensation, Medical, Vision, and Dental coverage, generous time-off policy, and the opportunity to contribute to your 401k plan to support your long-term goals. When you join, you'll receive a home office improvement stipend, as well as an annual education and wellness stipends to support your growth and wellbeing. We foster a vibrant company culture through regular events, and provide healthy lunches daily to keep you fueled and focused.\nWe are a diverse bunch of people and we want to continue to attract and retain a diverse range of people into our organization. We're committed to an inclusive and diverse company. We do not discriminate based on gender, ethnicity, sexual orientation, religion, civil or family status, age, disability, or race.", "comp": "$110,000.00", "title": "Solutions Engineer - East", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4195255567", "loc": "United States", "company": "Glean"}, {"desc": "About Glean\nFounded in 2019, Glean is an innovative AI-powered knowledge management platform designed to help organizations quickly find, organize, and share information across their teams. By integrating seamlessly with tools like Google Drive, Slack, and Microsoft Teams, Glean ensures employees can access the right knowledge at the right time, boosting productivity and collaboration. The company\u2019s cutting-edge AI technology simplifies knowledge discovery, making it faster and more efficient for teams to leverage their collective intelligence.\nGlean was born from Founder & CEO Arvind Jain\u2019s deep understanding of the challenges employees face in finding and understanding information at work. Seeing firsthand how fragmented knowledge and sprawling SaaS tools made it difficult to stay productive, he set out to build a better way - an AI-powered enterprise search platform that helps people quickly and intuitively access the information they need. Since then, Glean has evolved into the leading Work AI platform, combining enterprise-grade search, an AI assistant, and powerful application- and agent-building capabilities to fundamentally redefine how employees work.\nAbout The Role\nGlean is looking for a talented Cloud Infrastructure Engineer to join our rapidly expanding, venture-backed startup. We are building a modern knowledge assistant personalized to every employee in your organization, making all information within your company accessible, contextual, and fresh. Our team works hard and plays hard. We are professional, creative, passionate, and most importantly - customer-obsessed.\nAs a trusted technical resource to your assigned customers, you will ensure customer infrastructure releases and stability is your top priority, and ensure that application support issues are also managed professionally through resolution. By providing the highest level of service to our customers, you will ensure our customer experience is the best in the industry.\nYou Will\nPlease note that this role will be dedicated to select customers and requires additional background screenings/clearances/training/certification, carry & use of customer-provided equipment, and extended on-call shift timing based on customer contractual obligations.\nOwn the infrastructure stability for your designated customer(s). Assist the Engineering teams in monitoring alerts and troubleshooting errors in the customer\u2019s Glean environment. \nActively engage in any customer major incident and write up, deliver, and lead the customer review of any post-incident RCA documents\nCoordinate and execute software releases based on agreed-upon processes & maintenance windows\nSet up new customer projects following Glean\u2019s architectural design and best practices. Complete project setup in restricted environments, including running Terraform or other setup scripts manually\nRemediate any security vulnerabilities in your customers\u2019 projects.\nWork with customers and Glean\u2019s Security team to maintain security policies, including VPC SC, SCC, NGFW configs. \nMonitor security vulnerability findings and work with Glean Security and Engineering teams to address them within agreed-upon timeframes with customers\nAssist customers with cloud best practices with respect to the Glean implementation, including org policies, IAM setup, quotas, Disaster Recovery, and LLM setup\nCoordinate all support activities with your assigned customer(s), which may include more stringent access and security processes, ensuring you move with high urgency for their issues.\nRepresent the unique needs of your assigned customer(s) with respect to product and security improvements that will improve the customer support experience\nTake ownership of proactive and reactive support for Glean customers by prioritizing issues for your designated customer(s)\nCreate and maintain customer-specific runbooks and knowledge articles\nProvide first response, technical troubleshooting, resolution, and follow-through of customer issues and inquiries\nAssist customers in the configuration, set-up, and verification of new content sources and product features to enable them to realize additional value for their users\nHandle customer-impacting alerts which require coordination with customer admin and system resources through resolution\nAbout You\nTechnically curious: you have a never-ending desire to add technical knowledge and skills to your personal toolkit and share those learnings with your peers\nFearless: you have an intense need to tackle the toughest customer issues and technically complex issues with the goal of driving customer satisfaction\nStrong communicator: you are a professional presenter with superior interaction skills with both customers and internal teams\nDetail-oriented: you are highly organized and methodical, ensuring all issues are managed to completion\nData-driven: you utilize metrics and objective measurements to assess success and improvement opportunities for yourself and for the customer experience\nKey Knowledge And Skills Required\nMust haves\nExperience and certifications in Cloud technologies in at least one of the following: Google Cloud Platform (GCP), Amazon Web Services (AWS), or Microsoft Azure\nExperience with deployment and release using CI/CD and standard deployment frameworks in a production environment\nDeep knowledge of cloud network and security concepts with practical implementation experience\nKnowledge of SQL/database, Basic Kubernetes and Intermediate/Advanced Linux. Familiarity with infrastructure as code tools like Terraform is essential\nProblem solving: technical problem-solving skills including the ability to troubleshoot and isolate issues to their root cause in cloud environments\nAbility to debug issues including searching & reading application logs, analyzing stack traces and browser trace files\n2+ years of coding and debugging experience in Java and Python\n3+ years of experience in at least one of the following disciplines: Infrastructure Support, Solutions Engineering, Support Engineering, Professional Services, DevOps Engineering\nMust have experience in troubleshooting REST API issues\nWorking experience on SSO, SAML, and OAuth along with network troubleshooting\nExperience in using Github, Jira & Confluence\nGood to haves\nBasic knowledge of LLM\u2019s and how GPT works\nAble to fully document issues you manage and contribute to the support knowledge base\nHands-on experience in at least one of the following: Search technologies, Knowledge technologies, SaaS-based system integrations\nLocation:\nThis role is hybrid (4 days a week in one of our SF Bay Area offices)\nCompensation & Benefits\nThe standard base salary range for this position is $144,000 - $174,000 annually. Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for variable compensation, equity, and benefits.\nWe offer a comprehensive benefits package including competitive compensation, Medical, Vision, and Dental coverage, generous time-off policy, and the opportunity to contribute to your 401k plan to support your long-term goals. When you join, you'll receive a home office improvement stipend, as well as an annual education and wellness stipends to support your growth and wellbeing. We foster a vibrant company culture through regular events, and provide healthy lunches daily to keep you fueled and focused.\nWe are a diverse bunch of people and we want to continue to attract and retain a diverse range of people into our organization. We're committed to an inclusive and diverse company. We do not discriminate based on gender, ethnicity, sexual orientation, religion, civil or family status, age, disability, or race.", "comp": "$144,000.00", "title": "Cloud Infrastructure Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4195257195", "loc": "San Francisco Bay Area", "company": "Glean"}, {"desc": "About Glean\nFounded in 2019, Glean is an innovative AI-powered knowledge management platform designed to help organizations quickly find, organize, and share information across their teams. By integrating seamlessly with tools like Google Drive, Slack, and Microsoft Teams, Glean ensures employees can access the right knowledge at the right time, boosting productivity and collaboration. The company\u2019s cutting-edge AI technology simplifies knowledge discovery, making it faster and more efficient for teams to leverage their collective intelligence.\nGlean was born from Founder & CEO Arvind Jain\u2019s deep understanding of the challenges employees face in finding and understanding information at work. Seeing firsthand how fragmented knowledge and sprawling SaaS tools made it difficult to stay productive, he set out to build a better way - an AI-powered enterprise search platform that helps people quickly and intuitively access the information they need. Since then, Glean has evolved into the leading Work AI platform, combining enterprise-grade search, an AI assistant, and powerful application- and agent-building capabilities to fundamentally redefine how employees work.\nYou Will\nPartner with Account Executives to navigate complex, multi-stakeholder deal cycles with C-level executives\nCreate and demo custom environments based off of customer industry and line of business\nRun and manage a technical POC cycle\nPerform customer facing activities including technical discovery calls\nLead security based conversations to make customers comfortable with Glean\u2019s security posture\nWork cross functionally with product and engineering to deliver customer request and be a voice of the customer\nDevelop ROI and business justification reports and presentations\nAbout You\n5+ years of sales engineering or solution consulting experience in a SaaS organization\nBachelor's degree in CS or a related field\nExcellent written and verbal communication skills\nHighly motivated, driven and self-starting individual\nAbility to work in a fast paced, team environment\nClear examples of partnering with AEs to run technical deal cycles with Enterprise customers\nA consultative approach with solving your customer\u2019s business challenges and having a track record of successfully overcoming technical and security objections\nFamiliarity with any cloud environment (GCP, AWS, Azure)\nProficiency in Python or Java\nAbility to configure, monitor and maintain API based integrations\nLocation:\nThis role is remote-based in the Central region of the U.S.\nCompensation & Benefits\nThe OTE range for this position is $110,000 - $235,000 annually. Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for variable compensation, equity, and benefits.\nWe offer a comprehensive benefits package including competitive compensation, Medical, Vision, and Dental coverage, generous time-off policy, and the opportunity to contribute to your 401k plan to support your long-term goals. When you join, you'll receive a home office improvement stipend, as well as an annual education and wellness stipends to support your growth and wellbeing. We foster a vibrant company culture through regular events, and provide healthy lunches daily to keep you fueled and focused.\nWe are a diverse bunch of people and we want to continue to attract and retain a diverse range of people into our organization. We're committed to an inclusive and diverse company. We do not discriminate based on gender, ethnicity, sexual orientation, religion, civil or family status, age, disability, or race.", "comp": "$110,000.00", "title": "Solutions Engineer- Central", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4195256497", "loc": "United States", "company": "Glean"}, {"desc": "About Glean\nFounded in 2019, Glean is an innovative AI-powered knowledge management platform designed to help organizations quickly find, organize, and share information across their teams. By integrating seamlessly with tools like Google Drive, Slack, and Microsoft Teams, Glean ensures employees can access the right knowledge at the right time, boosting productivity and collaboration. The company\u2019s cutting-edge AI technology simplifies knowledge discovery, making it faster and more efficient for teams to leverage their collective intelligence.\nGlean was born from Founder & CEO Arvind Jain\u2019s deep understanding of the challenges employees face in finding and understanding information at work. Seeing firsthand how fragmented knowledge and sprawling SaaS tools made it difficult to stay productive, he set out to build a better way - an AI-powered enterprise search platform that helps people quickly and intuitively access the information they need. Since then, Glean has evolved into the leading Work AI platform, combining enterprise-grade search, an AI assistant, and powerful application- and agent-building capabilities to fundamentally redefine how employees work.\nAbout The Role\nGlean is looking for a highly skilled and motivated Red Team Engineer to join our team. We are looking for an ultimate ethical adversary, who can leverage their expertise in network penetration testing, social engineering, and attack methodologies to expose our weaknesses and make us stronger.\nYou Will\nThrive in a customer-focused, tight-nit and cross-functional environment - being a team player and willing to take on whatever is most impactful for the company is a must\nHave familiarity with cloud native development practices in GCP/AWS/Azure is a plus\nConduct network penetration testing, employing various techniques like exploiting vulnerabilities, bypassing defenses, and escalating privileges.\nDesign and execute targeted social engineering attacks to test human vulnerabilities and security awareness.\nDevelop assumed breach scenarios that mimic real-world attacks, testing our incident response procedures and readiness.\nUtilize penetration testing frameworks like Metasploit, Kali Linux, and Burp Suite, constantly updating your knowledge and exploring new tools.\nCollaborate with blue teams, developers, and stakeholders to communicate findings, prioritize vulnerabilities, and recommend remediation strategies.\nStay ahead of the curve by researching emerging threats, attending conferences, and actively contributing to the offensive security community.\nAbout You\nBachelor's degree in Computer Science, Information Security, or a related field (or equivalent work experience). Masters in Information Security a big plus.\nExperience with social engineering techniques and methodologies.\nProficiency in scripting languages like Python and Bash.\nExcellent communication and teamwork skills, able to explain complex technical concepts to both technical and non-technical audiences.\nA passion for learning, constantly seeking new ways to improve your skills and knowledge.\nBonus points for experience with cloud security, web application security, and post-exploitation frameworks.\nA proactive and positive attitude to lead, learn, troubleshoot and take ownership of both small tasks and large features\nLocation:\nThis role is hybrid (3-4 days a week in one of our SF Bay Area offices)\nCompensation & Benefits\nThe standard base salary range for this position is $200,000 - $280,000 annually. Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for variable compensation, equity, and benefits.\nWe offer a comprehensive benefits package including competitive compensation, Medical, Vision, and Dental coverage, generous time-off policy, and the opportunity to contribute to your 401k plan to support your long-term goals. When you join, you'll receive a home office improvement stipend, as well as an annual education and wellness stipends to support your growth and wellbeing. We foster a vibrant company culture through regular events, and provide healthy lunches daily to keep you fueled and focused.\nWe are a diverse bunch of people and we want to continue to attract and retain a diverse range of people into our organization. We're committed to an inclusive and diverse company. We do not discriminate based on gender, ethnicity, sexual orientation, religion, civil or family status, age, disability, or race.", "comp": "$200,000.00", "title": "Security Engineer (Red Team)", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4296503078", "loc": "San Francisco Bay Area", "company": "Glean"}, {"desc": "About Glean\nFounded in 2019, Glean is an innovative AI-powered knowledge management platform designed to help organizations quickly find, organize, and share information across their teams. By integrating seamlessly with tools like Google Drive, Slack, and Microsoft Teams, Glean ensures employees can access the right knowledge at the right time, boosting productivity and collaboration. The company\u2019s cutting-edge AI technology simplifies knowledge discovery, making it faster and more efficient for teams to leverage their collective intelligence.\nGlean was born from Founder & CEO Arvind Jain\u2019s deep understanding of the challenges employees face in finding and understanding information at work. Seeing firsthand how fragmented knowledge and sprawling SaaS tools made it difficult to stay productive, he set out to build a better way - an AI-powered enterprise search platform that helps people quickly and intuitively access the information they need. Since then, Glean has evolved into the leading Work AI platform, combining enterprise-grade search, an AI assistant, and powerful application- and agent-building capabilities to fundamentally redefine how employees work.\nAbout The Role\nGlean is looking for creative engineers to own and launch delightful user facing features. In a rapidly growing startup, this entails developing ideas with product managers and designers to best balance engineering constraints with requirements, delivering intuitive experiences that run in modern mobile and desktop browsers.\nYou Will\nOversee the entirety of your greenfield features from inception to implementation, experimentation, launch and beyond\nRevolutionize the current experience by incorporating AI into the product\nProvide leadership and mentor more junior engineers\nWork with designers, product managers, data scientists, and other engineers to understand our problem space and create elegant solutions\nArchitect REST APIs that are backed by stable, scalable server side implementations and maximize web client flexibility for rapidly meeting evolving product requirements\nWrite robust code that\u2019s efficient, easy to read, maintain and test\nAbout You\n5+ years of experience in product engineering with 2 years as a TL/M\nBA/BS in computer science, or related degree\nExperience of building and shipping scalable features across frontend and backend\nThrive in a customer-focused, tight-knit and cross-functional environment\nA proactive and positive attitude to lead, learn, troubleshoot and take ownership of both small tasks and large features\nA user-centric and empathetic mentality for building products\nExperience on a consumer grade web app frontend, preferably React based\nLove authoring easy-to-hold and future-proof REST APIs, OpenAPI is a plus\nExperience building distributed CRUD level functionality, ideally both SQL and NoSQL\nComfortable in or desire to master Golang, Java and TypeScript\nLocation:\nThis role is hybrid (3-4 days a week in one of our SF Bay Area offices)\nCompensation & Benefits\nThe standard base salary range for this position is $140,000 - $265,000 annually. Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for variable compensation, equity, and benefits.\nWe offer a comprehensive benefits package including competitive compensation, Medical, Vision, and Dental coverage, generous time-off policy, and the opportunity to contribute to your 401k plan to support your long-term goals. When you join, you'll receive a home office improvement stipend, as well as an annual education and wellness stipends to support your growth and wellbeing. We foster a vibrant company culture through regular events, and provide healthy lunches daily to keep you fueled and focused.\nWe are a diverse bunch of people and we want to continue to attract and retain a diverse range of people into our organization. We're committed to an inclusive and diverse company. We do not discriminate based on gender, ethnicity, sexual orientation, religion, civil or family status, age, disability, or race.", "comp": "$140,000.00", "title": "Lead Software Engineer, Product Backend", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4286815813", "loc": "San Francisco Bay Area", "company": "Glean"}, {"desc": "About Glean\nFounded in 2019, Glean is an innovative AI-powered knowledge management platform designed to help organizations quickly find, organize, and share information across their teams. By integrating seamlessly with tools like Google Drive, Slack, and Microsoft Teams, Glean ensures employees can access the right knowledge at the right time, boosting productivity and collaboration. The company\u2019s cutting-edge AI technology simplifies knowledge discovery, making it faster and more efficient for teams to leverage their collective intelligence.\nGlean was born from Founder & CEO Arvind Jain\u2019s deep understanding of the challenges employees face in finding and understanding information at work. Seeing firsthand how fragmented knowledge and sprawling SaaS tools made it difficult to stay productive, he set out to build a better way - an AI-powered enterprise search platform that helps people quickly and intuitively access the information they need. Since then, Glean has evolved into the leading Work AI platform, combining enterprise-grade search, an AI assistant, and powerful application- and agent-building capabilities to fundamentally redefine how employees work.\nAbout The Role\nAs a Strategic Solutions Engineer at Glean, you\u2019ll partner with sales to design, demo, and prove the value of our Work AI platform for customers. You\u2019ll lead technical discovery, architect integrations and data connections, and confidently navigate security to accelerate decisions. If you love translating complex technology into clear business outcomes, you\u2019ll thrive helping enterprises adopt AI that actually gets work done.\nYou Will\nPartner with Account Executives to navigate complex, multi-stakeholder deal cycles with C-level executives\nCreate and demo custom environments based off of customer industry and line of business\nRun and manage a technical POC cycle\nPerform customer facing activities including technical discovery calls\nLead security based conversations to make customers comfortable with Glean\u2019s security posture\nWork cross functionally with product and engineering to deliver customer request and be a voice of the customer\nDevelop ROI and business justification reports and presentations\nAbout You\n8+ years of sales engineering or solution consulting experience in a SaaS organization\nBachelor's degree in CS or a related field\nExcellent written and verbal communication skills\nHighly motivated, driven and self-starting individual\nAbility to work in a fast paced, team environment\nClear examples of partnering with AEs to run technical deal cycles with Enterprise customers\nA consultative approach with solving your customer\u2019s business challenges and having a track record of successfully overcoming technical and security objections\nFamiliarity with any cloud environment (GCP, AWS, Azure)\nProficiency in Python or Java\nAbility to configure, monitor, and maintain API based integrations \nLocation:\nThis role is hybrid for Bay Area based candidates \nCompensation & Benefits\nThe standard OTE range for this position is $160,000 - $245,000 annually. Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for variable compensation, equity, and benefits.\nWe offer a comprehensive benefits package including competitive compensation, Medical, Vision, and Dental coverage, generous time-off policy, and the opportunity to contribute to your 401k plan to support your long-term goals. When you join, you'll receive a home office improvement stipend, as well as an annual education and wellness stipends to support your growth and wellbeing. We foster a vibrant company culture through regular events, and provide healthy lunches daily to keep you fueled and focused.\nWe are a diverse bunch of people and we want to continue to attract and retain a diverse range of people into our organization. We're committed to an inclusive and diverse company. We do not discriminate based on gender, ethnicity, sexual orientation, religion, civil or family status, age, disability, or race.", "comp": "$160,000.00", "title": "Solutions Engineer - Strategic", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4307310391", "loc": "Palo Alto, CA", "company": "Glean"}, {"desc": "About Glean\nFounded in 2019, Glean is an innovative AI-powered knowledge management platform designed to help organizations quickly find, organize, and share information across their teams. By integrating seamlessly with tools like Google Drive, Slack, and Microsoft Teams, Glean ensures employees can access the right knowledge at the right time, boosting productivity and collaboration. The company\u2019s cutting-edge AI technology simplifies knowledge discovery, making it faster and more efficient for teams to leverage their collective intelligence.\nGlean was born from Founder & CEO Arvind Jain\u2019s deep understanding of the challenges employees face in finding and understanding information at work. Seeing firsthand how fragmented knowledge and sprawling SaaS tools made it difficult to stay productive, he set out to build a better way - an AI-powered enterprise search platform that helps people quickly and intuitively access the information they need. Since then, Glean has evolved into the leading Work AI platform, combining enterprise-grade search, an AI assistant, and powerful application- and agent-building capabilities to fundamentally redefine how employees work.\nAbout The Role\nWe are Glean\u2019s Data Foundation Team. We\u2019re a high\u2010impact team that owns the enterprise data ingestion and management infrastructure within Glean that powers Glean\u2019s Search and AI capabilities. We are looking for a technical lead who will pave the way for our hyper growth phase. With a robust product strategy, we are entering an ambitious product and team growth phase. We need engineering leaders who will build world-class software systems, uphold our cultural values of being fast-paced and customer-driven, and ensure solid execution in a highly collaborative environment.\nYou Will\nAs a hands-on technical lead at Glean, you will be pivotal in leading our engineering team to build and enhance our cutting-edge platform. You will:\nLead new product initiatives involving ingesting, understanding, and interacting with enterprise data\u2014experimenting, prototyping, and shipping ideas quickly.\nScale robust distributed systems to handle billions of permissions-aware documents in real time, as well as build new systems from the ground up.\nDrive high, direct impact by collaborating with cross-functional teams on business-critical projects, and working directly with customers.\nAbout You\nYou have 5+ years of experience in software engineering with 2 years experience as a technical lead, with a proven track record of delivering high scale backend services.\nYou have delivered vertical projects with net new features that needed to span & coordinate with multiple teams.\nYou have delivered a system that had to scale to large numbers of customers/users over a few years.\nYou have strong leadership skills and a demonstrated ability to inspire and motivate teams to achieve ambitious goals.\nYou are a strategic thinker passionate about driving innovation and leveraging technology to solve complex problems.\nYou have excellent communication and interpersonal skills and can collaborate effectively with stakeholders at all levels.\nYou thrive in a fast-paced, dynamic environment and are comfortable navigating ambiguity and driving change.\nLocation:\nThis role is hybrid (3-4 days a week in one of our SF Bay Area offices)\nCompensation & Benefits\nThe standard base salary range for this position is $200,000 - $265,000 annually. Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for variable compensation, equity, and benefits.\nWe offer a comprehensive benefits package including competitive compensation, Medical, Vision, and Dental coverage, generous time-off policy, and the opportunity to contribute to your 401k plan to support your long-term goals. When you join, you'll receive a home office improvement stipend, as well as an annual education and wellness stipends to support your growth and wellbeing. We foster a vibrant company culture through regular events, and provide healthy lunches daily to keep you fueled and focused.\nWe are a diverse bunch of people and we want to continue to attract and retain a diverse range of people into our organization. We're committed to an inclusive and diverse company. We do not discriminate based on gender, ethnicity, sexual orientation, religion, civil or family status, age, disability, or race.", "comp": "$200,000.00", "title": "Lead Software Engineer, Data Foundations", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4195255586", "loc": "San Francisco Bay Area", "company": "Glean"}, {"desc": "About Glean\nFounded in 2019, Glean is an innovative AI-powered knowledge management platform designed to help organizations quickly find, organize, and share information across their teams. By integrating seamlessly with tools like Google Drive, Slack, and Microsoft Teams, Glean ensures employees can access the right knowledge at the right time, boosting productivity and collaboration. The company\u2019s cutting-edge AI technology simplifies knowledge discovery, making it faster and more efficient for teams to leverage their collective intelligence.\nGlean was born from Founder & CEO Arvind Jain\u2019s deep understanding of the challenges employees face in finding and understanding information at work. Seeing firsthand how fragmented knowledge and sprawling SaaS tools made it difficult to stay productive, he set out to build a better way - an AI-powered enterprise search platform that helps people quickly and intuitively access the information they need. Since then, Glean has evolved into the leading Work AI platform, combining enterprise-grade search, an AI assistant, and powerful application- and agent-building capabilities to fundamentally redefine how employees work.\nAbout The Role\nWe are seeking a skilled and motivated Senior Site Reliability Engineer (SRE) to become a valuable addition to our dynamic and innovative team. As a SRE, you will play a critical role in ensuring the reliability, availability, and performance of our cloud-based services and applications. You will work closely with our engineering teams to design, build, and maintain robust, scalable, and highly available cloud infrastructure.\nMuch of our software development focuses on building infrastructure to scale our operations in a hybrid cloud environment and eliminating work through automation. On the SRE team, you\u2019ll have the opportunity to manage the complex challenges of scale and fast growth which are unique to Glean, while using your expertise in coding, algorithms, problem-solving, and SRE practices. We keep Glean applications up and running, ensuring our customers have the best and most reliable experience possible.\nYou Are\nTechnical Leadership and Mentorship: Play a key role in driving technical excellence and fostering a culture of reliability across engineering teams. You will lead by example, setting best practices for incident management, performance optimization, and automation. Influence best practices, drive cross-team collaborations, and contribute to the execution of key objectives in alignment with engineering leadership and cross-functional partners. Establish strong technical credibility, shaping architectural decisions and ensuring the delivery of high-quality, reliable systems.\nEnsure High Availability: Implement and maintain resilient cloud architectures, monitor system performance, and proactively identify and resolve potential bottlenecks or points of failure. \nIncident Management: Participate in primary oncall rotation; cultivate technical curiosity and growth mindset, and a blameless postmortem culture within the team. Continuously optimize the on-call process for sustainability and efficiency.\nAutomation and Tooling: Develop and maintain automation scripts, tools, and processes to streamline system deployment, monitoring, and management tasks. Your contributions will be vital in efficiently scaling cloud operations.\nPerformance Optimization: Optimize cloud infrastructure and applications for performance, scalability, and cost-effectiveness.\nSecurity and Compliance: Collaborate with security engineers to implement best practices and ensure compliance with security standards and policies.\nMonitoring and Alerting: Design and configure advanced monitoring systems to gain insights into system behavior, set up alerts, and respond proactively to potential issues. Create and maintain comprehensive dashboards and playbooks for production on-call.\nSoftware Development Consultation: Engage actively in the entire software development lifecycle. Participate in system design reviews and provide valuable SRE insights during launch reviews, influencing and enhancing system architecture.\nAbout You\nBachelor\u2019s degree in Computer Science, a related field, or equivalent practical experience.\n8+ years of experience in a senior-level role within Site Reliability Engineering or similar role, particularly in managing cloud-based services and infrastructure.\n5+ years of experience with software development in one or more programming languages.\n2+ years of experience managing people or teams, leading projects, and designing, analyzing, and troubleshooting distributed systems running in Cloud.\nStrong knowledge of cloud platforms such as Google Cloud Platform, AWS, or Azure.\nPractical experience with containerization technologies, including Docker and Kubernetes. Familiarity with infrastructure as code tools like Terraform is essential.\nSolid understanding of networking, security principles, and best SRE and security practices.\nProficiency in using monitoring and alerting tools to detect and respond to potential issues effectively\nLocation:\nThis role is hybrid (4 days a week in one of our Bay Area offices)\nCompensation & Benefits\nThe standard base salary range for this position is $155,000 - $250,000 annually. Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for variable compensation, equity, and benefits.\nWe offer a comprehensive benefits package including competitive compensation, Medical, Vision, and Dental coverage, generous time-off policy, and the opportunity to contribute to your 401k plan to support your long-term goals. When you join, you'll receive a home office improvement stipend, as well as an annual education and wellness stipends to support your growth and wellbeing. We foster a vibrant company culture through regular events, and provide healthy lunches daily to keep you fueled and focused.\nWe are a diverse bunch of people and we want to continue to attract and retain a diverse range of people into our organization. We're committed to an inclusive and diverse company. We do not discriminate based on gender, ethnicity, sexual orientation, religion, civil or family status, age, disability, or race.", "comp": "$155,000.00", "title": "Senior Site Reliability Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4256597563", "loc": "Palo Alto, CA", "company": "Glean"}, {"desc": "About Glean\nFounded in 2019, Glean is an innovative AI-powered knowledge management platform designed to help organizations quickly find, organize, and share information across their teams. By integrating seamlessly with tools like Google Drive, Slack, and Microsoft Teams, Glean ensures employees can access the right knowledge at the right time, boosting productivity and collaboration. The company\u2019s cutting-edge AI technology simplifies knowledge discovery, making it faster and more efficient for teams to leverage their collective intelligence.\nGlean was born from Founder & CEO Arvind Jain\u2019s deep understanding of the challenges employees face in finding and understanding information at work. Seeing firsthand how fragmented knowledge and sprawling SaaS tools made it difficult to stay productive, he set out to build a better way - an AI-powered enterprise search platform that helps people quickly and intuitively access the information they need. Since then, Glean has evolved into the leading Work AI platform, combining enterprise-grade search, an AI assistant, and powerful application- and agent-building capabilities to fundamentally redefine how employees work.\nAbout The Role\nAs the Product Manager for Glean Agents, you will define and drive the vision for an enterprise-ready, horizontal platform that empowers teams across the organization to build, deploy, orchestrate, and govern AI agents at scale. You\u2019ll lead the development of capabilities that make building powerful AI agents accessible to all; from non-technical business users writing natural language prompts to developers orchestrating complex workflows - while ensuring security, compliance, and high-quality outcomes.\nGlean Agents isn\u2019t just another feature, it\u2019s the engine for enterprise-scale AI transformation. This is your opportunity to shape the platform that moves AI beyond search into proactive, autonomous workflow orchestration across every function. We\u2019re currently a very lean product team, so you\u2019ll have an outsized role in shaping both the product roadmap and the product team itself.\nYou Will\nSpending a lot of time with our customers to deeply understand their knowledge needs\nDeveloping key parts of our product roadmap, marrying customers\u2019 needs with our product vision\nEmpowering your team by giving context, setting direction, and building alignment\nDriving customer-focused decisions, clear prioritization, and efficient execution\nCoordinating cross-functionally with with leadership, go-to-market teams, and other key stakeholders across the company\nBuilding processes that will scale as our team and company go through rapid growth\nAbout You\nYou have 4+ years of experience as a Product Manager with a track record of ownership across core product or high-engagement product features.\nYou have a strong technical background and a major desire to build products for the software engineering persona. Past experience working as an IC software engineer is a major plus.\nYou are an excellent written and verbal communicator.\nYou have a proven track record of taking ownership, taking initiative, and delivering results.\nYou collaborate effectively with cross-functional partners.\nYou have a learning and growth mindset.\nYou are mission-first and understand that your success is measured by your product and team\u2019s success.\nYou are an early adopter in building with or adopting AI for your own product craft and you are excited about helping customers accelerate their own AI adoption journey.\nLocation:\nThis role is hybrid (3-4 days a week in one of our SF Bay Area offices)\nCompensation & Benefits\nThe standard base salary range for this position is $130,000 - $240,000 annually. Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for variable compensation, equity, and benefits.\nWe offer a comprehensive benefits package including competitive compensation, Medical, Vision, and Dental coverage, generous time-off policy, and the opportunity to contribute to your 401k plan to support your long-term goals. When you join, you'll receive a home office improvement stipend, as well as an annual education and wellness stipends to support your growth and wellbeing. We foster a vibrant company culture through regular events, and provide healthy lunches daily to keep you fueled and focused.\nWe are a diverse bunch of people and we want to continue to attract and retain a diverse range of people into our organization. We're committed to an inclusive and diverse company. We do not discriminate based on gender, ethnicity, sexual orientation, religion, civil or family status, age, disability, or race.", "comp": "$130,000.00", "title": "Product Manager, Glean Agents", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4195257187", "loc": "San Francisco Bay Area", "company": "Glean"}, {"desc": "About Glean\nFounded in 2019, Glean is an innovative AI-powered knowledge management platform designed to help organizations quickly find, organize, and share information across their teams. By integrating seamlessly with tools like Google Drive, Slack, and Microsoft Teams, Glean ensures employees can access the right knowledge at the right time, boosting productivity and collaboration. The company\u2019s cutting-edge AI technology simplifies knowledge discovery, making it faster and more efficient for teams to leverage their collective intelligence.\nGlean was born from Founder & CEO Arvind Jain\u2019s deep understanding of the challenges employees face in finding and understanding information at work. Seeing firsthand how fragmented knowledge and sprawling SaaS tools made it difficult to stay productive, he set out to build a better way - an AI-powered enterprise search platform that helps people quickly and intuitively access the information they need. Since then, Glean has evolved into the leading Work AI platform, combining enterprise-grade search, an AI assistant, and powerful application- and agent-building capabilities to fundamentally redefine how employees work.\nAbout The Role\nWe\u2019re seeking a Tech Lead Manager to drive fullstack product and product infrastructure development for Glean\u2019s Generative AI products. As a TLM, you\u2019ll provide expert technical direction and thoughtful coaching to a passionate team of engineers. This team will work closely with product management, design, and data science to drive the Glean Assistant to the next generation of capabilities, features, performance and enterprise readiness. At the same time, it architects powerful, elegant abstractions that enable multiple teams working on Generative AI features to contribute safely and easily to the codebase.\nYou Will\nBuild a high-performing team with an inclusive and positive team culture.\nWork hands-on in making technical changes.\nProvide technical leadership and vision in a widely scoped engineering team.\nDrive the development of the product and platform in a fast-paced environment.\nPlan for headcount, iterate on interview processes, and close candidates to help grow the team.\nCoach and mentor engineers at different levels to achieve their career goals.\nAbout You\n8+ years of engineering with 1+ years of engineering management experience.\nExperience building delightful web products full stack from frontend, APIs, backend.\nProficiency in recruiting, organizing, and motivating teams\nPassionate about helping people grow in their careers and people management.\nAn owner mindset and passionate about being in a product-focused environment where everyone cares deeply about customer impact.\nExpertise in React, Typescript, Golang, SQL, GCP, and AWS are highly desirable.\nExperience with or desire to learn large language models, retrieval augmented generation, and agents is beneficial.\nLocation:\nThis role is hybrid (3 days a week in one of our SF Bay Area offices)\nCompensation & Benefits\nThe standard base salary range for this position is $200,000 - $300,000 annually. Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for variable compensation, equity, and benefits.\nWe offer a comprehensive benefits package including competitive compensation, Medical, Vision, and Dental coverage, generous time-off policy, and the opportunity to contribute to your 401k plan to support your long-term goals. When you join, you'll receive a home office improvement stipend, as well as an annual education and wellness stipends to support your growth and wellbeing. We foster a vibrant company culture through regular events, and provide healthy lunches daily to keep you fueled and focused.\nWe are a diverse bunch of people and we want to continue to attract and retain a diverse range of people into our organization. We're committed to an inclusive and diverse company. We do not discriminate based on gender, ethnicity, sexual orientation, religion, civil or family status, age, disability, or race.", "comp": "$200,000.00", "title": "Tech Lead Manager (Full Stack)  AI Assistant Product", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4282673777", "loc": "San Francisco, CA", "company": "Glean"}, {"desc": "Perplexity is an AI-powered answer engine founded in December 2022 and growing rapidly as one of the world\u2019s leading AI platforms. Perplexity has raised over $1B in venture investment from some of the world\u2019s most visionary and successful leaders, including Elad Gil, Daniel Gross, Jeff Bezos, Accel, IVP, NEA, NVIDIA, Samsung, and many more. Our objective is to build accurate, trustworthy AI that powers decision-making for people and assistive AI wherever decisions are being made. Throughout human history, change and innovation have always been driven by curious people. Today, curious people use Perplexity to answer more than 780 million queries every month\u2013a number that\u2019s growing rapidly for one simple reason: everyone can be curious. \nPerplexity is seeking an experienced Full Stack Engineer to help revolutionize the way people search and interact online. In this role, you'll translate cutting-edge AI advances into products that are both useful and engaging.\nTech Stack:\n TypeScript | Python | Docker | AWS | Vercel\nTeams Currently Hiring\nEnterprise\nThe Enterprise Team at Perplexity designs and builds core platform features like rich file attachments, secure file and app connectors (using cutting-edge Model Context Protocol), and Spaces for streamlined collaboration\u2014capabilities widely used by both enterprise and regular users. The team owns uniquely challenging domains at the intersection of AI, automation, and knowledge management, directly shaping how millions of people work with private data, files, and productivity apps across Perplexity. Their small, expert group operates with high autonomy, developing systems that set industry standards and deliver massive, visible product impact.\nGrowth\nThe Growth team shapes how millions of people experience Perplexity. We rapidly experiment and launch new ideas across all user-facing surfaces at Perplexity including onboarding, verticals like Students, and premium Max Tier. We build AI-powered features such as personalized prompts, auto-generated study guides, and contextual upsell nudges, driving user activation, retention, and revenue across all platforms. We own Perplexity\u2019s growth platform, including experimentation framework, feature flagging, and notifications, to mobilize impactful feature development across the company. Engineers have outsized impact, building both the product and the platform that power our company\u2019s growth.\nBilling\nThe Billing team powers how users subscribe to and pay for Perplexity, building seamless subscription experiences across all tiers. We partner with business and finance teams to define new pricing and subscription models, while also driving growth through partner integrations that expand distribution and brand presence. We develop and maintain secure, scalable systems\u2014including agentic payments that autonomously interact with payment platforms\u2014ensuring reliable financial transactions for millions of users worldwide. By shaping both user experience and revenue infrastructure, the Billing team sits at the core of Perplexity\u2019s growth and sustainability.\nConsumer Verticals\nWith AI-powered exploration and browsing, personalization and memory, live data visualization, comparison, and checkout, Perplexity is reimagining the consumer experience across verticals such as travel, shopping, health, real estate, finance, sports, live events and ticketing, and more. Each of these verticals represents an opportunity for Perplexity to disrupt massive markets dominated by slower-moving incumbents. Agentic actions powered by Comet unlock novel consumer experiences such as automated shopping and travel purchases, restaurant reservations, complete travel itineraries planned and booked from scratch, automated investing, and more.\nSpecial Projects\nSpecial Projects is a team dedicated to building 0-1 products that redefine the future of search. Our mandate is to iterate fast, deliver high quality experiences, and reinvent the role of AI in search, social media, and personal computing.By joining the Special Projects team, you will be given extreme ownership to deliver new consumer experiences and transform how people search the web and find answers. You will be expected to own projects end to end, to ship fast, and work through obstacles.We are looking for a talented Full Stack Engineer to join our team to help reinvent the future of search and AI assistants. Our current stack is Python, Docker, Kubernetes, NextJS, and React. In this role, you'll work on various projects that combine bleeding edge AI, consumer apps, and multi-modal capabilities (text, voice, image, video).\nResponsibilities\nBuilding new 0-1 products at high scale\nWorking closely with Product, Design, and Data to ship experiments and learn\nLaunching new features, experiments, campaigns, and partnerships in a fast-moving environment\nBuilding core growth infrastructure such as notification platforms, ad attribution, and more\nAnalyzing performance metrics and user feedback to identify opportunities for improvement and optimization\nBuilding delightful and data-proven user journeys\nQualifications\nStrong programming skills with the ability to work across the full stack\nSelf-motivated with a willingness to take ownership of tasks\nGood quantitative understanding of data and experimentation\nExperience making data-driven decisions and measuring impact of those decisions (experimentation, feature flags, adhoc analysis)\nA passion for shipping quality products\n4+ years of industry experience\nThe compensation range for this role is $180,000 - $300,000\nFinal offer amounts are determined by multiple factors, including, experience and expertise, and may vary from the amounts listed above. \nEquity: In addition to the base salary, equity may be part of the total compensation package.\nBenefits: Comprehensive health, dental, and vision insurance for you and your dependents. Includes a 401(k) plan.", "comp": "$180,000.00", "title": "Full Stack Software Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/3945819389", "loc": "San Francisco Bay Area", "company": "Perplexity"}, {"desc": "Perplexity is an AI-powered answer engine founded in December 2022 and growing rapidly as one of the world\u2019s leading AI platforms. Perplexity has raised over $1B in venture investment from some of the world\u2019s most visionary and successful leaders, including Elad Gil, Daniel Gross, Jeff Bezos, Accel, IVP, NEA, NVIDIA, Samsung, and many more. Our objective is to build accurate, trustworthy AI that powers decision-making for people and assistive AI wherever decisions are being made. Throughout human history, change and innovation have always been driven by curious people. Today, curious people use Perplexity to answer more than 780 million queries every month\u2013a number that\u2019s growing rapidly for one simple reason: everyone can be curious. \nPerplexity is looking for an experienced Backend Engineer to join our small team revolutionizing the way people search and interact with the internet. You will be responsible for leading design, implementation, and scaling of backend systems that power web, mobile, and browser products.\nTech Stack:\n Python | PostgreSQL | DynamoDB | Redis | FastAPI\nTeams Hiring\nEnterprise\nThe Enterprise Team at Perplexity designs and builds core platform features like rich file attachments, secure file and app connectors (using cutting-edge Model Context Protocol), and Spaces for streamlined collaboration\u2014capabilities widely used by both enterprise and regular users. The team owns uniquely challenging domains at the intersection of AI, automation, and knowledge management, directly shaping how millions of people work with private data, files, and productivity apps across Perplexity. Their small, expert group operates with high autonomy, developing systems that set industry standards and deliver massive, visible product impact.\nGrowth\nThe Growth team shapes how millions of people experience Perplexity. We rapidly experiment and launch new ideas across all user-facing surfaces at Perplexity including onboarding, verticals like Students, and premium Max Tier. We build AI-powered features such as personalized prompts, auto-generated study guides, and contextual upsell nudges, driving user activation, retention, and revenue across all platforms. We own Perplexity\u2019s growth platform, including experimentation framework, feature flagging, and notifications, to mobilize impactful feature development across the company. Engineers have outsized impact, building both the product and the platform that power our company\u2019s growth.\nBilling\nThe Billing team powers how users subscribe to and pay for Perplexity, building seamless subscription experiences across all tiers. We partner with business and finance teams to define new pricing and subscription models, while also driving growth through partner integrations that expand distribution and brand presence. We develop and maintain secure, scalable systems\u2014including agentic payments that autonomously interact with payment platforms\u2014ensuring reliable financial transactions for millions of users worldwide. By shaping both user experience and revenue infrastructure, the Billing team sits at the core of Perplexity\u2019s growth and sustainability.\nConsumer Verticals\nWith AI-powered exploration and browsing, personalization and memory, live data visualization, comparison, and checkout, Perplexity is reimagining the consumer experience across verticals such as travel, shopping, health, real estate, finance, sports, live events and ticketing, and more. Each of these verticals represents an opportunity for Perplexity to disrupt massive markets dominated by slower-moving incumbents. Agentic actions powered by Comet unlock novel consumer experiences such as automated shopping and travel purchases, restaurant reservations, complete travel itineraries planned and booked from scratch, automated investing, and more.\nResponsibilities\nBuild scalable systems that ingest and process data from the web, files, and other sources.\nOptimize interfaces that interact with databases and caching systems.\nCollaborate with PMs, frontend engineers, and other stakeholders to understand product requirements.\nWork closely with AI, Search, and Data Science teams to iterate on non-deterministic systems.\nManage a complex orchestration system with many moving parts and interfaces.\nScale, optimize, and load balance multiple services with rapidly changing needs.\nQualifications\nStrong experience with Python\nStrong experience with databases and caching\nExperience with AWS cloud infrastructure at scale\nExperience working with high-scale data and non-deterministic systems like LLMs\n4+ years of engineering experience\nOur compensation range for this role is $180,000 - $300,000\nFinal offer amounts are determined by multiple factors, including, experience and expertise, and may vary from the amounts listed above.\nEquity: In addition to the base salary, equity may be part of the total compensation package.\nBenefits: Comprehensive health, dental, and vision insurance for you and your dependents. Includes a 401(k) plan.", "comp": "$180,000.00", "title": "Backend Software Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4247160448", "loc": "New York, NY", "company": "Perplexity"}, {"desc": "Perplexity is an AI-powered answer engine founded in December 2022 and growing rapidly as one of the world\u2019s leading AI platforms. Perplexity has raised over $1B in venture investment from some of the world\u2019s most visionary and successful leaders, including Elad Gil, Daniel Gross, Jeff Bezos, Accel, IVP, NEA, NVIDIA, Samsung, and many more. Our objective is to build accurate, trustworthy AI that powers decision-making for people and assistive AI wherever decisions are being made. Throughout human history, change and innovation have always been driven by curious people. Today, curious people use Perplexity to answer more than 780 million queries every month\u2013a number that\u2019s growing rapidly for one simple reason: everyone can be curious. \nPerplexity is seeking an experienced Frontend-focused Engineer to help revolutionize the way people search and interact online. In this role, you'll be developing the future of AI products.\nTech Stack: React | TypeScript | Python | Docker | AWS\nResponsibilities\nDevelop new UX patterns to solve for user experience in an AI world\nWork with and improve the components that form the building blocks of Perplexity's frontend\nIterate closely with design to prototype and implement new features\nCreate scalable UX solutions in a rapidly evolving space.\nAnalyze performance and reliability of features in a realtime, non-deterministic application.\nKey Qualifications\nStrong coding fundamentals, and some experience working across the stack.\nAbility to build foundations that others can build on top of.\nExperience with highly interactive React applications using strongly typed code\nKnowledgeable about design and UI patterns at scale\nPassion for prototyping, experimentation, and creating accessible experiences\nExtreme ownership mindset\nTakes pride in getting the small details right\n4+ years of industry experience\nThe cash compensation range for this role is $180,000 - $300,000\nFinal offer amounts are determined by multiple factors, including, experience and expertise, and may vary from the amounts listed above.\nEquity: In addition to the base salary, equity may be part of the total compensation package.\nBenefits: Comprehensive health, dental, and vision insurance for you and your dependents. Includes a 401(k) plan.", "comp": "$180,000.00", "title": "Frontend Software Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4288704443", "loc": "New York City Metropolitan Area", "company": "Perplexity"}, {"desc": "Perplexity is an AI-powered answer engine founded in December 2022 and growing rapidly as one of the world\u2019s leading AI platforms. Perplexity has raised over $1B in venture investment from some of the world\u2019s most visionary and successful leaders, including Elad Gil, Daniel Gross, Jeff Bezos, Accel, IVP, NEA, NVIDIA, Samsung, and many more. Our objective is to build accurate, trustworthy AI that powers decision-making for people and assistive AI wherever decisions are being made. Throughout human history, change and innovation have always been driven by curious people. Today, curious people use Perplexity to answer more than 780 million queries every month\u2013a number that\u2019s growing rapidly for one simple reason: everyone can be curious. \nPerplexity AI is looking for an experienced Full-Stack Engineer to join our small team revolutionizing the way people browse the Internet. You will be responsible for building and expanding Comet - Perplexity\u2019s new browser.\nThe ideal candidate should have strong programming skills, an interest in AI and large language models, and a passion for delivering a great UX backed by a quality UI.\nResponsibilities\nDevelop a performant mobile browser that millions of users around the world enjoy using.\nEnsure a high craft and quality bar, both in the user experience and the developer experience.\nWork closely with design teams to design fast and intuitive UI.\nCollaborate with data science and machine learning teams to instrument, analyze, and improve the end-to-end experience.\nWork with infrastructure and QA teams on deployment processes, including testing, release, and monitoring.\nRequirements\n4+ years industry experience\nExpertise in TypeScript and top frameworks\nExpertise in Git and TypeScript building tools\nStrong Javascript fundamentals and a proven track record of working with a modern frontend stack\nEnjoys the craft of building nice UI, creating a good UX, and writing reusable and testable code\nUnderstands low-level intricacies, and knows how to profile and measure app performance and speed\nComfortable working with a small, fast-moving team, and must be willing to dive in and take ownership\nA passion for shipping\n(Bonus) Experience with Android or iOS\n(Bonus) Experience building custom Javascript native hooks\nOur cash compensation range for this role is $150,000 - $300,000.\nFinal offer amounts are determined by multiple factors, including, experience and expertise, and may vary from the amounts listed above.\nEquity: In addition to the base salary, equity \nmay be part\n of the total compensation package.\nBenefits: Comprehensive health, dental, and vision insurance for you and your dependents. Includes a 401(k) plan.", "comp": "$150,000.00", "title": "Full-Stack Engineer - Comet", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4247378915", "loc": "New York, NY", "company": "Perplexity"}, {"desc": "Perplexity is an AI-powered answer engine founded in December 2022 and growing rapidly as one of the world\u2019s leading AI platforms. Perplexity has raised over $1B in venture investment from some of the world\u2019s most visionary and successful leaders, including Elad Gil, Daniel Gross, Jeff Bezos, Accel, IVP, NEA, NVIDIA, Samsung, and many more. Our objective is to build accurate, trustworthy AI that powers decision-making for people and assistive AI wherever decisions are being made. Throughout human history, change and innovation have always been driven by curious people. Today, curious people use Perplexity to answer more than 780 million queries every month\u2013a number that\u2019s growing rapidly for one simple reason: everyone can be curious. \nAs our first Analytics Engineer, you\u2019ll be instrumental in defining and building our analytics infrastructure, ensuring data is reliable, accessible, and drives critical business decisions across the company. You\u2019ll play a key role in shaping how we use data at Perplexity, contributing directly to our mission of becoming the world\u2019s most knowledge-centric company.\nPerplexity is building the next-generation answer engine, empowering our users to find information more effectively. We are headquartered in San Francisco, and on a hybrid schedule with in-office days on Monday, Wednesday, Friday.\nResponsibilities\nDesign and build core data models to improve analysis efficiency, enabling rapid, reliable insights for teams\nDefine and champion data modeling standards and best practices using tools like dbt\nBoost data team productivity by improving tooling, automating workflows, and streamlining processes\nOwn decisions on tooling selection, balancing build vs. buy and managing vendor relationships when necessary\nPartner closely with Data Scientists to ensure analytics requirements are clearly understood and effectively implemented\nDevelop and maintain critical dashboards and reporting to track business health and enable better decision-making\nLead data governance efforts, ensuring security, compliance, and quality standards are consistently met\nQualifications\nHave 6-8+ years of professional experience as an analytics engineer, data engineer, data scientist, or closely related role\nSQL expert\nExperience in data modeling, including dimensional modeling and analytics engineering best practices\nExperience creating high-impact dashboards and visualizations using BI tools (e.g., Omni, Mode, Hex, Looker, or similar)\nHave prior experience in fast-paced, rapidly scaling environments\nComfortable working autonomously, taking projects from concept through execution with minimal oversight.\nBonus\nExperience with dbt\nComfortable with Python\nExperience with Snowflake administration and optimization\nFamiliarity or experience with Databricks\nPrevious experience as an early or first analytics engineer in a high-growth startup\nThe cash compensation range for this role is $200,000 - $300,000.\nFinal offer amounts are determined by multiple factors, including, experience and expertise, and may vary from the amounts listed above.\nEquity: In addition to the base salary, equity \nmay be part\n of the total compensation package.\nBenefits: Comprehensive health, dental, and vision insurance for you and your dependents. Includes a 401(k) plan.", "comp": "$200,000.00", "title": "Analytics Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4175743185", "loc": "San Francisco, CA", "company": "Perplexity"}, {"desc": "Perplexity is an AI-powered answer engine founded in December 2022 and growing rapidly as one of the world\u2019s leading AI platforms. Perplexity has raised over $1B in venture investment from some of the world\u2019s most visionary and successful leaders, including Elad Gil, Daniel Gross, Jeff Bezos, Accel, IVP, NEA, NVIDIA, Samsung, and many more. Our objective is to build accurate, trustworthy AI that powers decision-making for people and assistive AI wherever decisions are being made. Throughout human history, change and innovation have always been driven by curious people. Today, curious people use Perplexity to answer more than 780 million queries every month\u2013a number that\u2019s growing rapidly for one simple reason: everyone can be curious. \nPerplexity is looking for a Software Engineer to build the core infrastructure that powers agentic products across Perplexity including Search, Deep Research, and the Comet browser. You will design and evolve the runtime, orchestration, evaluation and training systems that let agents plan, use tools, browse, and verify at scale.\nResponsibilities\nDesign and implement a highly reliable and scalable agent runtime: orchestration, shared state and memory, tool calling interfaces, and scheduling for cost, latency, and quality.\nBuild secure sandboxed execution for agent actions and code. Optimize cold start, isolation, and observability.\nShip unified interfaces for multiple model sizes and providers. Integrate with open tool ecosystems such as MCP style connectors for data and actions.\nDevelop an evaluation platform for online and offline assessments, A/B tests, safety checks, and regression gates that improve agent reliability over time.\nPartner with Research, Inference, and Search to land new agent capabilities end to end, from prototype to production.\nQualifications\n6+ years of industry experience building large scale systems or platforms.\nExperience building agent applications with tool calling, context engineering, or open connector integrations.\nStrong coding skills in one or more of: Python, Java, Go. Comfortable with service design, APIs, and data models for high throughput systems.\nWorking knowledge of containers, virtualization, and sandboxing. Familiar with metrics, tracing, on call, and incident practices.\nBias to own problems across layers, collaborate in fast moving teams, and ship.\nNice to have\nPrior work on agent orchestration pipelines: task routing, planning, memory graphs, vector search, or browser automation.\nExperience with evaluations, preference optimization, or RL to improve agent reliability.\nExposure to MCP or similar open protocols for tool and data connectivity.\nSecurity hardening for multi tenant workloads, snapshotting, or untrusted code execution.\nThe cash compensation range for this role is $200,000 - $300,000.\nFinal offer amounts are determined by multiple factors, including, experience and expertise, and may vary from the amounts listed above.\nEquity: In addition to the base salary, equity may be part of the total compensation package.\nBenefits: Comprehensive health, dental, and vision insurance for you and your dependents. Includes a 401(k) plan.", "comp": "$200,000.00", "title": "Software Engineer - Agent Infra", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4296526286", "loc": "Palo Alto, CA", "company": "Perplexity"}, {"desc": "Perplexity is an AI-powered answer engine founded in December 2022 and growing rapidly as one of the world\u2019s leading AI platforms. Perplexity has raised over $1B in venture investment from some of the world\u2019s most visionary and successful leaders, including Elad Gil, Daniel Gross, Jeff Bezos, Accel, IVP, NEA, NVIDIA, Samsung, and many more. Our objective is to build accurate, trustworthy AI that powers decision-making for people and assistive AI wherever decisions are being made. Throughout human history, change and innovation have always been driven by curious people. Today, curious people use Perplexity to answer more than 780 million queries every month\u2013a number that\u2019s growing rapidly for one simple reason: everyone can be curious. \nPerplexity is seeking an experienced AI Agent Software Engineer to help revolutionize the way people search and interact online. In this role, you'll build scalable and elastic agent platform to power wide span of agent workloads from search to research to browser.\nResponsibilities\nArchitect and implement next-gen agent platform that powers all agentic products at Perplexity with high efficiency, reliability and scalability.\nStay up-to-date on new features released from external LLM providers and in house researchers and provide unified interfaces to interact with different sizes of models.\nImproving the speed and quality of AI agent codebase and engineering processes to ensure we consistently deliver an amazing product experience.\nHold a high quality bar to build generalized agentic & AI evaluation system to power all product online and offline evaluations.\nCollaborating across disciplines, including researchers, engineers, product managers, and designers, to fill gaps and ship products.\nQualifications\nPast experience building agent applications with tool calling, MCP and context engineering.\nUnderstands how to make tradeoffs in using different models to achieve the goal with most cost efficient and reliable system design.\nSelf-motivated with a willingness to take ownership of platform components.\n4+ years of industry experience.\n[Preferred] Past experience with open source LLM post training and evaluation experiences.\nThe cash compensation range for this role is $200,000 - $300,000.\nFinal offer amounts are determined by multiple factors, including, experience and expertise, and may vary from the amounts listed above.\nEquity: In addition to the base salary, equity \nmay be part\n of the total compensation package.\nBenefits: Comprehensive health, dental, and vision insurance for you and your dependents. Includes a 401(k) plan.", "comp": "$200,000.00", "title": "AI Software Engineer - Agent Platform", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4273007439", "loc": "New York City Metropolitan Area", "company": "Perplexity"}, {"desc": "Perplexity is an AI-powered answer engine founded in December 2022 and growing rapidly as one of the world\u2019s leading AI platforms. Perplexity has raised over $1B in venture investment from some of the world\u2019s most visionary and successful leaders, including Elad Gil, Daniel Gross, Jeff Bezos, Accel, IVP, NEA, NVIDIA, Samsung, and many more. Our objective is to build accurate, trustworthy AI that powers decision-making for people and assistive AI wherever decisions are being made. Throughout human history, change and innovation have always been driven by curious people. Today, curious people use Perplexity to answer more than 780 million queries every month\u2013a number that\u2019s growing rapidly for one simple reason: everyone can be curious. \nPerplexity is seeking an experienced Software Engineer focusing on building the next-gen AI Foundation & Platform to help revolutionize the way people search and interact online. In this role, you'll help build Perplexity\u2019s end-to-end AI data, evaluation and personalization infrastructure and flywheel which powers almost all agent products.\nTech Stack:\n Spark | AWS Data Stack (S3, RDS, DynamoDB, Docker, EKS, Kinesis) | Pytorch | DynamoDB | Databricks | Snowflake | LLM APIs\nPerplexity is rapidly scaling both in number of use cases and number of users. Perplexity\u2019s data stack powers scalable, personalized and fast answers for millions of people worldwide.\nResponsibilities\nCollaborate closely with AI Product, Applied ML, Post-Training, and Data Science teams to design, build, and maintain scalable data pipelines and data lakes\nDevelop high-performance infrastructure that powers personalization features including memory, discover, and agentic products\nCreate a scalable, multi-modal evaluation platform for all Perplexity AI products, including personalization, pro search, labs, deep research, and Comet\nDesign tools and abstractions on foundational infrastructure to enhance personalization, analytics, recommendations, AI products, and post-training capabilities\nHolistically improve engineering foundation to support rapid growth of Perplexity products and international user base.\nQualifications\nStrong programming and data engineering skills, with proficiency in open source & distributed framework(AWS, Spark, Flink, Iceberg, DynamoDB)\nFamiliarity with cloud-based data services (e.g., AWS, RDS, DynamoDB), containerized infrastructure (e.g., EKS, Docker), and data streaming (Flink, Spark streaming, CDC)\nStrong quantitative and engineering skills with experience in estimating performance at high scale\nExperience supporting various ML/AI engineering teams to build scalable frameworks to accelerate R&D for frontier models and AI products\nExperience iterating on improving LLM responses and set up proper evaluation framework or Judges to analysis performance holistically.\nSelf-motivated with a strong sense of ownership of systems and designs\n5+ years of industry experience in distributed systems or AI infrastructure", "comp": "0", "title": "Software Engineer, AI Foundation", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4303108161", "loc": "New York City Metropolitan Area", "company": "Perplexity"}, {"desc": "Perplexity is an AI-powered answer engine founded in December 2022 and growing rapidly as one of the world\u2019s leading AI platforms. Perplexity has raised over $1B in venture investment from some of the world\u2019s most visionary and successful leaders, including Elad Gil, Daniel Gross, Jeff Bezos, Accel, IVP, NEA, NVIDIA, Samsung, and many more. Our objective is to build accurate, trustworthy AI that powers decision-making for people and assistive AI wherever decisions are being made. Throughout human history, change and innovation have always been driven by curious people. Today, curious people use Perplexity to answer more than 780 million queries every month\u2013a number that\u2019s growing rapidly for one simple reason: everyone can be curious. \nWe are looking for an AI Inference engineer to join our growing team. Our current stack is Python, Rust, C++, PyTorch, Triton, CUDA, Kubernetes. You will have the opportunity to work on large-scale deployment of machine learning models for real-time inference.\nResponsibilities\nDevelop APIs for AI inference that will be used by both internal and external customers\nBenchmark and address bottlenecks throughout our inference stack\nImprove the reliability and observability of our systems and respond to system outages\nExplore novel research and implement LLM inference optimizations\nQualifications\nExperience with ML systems and deep learning frameworks (e.g. PyTorch, TensorFlow, ONNX)\nFamiliarity with common LLM architectures and inference optimization techniques (e.g. continuous batching, quantization, etc.)\nUnderstanding of GPU architectures or experience with GPU kernel programming using CUDA\nThe cash compensation range for this role is $190,000 - $250,000.\nFinal offer amounts are determined by multiple factors, including, experience and expertise, and may vary from the amounts listed above.\nEquity: In addition to the base salary, equity \nmay be part\n of the total compensation package.\nBenefits: Comprehensive health, dental, and vision insurance for you and your dependents. Includes a 401(k) plan.", "comp": "$190,000.00", "title": "AI Inference Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/3943072395", "loc": "New York City Metropolitan Area", "company": "Perplexity"}, {"desc": "Perplexity is an AI-powered answer engine founded in December 2022 and growing rapidly as one of the world\u2019s leading AI platforms. Perplexity has raised over $1B in venture investment from some of the world\u2019s most visionary and successful leaders, including Elad Gil, Daniel Gross, Jeff Bezos, Accel, IVP, NEA, NVIDIA, Samsung, and many more. Our objective is to build accurate, trustworthy AI that powers decision-making for people and assistive AI wherever decisions are being made. Throughout human history, change and innovation have always been driven by curious people. Today, curious people use Perplexity to answer more than 780 million queries every month\u2013a number that\u2019s growing rapidly for one simple reason: everyone can be curious. \nPerplexity is looking for a Senior Backend Engineer to join our small team revolutionizing the way people search and interact with the internet. You will be responsible for leading design, implementation, and scaling of systems that power our API products. Our backend stack is Python, Postgresql, DynamoDB, Redis, and Kubernetes, built alongside dedicated inhouse AI and search interfaces. The ideal candidate should have experience building systems, infrastructure, scaling, testing, and maintenance.\nResponsibilities\nDesign, build, expand and maintain APIs and services\nScope and lead large technical projects, laying the groundwork for early-stage products to iteratively evolve and scale\nWork with engineers across the company to understand when existing infrastructure can be leveraged vs. when building a bespoke solution is prudent\nAlign our technical decisions with the company\u2019s broad strategic initiatives, while also advocating for needs specific to emerging new API initiatives.\nShould be able to generalize specific customer requests and build features that are applicable to the broader user base of the product\nQualifications\nUnderstand good practices of building and working with natural language/LLM APIs\nHave experience managing infrastructure for API products\nHave a good intuition for what will last and scale\nHave experience in ensuring great user experience and ease of use of features and products you build.\n4+ years of engineering experience.\nOur cash compensation range for this role is $180,000 - $300,000.\nFinal offer amounts are determined by multiple factors, including, experience and expertise, and may vary from the amounts listed above.\nEquity: In addition to the base salary, equity may be part of the total compensation package.\nBenefits: Comprehensive health, dental, and vision insurance for you and your dependents. Includes a 401(k) plan.", "comp": "$180,000.00", "title": "Senior Backend Software Engineer - API Platform", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4173811489", "loc": "New York, NY", "company": "Perplexity"}, {"desc": "Perplexity is an AI-powered answer engine founded in December 2022 and growing rapidly as one of the world\u2019s leading AI platforms. Perplexity has raised over $1B in venture investment from some of the world\u2019s most visionary and successful leaders, including Elad Gil, Daniel Gross, Jeff Bezos, Accel, IVP, NEA, NVIDIA, Samsung, and many more. Our objective is to build accurate, trustworthy AI that powers decision-making for people and assistive AI wherever decisions are being made. Throughout human history, change and innovation have always been driven by curious people. Today, curious people use Perplexity to answer more than 780 million queries every month\u2013a number that\u2019s growing rapidly for one simple reason: everyone can be curious. \nWe\u2019re looking for curious, fast-moving builders in New York City. If you\u2019re a quant, trader, or engineer tired of the zero-sum game and ready to build something meaningful\u2014this is your sign. We care about velocity over ceremony. Ownership over org charts. Quality that feels invisible. Communication that\u2019s clear, direct, and human.", "comp": "0", "title": "Builder \u2013 NYC (General Interest)", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4293047569", "loc": "New York, NY", "company": "Perplexity"}, {"desc": "Perplexity is an AI-powered answer engine founded in December 2022 and growing rapidly as one of the world\u2019s leading AI platforms. Perplexity has raised over $1B in venture investment from some of the world\u2019s most visionary and successful leaders, including Elad Gil, Daniel Gross, Jeff Bezos, Accel, IVP, NEA, NVIDIA, Samsung, and many more. Our objective is to build accurate, trustworthy AI that powers decision-making for people and assistive AI wherever decisions are being made. Throughout human history, change and innovation have always been driven by curious people. Today, curious people use Perplexity to answer more than 780 million queries every month\u2013a number that\u2019s growing rapidly for one simple reason: everyone can be curious. \nPerplexity is seeking top-tier AI Research Scientists and Engineers to advance our AI products and capabilities. We're building the future of AI-powered search and agent experiences through our Sonar models, Deep Research Agent, Comet Agent, and Search products. Join us in creating SOTA experiences that handle hundreds of millions of queries and continue to scale rapidly.\nTeam Structure\nDepending on your interests and expertise, you'll work on one of three specialized teams:\n Core Research Team (Horizontal)\nFocus on generating and improving base models that power all our products. This team works on foundational model capabilities, post-training techniques, building RL infra and infrastructure that benefits the entire organization.\n Agent Products Team (Vertical)\nConcentrate on fine-tuning and optimizing models for our Deep Research Agent and Labs/Canvas products. This team bridges research and product, ensuring our agent capabilities deliver exceptional user experiences.\n Comet Agent Team (Vertical)\nDedicated to developing and enhancing our Comet Agent product. This specialized team focuses on the unique requirements and optimizations needed for Comet's specific use cases.\nResponsibilities\nResearch & Development\nPost-train SOTA LLMs using the latest supervised and reinforcement learning techniques (SFT/DPO/GRPO) \nLeverage our rich query/answer dataset to scale model performance across Sonar, Deep Research, Comet, and Search products \nStay current with the latest LLM research, especially in model training, optimization, and personalization techniques \nImplement preference optimization and personalization capabilities to enhance user experience \nInvent in-house improvements and optimizations to enhance SOTA models \nTurn research ideas into algorithms and run experiments to launch new models \nInfrastructure & Implementation\nOwn full-stack data, training, and evaluation pipelines required for model development \nBuild robust and effective training frameworks (on top of Megatron/PyTorch) for post-training LLMs \nImplement necessary infrastructure and components to support cutting-edge model training at scale \nIntegrate models seamlessly into our product ecosystem \nCollaboration\nWork closely with engineering teams to integrate models into Perplexity's product suite \nCollaborate across teams to ensure cohesive AI experiences throughout our platform \nPartner with product teams to understand user needs and translate them into model improvements \nQualifications\nRequired\nProven experience with large-scale LLMs and Deep Learning systems \nStrong programming skills in Python/PyTorch; versatility is a plus \nExperience with post-training techniques and reinforcement learning \nSelf-starter with a willingness to take ownership of tasks \nPassion for tackling challenging problems \nMinimum 2-6 years of experience on relevant projects (depending on seniority level) \nNice-to-have\nPhD in Machine Learning, AI, Systems, or related areas \nExperience in post-training LLMs with SFT/DPO/GRPO \nC++/CUDA programming skills \nExperience building LLM training frameworks \nAcademic publications and research impact \nExperience with agent systems and multi-step reasoning \nBackground in personalization and preference learning \nCompensation & Benefits\nOur cash compensation range for this role is $200,000 - $300,000.\nEquity: In addition to the base salary, equity is part of the total compensation package.\nBenefits: Comprehensive health, dental, and vision insurance for you and your dependents. Includes a 401(k) plan.\nFinal offer amounts are determined by multiple factors, including experience and expertise, and may vary from the amounts listed above.", "comp": "$200,000.00", "title": "AI Researcher", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4303107332", "loc": "New York City Metropolitan Area", "company": "Perplexity"}, {"desc": "Perplexity is an AI-powered answer engine founded in December 2022 and growing rapidly as one of the world\u2019s leading AI platforms. Perplexity has raised over $1B in venture investment from some of the world\u2019s most visionary and successful leaders, including Elad Gil, Daniel Gross, Jeff Bezos, Accel, IVP, NEA, NVIDIA, Samsung, and many more. Our objective is to build accurate, trustworthy AI that powers decision-making for people and assistive AI wherever decisions are being made. Throughout human history, change and innovation have always been driven by curious people. Today, curious people use Perplexity to answer more than 780 million queries every month\u2013a number that\u2019s growing rapidly for one simple reason: everyone can be curious. \nAbout The Role\nAs Comet continues to grow as a stand-alone product and codebase, we are seeking a Browser Security Engineer to lead and own browser-specific security initiatives, including custom Chromium development, extension security, and cross-device features.\nBrowser/Chromium Security: Browser security encompasses threats and vulnerabilities (e.g., XSS and Same-Origin Policy issues).\nCustom Engineering: The Comet product features substantial custom work, including our Chromium fork, browser extensions, and secure sync features between devices.\nProactive Partnership: As Comet\u2019s complexity grows, a dedicated security engineer embedded with the product team will enable us to proactively identify and address concerns\u2014well before red-teaming or external audits.\nWhat You\u2019ll Do\nLead threat modeling and security architecture reviews for all Comet browser surfaces.\nCollaborate closely with product and engineering teams to proactively identify and mitigate browser vulnerabilities, especially issues specific to custom Chrome engineering and browser extension architecture.\nDevelop security best practices, tooling, and documentation for engineers building browser-facing features.\nServe as the security expert for topics such as Same-Origin Policy (SOP), XSS, sandboxing, browser extension permissions, and secure inter-device communication.\nTriage and resolve vulnerabilities found by external researchers (e.g., bug bounty, red-teaming partners) and the Chromium community.\nBuild strong relationships with security partners and leverage their feedback for continuous improvement.\nStay up to date on emerging browser security threats, tools, and industry trends.\nWhat We're Looking For\nPrior experience in browser, application, or product security (ideally with Chrome/Chromium or other browser engine experience).\nDeep knowledge of modern browser architectures; understanding of XSS, CSP, sandboxing, extension security, and WebView-specific threats.\nExperience with security reviews and threat modeling for web, mobile, and extension platforms.\nAbility to work cross-functionally with engineers, product leads, and external security researchers.\nNice to Have\nContributions to open-source browser projects, security research, or participation in bug bounty programs.\nExperience with web and mobile threat modeling.\nFamiliarity with secure sync and cross-device communication mechanisms.\nTrack record of proactive security work embedded within product teams.\nWhy Join Us?\nShape security strategy for a next-generation browser product.\nWork on challenging problems at the intersection of custom Chromium engineering, browser extensions, and mobile security.\nCollaborate with top engineers in an environment that prioritizes security and product excellence.\nThe cash compensation range for this role is $250,000 - $350,000.\nFinal offer amounts are determined by multiple factors, including, experience and expertise, and may vary from the amounts listed above.\nEquity: In addition to the base salary, equity may be part of the total compensation package.\nBenefits: Comprehensive health, dental, and vision insurance for you and your dependents. Includes a 401(k) plan.", "comp": "$250,000.00", "title": "Browser Security Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4310028485", "loc": "New York, NY", "company": "Perplexity"}, {"desc": "Perplexity is an AI-powered answer engine founded in December 2022 and growing rapidly as one of the world\u2019s leading AI platforms. Perplexity has raised over $1B in venture investment from some of the world\u2019s most visionary and successful leaders, including Elad Gil, Daniel Gross, Jeff Bezos, Accel, IVP, NEA, NVIDIA, Samsung, and many more. Our objective is to build accurate, trustworthy AI that powers decision-making for people and assistive AI wherever decisions are being made. Throughout human history, change and innovation have always been driven by curious people. Today, curious people use Perplexity to answer more than 780 million queries every month\u2013a number that\u2019s growing rapidly for one simple reason: everyone can be curious. \nPerplexity is looking for an Applied ML Engineer to design, build, and iterate on cutting-edge AI models powering our core experience. As an expert in machine learning and artificial intelligence, you will develop scalable and impactful solutions for user personalization, query understanding, and content discovery - fulfilling the curiosity of millions of users across the globe.\nKey Responsibilities\n \nApply state-of-the-art ML and LLM techniques to solve problems spanning:\nPersonalization (LLM memory, context summarization, retrieval and ranking); \nQuery Understanding (intent modeling, rewriting, agentic decomposition); \nContent Discovery (feed ranking and surfacing) \nRigorously evaluate LLM/ML models with both offline and online techniques, designing experiments and metrics that provide deep insight into quality and impact. \nOwn the entire model lifecycle from research to production: data analysis, modeling, evaluation, offline/online A/B testing, and iterative improvement. \nCollaborate cross-functionally with engineers, PMs, data scientists, and designers to ensure our AI drives meaningful product improvements. \nStay at the forefront of ML/AI innovation by evaluating and incorporating emerging research and algorithms into the product lifecycle. \nPreferred Qualifications\n5+ years experience building and shipping robust ML/AI models for large-scale, user-facing or data-driven products. \nDeep expertise in deep learning (PyTorch, TensorFlow, JAX), LLMs, information retrieval, content summarization, recommendation systems, NLP, and/or ranking. \nStrong software engineering skills (Python, production-quality codebases, collaborative development). \nIn-depth experience with the full ML lifecycle: data analysis, feature engineering, iterative model development, rigorous evaluation, and ongoing monitoring/improvement. \nProven collaborator and communicator; excels in high-velocity, cross-functional teams. \nCurious, driven by end-user/product impact, and passionate about advancing the state of applied ML and AI. \nBS, MS, or PhD in Computer Science, Engineering, or related field (or equivalent experience). \nBonus Points For\nExperience with LLM prompt engineering, Retrieval-augmented generation (RAG) based systems. \nExperience in large scale user-centric and content-centric personalization challenges (user modeling, retrieval, content ranking, etc). \nOpen-source or published contributions in ML, NLP, IR, or relevant research fields.", "comp": "0", "title": "AI Engineer, Applied ML", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4302797642", "loc": "New York City Metropolitan Area", "company": "Perplexity"}, {"desc": "Perplexity is an AI-powered answer engine founded in December 2022 and growing rapidly as one of the world\u2019s leading AI platforms. Perplexity has raised over $1B in venture investment from some of the world\u2019s most visionary and successful leaders, including Elad Gil, Daniel Gross, Jeff Bezos, Accel, IVP, NEA, NVIDIA, Samsung, and many more. Our objective is to build accurate, trustworthy AI that powers decision-making for people and assistive AI wherever decisions are being made. Throughout human history, change and innovation have always been driven by curious people. Today, curious people use Perplexity to answer more than 780 million queries every month\u2013a number that\u2019s growing rapidly for one simple reason: everyone can be curious. \nPerplexity is seeking a Senior or Staff-level Backend Software Engineer to join our Product Platform Team. As a critical part of the team, you will be responsible for leading design, implementation, and scaling of systems that power our web and mobile products.\nOur backend stack is Python, GoLang, PostgreSQL, DynamoDB, Redis, and Kubernetes, built alongside dedicated in-house AI and search interfaces.\nAbout The Team\nThe Product Platform Team plays a pivotal role in enabling the success of product engineers and the broader Perplexity ecosystem. Our mission is to:\nDevelop foundational systems and tools that empower product teams to deliver with speed and confidence.\nEnsure the scalability, reliability, and performance of the core platform as we grow.\nResponsibilities\nDesign, implement, and maintain robust backend services that serve as the backbone of our platform.\nCollaborate with cross-functional teams to create scalable and maintainable system architectures.\nTackle complex infrastructure challenges, leveraging AWS services.\nDrive best practices in system design, coding standards, and engineering excellence.\nQualifications\n4+ years of backend engineering experience in designing and building scalable systems.\nStrong system design skills, with the ability to create efficient, reliable, and scalable architectures.\nHands-on experience with infrastructure tools, including AWS, Kubernetes, and related cloud technologies.\nStrong proficiency in Python.\nCollaborative mindset and eagerness to solve challenging technical problems.\nOur cash compensation range for this role is $220,000 - $300,000.\nFinal offer amounts are determined by multiple factors, including, experience and expertise, and may vary from the amounts listed above.\nEquity: In addition to the base salary, equity may be part of the total compensation package.\nBenefits: Comprehensive health, dental, and vision insurance for you and your dependents. Includes a 401(k) plan.", "comp": "$220,000.00", "title": "Senior/Staff Engineer - Platform", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4169376747", "loc": "Buffalo-Niagara Falls Area", "company": "Perplexity"}, {"desc": "Perplexity is an AI-powered answer engine founded in December 2022 and growing rapidly as one of the world\u2019s leading AI platforms. Perplexity has raised over $1B in venture investment from some of the world\u2019s most visionary and successful leaders, including Elad Gil, Daniel Gross, Jeff Bezos, Accel, IVP, NEA, NVIDIA, Samsung, and many more. Our objective is to build accurate, trustworthy AI that powers decision-making for people and assistive AI wherever decisions are being made. Throughout human history, change and innovation have always been driven by curious people. Today, curious people use Perplexity to answer more than 780 million queries every month\u2013a number that\u2019s growing rapidly for one simple reason: everyone can be curious. \nPerplexity AI is looking for an experienced Android Mobile Engineer to join our small team revolutionizing the way people search and interact with the internet. You will be responsible for building and expanding the Perplexity Android app.\nThe ideal candidate should have strong programming skills, an interest in search and large language models, and a passion for delivering a great UX backed by a quality UI.\nThis role can be based in San Francisco, New York City, London, or Belgrade.\nResponsibilities\nDevelop a performant native Android app that millions of users around the world enjoy using\nWork closely with product teams to implement novel mobile experiences\nWork closely with design teams to design fast and intuitive UI\nCollaborate with data science and machine learning teams to instrument, analyze, and improve the end-to-end experience\nQualifications\n4+ years industry experience\nExpertise in Android Compose\nExpertise in Kotlin Coroutines and Flow\nStrong Android fundamentals and a proven track record of working with a modern Android stack built in Kotlin\nEnjoys the craft of building nice UI, creating a good UX, and writing code that can be reused by others\nUnderstands how to manage performance and speed\nComfortable working with a small, fast-moving team, must be willing to dive in and take ownership\nA passion for shipping\nThe cash compensation range for this role is $180,000 - $240,000.\nFinal offer amounts are determined by multiple factors, including, experience and expertise, and may vary from the amounts listed above.\nEquity: In addition to the base salary, equity is part of the total compensation package.\nBenefits: Comprehensive health, dental, and vision insurance for you and your dependents. Includes a 401(k) plan.", "comp": "$180,000.00", "title": "Android Mobile Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4254416601", "loc": "New York City Metropolitan Area", "company": "Perplexity"}, {"desc": "Perplexity is an AI-powered answer engine founded in December 2022 and growing rapidly as one of the world\u2019s leading AI platforms. Perplexity has raised over $1B in venture investment from some of the world\u2019s most visionary and successful leaders, including Elad Gil, Daniel Gross, Jeff Bezos, Accel, IVP, NEA, NVIDIA, Samsung, and many more. Our objective is to build accurate, trustworthy AI that powers decision-making for people and assistive AI wherever decisions are being made. Throughout human history, change and innovation have always been driven by curious people. Today, curious people use Perplexity to answer more than 780 million queries every month\u2013a number that\u2019s growing rapidly for one simple reason: everyone can be curious. \nWe are looking for an AI Infra engineer to join our growing team. We work with Kubernetes, Slurm, Python, C++, PyTorch, and primarily on AWS. As an AI Infrastructure Engineer, you will be partnering closely with our Inference and Research teams to build, deploy, and optimize our large-scale AI training and inference clusters\nResponsibilities\nDesign, deploy, and maintain scalable Kubernetes clusters for AI model inference and training workloads\nManage and optimize Slurm-based HPC environments for distributed training of large language models\nDevelop robust APIs and orchestration systems for both training pipelines and inference services\nImplement resource scheduling and job management systems across heterogeneous compute environments\nBenchmark system performance, diagnose bottlenecks, and implement improvements across both training and inference infrastructure\nBuild monitoring, alerting, and observability solutions tailored to ML workloads running on Kubernetes and Slurm\nRespond swiftly to system outages and collaborate across teams to maintain high uptime for critical training runs and inference services\nOptimize cluster utilization and implement autoscaling strategies for dynamic workload demands\nQualifications\nStrong expertise in Kubernetes administration, including custom resource definitions, operators, and cluster management\nHands-on experience with Slurm workload management, including job scheduling, resource allocation, and cluster optimization\nExperience with deploying and managing distributed training systems at scale\nDeep understanding of container orchestration and distributed systems architecture\nHigh level familiarity with LLM architecture and training processes (Multi-Head Attention, Multi/Grouped-Query, distributed training strategies)\nExperience managing GPU clusters and optimizing compute resource utilization\nRequired Skills\nExpert-level Kubernetes administration and YAML configuration management\nProficiency with Slurm job scheduling, resource management, and cluster configuration\nPython and C++ programming with focus on systems and infrastructure automation\nHands-on experience with ML frameworks such as PyTorch in distributed training contexts\nStrong understanding of networking, storage, and compute resource management for ML workloads\nExperience developing APIs and managing distributed systems for both batch and real-time workloads\nSolid debugging and monitoring skills with expertise in observability tools for containerized environments\nPreferred Skills\nExperience with Kubernetes operators and custom controllers for ML workloads\nAdvanced Slurm administration including multi-cluster federation and advanced scheduling policies\nFamiliarity with GPU cluster management and CUDA optimization\nExperience with other ML frameworks like TensorFlow or distributed training libraries\nBackground in HPC environments, parallel computing, and high-performance networking\nKnowledge of infrastructure as code (Terraform, Ansible) and GitOps practices\nExperience with container registries, image optimization, and multi-stage builds for ML workloads\nRequired Experience\nDemonstrated experience managing large-scale Kubernetes deployments in production environments\nProven track record with Slurm cluster administration and HPC workload management\nPrevious roles in SRE, DevOps, or Platform Engineering with focus on ML infrastructure\nExperience supporting both long-running training jobs and high-availability inference services\nIdeally, 3-5 years of relevant experience in ML systems deployment with specific focus on cluster orchestration and resource management\nThe cash compensation range for this role is $190,000 - $250,000.\nFinal offer amounts are determined by multiple factors, including, experience and expertise, and may vary from the amounts listed above.\nEquity: In addition to the base salary, equity \nmay be part\n of the total compensation package.\nBenefits: Comprehensive health, dental, and vision insurance for you and your dependents. Includes a 401(k) plan.", "comp": "$190,000.00", "title": "AI Infra Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4265479005", "loc": "Buffalo-Niagara Falls Area", "company": "Perplexity"}, {"desc": "Perplexity is an AI-powered answer engine founded in December 2022 and growing rapidly as one of the world\u2019s leading AI platforms. Perplexity has raised over $1B in venture investment from some of the world\u2019s most visionary and successful leaders, including Elad Gil, Daniel Gross, Jeff Bezos, Accel, IVP, NEA, NVIDIA, Samsung, and many more. Our objective is to build accurate, trustworthy AI that powers decision-making for people and assistive AI wherever decisions are being made. Throughout human history, change and innovation have always been driven by curious people. Today, curious people use Perplexity to answer more than 780 million queries every month\u2013a number that\u2019s growing rapidly for one simple reason: everyone can be curious. \nPerplexity is seeking a Staff Authentication & Identity Engineer to join our innovative team revolutionizing internet search and interaction. You\u2019ll tackle distributed, high-scale challenges while ensuring seamless user experiences for millions of daily queries. Your work will directly support our mission to revolutionize secure, scalable access management for enterprise customers and individual users alike.\nResponsibilities\nDesign and build robust authentication systems for Next.js-based web applications, ensuring low-latency performance at scale.\nArchitect secure, modern authentication flows using OAuth 2.0, JWT, and passwordless/email providers.\nCollaborate cross-functionally with frontend, backend, security, and mobile teams to unify authentication across platforms.\nEvolve access control systems, including role-based permissions and ACLs for customer-specific resource management.\nOptimize authentication performance and reliability while maintaining strict security standards.\nOwn critical components of our authentication stack, from prototyping to production deployment.\nQualifications\n5+ years of web development experience, including 3+ years building authentication systems.\nExpertise in Python, JavaScript/TypeScript, React, Next.js, and NextAuth.js.\nDeep knowledge of OAuth 2.0, OpenID Connect, and modern security protocols.\nExperience designing high-scale architectures (100k+ requests/sec) with cloud platforms like AWS.\nProficiency with relational databases (e.g., PostgreSQL) for auth-related data.\nStrong problem-solving skills and commitment to code simplicity/performance.\nNice to Haves\nExperience with distributed systems or Go/Python backend development.\nFamiliarity with enterprise auth standards (SSO, SCIM, SAML).\nBackground in role-based access control (RBAC) for large user bases.\nMobile authentication implementation experience.\nOur cash compensation range for this role is $250,000 - $300,000.\nFinal offer amounts are determined by multiple factors, including, experience and expertise, and may vary from the amounts listed above.\nEquity: In addition to the base salary, equity may be part of the total compensation package.\nBenefits: Comprehensive health, dental, and vision insurance for you and your dependents. Includes a 401(k) plan.", "comp": "$250,000.00", "title": "Staff Software Engineer - Authentication & Identity", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4180270464", "loc": "New York City Metropolitan Area", "company": "Perplexity"}, {"desc": "Perplexity is an AI-powered answer engine founded in December 2022 and growing rapidly as one of the world\u2019s leading AI platforms. Perplexity has raised over $1B in venture investment from some of the world\u2019s most visionary and successful leaders, including Elad Gil, Daniel Gross, Jeff Bezos, Accel, IVP, NEA, NVIDIA, Samsung, and many more. Our objective is to build accurate, trustworthy AI that powers decision-making for people and assistive AI wherever decisions are being made. Throughout human history, change and innovation have always been driven by curious people. Today, curious people use Perplexity to answer more than 780 million queries every month\u2013a number that\u2019s growing rapidly for one simple reason: everyone can be curious. \nPerplexity is seeking a Senior or Staff level Reliability Engineer (SRE) to join our small team in revolutionizing the way people search and interact with the internet. You will be responsible for leading the design, implementation, and scaling of the infrastructure and systems that support our web and mobile products.\nThe ideal candidate should have experience in designing highly scalable infrastructure, building systems, and performing testing, monitoring, and maintenance.Our backend stack includes Python, PostgreSQL, DynamoDB, Redis, and Kubernetes - built alongside dedicated in-house AI and search interfaces.\nResponsibilities\nDesign and implement highly available, high-performance, and scalable systems.\nMaintain and optimize key-value and relational databases.\nScale and load balance web server backends to meet rapidly changing needs.\nParticipate in on-call rotation. Monitor systems and applications, proactively identifying and resolving reliability, scalability, or performance issues.\nDevelop monitoring tools, alerts, and dashboards to provide visibility into system health and performance.\nCollaborate with product engineering and security engineering teams to develop scalable automations.\nQualifications\nStrong experience with cloud infrastructure built on AWS.\nProficient in database management and caching strategies.\nExcellent problem-solving and troubleshooting skills, with the ability to analyze, debug, and resolve complex technical issues.\nExperience working with containers (Docker, Kubernetes) and orchestration tools.\nExcellent communication and collaboration skills.\nExperience with Python and Terraform.\n7+ years of industry experience.\nThe cash compensation range for US-based employees is $240,000 to $300,000.\nFinal offer amounts are determined by multiple factors, including, experience and expertise, and may vary from the amounts listed above.\nEquity: In addition to the base salary, equity may be part of the total compensation package.\nBenefits: Comprehensive health, dental, and vision insurance for you and your dependents. Includes a 401(k) plan.", "comp": "$240,000.00", "title": "Senior/Staff Engineer - Reliability (SRE)", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4030437958", "loc": "New York City Metropolitan Area", "company": "Perplexity"}, {"desc": "Perplexity is an AI-powered answer engine founded in December 2022 and growing rapidly as one of the world\u2019s leading AI platforms. Perplexity has raised over $1B in venture investment from some of the world\u2019s most visionary and successful leaders, including Elad Gil, Daniel Gross, Jeff Bezos, Accel, IVP, NEA, NVIDIA, Samsung, and many more. Our objective is to build accurate, trustworthy AI that powers decision-making for people and assistive AI wherever decisions are being made. Throughout human history, change and innovation have always been driven by curious people. Today, curious people use Perplexity to answer more than 780 million queries every month\u2013a number that\u2019s growing rapidly for one simple reason: everyone can be curious. \nPerplexity is seeking a highly skilled, experienced, and hands-on AI Security Engineer to join our security team, driving the protection of next-generation AI systems against adversarial threats. In this role, you\u2019ll design and implement robust mechanisms to secure self-hosted models, LLM APIs, agents, MCPs, and the core AI stack. You'll empower developers with tools and guidance, as well as technical contributions, enabling innovation while ensuring AI security is strong by default.\nOur tech stack includes Python, NextJS, TypeScript, Docker, AWS, Kubernetes, and PostgreSQL.\nResponsibilities\nDefine, build, and refine mechanisms to secure AI systems (including self-hosted models, LLM APIs, agents, MCPs, and other core components of the AI stack) against adversarial behavior of all kinds\nUnderstand technically complex AI systems, identify potential weaknesses in their architecture, and implement improvements\nAt least 50% of time performing hands-on remediation. Also working closely with peer engineers to drive remediations\nPlan and carry out threat modeling activities and realistic threat simulations across our offerings\nConduct cybersecurity evaluations and lead AI security assessments in a cross-functional environment\nDevelop initiatives that improve our capabilities to effectively evaluate AI systems and enhance the organization's prevention, detection, response, and threat hunting capabilities\nProvide guidance and education to developers to help deter and prevent threats\nQualifications\nHands-on coding and prompting experience.\nBachelor of Science or Master of Science in Computer Science or a related field, or equivalent experience\nBe a technical and process subject matter expert regarding AI security services and attacker tactics, techniques, and procedures\nGood understanding of LLMs, AI architecture patterns, machine learning models, and related technologies such as MCP\nUnderstanding of application security principles and secure coding practices\nExperience developing and implementing security procedures and policies\nStrong problem-solving, project management, leadership, and communication skills\nSelf-motivated with a willingness to take ownership of tasks\n4+ years of industry experience\nThe cash compensation range for this role is $250,000 - $350,000.\nFinal offer amounts are determined by multiple factors, including, experience and expertise, and may vary from the amounts listed above.\nEquity: In addition to the base salary, equity may be part of the total compensation package.\nBenefits: Comprehensive health, dental, and vision insurance for you and your dependents. Includes a 401(k) plan.", "comp": "$250,000.00", "title": "AI Security Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4273380317", "loc": "New York, NY", "company": "Perplexity"}, {"desc": "Perplexity is an AI-powered answer engine founded in December 2022 and growing rapidly as one of the world\u2019s leading AI platforms. Perplexity has raised over $1B in venture investment from some of the world\u2019s most visionary and successful leaders, including Elad Gil, Daniel Gross, Jeff Bezos, Accel, IVP, NEA, NVIDIA, Samsung, and many more. Our objective is to build accurate, trustworthy AI that powers decision-making for people and assistive AI wherever decisions are being made. Throughout human history, change and innovation have always been driven by curious people. Today, curious people use Perplexity to answer more than 780 million queries every month\u2013a number that\u2019s growing rapidly for one simple reason: everyone can be curious. \nPerplexity is seeking a Senior or Staff Developer Experience Engineer (DevEx) to join our team in revolutionizing the way people search and interact with the internet. As a DevEx engineer, you will take technical ownership of our developer infrastructure, lead architectural initiatives, and drive cross-functional collaboration to optimize the development experience for our growing engineering organization.\nThe ideal candidate is a seasoned engineer with deep expertise in build systems, containerization solutions, continuous integration, testing frameworks, and large-scale infrastructure. You will mentor other engineers, influence technical strategy, and ensure our developer tools scale with Perplexity's AI-driven platform.\nResponsibilities\nLead the design and architecture of scalable developer infrastructure systems that empower every Perplexity engineer to do their best work.\nDrive cross-team initiatives to dramatically boost reliability, speed, and efficiency of our largest builds and CI/CD pipelines.\nOwn and evolve the technical strategy for developer tooling, establishing long-term architectural vision while delivering incremental improvements.\nMentor engineers across teams on developer experience best practices and provide technical leadership on complex infrastructure challenges.\nLead comprehensive evaluations of external tools, vendors, and technologies to ensure strategic alignment with our AI platform architecture.\nDesign and maintain seamless development environments and IDE integrations across multiple languages (Python, TypeScript, Go, Rust).\nEstablish and enforce standards for testing, deployment, and monitoring that enable safe, rapid software delivery at scale.\nCollaborate with engineering leadership to identify and resolve systemic developer productivity bottlenecks.\nChampion a culture of operational excellence and developer empathy across the organization.\nDrive adoption of new technologies and practices that improve engineering velocity and code quality.\nQualifications\n7+ years of engineering experience, with +3 years focusing on developer experience.\nDemonstrated technical leadership in designing, implementing, and scaling developer productivity platforms in high-growth environments, ideally with an AI, SaaS, or large-scale cloud component.\nExpertise in build systems (Bazel, Buck, or similar), orchestration tools (Docker, Kubernetes), and CI/CD frameworks. Experience integrating new languages and frameworks into existing infrastructure. Strong programming skills in multiple languages including Python, TypeScript, Go, or Rust.\nExperience leading architectural decisions and mentoring engineers on complex technical challenges.\nProven cross-org influence, including setting organizational technical direction, standardizing best practices, and leading multi-team initiatives. Deep understanding of software development lifecycle challenges faced by engineering teams operating at scale.\nExperience with AI/ML infrastructure and tooling is strongly preferred given Perplexity's focus.\nExceptional communication skills\u2014able to articulate complex technical concepts and drive buy-in across technical and non-technical audiences.Track record of building and maintaining internal developer tools, testing frameworks, and deployment infrastructure.\nExperience with observability, monitoring, and debugging tools for distributed systems.\nRelentless focus on developer empathy, operational excellence, and the ability to see around corners to anticipate company-scale challenges and opportunities.\nOur cash compensation range for this role is $250k - $300k\nFinal offer amounts are determined by multiple factors, including, experience and expertise, and may vary from the amounts listed above.\nEquity: In addition to the base salary, equity may be part of the total compensation package.\nBenefits: Comprehensive health, dental, and vision insurance for you and your dependents. Includes a 401(k) plan.", "comp": "$250,000.00", "title": "Senior/Staff Engineer - Developer Experience", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4292695143", "loc": "Buffalo-Niagara Falls Area", "company": "Perplexity"}, {"desc": "Perplexity is an AI-powered answer engine founded in December 2022 and growing rapidly as one of the world\u2019s leading AI platforms. Perplexity has raised over $1B in venture investment from some of the world\u2019s most visionary and successful leaders, including Elad Gil, Daniel Gross, Jeff Bezos, Accel, IVP, NEA, NVIDIA, Samsung, and many more. Our objective is to build accurate, trustworthy AI that powers decision-making for people and assistive AI wherever decisions are being made. Throughout human history, change and innovation have always been driven by curious people. Today, curious people use Perplexity to answer more than 780 million queries every month\u2013a number that\u2019s growing rapidly for one simple reason: everyone can be curious. \nPerplexity is seeking a highly experienced and hands-on Cloud Security Engineer to join our dynamic security team, revolutionizing the way people search and interact with the internet. In this role, you\u2019ll lead efforts to build and maintain secure, scalable infrastructure that empowers engineers to innovate quickly and safely.\nResponsibilities\nPartner with infrastructure and engineering teams to embed security into development workflows and promote secure-by-default patterns\nBuild Terraform modules with built-in security guardrails, such as logging, encryption, and automated threat detection enablement\nDeploy cloud-native detection capabilities using AWS GuardDuty, Security Hub, and custom detection rules to identify credential compromise, crypto-mining, and lateral movement\nMaintain SOC 2 Type II and ISO 27001 compliance through automated collection of cloud control evidence\nConduct security audits of cloud resource configurations using tools like AWS Config and Open Policy Agent, and remediate deviations from CIS Benchmarks and our internal security policies\nSecure CI/CD and supply chain pipelines by implementing controls such as artifact signing, secret scanning, and dependency monitoring\nApply zero trust principles through strict network segmentation, authentication, and authorization across our cloud environments\nParticipate in the security on-call rotation and respond to security alerts and incidents to ensure rapid mitigation and root cause analysis\nQualifications\n8+ years of experience in Cloud Infrastructure, Platform Engineering, or similar roles\nProven track record of building and scaling infrastructure at high-growth technology companies\nDeep understanding of cloud-native architectures, microservices, and distributed systems\nExperience securing CI/CD pipelines, deployment automation, and internal tooling\nStrong programming skills in Python, Go, or similar languages\nBonus: Experience with AI/ML infrastructure and multi-cloud environments\nThe cash compensation range for this role is $250,000 - $350,000.\nFinal offer amounts are determined by multiple factors, including, experience and expertise, and may vary from the amounts listed above.\nEquity: In addition to the base salary, equity \nmay be part\n of the total compensation package.\nBenefits: Comprehensive health, dental, and vision insurance for you and your dependents. Includes a 401(k) pla", "comp": "$250,000.00", "title": "Cloud Security Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4239711907", "loc": "San Francisco, CA", "company": "Perplexity"}, {"desc": "Perplexity is an AI-powered answer engine founded in December 2022 and growing rapidly as one of the world\u2019s leading AI platforms. Perplexity has raised over $1B in venture investment from some of the world\u2019s most visionary and successful leaders, including Elad Gil, Daniel Gross, Jeff Bezos, Accel, IVP, NEA, NVIDIA, Samsung, and many more. Our objective is to build accurate, trustworthy AI that powers decision-making for people and assistive AI wherever decisions are being made. Throughout human history, change and innovation have always been driven by curious people. Today, curious people use Perplexity to answer more than 780 million queries every month\u2013a number that\u2019s growing rapidly for one simple reason: everyone can be curious. \nPerplexity AI is looking for a Senior iOS Engineer to join our small team revolutionizing the way people search and interact with the internet. You will be responsible for building new experiences and improving the performance of Perplexity\u2019s iOS app.\nThe ideal candidate should have strong programming skills, an interest in search and large language models, and a passion for delivering a great UX backed by a quality UI.\nResponsibilities\nYou will develop a native iOS app for Perplexity's evolving product\nYou will define the processes around mobile development, including planning, testing, releasing, and monitoring\nYou will work with the core team to design and implement novel mobile experiences\nQualifications\n5+ years industry experience\nStrong Swift fundamentals and a proven track record of working with a modern iOS stack built with Swift, SwiftUI (iOS16+) and UIKit\nEnjoys the craft of building nice UI, creating a good UX, and writing reusable and testable code\nUnderstands low-level intricacies, and knows how to profile and measure app performance and speed\nComfortable working with a small, fast-moving team, and must be willing to dive in and take ownership\nA passion for iOS development, and enjoys experimenting with what's new with each iteration of iOS and iPadOS\nNice to have\nExperience with related platforms like macOS and tools like Mac Catalyst\nExperience with WebSockets, HTTP\nExperience with concurrency and multithreading (GCD, critical sections, race conditions)\nThe cash compensation range for this role is $180,000 - $220,000.\nFinal offer amounts are determined by multiple factors, including, experience and expertise, and may vary from the amounts listed above.\nEquity: In addition to the base salary, equity may be part of the total compensation package.\nBenefits: Comprehensive health, dental, and vision insurance for you and your dependents. Includes a 401(k) plan.", "comp": "$180,000.00", "title": "Senior iOS Software Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4257561463", "loc": "San Francisco, CA", "company": "Perplexity"}, {"desc": "Perplexity is an AI-powered answer engine founded in December 2022 and growing rapidly as one of the world\u2019s leading AI platforms. Perplexity has raised over $1B in venture investment from some of the world\u2019s most visionary and successful leaders, including Elad Gil, Daniel Gross, Jeff Bezos, Accel, IVP, NEA, NVIDIA, Samsung, and many more. Our objective is to build accurate, trustworthy AI that powers decision-making for people and assistive AI wherever decisions are being made. Throughout human history, change and innovation have always been driven by curious people. Today, curious people use Perplexity to answer more than 780 million queries every month\u2013a number that\u2019s growing rapidly for one simple reason: everyone can be curious. \nThe \nPerplexity Research Residency\n is our flagship program for enabling the best research talent across all disciplines to shape the future of AI. Our program creates pathways for exceptional researchers, engineers, analysts from fields beyond traditional AI research to contribute meaningfully to the future of AI research and its impact on users. Whether you're a theoretical physicist, a cognitive scientist, a biochemist, a quant, a mathematician, a philosopher, or an exceptional research in any other discipline, we\u2019d like to encourage you to apply.\nPlease refer to the program homepage for full details on the Perplexity Research Residency and application process. In particular, refer to the \u201cWhat We\u2019re Looking For\u201d section for the program criteria that will be used to select candidates.\nThe cash compensation for this role is $220,000 per year, prorated to a six-month term.\nLocation: San Francisco or Palo Alto, California\nBenefits: Comprehensive health, dental, and vision insurance for you and your dependents. Includes a 401(k) plan.", "comp": "0", "title": "Research Resident", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4267609456", "loc": "Palo Alto, CA", "company": "Perplexity"}, {"desc": "Perplexity is an AI-powered answer engine founded in December 2022 and growing rapidly as one of the world\u2019s leading AI platforms. Perplexity has raised over $1B in venture investment from some of the world\u2019s most visionary and successful leaders, including Elad Gil, Daniel Gross, Jeff Bezos, Accel, IVP, NEA, NVIDIA, Samsung, and many more. Our objective is to build accurate, trustworthy AI that powers decision-making for people and assistive AI wherever decisions are being made. Throughout human history, change and innovation have always been driven by curious people. Today, curious people use Perplexity to answer more than 780 million queries every month\u2013a number that\u2019s growing rapidly for one simple reason: everyone can be curious. \nPerplexity is seeking a singularly creative and energetic engineer to spearhead our Acceleration team as its founding tech lead. We are revolutionizing the way people navigate the internet and the wider world. To continue building best-in-class products, we are reimagining how our company and our teams operate.\nJust as Perplexity is heralding an agentic future for the internet, you will lead our company in making the best use of AI tools and agents to multiply the leverage of our lean, mission-focused teams. Today, Perplexity uses AI tools across everything we do, from frontend and backend engineering to applied AI research and business operations. Tomorrow\u2019s AI technology will be even more capable, and the Acceleration team will lead both software and process engineering to harness AI so that the company can deliver at maximum velocity.\nThe ideal candidate will possess sound technical judgment forged in the trenches of internet-scale companies, paired with voracious use of today\u2019s most advanced AI tools/models and a capacious imagination to rethink how work gets done in the leading companies of tomorrow. They will provide hands-on technical leadership in a hybrid role that marries facets of AI product development, infrastructure/platform engineering, developer experience, and more.\nResponsibilities\nIdentify, prioritize, and execute on the highest-potential opportunities to accelerate Perplexity\u2019s delivery cadence with frontier AI capabilities.\nDevelop empathy for the nuances of our technical and business teams\u2019 work across disciplines and verticals, toward collaborating with them to harness AI in new ways.\nMake our codebases, systems, and knowledge stores legible to AI.\nHelp the company triangulate toward the optimal point on the quality-velocity Pareto frontier, while shifting that frontier outward with AI tools and agents.\nKeep abreast of new AI tools/models and make maximally effective use of them in your own work, setting an example across the company and inspiring others to do the same.\nHelp the company make high-conviction bets on specific technologies in situations where indecision is a comfortable and tempting default.\nWork with engineering leadership, recruiting, and others to ensure we instill an AI-forward culture and select for those who will thrive in such an environment.\nNote: this is an extremely technical and hands-on role. Strong vision and thought leadership is necessary but not sufficient for success. You will be expected to build both prototypes and production systems, as well as to reengineer our codebases, infrastructure, processes, and anything else that must evolve to realize this vision.\nQualifications\n6+ years of industry experience, ideally with a substantial portion focused on infrastructure/platform engineering or developer acceleration at companies with millions of users and hundreds or thousands of engineers.\nDaily use of AI models/tools, along with strong intuition on their jagged frontiers.\nProficiency with Python and working fluency with Typescript.\nStrong understanding of (and empathy for) the work of technical staff across disciplines, along with an enthusiasm to learn about the work of business and operations teams.\nBroad working knowledge of the typical stacks used by AI product & applied research companies. (For example: you don\u2019t need to have experience hand-rolling CUDA kernels, but you should know what CUDA is and when/where/why it\u2019s used.)\nAn obsession with improving the legibility of (and reducing brittleness in) both software and human-orchestrated processes.\nExperience navigating tricky exploration-exploitation tradeoffs, balancing the need to ship today with the need to build capacity for tomorrow.\nThe cash compensation range for this role is $250,000 - $325,000.\nFinal offer amounts are determined by multiple factors, including experience and expertise, and may vary from the amounts listed above.\nEquity: In addition to the base salary, equity \nmay be part\n of the total compensation package.\nBenefits: Comprehensive health, dental, and vision insurance for you and your dependents. Includes a 401(k) plan.", "comp": "$250,000.00", "title": "Tech Lead - Acceleration", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4257395685", "loc": "New York City Metropolitan Area", "company": "Perplexity"}, {"desc": "Perplexity is an AI-powered answer engine founded in December 2022 and growing rapidly as one of the world\u2019s leading AI platforms. Perplexity has raised over $1B in venture investment from some of the world\u2019s most visionary and successful leaders, including Elad Gil, Daniel Gross, Jeff Bezos, Accel, IVP, NEA, NVIDIA, Samsung, and many more. Our objective is to build accurate, trustworthy AI that powers decision-making for people and assistive AI wherever decisions are being made. Throughout human history, change and innovation have always been driven by curious people. Today, curious people use Perplexity to answer more than 780 million queries every month\u2013a number that\u2019s growing rapidly for one simple reason: everyone can be curious. \nIntroduction\nAt Perplexity AI, the \nSonar API\n powers AI-native search, retrieval, and automation for some of the world\u2019s most innovative companies. Our Support team is the frontline for developer and enterprise success\u2014ensuring that customers can build fast, reliable, and differentiated products on top of Sonar\u2019s capabilities.\nWe don\u2019t just answer tickets\u2014we partner deeply with customers, Product, and Engineering to architect solutions, debug complex integrations, and influence the roadmap based on real-world developer needs.\nAbout The Role\nWe\u2019re looking for a \nCustomer Success Engineer\n to be a hands-on technical partner for our Sonar API customers. This is a deeply technical, customer-facing role\u2014equal parts solution architect, developer advocate, and technical program manager.\nYou\u2019ll work end-to-end with developers, product teams, and executives at our customers\u2019 organizations\u2014from designing their Sonar-powered architecture to optimizing query performance and implementing new features. You\u2019ll also contribute to internal tooling, docs, and demos that make Sonar adoption easier and more impactful.\nThis role is ideal for \nTPMs\n, \nsolutions engineers\n, or \nsoftware engineers\n who have moved into customer-facing work but still want to build, prototype, and problem-solve daily.\nKey Responsibilities\nServe as the dedicated technical partner for strategic Sonar API customers, guiding them through architecture design, integration, and optimization. \nTroubleshoot API performance, grounding quality, and integration challenges\u2014diving directly into code and logs when needed. \nPrototype example integrations, search workflows, and demos to accelerate adoption and inspire customer innovation. \nCollaborate with Engineering and Product to resolve high-priority escalations, ensuring minimal downtime and maximum reliability. \nCapture and synthesize customer feedback to improve Sonar\u2019s API features, SDKs, and developer experience. \nMaintain deep familiarity with Sonar\u2019s latest capabilities, competitive positioning, and best practices, and use this knowledge to advise customers. \nWhat We\u2019re Looking For\nMust-Haves\n5+ years in technical support engineering, software engineering, or solutions engineering, with direct application development experience. \nStrong API integration skills\u2014able to design and debug REST/JSON payloads, manage auth flows, and optimize latency. \nProven track record of diagnosing complex technical issues across distributed systems, APIs, and customer environments. \nExcellent communicator who can work with both developer teams and non-technical stakeholders. \nBachelor\u2019s degree in Computer Science or equivalent hands-on experience. \nNice-to-Haves\nExperience working with search, retrieval-augmented generation (RAG), or AI/ML APIs. \nBackground in developer tools or platform engineering, especially in high-scale or low-latency environments. \nStrong familiarity with Python or JavaScript for building integrations, SDKs, or prototypes. \nHistory of working at startups or small teams where you owned customer projects end-to-end. \nWhy Join Us\nThe Sonar API is quickly becoming a core infrastructure layer for AI-powered search and automation. As a Customer Success Engineer, you\u2019ll help shape how our customers\u2014from startups to Fortune 500s\u2014bring their most ambitious ideas to life.\nYou\u2019ll be joining a fast-moving, high-impact team where your technical skills, creativity, and ability to bridge product and customer needs will directly influence both Sonar\u2019s roadmap and its market success.\nFinal offer amounts are determined by multiple factors, including, experience and expertise, and may vary from the amounts listed above.\nEquity: In addition to the base salary, equity \nmay be part\n of the total compensation package.\nBenefits: Comprehensive health, dental, and vision insurance for you and your dependents. Includes a 401(k) plan.", "comp": "0", "title": "Forward-Deployed Engineer - API Platform", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4286563568", "loc": "New York, NY", "company": "Perplexity"}, {"desc": "Perplexity is an AI-powered answer engine founded in December 2022 and growing rapidly as one of the world\u2019s leading AI platforms. Perplexity has raised over $1B in venture investment from some of the world\u2019s most visionary and successful leaders, including Elad Gil, Daniel Gross, Jeff Bezos, Accel, IVP, NEA, NVIDIA, Samsung, and many more. Our objective is to build accurate, trustworthy AI that powers decision-making for people and assistive AI wherever decisions are being made. Throughout human history, change and innovation have always been driven by curious people. Today, curious people use Perplexity to answer more than 780 million queries every month\u2013a number that\u2019s growing rapidly for one simple reason: everyone can be curious. \nPerplexity is seeking an experienced Infrastructure Capacity Engineer to own our infrastructure scaling, capacity planning, and resource optimization across our AI/ML infrastructure. The ideal candidate will have deep experience in large-scale distributed systems, capacity modeling, and infrastructure efficiency optimization to support our rapidly growing AI products and user base.\nResponsibilities\nDesign and implement comprehensive capacity planning models and forecasting systems that predict infrastructure needs across compute, storage, and network resources for our AI/ML workloads\nBuild and maintain automated capacity management systems that dynamically scale our infrastructure based on real-time demand patterns and usage forecasts\nLead cross-functional capacity planning initiatives including hardware procurement, data center expansion, and cloud resource optimization\nDevelop sophisticated monitoring and alerting systems that provide early warning indicators for capacity constraints and performance degradation\nCreate and maintain detailed infrastructure capacity models that account for seasonal patterns, product launches, and scaling efficiency across different workload types\nOptimize resource utilization and cost efficiency through advanced placement algorithms, load balancing strategies, and infrastructure rightsizing\nDesign and implement disaster recovery and business continuity plans that ensure service availability during infrastructure failures or capacity emergencies\nCollaborate with Site Reliability Engineering and Platform teams to establish capacity-aware deployment strategies and infrastructure automation\nPlay a leading role in defining the capacity engineering discipline within Perplexity\u2019s engineering organization\nQualifications\nMinimum of 4+ years of experience in infrastructure capacity planning, systems engineering, or related technical roles at scale\nProven experience managing infrastructure capacity for high-growth technology companies, preferably with AI/ML workloads or real-time systems\nStrong background in distributed systems architecture, cloud infrastructure (AWS/GCP/Azure), and container orchestration (Kubernetes)\nExperience with capacity modeling tools, forecasting methodologies, and statistical analysis for infrastructure planning\nProficiency in programming languages such as Python, Go, or similar for automation and tooling development\nDeep understanding of infrastructure monitoring, observability, and performance optimization techniques\nExperience with infrastructure-as-code tools (Terraform, Ansible) and CI/CD pipelines for infrastructure management\nStrong analytical and problem-solving skills with the ability to make data-driven decisions under uncertainty\nExcellent cross-functional collaboration skills and experience working with engineering, product, and business stakeholders\nExperience with large-scale database systems, caching layers, and content delivery networks preferred\nBackground in AI/ML infrastructure, LLM inference, GPU cluster management, or high-performance computing is a plus\nOur cash compensation range for this role is $225,000 - $300,000.\nFinal offer amounts are determined by multiple factors, including, experience and expertise, and may vary from the amounts listed above.\nEquity: In addition to the base salary, equity \nmay be part\n of the total compensation package.\nBenefits: Comprehensive health, dental, and vision insurance for you and your dependents. Includes a 401(k) plan.", "comp": "$225,000.00", "title": "Infrastructure Capacity Engineer", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4277160372", "loc": "Palo Alto, CA", "company": "Perplexity"}, {"desc": "Perplexity is an AI-powered answer engine founded in December 2022 and growing rapidly as one of the world\u2019s leading AI platforms. Perplexity has raised over $1B in venture investment from some of the world\u2019s most visionary and successful leaders, including Elad Gil, Daniel Gross, Jeff Bezos, Accel, IVP, NEA, NVIDIA, Samsung, and many more. Our objective is to build accurate, trustworthy AI that powers decision-making for people and assistive AI wherever decisions are being made. Throughout human history, change and innovation have always been driven by curious people. Today, curious people use Perplexity to answer more than 780 million queries every month\u2013a number that\u2019s growing rapidly for one simple reason: everyone can be curious. \nPerplexity is seeking an exceptional AI Research Tech Lead to drive our research strategy and lead the development of our in-house Online LLMs, the Sonar models. In this leadership role, you will set the macro research direction across different modalities, mentor a team of researchers, and take advantage of our rich query/answer dataset to continue scaling our Sonar model performance and deliver the SOTA Online LLM experience to our users.\nResponsibilities\nResearch Leadership & Strategy\nDefine and execute the macro research direction across multiple modalities, including post-training LLMs for agent trajectories and future mid-training initiatives\nLead strategic research planning and roadmap development to advance Sonar model capabilities\nDrive innovation in supervised and reinforcement learning techniques for query answering\nCollaborate with leadership to align research priorities with product and business objectives\nTeam Development & Mentorship\nCoach and mentor a team of AI research scientists and engineers, fostering their technical and professional growth\nEstablish the long-term macro research direction across the team, including our direction across different modalities\nLead hiring and onboarding of new research talent\nCreate a collaborative environment that encourages knowledge sharing and innovation\nTechnical Excellence\nPost-train SOTA LLMs on query answering using cutting-edge supervised and reinforcement learning techniques\nOwn and optimize the full stack data, training, and evaluation pipelines required for LLM post-training\nDeliver Sonar models that provide SOTA query answering performance\nDrive research into agent trajectories and multi-modal capabilities\nLead the technical roadmap for eventual mid-training investments\nCross-Functional Collaboration\nWork closely with engineering teams to integrate Sonar models into our product\nPartner with product teams to understand user needs and translate them into research priorities\nCollaborate with data teams to leverage our unique query/answer dataset effectively\nCommunicate research progress and findings to stakeholders across the organization\nQualifications\nRequired\nMinimum of 5 years of experience working on relevant AI/ML projects with 3**+ years in a technical leadership role**\nProven track record of leading and mentoring technical and research teams\nA Computer Science graduate degree at a premier academic intitution\nDeep expertise with large-scale LLMs and Deep Learning systems\nStrong programming skills with versatility across multiple languages and frameworks\nDemonstrated ability to set technical vision and drive execution\nExperience with pre-training and post-training techniques (self-supervised learning along with SFT/DPO/GRPO/PPO)\nSelf-starter with exceptional ownership mentality and ability to work in ambiguous environments\nPassion for solving challenging problems and pushing the boundaries of AI research\nNice-to-have\nPhD in Machine Learning, Computer Science, or related areas\nExperience with agent-based AI systems and multi-modal model development\nBackground in mid-training or pre-training of large language models\nPublications in top-tier AI/ML conferences\nExperience in fast-paced startup environments\nTrack record of translating research into production systems\nCompensation & Benefits\nOur cash compensation range for this role is $370,000 - $460,000.\nFinal offer amounts are determined by multiple factors, including experience and expertise, and may vary from the amounts listed above.\nEquity: In addition to the base salary, equity \nmay be part\n of the total compensation package.\nBenefits: Comprehensive health, dental, and vision insurance for you and your dependents. Includes a 401(k) plan.", "comp": "$370,000.00", "title": "AI Research Lead", "url": "https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/4270537382", "loc": "Palo Alto, CA", "company": "Perplexity"}]